---
title: SSD-(46、47讲)
date: 2020-03-20
categories:
  - 计算机原理
tags:
  - 计算机原理
---
#### SSD的读写原理
```
下边性能对比图显示: SSD的耐用性很差、若需要频繁的写入/删除数据、则机械硬盘比SSD性价比要高很多.

之前我们知道、CPU Cahe 是SRAM 用一个电容来存放一个比特的数据、对于SSD、也可先简单认为, 
是一个电容+一个电压计、记录一个或多个比特

`SLC`、`MLC`、`TLC`、`QLC`
给电容充电时、电压就是1; 放电后,里边没电、就是0. 采用这种方式存储的SSD硬盘、称`使用了SLC的颗粒`,
全称`Single-Level Cell`, 即: 一个存储单元只有一位数据.
但: 这样就会遇到与CPU Cache相同的问题: 相同面积下、由于存放的元器件有限、存储容量上不去.
于是, 有了`MLC`(Multi-Level Cell)、`TLC`(Triple-Level Cell)及`QLC`(Quad-Level Cell), 
即: 一个电容可存2、3乃至4个bit
同时, 由于对精度的要求更高、QLC的读写速度比SLC要慢好几倍

P/E擦写问题
SSD同其它IO设备、有对应接口和控制电路、控制电路中一个很重要的模块叫`TFL`(Flush Transaction Layer)
闪存转换层. SSD磁盘性能的好坏、很大程度上取决于FTL算法的好坏.

实际的IO设备和机械硬盘很像、有很多裸片叠在一起;
一张裸片上可放多个平面(Plane), 一个平面的存储容量大概在GB级别; 
一个平面上会划分成很多块(Block), 一般一个块的存储大小在几百KB到几MB;
一个块、还会分为很多页(Page), 大小通常是4KB.

SSD读取和写入的基本单位是`页`， 擦除单位是`块`.
SSD的使用寿命、其实就是每一个块的擦除次数.
`SLC`的擦除次数大概在10w次、`MLC`就1w次左右、`TLC`和`QLC`只有几千次.

SSD特别适合读多、写少的应用、在日常应用里、系统盘适合使用SSD.
但若使用SSD做下载盘、一直下载各种影音数据、就不好了、特别是现在QLC的SSD, 只有几千次的擦写寿命.
```
![SSD和HDD性能对比.png](https://upload-images.jianshu.io/upload_images/14027542-277084bb88844b36.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![SSD物理结构.png](https://upload-images.jianshu.io/upload_images/14027542-dbd383714531b895.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


#### 如何最大化利用SSD
```
`磨损均衡`: 实现的核心办法、类似虚拟内存、添加一个间接层`FTL`， 像通过一个页表映射虚拟内存和物理页
一样、在FLT里存放了逻辑块地址(Logic Block Address, LBA)到物理块地址(Physical Block Address, 
PBA)的映射.

操作系统所有对SSD的读写请求、都要经过FLT、FTL里又有逻辑块对应的物理块、这样FTL可以记录每个物理块
被擦写的次数. 若一个物理块被擦写较多、FTL就将它挪到一个擦写少的物理块上,逻辑块不动、操作系统无感.

`TRIM`指令支持
操作系统不关心底层硬件是什么、在SSD的使用上也会带来一个问题:
操作系统的逻辑层和SSD的逻辑层里的块状态是不匹配的.

在操作系统里删除一个文件、其实并没有真正在物理层操作删除、只在文件系统里把对应的inode元信息清理掉, 
这个inode还可以继续使用, 写入新的数据, 在物理层面对应的存储空间、在操作系统里被标示可写入.
所以: 日常文件删除、只是操作系统层面的逻辑删除、不小心误删文件时、还可以通过恢复软件、恢复出来,
想彻底删除数据、需要使用文件粉碎功能.

这个删除的逻辑在机械硬盘上可行、后续的写入可直接覆写该位置. 但在SSD上不行. 

eg. 在操作系统里删除一个刚下载的文件 a.txt, 在操作系统里、对应的inode里、就没有文件的元信息,
但 SSD的逻辑块层面、并不知道这个事情, a.txt 依然占用了空间、对应的物理页、也是被占用的.
此时: 若要对SSD进行垃圾回收、a.txt 对应的物理页、让要被搬运到其它Block中去、只有当操作系统再
在刚才的inode写入数据时、才会知道原来的数据已无用, 才会标记删除这种现象导致, 为了磨损均衡、
可能搬运了很多已删除的数据、导致很多不必要的数据读写和擦除, 损耗SSD性能.

为了解决这个问题、现在的操作系统和SSD的主控芯片都支持`TRIM`命令、可在文件删除时、让操作系统通知
SSD, 标记对应逻辑块为已删除.

`写入放大`:
TRIM 命令的发明，也反应了一个使用 SSD 硬盘的问题，那就是，SSD 硬盘容易越用越慢.
SSD存储空间被越占越多时、每次数据写入可能都没有足够空间, 不得不进行垃圾回收、合并块里的页、
然后擦除一些页. 此时, 从操作系统层看、可能只是写入4k或者4M的数据、通过FTL后、可能要搬运8MB、16MB甚至更多的数据

`实际的闪存写入的数据量 / 系统通过 FTL 写入的数据量 = 写入放大`
写入放大越多、SSD的性能也就越差.
解决写入放大、需要在后台定时进行垃圾回收.在磁盘较闲时、把搬运数据、擦除数据、留出空白的工作做完.
实际数据写入时、就不会有这么多的性能损耗了.

```
![image.png](https://upload-images.jianshu.io/upload_images/14027542-25a82b2bc13b5e1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#### AeroSpike: 如何最大化SSD的使用效率
```
1.AeroSpike 操作SSD硬盘、未通过操作系统的文件系统、而是直接操作SSD里的块和页.
2.AeroSpike 在读写数据时有2个优化.
  1) 写数据时、尽可能写一个较大的块, 而不是频繁的写很多小的数据块, 这样磁盘就不太容易出现磁盘碎片.
     也更好的理由磁盘的顺序写入优势.
  2) 读取时、可以读取小数据, 因为SSD的随机读取性能很好、也不像写入数据一样有擦除寿命问题. 
     且一次性读较大数据、需要在网络间传输时、可能导致带宽不够.

另: 由于AeroSpike是一个对响应时间要求很高的实时KV数据库、若出现严重的写放大效应、会导致数据写入
响应时长大幅度变长. 所以做了下边的优化:
1. 持续进行磁盘碎片整理. 使用高水位算法, 其实就是: 一旦一个物理块的数据碎片超过50%, 就将其搬运
压缩、然后进行数据擦除、确保始终有足够空间写入.
2.为保障数据库性能,建议只用SSD硬盘容量一半, 即: 人为预留SSD50%空间、确保SSD的写放大效应尽可能小.
```
