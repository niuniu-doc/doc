<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>FastDFS安装部署</title>
    <url>/2020/03/20/java_FastDFS%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>在学习<code>taotao商城</code>这个视频的过程中、用到了<code>fastdfs</code>、刚好自己有一台服务器就自己学习了下、参考了网上多篇文章、感谢各位分享~~</p>
<p><code>FastDFS</code>是<code>c</code>写的开源分布式文件系统、充分考虑了冗余被人、负载均衡、及线性扩容机制、注重高可用、高性能指标、可以很方便的搭建一套高性能的文件服务器集群提供文件上传、下载等服务~</p>
<p>###一、FastDFS架构<br><code>FastDFS</code>包括<code>Tracker server</code>和<code>Storage server</code>, 客户端请求<code>Tracker server</code>进行文件上传、下载，通过<code>Tracker server</code>调度最终由<code>Storage server</code>完成文件上传和下载。 <code>Tracker server</code> 的角色类似于<code>dubbo</code>的<code>registry</code>和<code>moniter</code>、并不直接提供服务、而是<code>storage server</code>启动时注册到<code>tracker server</code>, <code>client</code>通过<code>tracker server</code>连接<code>storage server</code>, <code>client</code>不知道自己连接的是哪一台<code>storage server</code>, 连接完成后、上传和下载是<code>client</code>直接请求<code>storage server</code>, 可类比于 <code>dubbo consumer</code>通过<code>registry</code>连接<code>dubbo service</code> 但、连接完成之后是<code>consumer</code>和<code>service</code>直接通信</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-81571b0c67e068ef.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="fastdfs.jpg"></p>
<p>#####文件上传流程<br><img src="https://upload-images.jianshu.io/upload_images/14027542-2c255cded5753807.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="文件上传流程.png"></p>
<h5 id="文件下载流程"><a href="#文件下载流程" class="headerlink" title="文件下载流程"></a>文件下载流程</h5><p><img src="https://upload-images.jianshu.io/upload_images/14027542-9b9dcd61bd1a9a57.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="文件下载流程.png"></p>
<p>####1.Tracker Server<br><code>Tracker server</code>作用是负载均衡和调度，通过<code>Tracker server</code>在文件上传时可以根据一些策略找到<code>Storage server</code>提供文件上传服务，可以将tracker称为追踪服务器或调度服务器</p>
<p>####1.Storage Server<br><code>Storage server</code>作用是文件存储，客户端上传的文件最终存储在<code>Storage</code>服务器上，<code>Storage server</code>没有实现自己的文件系统而是利用操作系统的文件系统来管理文件。可以将<code>storage</code>称为存储服务器。</p>
<h3 id="二、FastDFS安装"><a href="#二、FastDFS安装" class="headerlink" title="二、FastDFS安装"></a>二、FastDFS安装</h3><p>####1.安装libfastcommon</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 下载：</span><br><span class="line">wget https:<span class="regexp">//gi</span>thub.com<span class="regexp">/happyfish100/</span>libfastcommon<span class="regexp">/archive/</span>V1.<span class="number">0.7</span>.tar.gz</span><br><span class="line"><span class="number">2</span>. 修改名字：mv V1.<span class="number">0.7</span> libfastcommon-<span class="number">1.0</span>.<span class="number">7</span>.tar.gz</span><br><span class="line"><span class="number">3</span>. 解压：tar zxvf libfastcommon-<span class="number">1.0</span>.<span class="number">7</span>.tar.gz</span><br><span class="line"><span class="number">4</span>. cd libfastcommon-<span class="number">1.0</span>.<span class="number">7</span>/</span><br><span class="line"><span class="number">5</span>. 编译：./make.sh</span><br><span class="line"><span class="number">6</span>. 安装：./make.sh install</span><br><span class="line"></span><br><span class="line">另外：</span><br><span class="line">设置几个软链接、方便后续扩展nginx时使用：</span><br><span class="line">ln -s <span class="regexp">/usr/</span>lib64<span class="regexp">/libfastcommon.so /u</span>sr<span class="regexp">/local/</span>lib/libfastcommon.so</span><br><span class="line">ln -s <span class="regexp">/usr/</span>lib64<span class="regexp">/libfastcommon.so /u</span>sr<span class="regexp">/lib/</span>libfastcommon.so</span><br><span class="line">ln -s <span class="regexp">/usr/</span>lib64<span class="regexp">/libfdfsclient.so /u</span>sr<span class="regexp">/local/</span>lib/libfdfsclient.so</span><br><span class="line">ln -s <span class="regexp">/usr/</span>lib64<span class="regexp">/libfdfsclient.so /u</span>sr<span class="regexp">/lib/</span>libfdfsclient.so</span><br></pre></td></tr></table></figure>

<h4 id="2-安装-tracker"><a href="#2-安装-tracker" class="headerlink" title="2. 安装 tracker"></a>2. 安装 tracker</h4><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 下载：</span><br><span class="line">wget https:<span class="comment">//github.com/happyfish100/fastdfs/archive/V5.05.tar.gz</span></span><br><span class="line"><span class="number">2</span>. 修改名字：mv V5.<span class="number">05</span> FastDFS_v5.<span class="number">05</span><span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line"><span class="number">3</span>. 解压：tar zxvf FastDFS_v5.<span class="number">05</span><span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line"><span class="number">4</span>. 进入解压后目录：cd fastdfs-<span class="number">5.05</span>/</span><br><span class="line"><span class="number">5</span>. 编译：./make<span class="selector-class">.sh</span></span><br><span class="line"><span class="number">6</span>. 安装：./make<span class="selector-class">.sh</span> install</span><br></pre></td></tr></table></figure>
<h4 id="3-修改tracker配置文件"><a href="#3-修改tracker配置文件" class="headerlink" title="3. 修改tracker配置文件"></a>3. 修改tracker配置文件</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="number">2</span>安装完成后、在<span class="regexp">/etd/</span>fdfs下有tracker的配置文件</span><br><span class="line">复制一份：cp <span class="regexp">/etc/</span>fdfs<span class="regexp">/tracker.conf.sample /</span>etc<span class="regexp">/fdfs/</span>tracker.conf</span><br><span class="line">mkdir -p <span class="regexp">/usr/</span>local<span class="regexp">/fastdfs/</span>  (此处可以根据自己的情况和习惯存放)</span><br><span class="line">base_path= <span class="regexp">/usr/</span>local<span class="regexp">/fastdfs/</span></span><br><span class="line"></span><br><span class="line">启动 tracker 服务：<span class="regexp">/usr/</span>bin<span class="regexp">/fdfs_trackerd /</span>etc<span class="regexp">/fdfs/</span>tracker.conf</span><br><span class="line">重启 tracker 服务：<span class="regexp">/usr/</span>bin<span class="regexp">/fdfs_trackerd /</span>etc<span class="regexp">/fdfs/</span>tracker.conf restart</span><br><span class="line">查看是否有 tracker 进程：ps aux | <span class="keyword">grep</span> tracker</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>####4. storage(存储节点)服务部署</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">一般 storage 服务我们会单独部署到一台服务器上，但是这里为了方便(~~我只有一台服务器~~)就安装在同一台上了</span><br><span class="line"></span><br><span class="line">如果单独部署到一台服务器上、上边tracker的部署步骤重新来一遍即可</span><br><span class="line">这里是同一台server、只修改配置~~</span><br><span class="line"></span><br><span class="line">复制一份配置：cp <span class="regexp">/etc/</span>fdfs<span class="regexp">/storage.conf.sample /</span>etc<span class="regexp">/fdfs/</span>storage.conf</span><br><span class="line">编辑：vim <span class="regexp">/etc/</span>fdfs/storage.conf</span><br><span class="line">base_path= <span class="regexp">/usr/</span>local<span class="regexp">/fastdfs/</span></span><br><span class="line"></span><br><span class="line">创建目录：mkdir  <span class="regexp">/usr/</span>local<span class="regexp">/fastdfs/</span>storage/images-data</span><br><span class="line">store_path0= <span class="regexp">/usr/</span>local<span class="regexp">/fastdfs/</span>storage/images-data</span><br><span class="line"></span><br><span class="line">图片实际存放路径，如果有多个，这里可以有多行(要创建多个目录)：</span><br><span class="line">store_path0=<span class="regexp">/opt/</span>fastdfs<span class="regexp">/storage/im</span>ages-data0</span><br><span class="line">store_path1=<span class="regexp">/opt/</span>fastdfs<span class="regexp">/storage/im</span>ages-data1</span><br><span class="line"></span><br><span class="line">subdir_count_per_path=<span class="number">256</span> </span><br><span class="line">是用来配置目录个数的、如果只是练习不做实际存储服务、可改小一点儿</span><br><span class="line"></span><br><span class="line">指定 tracker 服务器的 IP 和端口</span><br><span class="line">tracker_server=<span class="number">192.168</span>.<span class="number">1.114</span>:<span class="number">22122</span> (<span class="number">192.168</span>.<span class="number">1.114</span>)是你的server服务器ip、本机也可以使用(<span class="number">0.0</span>.<span class="number">0.0</span>:<span class="number">22122</span>)、记得不可使用<span class="number">127.0</span>.<span class="number">0.1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5-测试服务"><a href="#5-测试服务" class="headerlink" title="5. 测试服务"></a>5. 测试服务</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">启动 storage 服务：<span class="regexp">/usr/</span>bin<span class="regexp">/fdfs_storaged /</span>etc<span class="regexp">/fdfs/</span>storage.conf，首次启动会很慢，因为它在创建预设存储文件的目录</span><br><span class="line">重启 storage 服务：<span class="regexp">/usr/</span>bin<span class="regexp">/fdfs_storaged /</span>etc<span class="regexp">/fdfs/</span>storage.conf restart</span><br><span class="line">查看是否有 storage 进程：ps aux | <span class="keyword">grep</span> storage</span><br></pre></td></tr></table></figure>

<p>####6. 查看<code>tracker</code>是否可以正常与<code>storage</code>通信</p>
<figure class="highlight node-repl"><table><tr><td class="code"><pre><span class="line">fdfs_monitor /etc/fdfs/storage.conf</span><br><span class="line"><span class="meta prompt_">...</span></span><br><span class="line">Storage 1:</span><br><span class="line">        id = 192.168.2.231</span><br><span class="line">        ip_addr = 192.168.2.231  ACTIVE --若看到ACTIVE这个字样、代表可以正常通信</span><br><span class="line"><span class="meta prompt_">...</span></span><br><span class="line">查看storage和tracker是否正常启动：</span><br><span class="line">ps aux | grep fdfs</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-c47e3762cf5b81c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="进程.png"></p>
<h4 id="7-使用fdfs-client测试"><a href="#7-使用fdfs-client测试" class="headerlink" title="7. 使用fdfs_client测试"></a>7. 使用fdfs_client测试</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">复制一份配置：cp <span class="regexp">/etc/</span>fdfs<span class="regexp">/client.conf.sample /</span>etc<span class="regexp">/fdfs/</span>client.conf</span><br><span class="line">编辑：vim <span class="regexp">/etc/</span>fdfs/client.conf</span><br><span class="line"></span><br><span class="line">base_path= <span class="regexp">/usr/</span>local<span class="regexp">/fastdfs/</span></span><br><span class="line"></span><br><span class="line">指定 tracker 服务器的 IP 和端口</span><br><span class="line">tracker_server=<span class="number">192.168</span>.<span class="number">1.114</span>:<span class="number">22122</span></span><br><span class="line">log_level=info</span><br><span class="line"></span><br><span class="line">echo asasasa &gt; ~/test.txt</span><br><span class="line"></span><br><span class="line">测试：fdfs_test <span class="regexp">/etc/</span>fdfs<span class="regexp">/client.conf upload ~/</span>test.txt </span><br><span class="line">可以看到如下图所示、就是上传成功了</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-3ebfd5dda0a5732d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="test.png"></p>
<p>####8. 安装Nginx和其插件</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">如果Nginx已经安装过，则仅需要fastdfs-nginx-module_v1.<span class="number">16</span>.tar.gz</span><br><span class="line">下载nginx：wget http:<span class="regexp">//</span>nginx.org<span class="regexp">/download/</span>nginx-<span class="number">1.11</span>.<span class="number">8</span>.tar.gz</span><br><span class="line">下载Nginx插件:wget http:<span class="regexp">//</span>jaist.dl.sourceforge.NET<span class="regexp">/project/</span>fastdfs<span class="regexp">/FastDFS%20Nginx%20Module%20Source%20Code/</span>fastdfs-nginx-module_v1.<span class="number">16</span>.tar.gz</span><br><span class="line">解压 Nginx 模块：tar zxvf fastdfs-nginx-module_v1.<span class="number">16</span>.tar.gz</span><br><span class="line">进入解压后的目录 </span><br><span class="line">cd fastdfs-nginx-module</span><br><span class="line">vim src/config</span><br><span class="line">修改：去掉local、因为实际安装fastdfs时、是放到了<span class="regexp">/usr/i</span>nclude下</span><br><span class="line"><span class="number">1</span>. CORE_INCS=<span class="string">&quot;$CORE_INCS /usr/local/include/fastdfs /usr/local/include/fastcommon/&quot;</span></span><br><span class="line">-&gt; CORE_INCS=<span class="string">&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>.  CORE_LIBS=<span class="string">&quot;$CORE_LIBS -L/usr/local/lib -lfastcommon -lfdfsclient&quot;</span></span><br><span class="line">-&gt; CORE_LIBS=<span class="string">&quot;$CORE_LIBS -L/usr/lib -lfastcommon -lfdfsclient&quot;</span></span><br><span class="line"></span><br><span class="line">回到nginx的解压目录</span><br><span class="line">cd ../nginx-<span class="number">1.11</span>.<span class="number">8</span></span><br><span class="line">sudo .<span class="regexp">/configure  --prefix=/u</span>sr<span class="regexp">/local/</span>nginx --sbin-path=<span class="regexp">/usr/</span>local<span class="regexp">/bin/</span>nginx --conf-path=<span class="regexp">/usr/</span>local<span class="regexp">/etc/</span>nginx<span class="regexp">/nginx.conf --pid-path=/u</span>sr<span class="regexp">/local/</span>var<span class="regexp">/run/</span>nginx.pid --lock-path=<span class="regexp">/usr/</span>local<span class="regexp">/var/</span>run<span class="regexp">/nginx.lock --error-log-path=/u</span>sr<span class="regexp">/local/</span>var<span class="regexp">/log/</span>nginx<span class="regexp">/^Cror.log --http-log-path=/u</span>sr<span class="regexp">/local/</span>var<span class="regexp">/log/</span>nginx<span class="regexp">/access.log --with-http_gzip_static_module --with-http_stub_status_module --with-http_ssl_module --with-file-aio --add-module=/</span>home<span class="regexp">/nj/</span>build<span class="regexp">/fastdfs-nginx-module/</span>src</span><br><span class="line"></span><br><span class="line">sudo make  &amp;&amp; sudo  make install （若是有权限的账户、可以不用加sudo、我使用的是普通用户）</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>####9. 整个fastdfs-nginx-module和nginx</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">copy</span> fastdfs-nginx-module的配置文件到 <span class="regexp">/etc/</span>fdfs下、方便查找</span><br><span class="line">cp <span class="regexp">/home/</span>nj<span class="regexp">/build/</span>fastdfs-nginx-module<span class="regexp">/src/m</span>od_fdfs.conf <span class="regexp">/etc/</span>fdfs</span><br><span class="line">vi <span class="regexp">/etc/</span>fdfs/mod_fdfs.conf</span><br><span class="line"></span><br><span class="line">base_path=<span class="regexp">/usr/</span>local/fastdfs</span><br><span class="line">tracker_server=<span class="number">192.168</span>.<span class="number">1.114</span>:<span class="number">22122</span></span><br><span class="line">url_have_group_name = <span class="keyword">true</span></span><br><span class="line">store_path0=<span class="regexp">/usr/</span>local<span class="regexp">/fastdfs/</span>storage</span><br></pre></td></tr></table></figure>

<p>####10. 然后配置Nginx，添加如下内容</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen       <span class="number">80</span>;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line">        </span><br><span class="line">         <span class="comment"># 配置fastdfs的访问路径</span></span><br><span class="line">        <span class="keyword">location</span> <span class="title">/group1</span>/M00 &#123;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">启动nginx</span><br></pre></td></tr></table></figure>

<h4 id="用浏览器访问刚才步骤7中测试上传的文件："><a href="#用浏览器访问刚才步骤7中测试上传的文件：" class="headerlink" title="用浏览器访问刚才步骤7中测试上传的文件："></a>用浏览器访问刚才步骤7中测试上传的文件：</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">http:<span class="regexp">//</span>xxxx<span class="regexp">/group1/</span>M00<span class="regexp">/00/</span><span class="number">00</span>/fwAAAVu0UTSAZiNHAAAACE6c2W4921_big.txt</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-2fc2f16221227b59.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片存储测试.png"></p>
<h3 id="哦啦-到此安装完成、可以使用了"><a href="#哦啦-到此安装完成、可以使用了" class="headerlink" title="^.^哦啦~ 到此安装完成、可以使用了~~~"></a><code>^.^</code>哦啦~ 到此安装完成、可以使用了~~~</h3><p>####另外：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">fastdfs提供了php_client、可以使用php调用fastdfs的服务</span><br><span class="line">参考：</span><br><span class="line">https:<span class="regexp">//gi</span>thub.com<span class="regexp">/happyfish100/</span>fastdfs<span class="regexp">/tree/m</span>aster<span class="regexp">/php_client/</span>FastDFS%<span class="number">20</span>Nginx%<span class="number">20</span>Module%<span class="number">20</span>Source%<span class="number">20</span>Code/fastdfs-nginx-module_v1.<span class="number">16</span>.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h4><blockquote>
<ol>
<li><a href="https://github.com/happyfish100/fastdfs/tree/master/php_client">https://github.com/happyfish100/fastdfs/tree/master/php_client</a></li>
<li><a href="https://www.waitig.com/fastdfs%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4.html">https://www.waitig.com/fastdfs%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4.html</a></li>
<li><a href="https://www.codetd.com/article/3138763">https://www.codetd.com/article/3138763</a></li>
<li><a href="http://soartju.iteye.com/blog/803477">http://soartju.iteye.com/blog/803477</a><br>等多个网络资源…</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Hystrix-MDC跟踪</title>
    <url>/2020/03/20/java_Hystrix-MDC%E8%B7%9F%E8%B8%AA/</url>
    <content><![CDATA[<p>一、实现HystrixConcurrencyStrategy</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MdcHystrixConcurrencyStrategy</span> <span class="keyword">extends</span> <span class="title class_">HystrixConcurrencyStrategy</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; Callable&lt;T&gt; <span class="title function_">wrapCallable</span><span class="params">(Callable&lt;T&gt; callable)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MdcAwareCallable</span>(callable, MDC.getCopyOfContextMap());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">class</span> <span class="title class_">MdcAwareCallable</span>&lt;T&gt; <span class="keyword">implements</span> <span class="title class_">Callable</span>&lt;T&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> Callable&lt;T&gt; delegate;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, String&gt; contextMap;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">MdcAwareCallable</span><span class="params">(Callable&lt;T&gt; callable, Map&lt;String, String&gt; contextMap)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.delegate = callable;</span><br><span class="line">            <span class="built_in">this</span>.contextMap = contextMap != <span class="literal">null</span> ? contextMap : <span class="keyword">new</span> <span class="title class_">HashMap</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> T <span class="title function_">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                MDC.setContextMap(contextMap);</span><br><span class="line">                <span class="keyword">return</span> delegate.call();</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                MDC.clear();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>二、注册一个插件</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HystrixConfig</span> &#123;</span><br><span class="line">    <span class="comment">//用来拦截处理HystrixCommand注解</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> HystrixCommandAspect <span class="title function_">hystrixAspect</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">HystrixCommandAspect</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">        HystrixPlugins.getInstance().registerConcurrencyStrategy(<span class="keyword">new</span> <span class="title class_">MdcHystrixConcurrencyStrategy</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>三、mq producer 和 consumer之间的trace跟踪</p>
<blockquote>
<p>正常情况下、用msgId就可以了、有些数据分析需要trace来全局跟踪</p>
</blockquote>
<ol>
<li><p>在生产者的消息属性中加入traceId</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SendResult</span> <span class="variable">result</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"> <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic, tag, key, val.getBytes());</span><br><span class="line"> msg.putUserProperty(<span class="string">&quot;traceId&quot;</span>, MDC.get(TraceConst.TRACE_KEY));</span><br></pre></td></tr></table></figure>
</li>
<li><p>在消费者中取出traceId、放入MDC</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">MessageExt</span> <span class="variable">msgExt</span> <span class="operator">=</span> msgs.get(i);</span><br><span class="line">                        <span class="type">String</span> <span class="variable">msgId</span> <span class="operator">=</span> msgExt.getMsgId();</span><br><span class="line">                        <span class="type">String</span> <span class="variable">msgBody</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(msgExt.getBody());</span><br><span class="line">                        MDC.put(TraceConst.TRACE_KEY, msgExt.getUserProperty(<span class="string">&quot;traceId&quot;</span>));</span><br><span class="line">                        logger.info(<span class="string">&quot;msgs-size=&#123;&#125;, msgId=&#123;&#125;, msgBody=&#123;&#125;&quot;</span>, msgs.size(), msgId, msgBody);</span><br></pre></td></tr></table></figure>
</li>
<li><p>部分源码<br><img src="https://upload-images.jianshu.io/upload_images/14027542-44bfdc7e5e6f2949.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-87639bf3513c1838.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>文章参考<br><a href="https://my.oschina.net/u/3748347/blog/1823392">https://my.oschina.net/u/3748347/blog/1823392</a><br><a href="https://wanghaolistening.github.io/2019/01/26/Hystrix-%E5%9C%A8%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/">https://wanghaolistening.github.io/2019/01/26/Hystrix-%E5%9C%A8%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java元注解</title>
    <url>/2020/03/20/java_Java%E5%85%83%E6%B3%A8%E8%A7%A3/</url>
    <content><![CDATA[<p>Java中元注解有4个：<code>@Retention</code>, <code>@Target</code>, <code>@Document</code>, <code>@Inherited</code></p>
<p><code>@Retention</code>注解的保留位置：<br><code>@Retention(RetentionPolicy.SOURCE)</code> 注解仅存在于源码中、在class字节码文件中不存在<br><code>@Retention(RetentionPolicy.CLASS)</code> 默认保留策略、注解会在class文件中存在、但、运行时无法获得<br><code>@Retention(RetentionPolicy.RUNTIME)</code> 注解会在class文件中存在、并且可以通过反射得到</p>
<p><code>@Target</code> 注解的作用目标<br><code>@Target(ElementType.TYPE)</code> 接口、类、枚举、注解<br><code>@Target(ElementType.FIELD)</code> 字段、枚举的常量<br><code>@Target(ElementType.METHOD)</code> 方法<br><code>@Target(ElementType.PARAMETER)</code> 方法参数<br><code>@Target(ElementType.CONSTRUCTOR)</code> 构造函数<br><code>@Target(ElementType.LOCAL_VARIABLE)</code> 局部变量<br><code>@Target(ElementType.ANNTATION_TYPE)</code> 注解<br><code>@Target(ElementType.PACKAGE)</code> 包</p>
<p><code>@Document</code> 说明该注解将会被包含在javadoc中</p>
<p><code>@Inherited</code> 说明子类可以继承父类中的该注解</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程实现基础(一)</title>
    <url>/2020/03/20/java_Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0%E5%9F%BA%E7%A1%80(%E4%B8%80)/</url>
    <content><![CDATA[<h4 id="CPU-的术语介绍"><a href="#CPU-的术语介绍" class="headerlink" title="CPU 的术语介绍"></a>CPU 的术语介绍</h4><p><code>内存屏障</code>: <code>memory barriers</code> 一组处理器指令、用于实现对内存操作的顺序限制</p>
<p><code>缓冲行</code>: <code>cache line</code> cpu高速缓冲中可以分配的最小存储单位<br>         处理器填写缓冲行时、会加载整个缓存行、现代CPU需要执行几百次CPU指令</p>
<p><code>原子操作</code>: <code>atomic operations</code> 不可中断的一个或者一系列操作</p>
<p><code>缓冲行填充</code>: <code>cache line fill</code>当处理器识别到从内存中读取的操作数是可缓存的,<br>        处理器读取整个高速缓存行到适当的缓存(L1,L2,L3或者所有)</p>
<p><code>缓存命中</code>: <code>cache hit</code>如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的<br>地址时、处理器从缓存行读取而不是从内存读取</p>
<p><code>写命中</code>: <code>write hit</code> 当处理器将操作数写回到内存缓存时、会先检查这个缓存的内存地址<br>是否在缓存行中、如果存在一个有效的缓存行、处理器会将这个操作数歇会到缓存、而不是内存</p>
<p><code>写缺失</code>: <code>write misses the cache</code> 一个有效的缓存行被写入到不存在的内存区域</p>
<p><code>比较并交换</code>: <code>Compare and Swap</code> cas操作需要两个值, old and new、在操作期间会比较这<br>两个值、如果发生变化则不交换、未发生变化才交换</p>
<p><code>CPU流水线</code>: <code>CPU pipeline</code>在CPU中由5、6个不同的电路单元组成一条指令处理流水线<br>然后一条X86指令分成5~6步后再由这些电路单元分别执行、就能实现在一个CPU周期内完成<br>一条指令、提高CPU的运算速率</p>
<p><code>内存顺序冲突</code>: <code>memory order violation</code>一般是由假共享引起的、是指多个CPU同时修改<br>同一个缓存行的不同部分而引起其中一个CPU的操作无效、当出现这个内存顺序冲突时、CPU必须清空流水线</p>
<h4 id="Lock前缀的指令"><a href="#Lock前缀的指令" class="headerlink" title="Lock前缀的指令"></a>Lock前缀的指令</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">lock 前缀的指令、在多核处理器下会引发两件事:</span><br><span class="line"><span class="bullet">1.</span> 将当期处理器的缓存行数据写回内存</span><br><span class="line"><span class="bullet">2.</span> 这个写回内存操作会使在其它CPU里缓存了该地址的数据无效</span><br></pre></td></tr></table></figure>

<h4 id="volatile的实现"><a href="#volatile的实现" class="headerlink" title="volatile的实现"></a>volatile的实现</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">为了提高速度、CPU不直接和内存通信、而是先将系统内存的数据加载到内存缓存后再操作</span><br><span class="line">但: 操作完全不知道何时会被写回内存</span><br><span class="line"></span><br><span class="line"><span class="keyword">volatile</span>声明的变量进行读写、JVM会向处理器发送一条<span class="keyword">Lock</span>前缀的指令、精讲变量所在的</span><br><span class="line">缓存行数据写回到内存</span><br><span class="line"></span><br><span class="line">在多核处理器下、实现了缓存一致性协议、每个处理器通过嗅探在总线上传播的数据来检查</span><br><span class="line">自己的缓存是否已过期、当处理器发现自己缓存行对应的内存地址呗修改、会将当期处理器的</span><br><span class="line">缓存行状态设为无效、重新从系统内存读取</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java类的加载和继承实现</title>
    <url>/2020/03/20/java_Java%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E7%BB%A7%E6%89%BF%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h4 id="类方法-amp-实例方法"><a href="#类方法-amp-实例方法" class="headerlink" title="类方法 &amp; 实例方法"></a>类方法 &amp; 实例方法</h4><figure class="highlight actionscript"><table><tr><td class="code"><pre><span class="line">类方法:(静态方法) <span class="keyword">static</span>修饰、可以通过类名直接访问、</span><br><span class="line">实例方法: 无<span class="keyword">static</span>修饰、必须通过创建的实例才能访问</span><br><span class="line"></span><br><span class="line">类变量和实例变量同理</span><br><span class="line"></span><br><span class="line">实例方法可以直接访问实例变量 ?</span><br><span class="line">因为在实例方法中、有一个隐含的参数(当前操作的对象本身)</span><br><span class="line"><span class="number">1.</span> 类方法只能调用类方法、访问类变量, 不能访问实例方法和实例变量</span><br><span class="line"><span class="number">2.</span> 实例方法可以访问类方法、类变量、实例方法、实例变量</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>可以将类看成自定义数据类型</strong></p>
<h4 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h4><figure class="highlight ocaml"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 定义一个类本身、什么都不会做、不会分配内存、也不会执行代码</span><br><span class="line"><span class="number">2.</span> 声明变量本身只分配存放位置的内存空间、这块空间还未指向任何实际内容</span><br><span class="line"><span class="number">3.</span> p = <span class="keyword">new</span> <span class="type">Point</span><span class="literal">()</span>; </span><br><span class="line">   <span class="number">1</span>) 分配内存、以存储新对象的数据(这个对象的属性、包括实例变量x|y)</span><br><span class="line">   <span class="number">2</span>) 给实例变量设置默认值、<span class="built_in">int</span>-&gt;<span class="number">0</span> boolean-&gt;<span class="literal">false</span> <span class="built_in">char</span>-&gt;\u000 refer-&gt;null</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> 修改变量默认值</span><br><span class="line">   <span class="number">1</span>) 定义的同时、初始化 <span class="keyword">private</span> <span class="built_in">int</span> x = <span class="number">1</span>;</span><br><span class="line">   <span class="number">2</span>) 初始化代码块 <span class="keyword">private</span> <span class="built_in">int</span> y; &#123;y=<span class="number">2</span>&#125;  </span><br><span class="line">   <span class="number">3</span>) 构造方法 </span><br><span class="line">   调用顺序 <span class="number">1</span>) -&gt; <span class="number">2</span>) -&gt; <span class="number">3</span>)  所以、若多种方式定义了默认值、前边的会被后边的覆盖</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> final修饰类变量、实例变量、表示变量只能被赋值一次、final也可以修饰实例方法</span><br></pre></td></tr></table></figure>

<h4 id="类和对象的生命周期"><a href="#类和对象的生命周期" class="headerlink" title="类和对象的生命周期"></a>类和对象的生命周期</h4><figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 程序运行时、第一次通过<span class="keyword">new</span><span class="type"></span>创建一个类的对象的时候、or 直接通过类名访问类变量/类方法的时候、</span><br><span class="line">   Java会讲类加载进内场、为这个类分配一块空间、保护类的定义、有哪些变量和方法、</span><br><span class="line">   还有类的静态变量、并对静态变量赋初值</span><br><span class="line">   </span><br><span class="line">   类加载进内存后一般不会释放、直到程序结束、一般情况下、只加载一次(静态变量在内存中只存在一份)</span><br><span class="line">   </span><br><span class="line"><span class="number">2.</span> 对象 每次<span class="keyword">new</span><span class="type"></span>、都会产生一个新的实例、会有一份独立的实例变量</span><br><span class="line">   每个对象除了保存实例变量的值、还保存着对应类的地址、即: <span class="type"></span>通过对象可以知道类、就能访问到类的变量和方法</span><br><span class="line">   实例方法可以理解为多了<span class="built_in">this</span>参数的静态方法</span><br><span class="line">   </span><br><span class="line">   对象的释放是被Java的垃圾回收机制管理的</span><br><span class="line">   a. 保存地址的部分分配在桟上、函数调用入栈就分配、出栈就释放</span><br><span class="line">   b. 保存内容的部分分配在堆上、无活跃变量指向对象的时候(已加载的类的类变量和桟中所有的变量)、</span><br><span class="line">      就可能被释放</span><br></pre></td></tr></table></figure>

<h4 id="类继承"><a href="#类继承" class="headerlink" title="类继承"></a>类继承</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> java 使用extends表明继承关系、一个类只有一个父类</span><br><span class="line"><span class="bullet">2.</span> 子类不可访问父类的私有属性和方法、可以访问 protected 和 public 的</span><br><span class="line"></span><br><span class="line"><span class="bullet">3.</span> 向上转型: 子类对象赋值给父类引用变量(转换为父类类型)、</span><br><span class="line"></span><br><span class="line"><span class="bullet">4.</span> 多态: 变量shape可以引用任何Shape子类类型的对象、即一种类型的变量、可以引用多种实际类型对象</span><br><span class="line">   变量shape有两种类型、类型Shape: 称为shape的静态类型、circle/line/arrowLine 称为shape的动态类型</span><br><span class="line">   </span><br><span class="line"><span class="bullet">5.</span> 动态绑定: shapes[i].draw() 调用的是其对应动态类型的draw方法、称为方法的动态绑定</span><br><span class="line"></span><br><span class="line"><span class="bullet">6.</span> 若父类只有一个带参数的构造方法、则所有子类都必须通过super调用base的带参构造</span><br><span class="line"></span><br><span class="line"><span class="bullet">7.</span> 若父类构造方法调用了可被重写的方法、可能会出现意想不到的结果</span><br><span class="line"></span><br><span class="line"><span class="bullet">8.</span> 静态绑定: 在类的内部、访问的是当前类</span><br><span class="line">   在类的外部、要看如何访问、静态类型是父类、则访问的是父类</span><br><span class="line"></span><br><span class="line"><span class="bullet">9.</span> 静态变量和方法、一般通过类名直接访问、也可以通过实例对象来访问</span><br><span class="line"></span><br><span class="line"><span class="bullet">10.</span> 在有多个重名函数的时候、首先按照参数类型进行匹配、然后才看变量的动态类型、进行动态绑定</span><br><span class="line"></span><br><span class="line"><span class="bullet">11.</span> 模板方法: 在父类定义一个实现的模板、具体实现由子类提供</span><br><span class="line"></span><br><span class="line"><span class="bullet">12.</span> 子类可以升级父类的可见性、不可降低</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">在Java中、类的加载时将类的相关信息加载到内存、Java是动态加载的、第一次使用时才会加载</span><br><span class="line">加载一个类时、会查看其父类是否已加载、若没有、会加载其父类</span><br><span class="line"></span><br><span class="line">类初始化代码:</span><br><span class="line"><span class="bullet">1.</span> 定义静态变量时的赋值语句</span><br><span class="line"><span class="bullet">2.</span> 静态初始化代码块</span><br><span class="line"></span><br><span class="line">实例初始化代码:</span><br><span class="line"><span class="bullet">1.</span> 定义实例变量时的赋值语句</span><br><span class="line"><span class="bullet">2.</span> 实例初始化代码块</span><br><span class="line"><span class="bullet">3.</span> 构造方法</span><br><span class="line"></span><br><span class="line">类加载过程:</span><br><span class="line"><span class="bullet">1.</span> 分配内存保存类的信息</span><br><span class="line"><span class="bullet">2.</span> 给类变量赋默认值</span><br><span class="line"><span class="bullet">3.</span> 加载父类</span><br><span class="line"><span class="bullet">4.</span> 设置父子关系</span><br><span class="line"><span class="bullet">5.</span> 执行类初始化代码(先执行父类 -&gt; 子类、不过父类执行时、子类静态变量是有值的、默认值)</span><br><span class="line"></span><br><span class="line">内存分为堆(存放动态分配的对象)和桟(存放函数的局部变量)、还有一个内存区: 方法区(存放类的信息)</span><br><span class="line"></span><br><span class="line">创建对象:</span><br><span class="line"><span class="bullet">1.</span> 分配内存</span><br><span class="line">   包括本类和父类的所有实例变量、但不包括任何静态变量</span><br><span class="line">   实例化代码从父类开始、再执行子类</span><br><span class="line">   但: 在任何类执行初始化代码之前、所有的实例变量都已设置完默认值</span><br><span class="line">   </span><br><span class="line"><span class="bullet">2.</span> 对所有的实例变量赋默认值</span><br><span class="line"><span class="bullet">3.</span> 执行实例初始化代码</span><br><span class="line"></span><br><span class="line"><span class="strong">**Note**</span> </span><br><span class="line">每个对象除了保存类的实例变量之外、还保存着实际类信息的引用</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="虚方法表"><a href="#虚方法表" class="headerlink" title="虚方法表"></a>虚方法表</h4><figure class="highlight"><table><tr><td class="code"><pre><span class="line">在类加载的时候、为每个类创建一个表、包括类的对象所有动态绑定的方法及地址、包括父类的方法</span><br><span class="line">但同一个方法只有一条记录、子类重写之后就只会保留子类的</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="疑问"><a href="#疑问" class="headerlink" title="疑问:"></a>疑问:</h4><figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">Q</span>. 实例变量的初始化是在<span class="selector-tag">new</span>的时候进行的、类变量的初始化呢 ？(MyNumber.class)</span><br><span class="line"><span class="selector-tag">A</span>. <span class="selector-tag">Java</span>对静态类的初始化</span><br><span class="line">   <span class="number">1</span>) 为类里边的静态变量分配内存空间、并赋初值</span><br><span class="line">   <span class="number">2</span>) 按照初始化的代码顺序对类变量进行初始化</span><br><span class="line">   </span><br><span class="line"><span class="selector-tag">Q</span>: 父子类、同名静态变量在内存中如何保存 ？</span><br><span class="line">   同名实例变量呢 ？</span><br><span class="line"><span class="selector-tag">A</span>: 对于子类来说、会保存两份、静态类型是哪个的时候、访问的就是哪个</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>参考：<br><a href="https://mp.weixin.qq.com/s/u_WmkE5meMWuZ81G5gHhBQ">https://mp.weixin.qq.com/s/u_WmkE5meMWuZ81G5gHhBQ</a></p>
<p>代码整理:<br><a href="https://github.com/niujing1/javaLearn/tree/master">https://github.com/niujing1/javaLearn/tree/master</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java线程池初探</title>
    <url>/2020/03/20/java_Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<h4 id="线程池类型"><a href="#线程池类型" class="headerlink" title="线程池类型"></a>线程池类型</h4><figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="keyword">new</span><span class="type">SingleThreadExecutor</span> </span><br><span class="line">   -&gt; <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">ThreadPoolExecutor</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>L, </span><br><span class="line">                                      TimeUnit.MILLISECONDS, <span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>&lt;Runnable&gt;());</span><br><span class="line">   只使用一个线程、使用无界队列 LinkedBlockingQueue, 线程创建后不会超时终止、该线程顺序执行所有任务</span><br><span class="line">   适用于需要确保所有任务呗顺序执行的场合</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> <span class="keyword">new</span><span class="type">FixedThreadPool</span> </span><br><span class="line">   -&gt; ThreadPoolExecutor(nThreads, nThreads, <span class="number">0</span>L, </span><br><span class="line">                         TimeUnit.MILLISECONDS,<span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>&lt;Runnable&gt;())</span><br><span class="line">   保持固定线程数、新的任务进入、会放进任务队列                       </span><br><span class="line">   </span><br><span class="line"><span class="number">2.</span> <span class="keyword">new</span><span class="type">CachedThreadPool</span> </span><br><span class="line">   -&gt; ThreadPoolExecutor(<span class="number">0</span>, Integer.MAX_VALUE, <span class="number">60</span>L, </span><br><span class="line">                         TimeUnit.SECONDS, <span class="keyword">new</span> <span class="type">SynchronousQueue</span>&lt;Runnable&gt;())</span><br><span class="line">   任务到达、有空闲线程就复用、无空闲线程就创建</span><br><span class="line">   任务执行完、线程最大空闲时间<span class="number">60</span>s、超过<span class="number">60</span>s会被销毁                     </span><br><span class="line">                         </span><br><span class="line"><span class="number">3.</span> <span class="keyword">new</span> <span class="type">ThreadPoolExecutor</span>(Runtime.getRuntime().availableProcessors() * <span class="number">3</span>,</span><br><span class="line">                          <span class="number">200</span>, <span class="number">1</span>,TimeUnit.MINUTES, <span class="keyword">new</span> <span class="type">ArrayBlockingQueue</span>&lt;Runnable&gt;(<span class="number">100000</span>), <span class="keyword">new</span> <span class="type">DefaultThreadFactory</span>())                    </span><br></pre></td></tr></table></figure>

<h4 id="核心参数"><a href="#核心参数" class="headerlink" title="核心参数"></a>核心参数</h4><figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">corePoolSize:</span> 线程池中维护的核心线程数、空闲依然存在、除非设置了 allowCoreThreadTimeOut 参数</span><br><span class="line"><span class="symbol">maximumPoolSize:</span> 最大线程数</span><br><span class="line"><span class="symbol">keepAliveTime:</span> 线程池中的线程数 &gt; 核心线程数的时候、空闲线程最大idle的时间</span><br><span class="line"><span class="symbol">workQueue:</span> 任务队列</span><br></pre></td></tr></table></figure>

<h4 id="Queue类型"><a href="#Queue类型" class="headerlink" title="Queue类型"></a>Queue类型</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> LinkedBlockingQueue</span><br><span class="line"><span class="bullet">2.</span> SynchronousQueue</span><br><span class="line"><span class="bullet">3.</span> ArrayBlockingQueue</span><br><span class="line"><span class="bullet">4.</span> </span><br></pre></td></tr></table></figure>

<h4 id="reject"><a href="#reject" class="headerlink" title="reject"></a>reject</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> ThreadPoolExecutor.AbortPolicy：这就是默认的方式，抛出异常</span><br><span class="line"><span class="bullet">2.</span> ThreadPoolExecutor.DiscardPolicy：静默处理，忽略新任务，不抛异常，也不执行</span><br><span class="line"><span class="bullet">3.</span> ThreadPoolExecutor.DiscardOldestPolicy：将等待时间最长的任务扔掉，然后自己排队</span><br><span class="line"><span class="bullet">4.</span> ThreadPoolExecutor.CallerRunsPolicy：在任务提交者线程中执行任务，而不是交给线程池中的线程执行</span><br><span class="line"></span><br><span class="line">拒绝策略只有在队列有界，且maximumPoolSize有限的情况下才会触发</span><br><span class="line">如果队列无界，服务不了的任务总是会排队，但这不见得是期望的，因为请求处理队列可能会消耗非常大的内存，甚至引发内存不够的异常</span><br><span class="line">如果队列有界但maximumPoolSize无限，可能会创建过多的线程，占满CPU和内存，使得任何任务都难以完成</span><br><span class="line">在任务量非常大的场景中，让拒绝策略有机会执行是保证系统稳定运行很重要的方面</span><br></pre></td></tr></table></figure>

<h4 id="线程池的选择"><a href="#线程池的选择" class="headerlink" title="线程池的选择"></a>线程池的选择</h4><figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 在系统负载很高的情况下、<span class="keyword">new</span><span class="type">FixedThreadPool</span>可以通过队列对新任务排队、保证有足够的资源处理实际任务</span><br><span class="line">   而<span class="keyword">new</span><span class="type">CachedThreadPool</span>会为每一个任务创建一个线程、导致创建过多的线程竞争CPU和内存资源、</span><br><span class="line">   使得任何任务都难以完成、此时使用<span class="keyword">new</span><span class="type">FixedThreadPool</span>更合适</span><br><span class="line"><span class="number">2.</span> 若系统负载不太高、单个任务执行时间也比较短、<span class="keyword">new</span><span class="type">CachedThreadPool</span> 因为不用排队、效率可能更高</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> 系统负载可能极高的情况下、两者都不是最好的选择</span><br><span class="line">   <span class="keyword">new</span><span class="type">FiexedThreadPool</span>的问题是: <span class="type"></span>队列过长、占用更多内存</span><br><span class="line">   <span class="keyword">new</span><span class="type">CachedThreadPool</span>的问题是: <span class="type"></span>线程数过多、导致过多线程竞争CPU和内存资源</span><br></pre></td></tr></table></figure>

<h4 id="线程池的死锁"><a href="#线程池的死锁" class="headerlink" title="线程池的死锁"></a>线程池的死锁</h4><figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">若任务之间有依赖、可能会出现线程池的死锁</span><br><span class="line">eg. 线程池的大小为<span class="number">5</span>、taskA 提交了<span class="number">5</span>个任务、taskA会提交<span class="number">5</span>个taskB、taskB因为无法创建新的线程只能在等待队列进行等待</span><br><span class="line">    而taskA一直在等待taskB的处理结果、这样就会造成线程池的死锁</span><br><span class="line">    </span><br><span class="line">resolve: <span class="type"></span></span><br><span class="line"><span class="number">1.</span> 使用 <span class="keyword">new</span><span class="type">CachedThreadPool</span> 替代 fixed: <span class="type"></span>这样、有新的任务提交就会创建新的线程</span><br><span class="line"><span class="number">2.</span> 使用 SynchronousQueue 这样、入队成功就意味着有线程接受处理、若入队失败、就会触发reject机制、不管怎么样、都不会死锁了</span><br><span class="line">   <span class="keyword">static</span> ExecutorService executor = <span class="keyword">new</span> <span class="type">ThreadPoolExecutor</span>(</span><br><span class="line">        THREAD_NUM, THREAD_NUM, <span class="number">0</span>, TimeUnit.SECONDS, </span><br><span class="line">        <span class="keyword">new</span> <span class="type">SynchronousQueue</span>&lt;Runnable&gt;());</span><br></pre></td></tr></table></figure>


<h4 id="note"><a href="#note" class="headerlink" title="note"></a>note</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 核心线程不会预先创建，只有当有任务时才会创建</span><br><span class="line"><span class="number">2.</span> 核心线程不会因为空闲而被终止，keepAliveTime参数不适用于它</span><br><span class="line"><span class="number">3.</span> 核心线程干预</span><br><span class="line">   <span class="number">1</span>) <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">prestartAllCoreThreads</span><span class="params">()</span> 预先创建所有的核心线程</span><br><span class="line">   <span class="number">2</span>) <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">prestartCoreThread</span><span class="params">()</span> 创建一个核心线程，如果所有核心线程都已创建，返回<span class="literal">false</span></span><br><span class="line">   <span class="number">3</span>) <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">allowCoreThreadTimeOut</span><span class="params">(<span class="type">boolean</span> value)</span> 如果参数为<span class="literal">true</span>，则keepAliveTime参数也适用于核心线程</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Solr搭建与配置</title>
    <url>/2020/03/20/java_Solr%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">http:<span class="regexp">//</span>archive.apache.org<span class="regexp">/dist/</span>lucene<span class="regexp">/solr/</span></span><br></pre></td></tr></table></figure>

<h4 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 将下载完成的solr解压到tomcat的指定目录中</span><br><span class="line">     eg. 我下载的是 tomcat-<span class="number">7.2</span>.<span class="number">1</span>.zip、</span><br><span class="line">         解压目录是 ~<span class="regexp">/Downloads/</span>solr-<span class="number">7.2</span>.<span class="number">1</span></span><br><span class="line">         tomcat部署目录是 ~<span class="regexp">/www/</span>Java</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 复制solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>solr-webapp/webapp到tomcat部署目录、同时重命名</span><br><span class="line">   (重命名为非必要步骤、为了方便理解)、</span><br><span class="line">   要<span class="keyword">copy</span>的目录是 solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>solr-webapp<span class="regexp">/webapp/</span>、不是  solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>solr-webapp/、注意别cp错了~</span><br><span class="line">     cp -R solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>solr-webapp<span class="regexp">/webapp/</span> ~<span class="regexp">/www/</span>Java/solr</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>. 相关jar包复制</span><br><span class="line">    <span class="number">1</span>）solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>lib/ext下所有jar包</span><br><span class="line">    <span class="number">2</span>) solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>lib/metrics*相关的jar包</span><br><span class="line">    <span class="number">3</span>) solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/dist/</span>solr-dataimporthandler*.jar</span><br><span class="line"> </span><br><span class="line"> [当前处于~/Downloads下]</span><br><span class="line">    cp -R solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>lib<span class="regexp">/ext/</span>  ~<span class="regexp">/www/</span>Java<span class="regexp">/solr/</span>WEB-INF<span class="regexp">/lib/</span></span><br><span class="line">    cp -R solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/dist/</span>solr-dataimporthandler-*  ~<span class="regexp">/www/</span>Java<span class="regexp">/solr/</span>WEB-INF<span class="regexp">/lib/</span></span><br><span class="line">    cp -R solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>lib<span class="regexp">/metrics-*  ~/</span>www<span class="regexp">/Java/</span>solr<span class="regexp">/WEB-INF/</span>lib/</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>. 在 ~<span class="regexp">/www/</span>Java<span class="regexp">/solr/</span>WEB-INF/ 下创建文件夹 classes 用来存放日志配置文件</span><br><span class="line">    mkdir  ~<span class="regexp">/www/</span>Java<span class="regexp">/solr/</span>WEB-INF/classes </span><br><span class="line">  </span><br><span class="line"><span class="number">5</span>. 将日志配置文件放入</span><br><span class="line">     cp ~<span class="regexp">/Downloads/</span>solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/server/</span>resources<span class="regexp">/log4j.properties ~/</span>www<span class="regexp">/Java/</span>solr<span class="regexp">/WEB-INF/</span>classes/</span><br><span class="line"></span><br><span class="line"><span class="number">6</span>. 创建solr_home目录、作为solr的运行目录</span><br><span class="line">   (eg. solr创建的score会放在这里)</span><br><span class="line">    mkdir ~<span class="regexp">/www/</span>Java/solr_home</span><br><span class="line">    </span><br><span class="line"><span class="number">7</span>. 修改配置、将solr_home指定为刚刚创建的位置</span><br><span class="line">    vi ~<span class="regexp">/www/</span>Java<span class="regexp">/solr/</span>WEB-INF/web.xml </span><br><span class="line"></span><br><span class="line">   两处修改:</span><br><span class="line">  <span class="number">1</span>) env-entry 的注释打开、并且将</span><br><span class="line">       &lt;env-entry-value&gt;。。。&lt;/env-entry-value&gt;修改为刚才创建的目录</span><br><span class="line">       &lt;env-entry-value&gt;<span class="regexp">/Users/</span>nj<span class="regexp">/www/</span>Java<span class="regexp">/solr_home&lt;/</span>env-entry-value&gt;</span><br><span class="line">  <span class="number">2</span>) &lt;security-constraint&gt;注释掉(配置访问权限、不然有可能会<span class="number">403</span>)、 </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-6ff0528121e02f7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="env.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-5eb1ffc4a8d226f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="security.png"></p>
<h4 id="启动solr"><a href="#启动solr" class="headerlink" title="启动solr"></a>启动solr</h4><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">重启tomcat</span><br><span class="line"><span class="keyword">cd</span> ~/build/java/apache-tomcat/bin</span><br><span class="line"><span class="keyword">sh</span> shutdown.<span class="keyword">sh</span></span><br><span class="line"><span class="keyword">sh</span> startup.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>

<h4 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h4><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">访问 localhos<span class="variable">t:8081</span>/solr/<span class="built_in">index</span>.html 可以看到solr的管理界面</span><br><span class="line">注:</span><br><span class="line"><span class="number">1</span>. 端口号是自己的tomcat的访问端口、可能是<span class="number">8080</span>或者其它任意端口</span><br><span class="line"><span class="number">2</span>. 访问时一定加上 <span class="built_in">index</span>.html</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-44dc0994227bfdc4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>&#x3D;&#x3D;solr服务搭建end</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">这样就搭建完成、可以开始使用了</span><br><span class="line">如果遇到<span class="number">404</span>的情况、可以检查下 使用的jar包是不是都<span class="keyword">copy</span>完成了</span><br></pre></td></tr></table></figure>

<h4 id="初始化solr数据"><a href="#初始化solr数据" class="headerlink" title="初始化solr数据"></a>初始化solr数据</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 创建文件夹 ~<span class="regexp">/www/</span>Java<span class="regexp">/solr_home/</span>new_core 用来存放core内容</span><br><span class="line">    将conf文件cp进去</span><br><span class="line">    cp -r ~<span class="regexp">/www/</span>Java<span class="regexp">/solr_home/</span>configsets<span class="regexp">/_default/</span>conf ~<span class="regexp">/www/</span>Java<span class="regexp">/solr_home/</span>new_core/</span><br><span class="line"><span class="number">2</span>. 在页面上可以看到 如下图所示、点击添加一个 core</span><br><span class="line"><span class="number">3</span>. image2中填写的部分都可以修改 name和instanceDir要保持一致(同为刚刚建立的文件夹的名字)</span><br><span class="line"><span class="number">4</span>. 创建成功之后、就可以看到 image中、划线的地方变成了、core Selector、点击、可以看到我们刚刚创建的new_core、如image3</span><br><span class="line">自定义core创建完成、</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-db08b19d9c30d8c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-dd02545058169919.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image2.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-87109e2aadbef028.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image3.png"></p>
<h4 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 引入jar包</span><br><span class="line">   cp ~<span class="regexp">/www/</span>Java<span class="regexp">/lib/my</span>sql<span class="regexp">/mysql-connector-java-5.1.38.jar ~/</span>www<span class="regexp">/Java/</span>solr<span class="regexp">/WEB-INF/</span>lib/</span><br><span class="line"><span class="number">2</span>. 复制solr-<span class="number">7.2</span>.<span class="number">1</span><span class="regexp">/example/</span>example-DIH<span class="regexp">/solr/</span>db<span class="regexp">/conf/</span>下的db-data-config.xml到solr-home<span class="regexp">/core2/</span>conf/下，此处改名为data-config.xml(也可以不修改)</span><br><span class="line"><span class="number">3</span>. 修改配置内容</span><br><span class="line">   &lt;dataConfig&gt;</span><br><span class="line">    &lt;dataSource type=<span class="string">&quot;JdbcDataSource&quot;</span> driver=<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span> url=<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/taotao&quot;</span> user=<span class="string">&quot;root&quot;</span> password=<span class="string">&quot;root&quot;</span>/&gt;</span><br><span class="line">    &lt;document&gt;</span><br><span class="line">        &lt;entity name=<span class="string">&quot;tb_item&quot;</span> </span><br><span class="line">            query=<span class="string">&quot;select id,title,sell_point,price,num,barcore,image,cid,status,created,updated from tb_item&quot;</span>&gt;</span><br><span class="line">        &lt;/entity&gt;</span><br><span class="line">    &lt;/document&gt;</span><br><span class="line">&lt;/dataConfig&gt;</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>. 修改solrconfig、添加导入信息</span><br><span class="line">  vi  ~<span class="regexp">/www/</span>Java<span class="regexp">/solr_home/</span>new_core<span class="regexp">/conf/</span>solrconfig.xml</span><br><span class="line"></span><br><span class="line">     &lt;!-- add by myself --&gt;</span><br><span class="line">    &lt;requestHandler name=<span class="string">&quot;/dataimport&quot;</span> <span class="keyword">class</span>=<span class="string">&quot;org.apache.solr.handler.dataimport.DataImportHandler&quot;</span>&gt;</span><br><span class="line">        &lt;lst name=<span class="string">&quot;defaults&quot;</span>&gt;</span><br><span class="line">          &lt;str name=<span class="string">&quot;config&quot;</span>&gt;data-config.xml&lt;/str&gt;</span><br><span class="line">        &lt;/lst&gt;</span><br><span class="line">    &lt;/requestHandler&gt;</span><br><span class="line">注意要和requestHandler标签同级</span><br><span class="line"><span class="number">4</span>. 自定义solr字段、在manager-schema中添加filed字段(放在text后即可)</span><br><span class="line">    如：field.png所示</span><br><span class="line">   注意：type必须是fileType已定义的类型(defined.png)</span><br><span class="line"><span class="number">5</span>. 数据导入</span><br><span class="line"><span class="number">6</span>. 数据查询(query.png)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-b36efbd2eea2cb82.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="data-config.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-ac54aea06f0bd371.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="solrconfig.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-13915d20a978490d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="field.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-832f12d71e6bf66d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="defined.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-324870b92233d0fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="import.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-2290be0f85dba4b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="query.png"></p>
<h4 id="end"><a href="#end" class="headerlink" title="end"></a>end</h4><figure class="highlight parser3"><table><tr><td class="code"><pre><span class="line"><span class="language-xml">这样就可以开始使用了</span><span class="keyword">^.</span><span class="language-xml">^</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>effective-java笔记</title>
    <url>/2020/03/20/java_effective-java%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<ul>
<li>考虑静态工厂方法代替构造器<ol>
<li>含义更明确</li>
<li></li>
</ol>
</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>hbase</title>
    <url>/2020/03/20/java_hbase/</url>
    <content><![CDATA[<h3 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h3><h4 id="install"><a href="#install" class="headerlink" title="install"></a>install</h4><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">1</span>. brew install hbase</span><br><span class="line"><span class="attribute">2</span>. http://hbase.apache.org/book.html#quickstart</span><br><span class="line">   <span class="attribute">tar</span> xzvf hbase-<span class="number">3</span>.<span class="number">0</span>.<span class="number">0</span>-SNAPSHOT-bin.tar.gz</span><br><span class="line">   <span class="attribute">cd</span> hbase-<span class="number">3</span>.<span class="number">0</span>.<span class="number">0</span>-SNAPSHOT/</span><br></pre></td></tr></table></figure>

<h4 id="modify-config"><a href="#modify-config" class="headerlink" title="modify config"></a>modify config</h4><figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">1. conf/hbase-env.sh 添加Java jdk路径</span><br><span class="line">vim xxxx/libexec/conf/hbase-env.sh</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=<span class="string">&quot;/Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home&quot;</span></span><br><span class="line"></span><br><span class="line">2. conf/hbase-site.xml 添加hbase文件存储路径</span><br><span class="line"></span><br><span class="line"><span class="variable">&lt;configuration&gt;</span></span><br><span class="line">  <span class="variable">&lt;property&gt;</span></span><br><span class="line">    <span class="variable">&lt;name&gt;</span>hbase.rootdir<span class="variable">&lt;/name&gt;</span></span><br><span class="line">    <span class="variable">&lt;value&gt;</span>file:///usr/local/var/hbase<span class="variable">&lt;/value&gt;</span></span><br><span class="line">  <span class="variable">&lt;/property&gt;</span></span><br><span class="line">  <span class="variable">&lt;property&gt;</span></span><br><span class="line">    <span class="variable">&lt;name&gt;</span>hbase.zookeeper.property.clientPort<span class="variable">&lt;/name&gt;</span></span><br><span class="line">    <span class="variable">&lt;value&gt;</span>2181<span class="variable">&lt;/value&gt;</span></span><br><span class="line">  <span class="variable">&lt;/property&gt;</span></span><br><span class="line">  <span class="variable">&lt;property&gt;</span></span><br><span class="line">    <span class="variable">&lt;name&gt;</span>hbase.zookeeper.property.dataDir<span class="variable">&lt;/name&gt;</span></span><br><span class="line">    <span class="variable">&lt;value&gt;</span>/usr/local/var/zookeeper<span class="variable">&lt;/value&gt;</span></span><br><span class="line">  <span class="variable">&lt;/property&gt;</span></span><br><span class="line"><span class="variable">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="start-server"><a href="#start-server" class="headerlink" title="start server"></a>start server</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/Cellar/</span>hbase<span class="regexp">/&#123;version&#125;/</span>libexec<span class="regexp">/bin/</span>start-hbase.sh</span><br></pre></td></tr></table></figure>

<h4 id="start-shell"><a href="#start-shell" class="headerlink" title="start shell"></a>start shell</h4><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line">hbase <span class="keyword">shell</span></span><br></pre></td></tr></table></figure>

<h4 id="command"><a href="#command" class="headerlink" title="command"></a>command</h4><h4 id="base-command"><a href="#base-command" class="headerlink" title="base command"></a>base command</h4><figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">status 查询服务器的状态</span><br><span class="line"><span class="built_in">version</span> 查询hbase版本</span><br><span class="line">whoami 查看连接用户</span><br><span class="line"></span><br><span class="line"><span class="built_in">list</span> 查询库中所有表</span><br></pre></td></tr></table></figure>

<h4 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="keyword">create</span></span><br><span class="line">   <span class="keyword">create</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;cf1&#x27;</span>, <span class="string">&#x27;cf2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> <span class="keyword">drop</span></span><br><span class="line">   <span class="keyword">disable</span> <span class="string">&#x27;table_name&#x27;</span> 删除之前需要先让表失效、修改表结构是也是</span><br><span class="line">   <span class="keyword">drop</span> <span class="string">&#x27;table_name&#x27;</span> 删除</span><br><span class="line">   </span><br><span class="line"><span class="number">3.</span> <span class="keyword">exists</span></span><br><span class="line">   <span class="keyword">exists</span> <span class="string">&#x27;table_name&#x27;</span> 查看表是否存在</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> describe 查看表结构</span><br><span class="line">   describe <span class="string">&#x27;table_name&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> <span class="keyword">enable</span> 使表有效</span><br><span class="line">   <span class="keyword">enable</span> <span class="string">&#x27;table_name&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">6.</span> modify <span class="keyword">table</span> structure</span><br><span class="line">   <span class="number">1</span>) <span class="keyword">alter</span> <span class="string">&#x27;table_name&#x27;</span> <span class="string">&#x27;cf3&#x27;</span>   # 新增列族</span><br><span class="line">   <span class="number">2</span>) <span class="keyword">alter</span> <span class="string">&#x27;test&#x27;</span>, &#123;<span class="type">NAME</span>=&gt;<span class="string">&#x27;cf3&#x27;</span>, <span class="keyword">METHOD</span>=&gt;<span class="string">&#x27;delete&#x27;</span>&#125; # 删除列族</span><br></pre></td></tr></table></figure>

<h4 id="DML"><a href="#DML" class="headerlink" title="DML"></a>DML</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="keyword">add</span></span><br><span class="line">put <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;rowkey&#x27;</span>, <span class="string">&#x27;列族名 1: 列名 1&#x27;</span>, <span class="string">&#x27;value&#x27;</span> #同一个rowkey、执行两次put、认为是更新操作</span><br><span class="line">eg. put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;row_key1&#x27;</span>,<span class="string">&#x27;cf1:a&#x27;</span>,<span class="string">&#x27;a&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> incr</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> count 查询表的行数(比较耗时)</span><br><span class="line">   count <span class="string">&#x27;table_name&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> <span class="keyword">select</span></span><br><span class="line">    <span class="number">1</span>) <span class="keyword">get</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;rowkey&#x27;</span>, <span class="string">&#x27;列族名：列名&#x27;</span> #查询指定列族的指定列的值</span><br><span class="line">       eg. <span class="keyword">get</span> <span class="string">&#x27;test&#x27;</span>, <span class="string">&#x27;row_key1&#x27;</span>, <span class="string">&#x27;cf1:a,cf4&#x27;</span> </span><br><span class="line">       </span><br><span class="line">    <span class="number">2</span>) <span class="keyword">get</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;rowkey&#x27;</span> #获取指定row_key的所有数据</span><br><span class="line">       eg. <span class="keyword">get</span> <span class="string">&#x27;test&#x27;</span>, <span class="string">&#x27;row_key1&#x27;</span></span><br><span class="line">       </span><br><span class="line">    <span class="number">3</span>) <span class="keyword">get</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;rowkey&#x27;</span>, &#123;COLUMN=&gt;<span class="string">&#x27;列族名：列&#x27;</span>, <span class="type">TIMESTAMP</span>=&gt;<span class="number">1373737746997</span>&#125; # 获取指定时间戳的数据</span><br><span class="line">        <span class="keyword">get</span> <span class="string">&#x27;test&#x27;</span>, <span class="string">&#x27;row_key1&#x27;</span>, &#123;COLUMN=&gt;<span class="string">&#x27;cf1:a&#x27;</span>,<span class="type">TIMESTAMP</span>=&gt;<span class="number">1559367213477</span>&#125;</span><br><span class="line">        </span><br><span class="line">    <span class="number">4</span>) <span class="keyword">get</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;rowkey&#x27;</span>, &#123;COLUMN =&gt; <span class="string">&#x27;列族名：列名&#x27;</span>, VERSIONS =&gt; <span class="number">2</span>&#125; 获取多个版本值、默认返回第一个</span><br><span class="line">       <span class="keyword">get</span> <span class="string">&#x27;test&#x27;</span>, <span class="string">&#x27;row_key1&#x27;</span>, &#123;COLUMN=&gt;<span class="string">&#x27;cf1:a&#x27;</span>,VERSIONS=&gt;<span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> <span class="keyword">delete</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>) <span class="keyword">delete</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;rowkey&#x27;</span>, <span class="string">&#x27;列族名：列名&#x27;</span> 删除指定rowkey的指定列族的列名数据</span><br><span class="line">   eg. <span class="keyword">delete</span> <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;row_key1&#x27;</span>,<span class="string">&#x27;cf1:a&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>) <span class="keyword">delete</span> <span class="string">&#x27;table_name&#x27;</span>, <span class="string">&#x27;rowkey&#x27;</span>, <span class="string">&#x27;列族名&#x27;</span>  删除指定rowkey指定列族的数据</span><br><span class="line">   eg. <span class="keyword">delete</span> <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;row_key1&#x27;</span>,<span class="string">&#x27;cf1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>) deleteall <span class="string">&#x27;table_name&#x27;</span>, ’rowkey<span class="string">&#x27; 删除rowkey所有column的calue、删除整行数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">6. scan &#x27;</span>table_nam<span class="string">e&#x27; 全表扫描</span></span><br><span class="line"><span class="string">   scan &#x27;</span>test<span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">7. truncate &#x27;</span>table_nam<span class="string">e&#x27; 删除全表数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">8. hbase shell test.hbaseshell 执行shell脚本</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>

<h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 行以 rowkey 作为唯一标识、最大长度 <span class="number">64</span>KB</span><br><span class="line">   不支持<span class="keyword">order</span> <span class="keyword">by</span>只能按照rowkey或者range或者全表扫描</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> 列族是列的集合 列族:列</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> HBase 通过 <span class="keyword">row</span> 和 <span class="keyword">column</span> 确定一份数据</span><br><span class="line">   tableName + RowKey + ColumnKey + <span class="type">Timestamp</span> =&gt; <span class="keyword">value</span> 唯一确定。Cell 中数据没有类型，字节码存储</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h4><p><a href="http://einverne.github.io/post/2017/02/hbase-introduction-and-use.html">http://einverne.github.io/post/2017/02/hbase-introduction-and-use.html</a></p>
<p><a href="http://einverne.github.io/post/2017/02/hbase-shell-command.html">http://einverne.github.io/post/2017/02/hbase-shell-command.html</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>java基础</title>
    <url>/2020/03/20/java_java%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h4 id="bean的作用域"><a href="#bean的作用域" class="headerlink" title="bean的作用域"></a>bean的作用域</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="title">Spring的`scope` :</span></span><br><span class="line">`Singleton` 一个spring容器中、只有一个`bean` 的实例、spring默认配置</span><br><span class="line">`Prototype` 每次调用新建一个bean</span><br><span class="line">`Request` web项目中、给每个http request请求一个bean实例</span><br><span class="line">`Session` web项目中、给每个http session一个bean实例</span><br><span class="line">`GlobalSession` 只有在Portal应用中有、给每个global http request一个bean实例</span><br></pre></td></tr></table></figure>
<h4 id="postConstructor"><a href="#postConstructor" class="headerlink" title="postConstructor"></a>postConstructor</h4><figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="variable">@PostConstruct</span> 在 construct之后执行、</span><br><span class="line">相当于java配置方式的 <span class="variable">@Bean</span>(initMethod=<span class="string">&#x27;xxx&#x27;</span>)、</span><br><span class="line">相当于xml配置方式的 init-method</span><br><span class="line"></span><br><span class="line"><span class="variable">@PreDestroy</span> 在bean销毁之前执行、</span><br><span class="line">相当于java配置方式的 <span class="variable">@Bean</span>(deatroyMethod=<span class="string">&#x27;xxx&#x27;</span>)</span><br><span class="line">相当于xml配置方式的 destroy-method</span><br></pre></td></tr></table></figure>

<h4 id="profile"><a href="#profile" class="headerlink" title="profile"></a>profile</h4><figure class="highlight"><table><tr><td class="code"><pre><span class="line">提供不同环境不同配置文件的支持</span><br></pre></td></tr></table></figure>

<h4 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">Spring的事件为<span class="keyword">Bean与Bean之间的通信提供了支持、</span></span><br><span class="line"><span class="keyword"></span><span class="number">1</span>) 自定义事件  继承ApplicationEvent</span><br><span class="line"><span class="number">2</span>) 定义事件监听器  实现 ApplicationListener</span><br><span class="line"><span class="number">3</span>) 使用容器发布事件</span><br></pre></td></tr></table></figure>

<h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><figure class="highlight aspectj"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 异步任务 <span class="meta">@Async</span> </span><br><span class="line"><span class="number">2.</span> 规划任务 <span class="meta">@Scheduled</span> 每隔固定时间执行</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="桟"><a href="#桟" class="headerlink" title="桟"></a>桟</h4><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">主要用来存放函数调用所需要的数据<span class="comment">(函数参数、返回地址及函数内部的局部变量)</span>、但、返回值不在桟中、会有一个专门的返回值存储器、</span><br></pre></td></tr></table></figure>

<h4 id="变量的生命周期"><a href="#变量的生命周期" class="headerlink" title="变量的生命周期"></a>变量的生命周期</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 函数中的参数和函数内定义的变量、都分配在桟上、在函数调用时被分配、调用结束释放</span><br><span class="line"><span class="bullet">2.</span> 数组和对象 存放变量地址的空间是分配在桟上的、存放变量内容的空间是分配在堆上的</span><br><span class="line">函数调用结束、存放变量地址的空间会被立即释放、而存放内容的空间不会、它会因为没有变量引用、而被垃圾回收机制回收掉</span><br></pre></td></tr></table></figure>

<h4 id="类和对象的声明周期"><a href="#类和对象的声明周期" class="headerlink" title="类和对象的声明周期"></a>类和对象的声明周期</h4><figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">类加载进内存后、一般不会释放、直到程序结束、一般情况下、类只会加载<span class="number">1</span>次、所以、静态变量在内存中只有一份</span><br><span class="line"></span><br><span class="line">对象：每次<span class="keyword">new</span><span class="type"></span>创建一个对象的时候、对象产生、在内存中、会存储这个对象的实例变量值、每<span class="keyword">new</span><span class="type"></span>一次、对象就会产生一个、就会有一份独立的实例变量</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>java常用注解</title>
    <url>/2020/03/20/java_java%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/</url>
    <content><![CDATA[<p><code>@Controller</code> mvc中、声明一个控制器<br><code>@Component</code> 声明一个通用组件<br><code>@Repository</code> 声明一个dao组件<br><code>@Service</code> 声明一个service组件</p>
<p><code>@Bean</code> 声明一个bean容器<br><code>@Configuration</code> 声明配置类<br><code>@ComponentScan</code> 包扫描</p>
<p><code>@Async</code>声明一个异步方法<br><code>@EnableAsync</code> 开启异步任务支持<br><code>@Scheduled</code> 声明一个计划任务<br>       <code>fixdRate</code> 表明每隔固定时间间隔执行<br>      <code>cron</code>表明按照cron表达式在指定时间执行<br><code>@EnableScheduling</code> 开启计划任务支持<br><code>@EnableCaching</code> 开启注解式的缓存支持</p>
<p><code>@RequestMapping</code> 配置url和方法之间的映射关系<br><code>@Conditional</code> 条件注解<br><code>@ResponseBody</code> 将返回值放在response返回体内、而不是返回一个页面<br><code>@RequestBody</code>允许将request参数放在request体中、而不是放在连接地址后边<br><code>@PathVariable</code>用来接收路径参数</p>
<p>组合注解<br><code>@WiselyConfiguration</code> 代替 <code>@Configuration</code> + <code>@ComponentScan</code><br><code>@RestController</code> 代替 <code>@Controller</code> + <code>@ResponseBody</code><br><code>@SpringBootApplication</code> 组合了<br><code>@Configuration</code>+<code>@EnableAutoConfiguration</code>+<code>@ComponentScan</code></p>
<p><code>@ConditionalOnBean</code>当容器里有指定的bean的条件下<br><code>@ConditionalOnClass</code> 当类路径下有指定的类的条件下<br><code>@ConditionalOnExpression</code>基于SpEL做判断<br><code>@ConditionalOnJava</code> 基于jvm版本做判断<br><code>@ConditionalOnMissingBean</code> 当容器中无指定bean的条件下<br><code>@ConditionalOnMissingClass</code> 类路径下无指定class的情况下<br><code>@ConditionalOnNotWebApplication</code> 当前项目不是web项目的情况下<br><code>@ConditionalOnWebApplication</code> 当前项目是web项目的情况下<br><code>@ConditionalOnProperty</code> 指定的属性是否有指定值<br><code>@ConditionalOnResource</code> 类路径是否有指定值</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>solr使用IK分词器</title>
    <url>/2020/03/20/java_solr%E4%BD%BF%E7%94%A8IK%E5%88%86%E8%AF%8D%E5%99%A8/</url>
    <content><![CDATA[<h4 id="下载分词器jar包"><a href="#下载分词器jar包" class="headerlink" title="下载分词器jar包"></a>下载分词器jar包</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">百度网盘地址：</span><br><span class="line">链接:https:<span class="regexp">//</span>pan.baidu.com<span class="regexp">/s/</span><span class="number">1</span>GHwv6uBcUhI7GpOpqFnl4g  密码:<span class="number">121</span>w</span><br></pre></td></tr></table></figure>

<h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 将压缩包解压、重命名为ik_analyzer</span><br><span class="line"><span class="number">2</span>. 将 ik-analyzer-solr6.jar 复制到 solr lib目录下</span><br><span class="line">    cp ~<span class="regexp">/Downloads/i</span>k_analyzer<span class="regexp">/ik-analyzer-solr6.jar ~/</span>www<span class="regexp">/Java/</span>solr<span class="regexp">/WEB-INF/</span>lib</span><br><span class="line"><span class="number">3</span>. 将相关包放入solr <span class="keyword">classpath</span></span><br><span class="line">    cp  ~<span class="regexp">/Downloads/i</span>k_analyzer<span class="regexp">/mydict.dic    ~/</span>Downloads<span class="regexp">/ik_analyzer/I</span>KAnalyzer.cfg.xml    ~<span class="regexp">/Downloads/i</span>k_analyzer<span class="regexp">/ext_stopword.dic  ~/</span>www<span class="regexp">/Java/</span>solr<span class="regexp">/WEB-INF/</span>classes</span><br><span class="line">  若~<span class="regexp">/www/</span>Java<span class="regexp">/solr/</span>WEB-INF/classes文件夹不存在、需要新建</span><br><span class="line"><span class="number">4</span>. 配置schema</span><br><span class="line">   </span><br><span class="line">    &lt;!-- IKAnalyzer--&gt;</span><br><span class="line">      &lt;fieldType name=<span class="string">&quot;text_ik&quot;</span> <span class="keyword">class</span>=<span class="string">&quot;solr.TextField&quot;</span>&gt;</span><br><span class="line">          &lt;analyzer <span class="keyword">class</span>=<span class="string">&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;</span>/&gt;</span><br><span class="line">      &lt;/fieldType&gt;</span><br><span class="line"></span><br><span class="line">      &lt;field name=<span class="string">&quot;item_title&quot;</span> type=<span class="string">&quot;text_ik&quot;</span> indexed=<span class="string">&quot;true&quot;</span> stored=<span class="string">&quot;true&quot;</span>/&gt;</span><br><span class="line">      &lt;field name=<span class="string">&quot;item_sell_point&quot;</span> type=<span class="string">&quot;text_ik&quot;</span> indexed=<span class="string">&quot;true&quot;</span> stored=<span class="string">&quot;true&quot;</span>/&gt;</span><br><span class="line">      &lt;field name=<span class="string">&quot;item_price&quot;</span>  type=<span class="string">&quot;plong&quot;</span> indexed=<span class="string">&quot;true&quot;</span> stored=<span class="string">&quot;true&quot;</span>/&gt;</span><br><span class="line">      &lt;field name=<span class="string">&quot;item_image&quot;</span> type=<span class="string">&quot;string&quot;</span> indexed=<span class="string">&quot;false&quot;</span> stored=<span class="string">&quot;true&quot;</span> /&gt;</span><br><span class="line">      &lt;field name=<span class="string">&quot;item_category_name&quot;</span> type=<span class="string">&quot;string&quot;</span> indexed=<span class="string">&quot;true&quot;</span> stored=<span class="string">&quot;true&quot;</span> /&gt;</span><br><span class="line"></span><br><span class="line">      &lt;field name=<span class="string">&quot;item_keywords&quot;</span> type=<span class="string">&quot;text_ik&quot;</span> indexed=<span class="string">&quot;true&quot;</span> stored=<span class="string">&quot;false&quot;</span> multiValued=<span class="string">&quot;true&quot;</span>/&gt;</span><br><span class="line">      &lt;copyField <span class="keyword">source</span>=<span class="string">&quot;item_title&quot;</span> dest=<span class="string">&quot;item_keywords&quot;</span>/&gt;</span><br><span class="line">      &lt;copyField <span class="keyword">source</span>=<span class="string">&quot;item_sell_point&quot;</span> dest=<span class="string">&quot;item_keywords&quot;</span>/&gt;</span><br><span class="line">      &lt;copyField <span class="keyword">source</span>=<span class="string">&quot;item_category_name&quot;</span> dest=<span class="string">&quot;item_keywords&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line">其中：copyfiled是将item_title、item_sell_point、item_category_name都作为后边的item_keywords来搜索</span><br><span class="line"></span><br><span class="line"><span class="number">5</span>. 保存、重启tomcat、访问页面</span><br><span class="line">    http:<span class="comment">//localhost:8081/solr/index.html</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-25bef17f4a7bd4d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="analyzer.png"></p>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">如果遇到错误：java<span class="selector-class">.lang</span><span class="selector-class">.AbstractMethodError</span></span><br><span class="line">可以检查下分词器的版本是否过低</span><br><span class="line">当前这篇文章使用的solr是<span class="number">7.2</span>.<span class="number">1</span>的版本、使用的是网盘保存的分词器版本、是ok的、</span><br><span class="line">之前使用了 IKAnalyzer2012FF_u1<span class="selector-class">.jar</span> 这个版本、出现的上述错误~</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-733f055952b7cd35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="error.png"></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>java秒级定时任务的实现</title>
    <url>/2020/03/20/java_java%E7%A7%92%E7%BA%A7%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p><code>@Scheduled</code> 注解、简单轻量级task配置</p>
<p><code>@Scheduled</code> 使用：</p>
<ul>
<li><code>@Scheduled(cron = &quot;0 5 * * * * ?&quot;)</code> 10分钟执行1次</li>
<li><code>@Scheduled(fixedRate = 2000)</code> 每2s执行1次、不用等待上次执行完成</li>
<li><code>@Scheduled(fixedDelay = 2000)</code> 等待上次请求结束后、delay 2s 执行下次任务</li>
<li><code>@Scheduled(fixedDelay = 2000, initDelay = 2000)</code> 项目启动成功后、延迟2s执行任务</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收---G1收集器</title>
    <url>/2020/03/20/java_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6---G1%E6%94%B6%E9%9B%86%E5%99%A8/</url>
    <content><![CDATA[<h4 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h4><p>上篇文章简单介绍了七种垃圾回收器、既然G1是最前沿的、有必要补充说明一下:<br>     1. <code>横跨整个堆内存</code>: 在G1之前的其它收集器收集范围都是整个新生代或者老年代<br>         G1在使用时、将整个Java堆划分为多个大小相等的<code>独立区域(Region)</code><br>         保留新生代和老年代的概念、但不再物理隔离、都是一部分<code>Region</code>(不需要连续)的集合<br>     2. <code>建立可预测的时间模型</code>: G1跟踪各个Region里垃圾堆积的价值大小(回收可获得空间大小及回收所需时间的经验值)<br>         在后台维护一个优先级列表, 每次根据允许的收集时间、优先回收价值最大的Region(Garbage First)<br>         这种实验Region划分内存空间及有优先级的区域回收方式、保证了G1在有限时间内的收集效率<br>     3. <code>避免全堆扫描</code>: G1将堆分为多个Region、就是化整为零、单Region不可能是孤立的、一个对象分配在某个Region中<br>         可能与整个Java堆任意的对象发生引用关系、在做可达性分析确定对象是否存活时、需要扫整个Java堆保证准确性<br>         严重损耗GC效率，<br>        <code>注意：</code><br>为了避免全堆扫描、虚拟机为每个Region维护了一个对应的<code>Remembered Set</code>、虚拟机发现程序对在<code>Reference</code>类型的<br>         数据进行写操作时、会产生一个<code>Writer Barrier</code>暂时中断写操作、检测<code>Reference引用的对象</code>是否<code>在不同的Region中</code><br>         (在分代的例子中就是检测老年代对象是否引用了新生代对象)、若是则通过<code>CardTable</code>把相关引用记录到被引用对象所属的<br>         Region的<code>Remembered Set</code>中、垃圾回收时，在GC根节点的枚举范围内<code>加入Remembered Set</code>即可保证不用全堆扫描也能不遗漏</p>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">若不计算维护Remembered Set的操作、G1大致步骤为：</span><br><span class="line"><span class="number">1</span>) 初始标记：initial mark仅标记GC Roots能直接关联的对象、并且修改TAMS(Nest top mark start)的值</span><br><span class="line">   让下阶段用户程序并发运行时、可在正确可以的Region中创建对象、此阶段需要停顿用户线程、但时间较短</span><br><span class="line">   </span><br><span class="line"><span class="number">2</span>) 并发标记: concurrent Marking 从GC Root开始对堆中对象做可达性分析、找到存活对象</span><br><span class="line">   耗时较长、但可与用户线程`并发执行`</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>) 最终标记: Final Marking 为了修正标记期间因用户程序继续运行导致标记产生变化的对象、</span><br><span class="line">   虚拟机将这段时间内对象变化记录在线程的`Remembered Set Logs`里、最终标记阶段需要将这部分数据合并</span><br><span class="line">   到 Remembered Set 中、需要`停顿线程`、但可`并行执行`</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>) 筛选回收: Live Data <span class="literal">and</span> Evacuation 先对各个Region中的回收价值和成本进行排序</span><br><span class="line">   根据用户所期望的GC停顿时间来定制回收计划、此阶段也`可以`做到与用户线程`并发执行`、但因为只回收</span><br><span class="line">   一部分Region、且时间是用户可控制的、`停顿用户线程`将大幅度`提高收集效率`</span><br></pre></td></tr></table></figure>
<h5 id="G1适用分析"><a href="#G1适用分析" class="headerlink" title="G1适用分析"></a>G1适用分析</h5><pre><code>场景Scense：
   1. 多核多CPU而且大内存
   2. 要求低停顿

如何实现-XX:MaxGCPauseMillis所设置的目标？
   1. 对于新生代来说，G1自动调整新生代的大小
   2. 对于老年代来说，每次Mixed Garbage Collecttion的时候回收的Rigion个数会基于
      Mixed Garbage Collection的目标次数，每个Region中的存活对象百分比，以及堆全局的垃圾比例来设定
</code></pre>
<h5 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h5><pre><code>如何实现避免碎片？
   无论是新生代还是老年代，使用复制算法(将一批Region复制到另外一批Region中)

如何避免可达性分析扫描整个堆？
   每一个Region都有自己的RSets(Remembered Set) 用来记录对自己Region内对象的引用
   
在什么时机进行Mixed Garbage Collection?
   在堆的使用率达到-XX:InitiatingHeapOccupancyPercent所设置的使用率(老年代使用的内存/整个堆内存)时
   
   判断的时机是? 每次Young GC结束的时候
   
   因为老年代空间中的使用内存发生变化只有一个情形：Young GC的时候

G1的哪些过程需要STW？
   1) young gc: 采用的是复制算法 - 会STW、多线程进行
   2) mixed gc: 也是复制算法、mixed gc也包括对新生代的收集
   3) global concurrent mark中的initial mark、remark、部分clean up

既然有CMS，为什么要选择G1?
   1. STW更加可控
   2. 由于采用了标记-整理算法，不会产生内存碎片

Humongous Objects的分配和回收:
   1. 怎么算？大于Region的空间的一半的算Humongous Objects
   2. 放哪里？Humongous Objects被分配在Humongous Region，直接在老年代
   3. 回收：不在mixed gc，而在 global concurrent marking的最后一步：clean up中

可达性分析：
   找一组对象作为GC Root（根结点），并从根结点进行遍历，遍历结束后如果发现某个对象是不可达的,
   那么它就会被标记为不可达对象，等待GC

哪些对象可以作为GC Root
    能作为GC Root的对象必定为可以存活的对象，
    eg. 全局性的引用（静态变量和常量）以及某些方法的局部变量（栈帧中的本地变量表）
    
    以下对象通常可以作为GC Root：
    1) 存活的线程
    2) 虚拟机栈(栈桢中的本地变量表)中的引用的对象
    3) 方法区中的类静态属性以及常量引用的对象
    4) 本地方法栈中JNI引用的局部变量以及全局变量
</code></pre>
<h5 id="G1调优"><a href="#G1调优" class="headerlink" title="G1调优"></a>G1调优</h5><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. -<span class="variable constant_">XX</span><span class="symbol">:MaxGCPauseMillis</span></span><br><span class="line">   最大<span class="variable constant_">STW</span>时间、参数设置过小会频繁<span class="variable constant_">GC</span>、设置过大、吞吐量会降低、所以要合理的设置来保证 </span><br><span class="line">   <span class="string">`最大停顿时间`</span>和<span class="string">`最大吞吐量`</span>的平衡</span><br><span class="line"><span class="number">2</span>. -<span class="variable constant_">XX</span><span class="symbol">:InitiatingHeapOccupancyPercent</span> &amp; -<span class="variable constant_">XX</span><span class="symbol">:+G1UseAdaptiveHop</span></span><br><span class="line">   InitiatingHeapOccupancyPercent简称<span class="variable constant_">IHOP</span></span><br><span class="line">   -<span class="variable constant_">XX</span><span class="symbol">:+G1UseAdaptiveIHOP</span>是默认值，也就是说<span class="variable constant_">IHOP</span>是adaptive的</span><br><span class="line">   -<span class="variable constant_">XX</span><span class="symbol">:InitiatingHeapOccupancyPercent</span>是初始值</span><br></pre></td></tr></table></figure>
<h5 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h5><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 跟cms一样、无法避免浮动垃圾的产生和溢出</span><br><span class="line">    可以增加堆大小、或者<span class="variable constant_">GC</span>线程<span class="string">`-XX:ConcGCThreads`</span>来尽量避免</span><br><span class="line"><span class="number">2</span>. 同样存在晋升失败的问题</span><br><span class="line">    可以提升<span class="string">`-XX:G1ReservePercent`</span>同时同比例的增加堆大小、</span><br><span class="line">    或者提前启动标记周期(减少-<span class="variable constant_">XX</span><span class="symbol">:InitiatingHeapOccupancyPercent</span>)</span><br></pre></td></tr></table></figure>
<h5 id="GC-收集器总结"><a href="#GC-收集器总结" class="headerlink" title="GC 收集器总结:"></a>GC 收集器总结:</h5><table>
<thead>
<tr>
<th>收集器</th>
<th>串行、并行or并发</th>
<th>新生代&#x2F;老年代</th>
<th>算法</th>
<th>目标</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>Serial</td>
<td>串行</td>
<td>新生代</td>
<td>复制算法</td>
<td>响应速度优先</td>
<td>单CPU环境下的Client模式</td>
</tr>
<tr>
<td>Serial Old</td>
<td>串行</td>
<td>老年代</td>
<td>标记-整理</td>
<td>响应速度优先</td>
<td>单CPU环境下的Client模式、CMS的后备预案</td>
</tr>
<tr>
<td>ParNew</td>
<td>并行</td>
<td>新生代</td>
<td>复制算法</td>
<td>响应速度优先</td>
<td>多CPU环境时在Server模式下与CMS配合</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>并行</td>
<td>新生代</td>
<td>复制算法</td>
<td>吞吐量优先</td>
<td>在后台运算而不需要太多交互的任务</td>
</tr>
<tr>
<td>Parallel Old</td>
<td>并行</td>
<td>老年代</td>
<td>标记-整理	吞吐量优先</td>
<td>在后台运算而不需要太多交互的任务</td>
<td></td>
</tr>
<tr>
<td>CMS</td>
<td>并发</td>
<td>老年代</td>
<td>标记-清除</td>
<td>响应速度优先</td>
<td>集中在互联网站或B&#x2F;S系统服务端上的Java应用</td>
</tr>
<tr>
<td>G1</td>
<td>并发</td>
<td>both</td>
<td>标记-整理+复制算法</td>
<td>响应速度优先</td>
<td>面向服务端应用，将来替换CMS</td>
</tr>
</tbody></table>
<h6 id="附："><a href="#附：" class="headerlink" title="附："></a>附：</h6><pre><code> 1. `可达性`: GC Root可以到达此对象
 2. `并行执行`: 多个线程同时执行gc
 3. `并发执行`: 用户线程和GC线程同时执行
 
</code></pre>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-907fa5f1c490a4f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="G1.png"></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>zk使用</title>
    <url>/2020/03/20/java_zk%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="参考配置项"><a href="#参考配置项" class="headerlink" title="参考配置项"></a>参考配置项</h1><p><code>tickTime</code> 用于计算的时间单元、eg. session超时、N*tickTime<br><code>initLimit</code> 用于集群、允许从节点连接、并同步到master节点的初始化连接时间、以tickTime的倍数来表示<br><code>syncLimit</code> 用于集群、master主节点与从节点之间发送消息、请求和应答的时间长度(心跳机制)<br><code>dataDir</code> 数据文件目录、必须<br><code>dataLogDir</code> 日志目录、非必须、默认<code>dataDir</code><br><code>clientPort</code> 连接服务器的端口、默认 <code>2181</code></p>
<h1 id="client-连接"><a href="#client-连接" class="headerlink" title="client 连接"></a>client 连接</h1><p><code>zkCli.sh</code> 默认连接2181</p>
<h1 id="client-命令"><a href="#client-命令" class="headerlink" title="client 命令"></a>client 命令</h1><p><code>ls</code> 与linux下<code>ls</code>同义<br><code>ls</code> 等同于  <code>ls</code> + <code>stat</code><br><code>stat</code> 状态显示 zZxid zookeeper为数据分配的id pZxid 子节点的id<br><code>get</code> 查看节点数据<br><code>create</code> 创建节点 -e 临时节点<br><code>set</code> 修改节点数据<br><code>delete</code> 删除节点数据</p>
<h1 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h1><p>构成: scheme: 采用的权限机制<br>(word:anyone:[permissions] |<br>auth:user:password:[permissions] |<br>digest:user:BASE64(SHA1(pass)):[permissions])<br>(ip:192.168.1.1:[permission])<br>(super: 代表超管、拥有所有的权限)</p>
<p>id: 代表允许访问的机制 </p>
<p>permissons: 权限</p>
<p>权限字符缩写 crdwa<br>create: 创建子节点<br>read: 获取节点、子节点<br>write: 设置节点数据<br>delete: 删除子节点<br>admin: 设置权限</p>
<p><code>getAcl</code> 获取节点的acl权限信息<br><code>setAcl</code> 设置某个节点的acl权限信息<br><code>addAuth</code> 输入认证权限信息、注册时、输入明文密码(登录)、但在zk的系统里、是以密文存在的</p>
<h1 id="four-letter-cmd"><a href="#four-letter-cmd" class="headerlink" title="four letter cmd"></a>four letter cmd</h1><p><code>stat</code> 当前节点的状态信息<br><code>ruok</code> 当前节点是否ok<br><code>conf</code> 查看服务器相关的配置<br><code>cons</code> 展示连接到server的client信息<br><code>envi</code> 打印环境变量信息<br><code>mntr</code> 监控zk的健康信息<br><code>wchs</code> watcher的信息<br><code>wchc</code> session与watch对应关系信息<br><code>wchp</code> path与watch对应关系</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收---GC日志解读</title>
    <url>/2020/03/20/java_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6---GC%E6%97%A5%E5%BF%97%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<h4 id="年轻代log解读"><a href="#年轻代log解读" class="headerlink" title="年轻代log解读"></a>年轻代log解读</h4><p>年轻代以ParNew收集器为例, 采用的是复制算法, log如下：<br><img src="https://upload-images.jianshu.io/upload_images/14027542-4695c4709d665059.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span><span class="operator">-</span><span class="number">02</span><span class="operator">-</span><span class="number">01</span><span class="variable">T21</span><span class="operator">:</span><span class="number">18</span><span class="operator">:</span><span class="number">15</span><span class="operator">:</span><span class="number">00.382</span><span class="operator">+</span><span class="number">0800</span><span class="operator">:</span> <span class="number">718675.758</span><span class="operator">:</span> <span class="variable">Application</span> <span class="variable">time</span><span class="operator">:</span> <span class="number">0.7177964</span> <span class="variable">seconds</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="variable">Heap</span> <span class="variable">before</span> <span class="variable">GC</span> <span class="variable">invocations</span><span class="operator">=</span><span class="number">65632</span> <span class="punctuation">(</span><span class="variable">full</span> <span class="number">18</span><span class="punctuation">)</span><span class="operator">:</span></span><br><span class="line"> <span class="variable">par</span> <span class="variable">new</span> <span class="variable">generation</span>   <span class="variable">total</span> <span class="number">471872</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">used</span> <span class="number">421490</span><span class="built_in">K</span> <span class="punctuation">[</span><span class="number">0</span><span class="variable">x0000000080000000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x00000000a0000000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x00000000a0000000</span><span class="punctuation">)</span></span><br><span class="line">  <span class="variable">eden</span> <span class="variable">space</span> <span class="number">419456</span><span class="built_in">K</span><span class="operator">,</span> <span class="number">100</span><span class="operator">%</span> <span class="variable">used</span> <span class="punctuation">[</span><span class="number">0</span><span class="variable">x0000000080000000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x00000000999a0000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x00000000999a0000</span><span class="punctuation">)</span></span><br><span class="line">  <span class="variable">from</span> <span class="variable">space</span> <span class="number">52416</span><span class="built_in">K</span><span class="operator">,</span>   <span class="number">3</span><span class="operator">%</span> <span class="variable">used</span> <span class="punctuation">[</span><span class="number">0</span><span class="variable">x00000000999a0000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x0000000099b9c830</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x000000009ccd0000</span><span class="punctuation">)</span></span><br><span class="line">  <span class="variable">to</span>   <span class="variable">space</span> <span class="number">52416</span><span class="built_in">K</span><span class="operator">,</span>   <span class="number">0</span><span class="operator">%</span> <span class="variable">used</span> <span class="punctuation">[</span><span class="number">0</span><span class="variable">x000000009ccd0000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x000000009ccd0000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x00000000a0000000</span><span class="punctuation">)</span></span><br><span class="line"> <span class="variable">concurrent</span> <span class="variable">mark</span><span class="operator">-</span><span class="variable">sweep</span> <span class="variable">generation</span> <span class="variable">total</span> <span class="number">1572864</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">used</span> <span class="number">905696</span><span class="built_in">K</span> <span class="punctuation">[</span><span class="number">0</span><span class="variable">x00000000a0000000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x0000000100000000</span><span class="operator">,</span> <span class="number">0</span><span class="variable">x0000000100000000</span><span class="punctuation">)</span></span><br><span class="line"> <span class="variable">Metaspace</span>       <span class="variable">used</span> <span class="number">104594</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">capacity</span> <span class="number">113116</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">committed</span> <span class="number">113664</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">reserved</span> <span class="number">1148928</span><span class="built_in">K</span></span><br><span class="line">  <span class="variable">class</span> <span class="variable">space</span>    <span class="variable">used</span> <span class="number">12280</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">capacity</span> <span class="number">13738</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">committed</span> <span class="number">13824</span><span class="built_in">K</span><span class="operator">,</span> <span class="variable">reserved</span> <span class="number">1048576</span><span class="built_in">K</span></span><br><span class="line"></span><br><span class="line"><span class="number">2019</span><span class="operator">-</span><span class="number">02</span><span class="operator">-</span><span class="number">01</span><span class="variable">T18</span><span class="operator">:</span><span class="number">15</span><span class="operator">:</span><span class="number">00.383</span><span class="operator">+</span><span class="number">0800</span><span class="operator">:</span> <span class="number">718675.758</span><span class="operator">:</span> <span class="punctuation">[</span><span class="variable">GC</span> <span class="punctuation">(</span><span class="variable">Allocation</span> <span class="built_in">Failure</span><span class="punctuation">)</span> <span class="number">2019</span><span class="operator">-</span><span class="number">02</span><span class="operator">-</span><span class="number">01</span><span class="variable">T18</span><span class="operator">:</span><span class="number">15</span><span class="operator">:</span><span class="number">00.384</span><span class="operator">+</span><span class="number">0800</span><span class="operator">:</span> <span class="number">718675.759</span><span class="operator">:</span> <span class="punctuation">[</span><span class="variable">ParNew</span><span class="operator">:</span> <span class="number">109872</span><span class="built_in">K</span><span class="operator">-&gt;</span><span class="number">5255</span><span class="built_in">K</span><span class="punctuation">(</span><span class="number">118016</span><span class="built_in">K</span><span class="punctuation">)</span><span class="operator">,</span> <span class="number">0.0211147</span> <span class="variable">secs</span><span class="punctuation">]</span> <span class="number">142365</span><span class="built_in">K</span><span class="operator">-&gt;</span><span class="number">37748</span><span class="built_in">K</span><span class="punctuation">(</span><span class="number">511232</span><span class="built_in">K</span><span class="punctuation">)</span><span class="operator">,</span> <span class="number">0.0212949</span> <span class="variable">secs</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="built_in">Times</span><span class="operator">:</span> <span class="variable">user</span><span class="operator">=</span><span class="number">0.26</span> <span class="variable">sys</span><span class="operator">=</span><span class="number">0.04</span><span class="operator">,</span> <span class="variable">real</span><span class="operator">=</span><span class="number">0.02</span> <span class="variable">secs</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>其中:<br>*<code>Heap before GC invocations=65632 (full 18)</code>: <code> invocations=65632</code>表示经历的gc的次数 <code>full 18</code>表示经历的full gc的次数</p>
<ul>
<li><code>2019-02-01T18:15:00.383</code>：发生<code>minor gc</code>的时间</li>
<li><code>718675.758</code>：GC时、相对GVM启动时间的偏移量</li>
<li><code>ParNew</code> 收集器的名称 , 会<code>STW</code>(<a href="https://www.jianshu.com/p/d07194a20ec1">https://www.jianshu.com/p/d07194a20ec1</a>)</li>
<li><code>109872K-&gt;5255K</code>：收集前后年轻代的使用情况</li>
<li><code>118016K</code>：整个年轻代的容量</li>
<li><code>0.0211147 secs</code>： stw的时间</li>
<li><code>142365K-&gt;37748K</code>：GC前后整个堆的使用情况</li>
<li><code>511232K</code>：整个堆的容量</li>
<li><code>0.0212949 secs</code>：ParNew 收集器标记和复制年轻代活着的对象所花费的时间(包括和老年代通信的开销、对象晋升到老年代开销、垃圾收集周期结束一些最后的清理对象等的花销)</li>
<li><code>user</code>：GC 线程在垃圾收集期间所使用的 CPU 总时间</li>
<li><code>sys</code>：系统调用或者等待系统事件花费的时间</li>
<li><code>real</code>: 应用被暂停的时钟时间、由于GC是多线程的、<code>real</code>可能会<code>小于</code> <code>user+sys</code>, 如果是单线程的、real是接近 <code>user+sys</code>的时间的</li>
</ul>
<h4 id="CMS-log-大致解读"><a href="#CMS-log-大致解读" class="headerlink" title="CMS log 大致解读"></a>CMS log 大致解读</h4><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">233</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">148</span>:<span class="meta"> [GC [1 CMS-initial-mark: 6294851K(20971520K)] 6354687K(24746432K), 0.0466580 secs] [Times: user=0.04 sys=0.00, real=0.04 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">280</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">195</span>:<span class="meta"> [CMS-concurrent-mark-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">418</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">333</span>:<span class="meta"> [CMS-concurrent-mark: 0.138/0.138 secs] [Times: user=1.01 sys=0.21, real=0.14 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">418</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">334</span>:<span class="meta"> [CMS-concurrent-preclean-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">476</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">391</span>:<span class="meta"> [CMS-concurrent-preclean: 0.056/0.057 secs] [Times: user=0.20 sys=0.12, real=0.06 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">476</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">391</span>:<span class="meta"> [CMS-concurrent-abortable-preclean-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">29</span>.<span class="number">989</span>+<span class="number">0800</span>: <span class="number">15581</span>.<span class="number">905</span>:<span class="meta"> [CMS-concurrent-abortable-preclean: 3.506/3.514 secs] [Times: user=11.93 sys=6.77, real=3.51 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">29</span>.<span class="number">991</span>+<span class="number">0800</span>: <span class="number">15581</span>.<span class="number">906</span>:<span class="meta"> [GC[YG occupancy: 1805641 K (3774912 K)]2018-04-12T13:48:29.991+0800: 15581.906: [GC2018-04-12T13:48:29.991+0800: 15581.906: [ParNew: 1805641K-&gt;48395K(3774912K), 0.0826620 secs] 8100493K-&gt;6348225K(24746432K), 0.0829480 secs] [Times: user=0.81 sys=0.00, real=0.09 secs]2018-04-12T13:48:30.074+0800: 15581.989: [Rescan (parallel) , 0.0429390 secs]2018-04-12T13:48:30.117+0800: 15582.032: [weak refs processing, 0.0027800 secs]2018-04-12T13:48:30.119+0800: 15582.035: [class unloading, 0.0033120 secs]2018-04-12T13:48:30.123+0800: 15582.038: [scrub symbol table, 0.0016780 secs]2018-04-12T13:48:30.124+0800: 15582.040: [scrub string table, 0.0004780 secs] [1 CMS-remark: 6299829K(20971520K)] 6348225K(24746432K), 0.1365130 secs] [Times: user=1.24 sys=0.00, real=0.14 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">30</span>.<span class="number">128</span>+<span class="number">0800</span>: <span class="number">15582</span>.<span class="number">043</span>:<span class="meta"> [CMS-concurrent-sweep-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">36</span>.<span class="number">638</span>+<span class="number">0800</span>: <span class="number">15588</span>.<span class="number">553</span>:<span class="meta"> [GC2018-04-12T13:48:36.638+0800: 15588.554: [ParNew: 3403915K-&gt;52142K(3774912K), 0.0874610 secs] 4836483K-&gt;1489601K(24746432K), 0.0877490 secs] [Times: user=0.84 sys=0.00, real=0.09 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">38</span>.<span class="number">412</span>+<span class="number">0800</span>: <span class="number">15590</span>.<span class="number">327</span>:<span class="meta"> [CMS-concurrent-sweep: 8.193/8.284 secs] [Times: user=30.34 sys=16.44, real=8.28 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">38</span>.<span class="number">419</span>+<span class="number">0800</span>: <span class="number">15590</span>.<span class="number">334</span>:<span class="meta"> [CMS-concurrent-reset-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">38</span>.<span class="number">462</span>+<span class="number">0800</span>: <span class="number">15590</span>.<span class="number">377</span>:<span class="meta"> [CMS-concurrent-reset: 0.044/0.044 secs] [Times: user=0.15 sys=0.10, real=0.04 secs]</span></span><br></pre></td></tr></table></figure>
<p>由于CMS涉及的阶段比较多、分阶段来说下~</p>
<h5 id="初始标记-initial-mark阶段"><a href="#初始标记-initial-mark阶段" class="headerlink" title="初始标记 initial mark阶段"></a>初始标记 initial mark阶段</h5><p><code>STW</code>中的一次、为了标记直接被<code>GC root引用</code>或者<code>年轻代</code> <code>存活对象引用</code>的所有对象(<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep">https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep</a>)<br><img src="https://upload-images.jianshu.io/upload_images/14027542-550f1b5ef67f99d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>上述示例的对应信息为：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">233</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">148</span>:<span class="meta"> [GC [1 CMS-initial-mark: 6294851K(20971520K)] 6354687K(24746432K), 0.0466580 secs] [Times: user=0.04 sys=0.00, real=0.04 secs]</span></span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>2018-04-12T13:48:26.233+0800</code>：GC开始时间(同 ParNew收集器)</li>
<li><code>15578.148</code>：JVM运行时间(同 ParNew收集器)</li>
<li><code>CMS-initial-mark</code>：CMS当前阶段(这里代表 <code>初始标记</code>)</li>
<li><code>6294851K</code>：当前老年代使用的容量</li>
<li><code>(20971520K)</code>：老年代可使用的最大容量</li>
<li><code>6354687K</code>：整个堆目前使用的情况</li>
<li><code>(24746432K)</code>：整个堆当前可用情况</li>
<li><code>0.0466580 secs</code>：该阶段持续时间</li>
<li><code>[Times: user=0.04 sys=0.00, real=0.04 secs]</code> 同 <code>ParNew</code>收集器</li>
</ul>
<h5 id="并发标记阶段-Concurrent-Mark"><a href="#并发标记阶段-Concurrent-Mark" class="headerlink" title="并发标记阶段(Concurrent Mark)"></a>并发标记阶段(Concurrent Mark)</h5><p>遍历老年代，然后标记所有存活的对象、会根据上个阶段找到的 GC Roots 遍历查找，与用户的应用程序<code>并发运行</code><br><code>注意</code>不是所有的老年代存活对象都会被标记、因为在标记期间引用关系可能会发生改变(<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep)%E3%80%81">https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep)、</a><br><img src="https://upload-images.jianshu.io/upload_images/14027542-b3d7a48abe067d6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>与上图对比可用发现已经有一个对象的引用关系发生了改变</p>
<p>本阶段log如下：</p>
<blockquote>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">&gt;<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">26</span>.<span class="number">280+0800</span>: <span class="number">15578.195</span>: [CMS-concurrent-mark-start]</span><br><span class="line">&gt;<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">26</span>.<span class="number">418+0800</span>: <span class="number">15578.333</span>: [CMS-concurrent-mark: <span class="number">0.138/0.138</span> secs] [Times: user=<span class="number">1</span>.<span class="number">01</span> sys=<span class="number">0</span>.<span class="number">21</span>, real=<span class="number">0</span>.<span class="number">14</span> secs]</span><br></pre></td></tr></table></figure>
<ul>
<li><code>CMS-concurrent-mark</code>: <code>并发收集</code>阶段, 遍历老年代、标记所有存活对象</li>
<li><code>0.138/0.138 secs</code>这个阶段的<code>持续时间</code>与<code>时钟时间</code></li>
<li><code>[Times: user=1.01 sys=0.21, real=0.14 secs]</code>：同上、但是从并发标记的开始时间计算的、期间是并发进行、所以参考意义不大(包含的不仅仅是gc线程的工作)</li>
</ul>
</blockquote>
<h5 id="并发预清理-concurrent-preclean"><a href="#并发预清理-concurrent-preclean" class="headerlink" title="并发预清理(concurrent preclean)"></a>并发预清理(concurrent preclean)</h5><p>也是一个并发阶段，与应用的线程<code>并发运行</code>，<code>不会 stop </code>应用的线程<br>在并发运行的过程中、一些对象的引用可能会发生变化、发生这种情况时、jvm会将这个对象的区域<code>Card</code>标记为<code>Dirty</code>，也就是<code>Card Marking</code></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-c040c645b1abbe18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>在 <code>preclean</code>阶段、能够从Dirty对象可到达的对象也会被标记、标记完成之后、<code>Dirty Card</code>就会被清除了、<br><img src="https://upload-images.jianshu.io/upload_images/14027542-2fd204c365b46807.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>这个阶段的log如下：</p>
<blockquote>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">418</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">334</span>:<span class="meta"> [CMS-concurrent-preclean-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">26</span>.<span class="number">476</span>+<span class="number">0800</span>: <span class="number">15578</span>.<span class="number">391</span>:<span class="meta"> [CMS-concurrent-preclean: 0.056/0.057 secs] [Times: user=0.20 sys=0.12, real=0.06 secs]</span></span><br></pre></td></tr></table></figure>
<p><code>CMS-concurrent-preclean</code> 阶段名称、对前边并发标记阶段中引用发生变化的对象进行标记<br><code>0.056/0.057 secs</code> 这个阶段持续的时间与时钟时间<br><code>[Times: user=0.20 sys=0.12, real=0.06 secs]</code> 同<code>并发标记</code>阶段</p>
</blockquote>
<h5 id="可中止的并发预清理-Concurrent-Abortable-Preclean"><a href="#可中止的并发预清理-Concurrent-Abortable-Preclean" class="headerlink" title="可中止的并发预清理(Concurrent Abortable Preclean)"></a>可中止的并发预清理(Concurrent Abortable Preclean)</h5><p><code>并发</code> &amp; <code>不影响</code>用户线程, 是为了 尽量承担STW中的最终标记阶段的工作， 这个阶段是在重复做很多相同的工作，直接满足一些条件（比如：重复迭代的次数、完成的工作量或者时钟时间等）<br>log如下：</p>
<blockquote>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">&gt;<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">26</span>.<span class="number">476+0800</span>: <span class="number">15578.391</span>: [CMS-concurrent-abortable-preclean-start]</span><br><span class="line">&gt;<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">29</span>.<span class="number">989+0800</span>: <span class="number">15581.905</span>: [CMS-concurrent-abortable-preclean: <span class="number">3.506/3</span>.<span class="number">514</span> secs] [Times: user=<span class="number">11</span>.<span class="number">93</span> sys=<span class="number">6</span>.<span class="number">77</span>, real=<span class="number">3</span>.<span class="number">51</span> secs]</span><br></pre></td></tr></table></figure>
<p><code>CMS-concurrent-abortable-preclean</code>阶段名称<br><code>3.506/3.514 secs</code>通常在<code>5s</code>左右、<br><code>[Times: user=11.93 sys=6.77, real=3.51 secs]</code>同预清理阶段<br>主要做了两件事：</p>
</blockquote>
<ul>
<li>处理 From 和 To 区的对象，标记可达的老年代对象</li>
<li>和上一个阶段一样，扫描处理Dirty Card中的对象</li>
</ul>
<p>具体执行多久，取决于许多因素，满足其中一个条件将会中止运行：</p>
<ul>
<li>执行循环次数达到了阈值</li>
<li>执行时间达到了阈值</li>
<li>新生代Eden区的内存使用率达到了阈值</li>
</ul>
<h5 id="最终标记阶段-Final-Remark"><a href="#最终标记阶段-Final-Remark" class="headerlink" title="最终标记阶段(Final Remark)"></a>最终标记阶段(Final Remark)</h5><p>第二个 <code>STW </code>阶段, 也是最后一个、目标是标记所有老年代所有的存活对象，由于之前的阶段是并发执行的，gc 线程可能跟不上应用程序的变化，为了完成标记老年代所有存活对象的目标，STW 就非常有必要了， 通常 CMS 的 Final Remark 阶段会在年轻代尽可能干净的时候运行，目的是为了减少连续 STW 发生的可能性（年轻代存活对象过多的话，也会导致老年代涉及的存活对象会很多）。这个阶段会比前面的几个阶段更复杂一些，相关日志如下：</p>
<blockquote>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">&gt;<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">29</span>.<span class="number">991+0800</span>: <span class="number">15581.906</span>: </span><br><span class="line">&gt;[GC[YG occupancy: <span class="number">1805641</span> K (<span class="number">3774912</span> K)]<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">29</span>.<span class="number">991+0800</span>: <span class="number">15581.906</span>: [GC20<span class="number">18-04-12T13</span>:<span class="number">48:29.991</span>+<span class="number">0800</span>: <span class="number">15581.906</span>: [ParNew: <span class="number">1805641</span>K-&gt;<span class="number">48395</span>K(<span class="number">3774912</span>K), <span class="number">0.0826620</span> secs] <span class="number">8100493</span>K-&gt;<span class="number">6348225</span>K(<span class="number">24746432</span>K), <span class="number">0.0829480</span> secs] [Times: user=<span class="number">0</span>.<span class="number">81</span> sys=<span class="number">0</span>.<span class="number">00</span>, real=<span class="number">0</span>.<span class="number">09</span> secs]<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">30</span>.<span class="number">074+0800</span>: <span class="number">15581.989</span>: [Rescan (parallel) , <span class="number">0.0429390</span> secs]<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">30.117+0800</span>: <span class="number">15582.032</span>: [weak refs processing, <span class="number">0.0027800</span> secs]<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">30.119+0800</span>: <span class="number">15582.035</span>: [class unloading, <span class="number">0.0033120</span> secs]<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">30.123+0800</span>: <span class="number">15582.038</span>: [scrub symbol table, <span class="number">0.0016780</span> secs]<span class="number">2018</span>-<span class="number">04-12T13:48</span>:<span class="number">30.124+0800</span>: <span class="number">15582.040</span>: [scrub string table, <span class="number">0.0004780</span> secs] [<span class="number">1</span> CMS-remark: <span class="number">6299829</span>K(<span class="number">20971520</span>K)] <span class="number">6348225</span>K(<span class="number">24746432</span>K), <span class="number">0.1365130</span> secs] [Times: user=<span class="number">1</span>.<span class="number">24</span> sys=<span class="number">0</span>.<span class="number">00</span>, real=<span class="number">0</span>.<span class="number">14</span> secs]</span><br></pre></td></tr></table></figure>
<p><code>YG occupancy: 1805641 K (3774912 K)</code> 年轻代当前占用量及容量<br><code>ParNew:...</code>触发了一次<code>young gc</code>, 触发的原因是为了减少 年轻代的存活对象、尽量是年前代干净一些<br><code>[Rescan (parallel) , 0.0429390 secs]</code> 这个 Rescan 是当应用暂停的情况下完成对所有存活对象的标记，这个阶段是<code>并行</code>处理的，这里花费了 0.0429390s<br><code>[weak refs processing, 0.0027800 secs]</code> 第一个子阶段，它的工作是处理弱引用<br><code>[class unloading, 0.0033120 secs]</code> 删除无用class<br><code>[scrub symbol table, 0.0016780 secs] ... [scrub string table, 0.0004780 secs]</code> 最后一个子阶段, cleaning up symbol and string tables which hold class-level metadata and internalized string respectively<br><code>6299829K(20971520K)</code> 这个阶段之后，老年代的使用量与总量<br><code>6348225K(24746432K)</code>这个阶段后，堆的使用量与总量<br><code>0.1365130 secs</code>阶段持续时长<br><code>[Times: user=1.24 sys=0.00, real=0.14 secs]</code>对应时间信息</p>
</blockquote>
<h5 id="并发清理-Concurrent-Sweep"><a href="#并发清理-Concurrent-Sweep" class="headerlink" title="并发清理(Concurrent Sweep)"></a>并发清理(Concurrent Sweep)</h5><p>不需要 STW，它是与用户的应用程序<code>并发运行</code>, 清除那些不再使用的对象，回收它们的占用空间为将来使用(<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep">https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep</a>)<br><img src="https://upload-images.jianshu.io/upload_images/14027542-d560490b0613a37e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>log如下(这中间又发生了一次 Young GC)：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">30</span>.<span class="number">128</span>+<span class="number">0800</span>: <span class="number">15582</span>.<span class="number">043</span>:<span class="meta"> [CMS-concurrent-sweep-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">36</span>.<span class="number">638</span>+<span class="number">0800</span>: <span class="number">15588</span>.<span class="number">553</span>:<span class="meta"> [GC2018-04-12T13:48:36.638+0800: 15588.554: [ParNew: 3403915K-&gt;52142K(3774912K), 0.0874610 secs] 4836483K-&gt;1489601K(24746432K), 0.0877490 secs] [Times: user=0.84 sys=0.00, real=0.09 secs]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">38</span>.<span class="number">412</span>+<span class="number">0800</span>: <span class="number">15590</span>.<span class="number">327</span>:<span class="meta"> [CMS-concurrent-sweep: 8.193/8.284 secs] [Times: user=30.34 sys=16.44, real=8.28 secs]</span></span><br></pre></td></tr></table></figure>
<p>*<code>CMS-concurrent-sweep</code> 阶段名称: 主要是清除那些没有被标记的对象，回收它们的占用空间</p>
<ul>
<li><code>8.193/8.284 secs</code> 这个阶段的持续时间与时钟时间</li>
<li><code>[Times: user=30.34 sys=16.44, real=8.28 secs]</code> 同上</li>
</ul>
<h5 id="并发重置-Concurrent-Reset"><a href="#并发重置-Concurrent-Reset" class="headerlink" title="并发重置(Concurrent Reset)"></a>并发重置(Concurrent Reset)</h5><p>这个阶段也是并发执行的，它会重设 CMS 内部的数据结构，为下次的 GC 做准备</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">38</span>.<span class="number">419</span>+<span class="number">0800</span>: <span class="number">15590</span>.<span class="number">334</span>:<span class="meta"> [CMS-concurrent-reset-start]</span></span><br><span class="line"><span class="attribute">2018</span>-<span class="number">04</span>-<span class="number">12</span>T13:<span class="number">48</span>:<span class="number">38</span>.<span class="number">462</span>+<span class="number">0800</span>: <span class="number">15590</span>.<span class="number">377</span>:<span class="meta"> [CMS-concurrent-reset: 0.044/0.044 secs] [Times: user=0.15 sys=0.10, real=0.04 secs]</span></span><br></pre></td></tr></table></figure>
<p>*<code>CMS-concurrent-reset</code> 阶段名称</p>
<ul>
<li><code>0.044/0.044 secs</code> 这个阶段的持续时间与时钟时间</li>
<li><code>[Times: user=0.15 sys=0.10, real=0.04 secs]</code> 同上</li>
</ul>
<h4 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h4><p>CMS 通过将大量工作分散到并发处理阶段来在减少 STW 时间，在这块做得非常优秀，但是 CMS 也有一些其他的问题：</p>
<ul>
<li>CMS 收集器无法处理浮动垃圾（ Floating Garbage），可能出现 “Concurrnet Mode Failure” 失败而导致另一次 Full GC 的产生，可能引发串行 Full GC；</li>
<li>空间碎片，导致无法分配大对象，CMS 收集器提供了一个 -XX:+UseCMSCompactAtFullCollection 开关参数（默认就是开启的），用于在 CMS 收集器顶不住要进行 Full GC 时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长；</li>
<li>对于堆比较大的应用上，GC 的时间难以预估</li>
</ul>
<p>so. G1开始兴起、</p>
<blockquote>
<ul>
<li>由于<code>G1</code>采用复制算法、很好的避免了 <code>空间碎片</code></li>
<li>采用region分区思想、解决了停顿时长可控</li>
<li>不过貌似并没有从根源上解决 浮动垃圾的问题~~</li>
</ul>
</blockquote>
<h4 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h4><ul>
<li><a href="http://matt33.com/2018/07/28/jvm-cms/">http://matt33.com/2018/07/28/jvm-cms/</a></li>
<li><a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep">https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep</a></li>
<li><a href="https://zhanjia.iteye.com/blog/2435266">https://zhanjia.iteye.com/blog/2435266</a><br>等</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收---JDK监控工具</title>
    <url>/2020/03/20/java_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6---JDK%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h4 id="JDK监控工具"><a href="#JDK监控工具" class="headerlink" title="JDK监控工具"></a>JDK监控工具</h4><p><code>jps</code>: JVM Process Status Tool. 显示指定系统内所有HotSpot vm 进程<br><code>jstat</code>: JVM statistic Monitor Tool. 用于收集vm各方面的运行数据<br><code>jinfo</code>: Configuration Info For Java. 显示虚拟机配置信息<br><code>jmap</code>: Memory Map For Java. 生成内存转储快照文件(headdump文件)<br><code>jhat</code>: JVM Head Dump Browser. 用于分析dump文件、<br><code>jstack</code>: 显示虚拟机的线程快照</p>
<h4 id="jps"><a href="#jps" class="headerlink" title="jps"></a><code>jps</code></h4><p><code>usage</code>: <code>jps [opt] [hostid]</code></p>
<blockquote>
<p><code>-q</code> 只输出LVMID 省略主类的名称<br><code>-m</code> 输出虚拟机的进程启动时传递给主类函数的参数<br><code>-l</code> 输出主类的全名、若主类注销的是jar包、输出jar包路径<br><code>-v</code> 输出虚拟机启动时的jvm参数</p>
</blockquote>
<h4 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a><code>jstat</code></h4><p><code>usage</code>: <code>jstat [opt vmid [interval][s|ms] [count]]</code></p>
<blockquote>
<p><code>-class</code> 监视类装载、卸载数量、总空间及类装载所需时间<br><code>-gc</code> 监视Java堆情况、包括Eden区、两个Survivor区、老年代、永久代的容量、已用空间、GC时间合计等信息<br><code>-gccapacity</code> 监视内容与<code>-gc</code>基本相同、主要关注java堆各个区域用到的最大、最小空间<br><code>-gcutil</code>  监视内容与<code>-gc</code>基本相同、主要关注已使用空间与总空间的比率<br><code>-gccause</code> 与<code>-gcutil</code>相同、会额外输出导致上次gc的原因<br><code>-gcnew</code> 监视新生代gc的状况<br><code>-gcnewcapacity</code> 与<code>gcnew</code>基本相同、输出主要关注最大、最小空间<br><code>-gcold</code> 监视老年代gc的状况<br><code>-gcoldcapacity</code> 与<code>gcold</code>基本相同、输出主要关注最大、最小空间<br><code>-gcpermcapacity</code> 输出永久代最大、最小空间<br><code>-compiler</code>  输出jit编译过的方法、耗时等信息<br><code>-printcompalition</code> 输出已被编译过的方法</p>
</blockquote>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">eg</span>. jstat -gcutil  <span class="number">41610</span> <span class="number">250</span> <span class="number">3</span></span><br><span class="line">  <span class="attribute">S0</span>     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line">  <span class="attribute">0</span>.<span class="number">00</span>   <span class="number">0</span>.<span class="number">00</span>   <span class="number">4</span>.<span class="number">00</span>   <span class="number">0</span>.<span class="number">43</span>  <span class="number">62</span>.<span class="number">81</span>  <span class="number">65</span>.<span class="number">59</span>      <span class="number">1</span>    <span class="number">0</span>.<span class="number">002</span>     <span class="number">1</span>    <span class="number">0</span>.<span class="number">006</span>    <span class="number">0</span>.<span class="number">008</span></span><br><span class="line">  <span class="attribute">0</span>.<span class="number">00</span>   <span class="number">0</span>.<span class="number">00</span>   <span class="number">4</span>.<span class="number">00</span>   <span class="number">0</span>.<span class="number">43</span>  <span class="number">62</span>.<span class="number">81</span>  <span class="number">65</span>.<span class="number">59</span>      <span class="number">1</span>    <span class="number">0</span>.<span class="number">002</span>     <span class="number">1</span>    <span class="number">0</span>.<span class="number">006</span>    <span class="number">0</span>.<span class="number">008</span></span><br><span class="line">  <span class="attribute">0</span>.<span class="number">00</span>   <span class="number">0</span>.<span class="number">00</span>   <span class="number">4</span>.<span class="number">00</span>   <span class="number">0</span>.<span class="number">43</span>  <span class="number">62</span>.<span class="number">81</span>  <span class="number">65</span>.<span class="number">59</span>      <span class="number">1</span>    <span class="number">0</span>.<span class="number">002</span>     <span class="number">1</span>    <span class="number">0</span>.<span class="number">006</span>    <span class="number">0</span>.<span class="number">008</span></span><br><span class="line"><span class="attribute">S0</span>: survivor0区、都是空的</span><br><span class="line"><span class="attribute">S1</span>: survivor0区、都是空的</span><br><span class="line"><span class="attribute">E</span>: Eden区、<span class="number">4</span>%的使用率</span><br><span class="line"><span class="attribute">O</span>: Old区、<span class="number">0</span>.<span class="number">43</span>%的使用率</span><br><span class="line"><span class="attribute">M</span>:Perm区、<span class="number">62</span>.<span class="number">81</span>%的使用率</span><br><span class="line"><span class="attribute">CCS</span>: class Space、 <span class="number">65</span>.<span class="number">59</span>%的使用率</span><br><span class="line"><span class="attribute">YGC</span>: young gc、<span class="number">1</span>次</span><br><span class="line"><span class="attribute">YGCT</span>： young gc 耗时 <span class="number">0</span>.<span class="number">002</span>s</span><br><span class="line"><span class="attribute">FGC</span>: full gc <span class="number">1</span>次</span><br><span class="line"><span class="attribute">FGCT</span>: full  gc 耗时 <span class="number">0</span>.<span class="number">006</span>s</span><br><span class="line"><span class="attribute">GCT</span>: 总的gc耗时 <span class="number">0</span>.<span class="number">008</span>s</span><br></pre></td></tr></table></figure>

<h4 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a><code>jinfo</code></h4><p><code>usage</code> : <code>jinfo [opt] pid</code></p>
<blockquote>
<p>实时查看和调整虚拟机启动参数<br>eg.  jinfo -flag CMSInitiatingOccupancyFraction 41610<br>使用<code> [+|-] name</code> 修改一部分运行时虚拟机参数值<br>也可以使用 <code>jps -v</code> 来查看启动时默认参数<br><code>-XX:+PrintFlagsFinal</code> 可以将参数打印出来</p>
</blockquote>
<h4 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a><code>jmap</code></h4><blockquote>
<p><code>-dump</code> 生成快照文件<br>eg. jmap -dump:format&#x3D;b, file&#x3D;path pid<br><code>-finalizerinfo</code> 线上在F-Queue中等等Finalizer线程执行finalize方法的对象<br><code>-heap</code> 线上Java堆详细信息<br><code>-histo</code> 显示堆中对象的统计信息<br><code>-permstat</code> 以classLoader为统计路径、显示永久代内存使用情况<br><code>-F</code> 虚拟机不响应-dump时、使用-F强制生成dump文件</p>
</blockquote>
<figure class="highlight tcl"><table><tr><td class="code"><pre><span class="line">jmap -histo[:live] <span class="keyword">pid</span> 显示堆中活跃对象</span><br><span class="line">jmap -dump:[live,], <span class="keyword">file</span>=<span class="keyword">filename</span> 生成java堆</span><br></pre></td></tr></table></figure>

<h4 id="jhat"><a href="#jhat" class="headerlink" title="jhat"></a><code>jhat</code></h4><p><code>Usage:</code> <code>jhat -port 9000 dump-file</code></p>
<blockquote>
<p><code>-port</code> 指定端口<br>分析结果以<code>包</code>为单位、分析内存泄露时、可能会用到 Heap Histogram(与 jmap -histo 功能一致)</p>
</blockquote>
<h4 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h4><p><code>stack trace for java</code>生成虚拟机当前时刻的快照<br><code>Usage</code>: <code>jstack opt vmid</code></p>
<blockquote>
<p><code>-F</code> 正常的输出请求不被响应时、强制输出线程堆栈<br><code>-l</code> 除堆栈外、显示线程的锁信息<br><code>-m</code> 若调用本地方法、显示C&#x2F;C++的线程堆栈</p>
</blockquote>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收---JVM参数小记</title>
    <url>/2020/03/20/java_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6---JVM%E5%8F%82%E6%95%B0%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[<h4 id="JVM参数解析"><a href="#JVM参数解析" class="headerlink" title="JVM参数解析"></a>JVM参数解析</h4><table>
<thead>
<tr>
<th>参数名称</th>
<th>含义</th>
<th>默认值</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-Xms</td>
<td>初始堆大小</td>
<td>物理内存的1&#x2F;64(&lt;1G)</td>
<td>默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制.</td>
</tr>
<tr>
<td>-Xmx</td>
<td>最大堆大小</td>
<td>物理内存的1&#x2F;4(&lt;1G)</td>
<td>默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制</td>
</tr>
<tr>
<td>-Xmn</td>
<td>年轻代大小</td>
<td></td>
<td><code>注意</code>：此处的大小是（eden+ 2 survivor space)与jmap -heap中显示的New gen是不同的。 整个堆大小&#x3D;年轻代大小 + 年老代大小 + 持久代大小.增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3&#x2F;8</td>
</tr>
<tr>
<td>-Xss</td>
<td>每个线程的堆栈大小</td>
<td></td>
<td>JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.更具应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右，一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（较长）和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:””Xss is translated in a VM flag named ThreadStackSize”一般设置这个值就可以了。</td>
</tr>
<tr>
<td>-XX:NewRatio</td>
<td>年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代)</td>
<td></td>
<td>-XX:NewRatio&#x3D;4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1&#x2F;5 Xms&#x3D;Xmx并且设置了Xmn的情况下，该参数不需要进行设置。</td>
</tr>
<tr>
<td>-XX:SurvivorRatio</td>
<td>Eden区与Survivor区的大小比值</td>
<td></td>
<td>设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1&#x2F;10</td>
</tr>
<tr>
<td>-XX:MaxTenuringThreshold</td>
<td>垃圾年龄的最大值</td>
<td></td>
<td>如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率 该参数只有在串行GC时才有效</td>
</tr>
<tr>
<td>-XX:PretenureSizeThreshold</td>
<td>对象超过多大是直接在老年代分配</td>
<td>0</td>
<td>单位字节 新生代采用Parallel Scavenge GC时无效，另一种直接在老年代分配的情况是大的数组对象,且数组中无外部引用对象.</td>
</tr>
<tr>
<td>-XX:LargePageSizeInBytes</td>
<td>内存页的大小不可设置过大， 会影响Perm的大小</td>
<td></td>
<td>&#x3D;128m</td>
</tr>
<tr>
<td>-XX:+CollectGen0First</td>
<td>FullGC时是否先YGC</td>
<td>false</td>
<td></td>
</tr>
<tr>
<td>-XX:+UseFastAccessorMethods</td>
<td>原始类型的快速优化</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:+UseBiasedLocking</td>
<td>锁机制的性能改善</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:NewSize</td>
<td>年轻代大小(JDK 1.3&#x2F;1.4)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:MaxNewSize</td>
<td>年轻代最大值(JDK 1.3&#x2F;1.4)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:PermSize</td>
<td>设置持久代(perm gen)初始值</td>
<td>物理内存的1&#x2F;64</td>
<td></td>
</tr>
<tr>
<td>-XX:MaxPermSize</td>
<td>设置持久代最大值</td>
<td>物理内存的1&#x2F;4</td>
<td></td>
</tr>
<tr>
<td>-XX:ThreadStackSize</td>
<td>Thread Stack Size</td>
<td></td>
<td>(0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.]</td>
</tr>
<tr>
<td>-XX:+AggressiveOpts</td>
<td>加快编译</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h5 id="并行收集器相关参数"><a href="#并行收集器相关参数" class="headerlink" title="并行收集器相关参数"></a>并行收集器相关参数</h5><table>
<thead>
<tr>
<th>参数名称</th>
<th>含义</th>
<th>默认值</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-XX:+UseParallelGC</td>
<td>Full GC采用parallel MSC(此项待验证)</td>
<td></td>
<td>选择垃圾收集器为并行收集器.此配置仅对年轻代有效.即上述配置下,年轻代使用并发收集,而年老代仍旧使用串行收集.(此项待验证)</td>
</tr>
<tr>
<td>-XX:+UseParNewGC</td>
<td>设置年轻代为并行收集</td>
<td></td>
<td>可与CMS收集同时使用, JDK5.0以上,JVM会根据系统配置自行设置,所以无需再设置此值</td>
</tr>
<tr>
<td>-XX:ParallelGCThreads</td>
<td>并行收集器的线程数</td>
<td></td>
<td>此值最好配置与处理器数目相等 同样适用于CMS</td>
</tr>
<tr>
<td>-XX:+UseParallelOldGC</td>
<td>年老代垃圾收集方式为并行收集(Parallel Compacting)</td>
<td></td>
<td>java6开始出现的参数</td>
</tr>
<tr>
<td>-XX:MaxGCPauseMillis</td>
<td>每次年轻代垃圾回收的最长时间(最大暂停时间)</td>
<td></td>
<td>如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值.</td>
</tr>
<tr>
<td>-XX:+UseAdaptiveSizePolicy</td>
<td>自动选择年轻代区大小和相应的Survivor区比例</td>
<td></td>
<td>设置此选项后,并行收集器会自动选择年轻代区大小和相应的Survivor区比例,以达到目标系统规定的最低相应时间或者收集频率等,此值建议使用并行收集器时,一直打开.</td>
</tr>
<tr>
<td>-XX:GCTimeRatio</td>
<td>设置垃圾回收时间占程序运行时间的百分比</td>
<td></td>
<td>公式为1&#x2F;(1+n)</td>
</tr>
<tr>
<td>-XX:+ScavengeBeforeFullGC</td>
<td>Full GC前调用YGC</td>
<td>true</td>
<td>Do young generation GC prior to a full GC. (Introduced in 1.4.1.)</td>
</tr>
</tbody></table>
<h5 id="CMS相关参数"><a href="#CMS相关参数" class="headerlink" title="CMS相关参数"></a>CMS相关参数</h5><table>
<thead>
<tr>
<th>参数名称</th>
<th>含义</th>
<th>默认值</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-XX:+UseConcMarkSweepGC</td>
<td>使用CMS内存收集</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:CMSFullGCsBeforeCompaction</td>
<td>多少次后进行内存压缩</td>
<td></td>
<td>由于并发收集器不对内存空间进行压缩,整理,所以运行一段时间以后会产生”碎片”,使得运行效率降低.设置运行多少次GC以后对内存空间进行压缩,整理</td>
</tr>
<tr>
<td>-XX:+CMSParallelRemarkEnabled</td>
<td>降低标记停顿</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX+UseCMSCompactAtFullCollection</td>
<td>在FULL GC的时候，对年老代进行压缩</td>
<td></td>
<td>CMS是不会移动内存的， 因此， 这个非常容易产生碎片， 导致内存不够用， 因此， 内存的压缩这个时候就会被启用</td>
</tr>
<tr>
<td>-XX:+UseCMSInitiatingOccupancyOnly</td>
<td>使用手动定义初始化定义开始CMS收集</td>
<td></td>
<td>禁止hostspot自行触发CMS GC</td>
</tr>
<tr>
<td>-XX:CMSInitiatingOccupancyFraction&#x3D;70</td>
<td>使用cms作为垃圾回收使用70％后开始CMS收集</td>
<td>92</td>
<td>为了保证不出现promotion failed错误、设置需要满足：<a href="http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html#CMSInitiatingOccupancyFraction_value">http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html#CMSInitiatingOccupancyFraction_value</a></td>
</tr>
<tr>
<td>-XX:CMSInitiatingPermOccupancyFraction</td>
<td>设置Perm Gen使用到达多少比率时触发</td>
<td>92</td>
<td></td>
</tr>
<tr>
<td>-XX:+CMSIncrementalMode</td>
<td>设置为增量模式</td>
<td></td>
<td>适用于单CPU的情况</td>
</tr>
</tbody></table>
<h5 id="辅助信息"><a href="#辅助信息" class="headerlink" title="辅助信息"></a>辅助信息</h5><table>
<thead>
<tr>
<th>参数名称</th>
<th>含义</th>
<th>默认值</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-XX:+PrintGC</td>
<td></td>
<td></td>
<td>[GC 118250K-&gt;113543K(130112K), 0.0094143 secs]</td>
</tr>
</tbody></table>
<pre><code>               [Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] | 
</code></pre>
<p>|-XX:+PrintGCDetails| | | 输出形式:[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs] [GC [ParNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs]|<br>|-XX:+PrintGCTimeStamps| | | 输出每个阶段的gc时间|<br>|-XX:+PrintGCApplicationStoppedTime|打印垃圾回收期间程序暂停的时间.可与上面混合使用| | 输出形式:Total time for which application threads were stopped: 0.0468229 seconds|<br>|-XX:+PrintGCApplicationConcurrentTime|打印每次垃圾回收前,程序未中断的执行时间.可与上面混合使用| |输出形式:Application time: 0.5291524 seconds |<br>|-XX:+PrintHeapAtGC|打印GC前后的详细堆栈信息| | |<br>|-Xloggc:filename|把相关日志信息记录到文件以便分析.与上面几个配合使用 | | |<br>|-XX:+PrintTLAB|查看TLAB空间的使用情况| | |<br>|-XX:+PrintTenuringDistribution|查看每次minor GC后新的存活周期的阈值| | Desired survivor size 1048576 bytes, new threshold 7 (max 15) new threshold 7即标识新的存周期的阈值为7|</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收---Java类型引用</title>
    <url>/2020/03/20/java_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6---Java%E7%B1%BB%E5%9E%8B%E5%BC%95%E7%94%A8/</url>
    <content><![CDATA[<p>Java垃圾回收的依据是：是否还有引用.</p>
<h5 id="什么是引用呢-？"><a href="#什么是引用呢-？" class="headerlink" title="什么是引用呢 ？"></a>什么是引用呢 ？</h5><p>jdk1.2 之前的定义是：</p>
<blockquote>
<p>若reference类型的数据中存储的数值代表一块内存的起始地址、则这块内存代表一个引用</p>
</blockquote>
<p>jdk1.2 之后进行了扩充：</p>
<blockquote>
<p>分为<code>强引用</code>、<code>软引用</code>、<code>若引用</code>、<code>虚引用</code>.</p>
</blockquote>
<p>如何定义 ？<br><code>强引用 (strong reference)</code>: 程序代码中普遍存在的、类似 <code>Object obj = new Object()</code> 这类的引用， 只要引用还在、永远不会被回收掉的对象</p>
<p><code>软引用 (soft reference)</code>：描述一些还有用、但不是必须的对象. 软引用关联的对象、在系统将要发生<code>OOM</code>前会对这些对象进行一次回收、若回收能够产生足够的空间、则不会发生<code>OOM</code>， 回收完成依然没有足够的空间才会抛出<code>OOM</code>异常, <code>JDK1.2</code>之后、系统提供了<code>SoftReference</code>来实现软引用</p>
<p><code>弱引用 (weak reference)</code>: 也是非必须对象、比软引用的引用更弱一些、被弱引用关联的对象只能生存到下次gc发生之前、当垃圾收集器工作时、无论当前内存是否足够、都会回收掉只被弱引用关联的对象<br><code>JDK1.2</code>之后提供了<code>WeakReference类</code>来实现弱引用</p>
<p><code>虚引用 (Phantom reference)</code>: 一个对象是否有虚引用的存在、完全不影响其生存时间、也无法通过虚引用来取得一个对象的实例、设置虚引用的唯一目的就是能在整个对象进行垃圾收集时收到一个系统通知</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收---七种垃圾收集器简介</title>
    <url>/2020/03/20/java_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6---%E4%B8%83%E7%A7%8D%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>####基本概念：</p>
<p>新生代：大多数对象在eden区生产、很多对象的什么周期很短、每次新生代的垃圾回收(<code>minor gc</code>)后只有少量对象存活<br>      所以选用的是复制算法、只需要少量的复制成本就可以完成回收<br>      <code>young generation</code> 一般又分为 <code>eden</code>区 和 <code>survivor</code> 区(一般<code>2</code>个<code>survivor</code>区)<br>      大部分对象在eden区生产、eden区满时、还存活的对象被复制到两个survivor区中的一个、这个survivor区满时<br>      此区存活切不满足<code>晋升</code>条件的对象将被复制到另一个survivor区(对象每经历一次<code>minor gc</code>， <code>age</code> + 1，<br>      到达年龄阈值后、被放到老年代<code>old generation</code>, 在<code>Serial</code>和<code>ParNew GC</code>)两种垃圾回收器中、<code>晋升年龄阈值</code><br>      由参数 <code>MaxTenuringThreshould</code>设定、默认15</p>
<p>老年代：<code>old generation</code>在新生代中经历了n次垃圾回收后仍然存活的对象、会被放到老年代、改区域对象存活的几率比较高<br>      老年代的垃圾回收(<code>Major gc</code>)通常使用 <code>标记-清理</code>或者<code>标记-整理</code>算法，整堆的回收(包括young和old)称为<code>full gc</code><br>      (HotSpot VM)中、除了<code>CMS</code>之外、其它能收集老年代的gc都会同时回收整个GC堆、包括新生代</p>
<p>永久代: <code>perm generation</code>主要存放元数据、eg. <code>class</code>, <code>method</code>的元信息、与垃圾回收要回收的关系不大、相对新生代<br>      和老年代、改区域对垃圾回收的影响较小</p>
<h4 id="常见的垃圾回收器"><a href="#常见的垃圾回收器" class="headerlink" title="常见的垃圾回收器"></a>常见的垃圾回收器</h4><h5 id="新生代垃圾收集器"><a href="#新生代垃圾收集器" class="headerlink" title="新生代垃圾收集器"></a>新生代垃圾收集器</h5><ol>
<li><code>Serial</code>：串行收集器、采用复制算法、jdk1.3之前的唯一选择、单线程、进行垃圾收集时、会STW<br>   <code>jdk1.3</code>之后又很多优秀收集器、单由于它 对于限定单个cpi的环境来说、没有线程交互的开销、简单高效<br>   至今仍然是 hotspot 虚拟机运行在client模式下的默认新生代收集器</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-ffea12d750747d02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="serial &amp; serial old.png"></p>
<ol start="2">
<li><code>ParNew</code>：<code>Serial</code>的多线程版本、除了使用多线程进行垃圾收集外、其余行为包括<code>Serial收集器可用的控制参数</code>，<br>  <code>收集算法</code>, <code>stw</code>, <code>对象分配规则</code>, <code>回收策略</code>等 与<code>Serial</code>收集器的完全相同、两者公用了很多代码<br>  ParNew收集器除了使用多线程收集外、其它与Serial收集器并无太多创新之处、<code>但</code>是在Server模式下的首选<br>  一个与性能无关的原因:除Serial外、它是唯一能够和<code>CMS</code>收集器(<code>Concurrent Mark Sweep</code>)配合工作的<br>  <code>ParNew</code> 收集器在 <code>单CPU</code> 的环境中、不会有比<code>Serial</code>收集器更好的效果、甚至由于存在线程交互的开销<br>  在两个CPU的环境中都不能百分之百的保证超越、在多CPU的环境下、随着<code>CPU的增加</code>、在GC时、<br>  对资源的有效利用是有好处的、默认开启的<code>收集线程</code>数和<code>CPU的数量</code>相同, 在CPU非常多的时候、可以通过<br>  <code>-XX:ParallerGCThreads</code>参数设置</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-7b2a44d4cfdc7d12.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ParNew &amp; Serial Old.png"></p>
<ol start="3">
<li><code>Parallel Scavenge</code>: 收集器是<code>并行</code>的<code>多线程</code> <code>新生代</code>收集器, 使用<code>复制</code>算法<br>  它与其它收集器的关注点不同、CMS等收集器的关注点是：尽可能缩短垃圾收集时用户线程的停顿时间<br>  而Parallel Scavenge的关注点是：达到一个可控制的吞吐量<br>  <code>停顿短</code>适合需要与用户交互的程序、良好的响应可以提高用户体验<br>  <code>高吞吐量</code>则可以高效的利用CPU时间、尽快的完成任务、适合在后台运算无需太多交互的任务<br>  <code>Parallel Scavenge</code>收集器提供了一个开关参数 <code>-XX:UseAdaptiveSizePolicy</code>指定后可以不用人工指定<br>  新生代大小(-Xmn)、Eden和Survivor区的比率(-XX:SurvivorRatio)、<br>  晋升老年代年龄(-XX:PretenureSizeThreshold)等参数细节了、虚拟机会根据当前系统的运行情况、动态调整参数<br>  这种方式称为：<code>GC的自适应调节策略</code><br>  <code>注意</code> Parallel Scavenge收集器无法和CMS配合使用、在<code>JDK1.6</code>推出<code>Parallel Old</code>之前、<br>  只能和<code>Serail Old</code>收集器一起使用<br>·<br> <img src="https://upload-images.jianshu.io/upload_images/14027542-601ead2dd3099f9a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Paralle Scavenge.png"></li>
</ol>
<h5 id="老年代收集器"><a href="#老年代收集器" class="headerlink" title="老年代收集器"></a>老年代收集器</h5><ol>
<li><p><code>Serial Old</code>是<code>Serial</code>收集器的老年代版本、<code>单线程</code>, 使用<code>标记-整理</code>(<code>Mark-Compact</code>)算法<br>     1) JDK1.5及之前的版本(Parallel Old)诞生之前、与 <code>Parallel Scavenge</code>配合使用<br>     2) 作为CMS收集器的后备预案、在并发手机发生 <code>Concurrent Mode Failuer</code>时使用</p>
</li>
<li><p><code>Parallel Old</code>是<code>Parallel Scavenge</code>的老年代版本, 使用<code>多线程</code>和<code>标记-整理</code>算法, <code>JDK1.6</code>的版本才开始提供<br>     在它出现之后<code>吞吐量优先</code>才有了名副其实的应用组合、在注重吞吐量和cpu敏感的场合、都可以优先考虑<br>     <code>Parallel Scavenge</code>和<code>Parallel Old</code>组合     </p>
</li>
<li><p><code>CMS</code>:<code>Concurrent Mark Sweep</code>收集器是一种以最短回收停顿时间为目标的收集器、使用<code>标记-清除</code>算法<br>   基本流程：</p>
<ol>
<li><code>初始标记</code>:<code>CMS Initial mark</code>仅标记<code>GC Roots</code>能直接关联的对象、速度很快, 会 STW</li>
<li><code>并发标记</code>:<code>CMS Concurrent mark</code>是<code>GC Roots Tracing</code>的过程、耗时最长、但不会STW</li>
<li><code>重新标记</code>:<code>CMS remark</code>为了修正并发标记期间用户程序继续访问导致标记产生变动的对象的标记<br> 时间会比初始标记长、单远小于并发标记, 需要 STW</li>
<li><code>并发清除</code>: <code>CMS concurrent sweep</code><br>   缺点：1) CPU资源敏感、在并发阶段不会导致停顿、单会占用CPU资源、导致应用程序变慢、总的吞吐量降低<br> 默认启动的回收线程数是<code>(CPU数+3)/4</code>，即不少于25%的CPU资源、且随着cpu的增加而下降<br> 但、CPU资源不足时、cms对用户程序的影响可能变大、若CPU的负载本身就很高、还要分出一般运算能力<br> 去执行垃圾收集、系统也会有明显的卡顿<br>   2)无法处理浮动垃圾<code>Floating Garbage</code>可能出现<code>Concurrent Mode Failure</code>而导致Full gc<br>  由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。<br>  出现在标记过程之后，无法再当次收集中处理掉它们，只能待下一次GC时再清理掉。这一部分垃圾就被称为<code>浮动垃圾</code><ol start="3">
<li>产生空间碎片: 空间碎片过多时、会导致老年代空间有剩余、单无法找到足够大连续空间来分配当前对象</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-a48e748a7206f8ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="cms.png"></p>
<ol start="4">
<li>G1 收集器<br>   <code>G1</code>: <code>Garbage First</code>收集器是新的、面向Server应用、HotSpot团队赋予它的使命是：在将来替换掉CMS收集器<br>     1) 并发与并行：G1可充分利用多CPU、多核条件下的硬件优势、使用多个CPU来缩短STW的停顿时间、<br>        部分收集器原本需要停顿Java线程执行的GC动作、G1可以通过并发的方式让Java程序继续执行<br>     2) 分代收集: G1可以不需要其它收集器的配合自己管理整个GC堆、可以采用不同方式去处理新创建的对象和<br>        已存活一段时间、经过了n次GC的old对象来获取更好的收集效果<br>     3) 空间整合: G1从整体来看是基于<code>标记-整理</code>实现的, 从局部(两个Region间)来看是基于复制的<br>        所以、在G1运行期间不会产生大量的内存空间碎片、避免提前触发full gc<br>     4) 可预测的停顿: G1和CMS的共同关注点是降级停顿、但G1除了降低停顿之外、还能建立可预测的停顿时间模型<br>        让使用者明确指定在一个长度为M ms的时间片段内、消耗在GC上的时间不得超过N ms、<br>        这几乎是实时Java(RTSJ)的垃圾收集器的特征了</li>
</ol>
<p>G1收集器：<a href="https://www.jianshu.com/p/5a95ce2bbb36">https://www.jianshu.com/p/5a95ce2bbb36</a></p>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ul>
<li><a href="https://crowhawk.github.io/2017/08/15/jvm_3/">https://crowhawk.github.io/2017/08/15/jvm_3/</a></li>
<li><a href="https://tech.meituan.com/2017/12/29/jvm-optimize.html">https://tech.meituan.com/2017/12/29/jvm-optimize.html</a><br>等众多网络文章</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收---小疑问</title>
    <url>/2020/03/20/java_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6---%E5%B0%8F%E7%96%91%E9%97%AE/</url>
    <content><![CDATA[<p>看懂了gc日志、可能心中还有小小的疑惑？</p>
<h5 id="为什么需要垃圾回收"><a href="#为什么需要垃圾回收" class="headerlink" title="为什么需要垃圾回收"></a>为什么需要垃圾回收</h5><blockquote>
<p>在内存的动态分配和回收机制十分成熟的情况下、仍然没办法避免排查各种内存溢出、内存泄露的问题, 当垃圾收集称为系统达到更高并发量的瓶颈时、就需要了解gc的细节、对gc进行必要的监控和调节</p>
</blockquote>
<blockquote>
<p>程序计数器、虚拟机栈、本地方法栈 随线程运行结束而消亡、这几个区域的内存分配和回收具有确定性、不需要过多的考虑内存回收问题<br>而Java堆和方法区、则在运行时才知道要创建的对象、内存的分配是动态的、垃圾回收主要关注的是这部分的内存</p>
</blockquote>
<h5 id="如何判断对象已死？"><a href="#如何判断对象已死？" class="headerlink" title="如何判断对象已死？"></a>如何判断对象已死？</h5><blockquote>
<ol>
<li>引用计数法<br>给对象添加一个引用计数器、当有新的引用时、计数器的值+1， 引用失效是、计数器的值-1， 计数器的值为0的对象就是不再有引用的对象<br>这种方式的判断效率很高、实现也比较简单、但是不太好判断 循环引用的问题<br>A-&gt;B, B-&gt;A</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>可达性分析<br>通过 <code>GC Roots</code> 作为分析的起点、从这些节点向下搜索、若一个对象通过任意引用链不可达、则会被判断为<code>可回收对象</code></li>
</ol>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">可作为 <span class="code">`gc root`</span> 的对象：</span><br><span class="line"><span class="bullet">1.</span> 虚拟机桟中引用的对象</span><br><span class="line"><span class="bullet">2.</span> 方法区中静态属性引用的对象</span><br><span class="line"><span class="bullet">3.</span> 方法区中常量引用的对象</span><br><span class="line"><span class="bullet">4.</span> 本地方法桟中JNI(Native方法)引用的对象</span><br></pre></td></tr></table></figure>

<h5 id="为什么gc的过程要stw-？"><a href="#为什么gc的过程要stw-？" class="headerlink" title="为什么gc的过程要stw ？"></a>为什么gc的过程要stw ？</h5><blockquote>
<p>为了避免分析过程中对象的引用关系还在不断的发生变化、导致分析结果的准确性无法保证<br>系统停顿下来后如果得知对象引用关系呢 ？<br>在hotspot的实现中、有一个OopMap的数据结构、在类加载的时候， 它就把对象内什么偏移量位置上是什么类型的数据计算出来、在jit编译的过程中也会在特定的位置记录桟和寄存器哪些位置是引用、这样gc扫描时就可以直接得到了<br>但是、为什么是特定位置 ？<br>如果每条指令都生成对应OopMap、会需要大量的额外空间、所以只是在特定位置(安全点<code>safepoint</code>)记录这些信息<br><code>notice</code> : 设置标记等待线程运行到安全点再gc解决了大部分问题、但如果线程是<code>sleep</code>或者<code>block</code>状态呢 ？线程无法响应jvm的中断请求、运行到安全点去中断挂起、jvm也不可能得到线程被重新分配CPU时间、so、有了<code>安全区域</code>-<code>safe region</code>来解决<br><code>safe region</code>: 在一个代码片段之内、引用关系不会发生变化、在这个区域内的任意位置进行gc都是安全的，线程在进入安全区域的时候、会设置自己进入安全区域的标记、jvm在gc时、会忽略这类线程<br>在线程离开安全区域时会检测系统是否已经完成了gc、ok则可以继续运行、否则需要等待可以离开安全点的信号</p>
</blockquote>
<h5 id="晋升为老年代的判断？"><a href="#晋升为老年代的判断？" class="headerlink" title="晋升为老年代的判断？"></a>晋升为老年代的判断？</h5><blockquote>
<ol>
<li>对象优先在Eden区分配、若Eden区无足够的空间、虚拟机会发起一次Minor GC， 经过一次Minor gc、<code>age</code>会<code>+1</code>、达到指定age(<code>-XX:MaxTenuringThreshold指定</code>)时、对象会进入老年代</li>
<li>Minor gc时、无法放入 <code>survivor</code> 区的对象、会通过<code>分配担保机制</code>提前转移到<code>old generation</code></li>
<li>大对象直接进入老年代, 为避免提前触发gc  大于 <code>-XX:PreTenureThreshold</code>指定值得对象会提前进入直接在老年代分配</li>
<li>若survivor区 相同年龄的所有对象的大小的总和&gt;survivor区的一半、则 age &gt;&#x3D; 该age值得对象可以直接进入老年代、无需等到 <code>-XX:MaxTenuringThreshold</code> 指定年龄值</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s出现的契机</title>
    <url>/2020/03/26/k8s_%E5%A5%91%E6%9C%BA/</url>
    <content><![CDATA[<h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>以 <code>Colud Foundry</code> 为代表的开源PaaS项目、在2013年已经度过了最艰难的概念普及和用户教育阶段、吸引了包括京东、华为、百度、IBM等一大批国内外技术厂商, 开启了以开源PaaS为核心构建平台服务能力的变革、而此时 Docker 项目却意外的出现了. Dot Cloud 公司开源了Docker项目. </p>
<p>PaaS平台被接纳的主要原因是提供了 <code>应用托管能力</code>, <code>Cloud Foundry</code> 最核心的组件是应用的打包和分发机制.  <code>cf push</code> 基本上等同于将应用的可执行文件和启动脚本打进一个压缩包内, 上传到cf的存储中. 接着, 会通过调度器选择一个可运行该应用的虚拟机、通知虚拟机上的agent把应用压缩包下载启动.</p>
<p>若需要启动很多个来自不同用户的应用呢 ? </p>
<p>cf 会调用操作系统的 <code>Cgroups</code> 和 <code>Namespace</code> 机制来为每一个应用单独创建一个称为 <code>沙盒</code>的隔离环境、分别在隔离环境中运行. </p>
<p><code>Docker</code> 实际上跟<code>Cloud Foundry</code> 基本类似、大部分功能和实现原理都一样. 然而、正是这一点点差异 造就了<code>Docker</code>, 它在几个月内快速崛起.</p>
<p><code>Docker image</code> 就是这一点点的差异.  PaaS之所以能帮助大规模用户部署应用到集群里、是因为提供了打包的功能、偏偏也就是<code>打包</code>这个功能、却成了一个软肋. 因为一旦用上PaaS、就必须为每种语言、每种框架甚至每个版本都得维护一个包, 比较麻烦的是本地运行很好的项目、需要修改很多东西和配置才能在PaaS里运行. 为了 <code>cf push</code> 这个一键部署的工作、<code>打包</code>这个前置工作特别麻烦</p>
<p><code>Docker image</code> 从根本上解决了这个问题. 所谓 Docker 镜像, 其实就是一个压缩包. 大多数Docker 镜像包含一个完整的操作系统和所有文件、目录, 这个压缩包的环境、与本地完全一致. 那么、如果本地环境是 CentOS 7.2, 使用CentOS 7.2 的ISO做一个压缩包、再把应用可执行文件也压缩进去, 就可以得到一个与本地完全一致的环境了. 它包含了应用运行的所有依赖.</p>
<p>这就是 Docker 镜像的精髓.</p>
<p><code>docker build &quot;image name&quot;</code> 就可以制作成一个压缩包.</p>
<p><code>docker run &quot;image name&quot;</code> 就是用Docker创建一个<code>沙盒</code>来解压镜像、然后在其中运行应用.</p>
<p><code>docker run</code> 创建的<code>沙盒</code>, 也是使用 <code>Cgroups</code> 和 <code>namespace</code>创建的隔离环境.</p>
<h4 id="Docker崛起"><a href="#Docker崛起" class="headerlink" title="Docker崛起"></a>Docker崛起</h4><p>Docker解决了应用打包和发布的问题, 且将一个存后端的技术概念通过友好的设计和封装、交给了广大的开发者. 得以迅速受到青睐.  一个以容器为中心的全新云计算市场、即将呼之欲出, 此时 dotCloud 公司、却突然改名 <code>Docker</code>, 意味着, 任何公司都不能在商业活动中再使用这个词及鲸鱼的logo. 14年, 又发布了 <code>Swarm</code> 项目. 兜兜转转, Docker 公司还是回到了<code>如何让开发者把应用部署到我的项目</code>这个主题上. </p>
<p>此时, PaaS 已经变成了一套以 Docker 容器为技术核心、以Docker镜像为打包标准的、全新的容器化思路. </p>
<p>这、正是 Docker 项目从开始悉心运作<code>容器化</code>概念和努力经营 Docker 生态系统的目的. 而 <code>Swarm</code> 项目、正是承载Docker接下来所有这些努力的关键.</p>
<p>综合来说、Docker的崛起有3个因素:</p>
<ol>
<li>Docker镜像通过技术手段解决了 PaaS平台的根本性问题.</li>
<li>Docker 容器和开发者之间与生俱来的密切关系</li>
<li>PaaS概念已深入人心的完美契机.</li>
</ol>
<h4 id="群雄并起"><a href="#群雄并起" class="headerlink" title="群雄并起"></a>群雄并起</h4>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_README/</url>
    <content><![CDATA[<h4 id="let’s-start"><a href="#let’s-start" class="headerlink" title="let’s start"></a>let’s start</h4><p>知识的海洋是浩瀚的、有太多的好奇与未知。。。。<br>一直想要探索linux系统到底是如何运行而不得其法、偶然间遇到极课时间的一个linux系统优化的专栏、还不错、<br>写一下自己的收获吧、算是由表及里也好~</p>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>linux性能监控---pidstat</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7---pidstat/</url>
    <content><![CDATA[<ol>
<li><p>cpu使用率监控<br>pidstat -t {pid}  1 3 -u 每隔1s输出1次、共输出3次系统状况<br>pidstat -t {pid}  1 3 -u -t 同时输出线程使用情况</p>
</li>
<li><p>io监控<br>pidstat -t {pid}  1 3 -d -t 查看线程io信息</p>
</li>
<li><p>内存使用监控<br>pidstat -t {pid}  1 3 -m -t 查看线程内存使用</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>linux性能监控---vmstat</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7---vmstat/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-63558050c585c684.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>各列含义如下：<br><code>procs</code>:<br><code>r</code> 等待运行的进程数<br> <code>b</code> 可中断休眠的进程数</p>
<p><code>memory</code>: kb<br><code>swpd</code> 虚拟内存的使用项目<br><code>free</code> 空闲的内存<br><code>buff</code> 被用来作为缓存的内存数</p>
<p><code>swap</code><br><code>si</code> 从磁盘交换到内存的交换页数量、<br><code>so</code> 从内存交换到磁盘的交换页数量、</p>
<p><code>io</code><br><code>bi</code> 发送到块设备的块数<br><code>bo</code> 从块设备接收到的块数</p>
<p><code>system</code><br><code>in</code> 每秒的中断数包括时钟中断<br><code>cs</code> 每秒的上下文切换数</p>
<p><code>cpu</code><br><code>us</code> 用户cpu使用时间<br><code>sy</code> 系统cpu使用时间<br><code>id</code> 空闲时间</p>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程实现基础(二)</title>
    <url>/2020/03/20/java_Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0%E5%9F%BA%E7%A1%80(%E4%BA%8C)/</url>
    <content><![CDATA[<h4 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h4><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 线程通信</span><br><span class="line">   线程之间以何种方式进行消息传递</span><br><span class="line">   共享内存 &amp; 消息传递</span><br><span class="line">   </span><br><span class="line"><span class="number">2</span>. 线程同步</span><br><span class="line">   程序间用于控制不同线程间操作发生相对顺序的机制</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">java是共享内存模型】采用的是隐式通信、显式修改</span></span><br><span class="line"><span class="keyword"></span>   </span><br><span class="line">   <span class="keyword">jvm定义了线程和主内存(Main </span>Memory)之间的关系:</span><br><span class="line">   <span class="number">1</span>) 线程之间的共享变量存储在主内存中</span><br><span class="line">   <span class="number">2</span>) 线程私有变量存储在私有本地内存 Local Memory中、</span><br><span class="line">      本地内存是<span class="keyword">jvm的一个抽象概念、并非真实存在、涵盖缓存、缓冲区、寄存器及其它硬件及编译器优化</span></span><br><span class="line"><span class="keyword"></span>   <span class="keyword">Java同步原语(synchronize </span>volatile  final)</span><br></pre></td></tr></table></figure>

<h3 id="指令重排"><a href="#指令重排" class="headerlink" title="指令重排"></a>指令重排</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 编译器重排</span><br><span class="line">   在不改变单线程语义的条件下、编译器可以重排指令的执行顺序</span><br><span class="line"><span class="bullet">2.</span> 指令重排 </span><br><span class="line">   现代cpu采用了指令级并行技术、可以同时执行多条指令、若无数据依赖、</span><br><span class="line">   处理器可以改变机器指令的执行顺序</span><br><span class="line"><span class="bullet">3.</span> 内存系统的重排</span><br><span class="line">   由于处理器采用缓存和读写缓冲区、使得加载和存储操作看上去是乱序的、</span><br><span class="line">   可能在乱序执行</span><br></pre></td></tr></table></figure>

<h4 id="jvm-指令执行"><a href="#jvm-指令执行" class="headerlink" title="jvm 指令执行"></a>jvm 指令执行</h4><figure class="highlight haskell"><table><tr><td class="code"><pre><span class="line">未使用同步的程序在<span class="keyword">jvm</span>中的执行基本无序、</span><br><span class="line"><span class="number">1</span>. <span class="keyword">jvm</span>不保证单线程内的操作会按照程序代码顺序执行、临界区指令重排</span><br><span class="line"><span class="number">2</span>. <span class="keyword">jvm</span>不保证所有线程看到的执行顺序一致</span><br><span class="line"><span class="number">3</span>. <span class="keyword">jvm</span>不保证<span class="number">64</span>位的long、double类型写操作具有原子性</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>lsof---一切皆文件</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_lsof---%E4%B8%80%E5%88%87%E7%9A%86%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<blockquote>
<p>lsof(list open files) 查看当前系统文件、Linux下任何事物都以文件的形式存在、通过文件不仅可以访问常规数据库、还可以访问网络连接(tcp、udp等)和硬件</p>
</blockquote>
<p><strong>lsof 打开文件可以是：</strong></p>
<ul>
<li>普通文件 </li>
<li>目录</li>
<li>网络文件系统的文件</li>
<li>字符或设备文件</li>
<li>共享库</li>
<li>管道、命名管道</li>
<li>符号连接</li>
<li>网络文件 (eg. NFS file、网络socket、unix 域名socket等)</li>
<li>其它类型的文件</li>
</ul>
<p><strong>命令参数</strong></p>
<blockquote>
<p>-a 列出打开文件存在的进程<br>-c&lt;进程名&gt;</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>tcpdump基本使用</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_tcpdump%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p><strong>选项</strong></p>
<ul>
<li><code>-i any</code> 监听所有的网卡接口、用来查看是否有网络流量</li>
<li><code>-i eth0</code> 只监听eth0网卡流量</li>
<li><code>-D</code> 显示可用的接口列表</li>
<li><code>-n</code> 不解析主机名、直接使用ip</li>
<li><code>-nn</code> 显示端口</li>
<li><code>-q</code> 显示简化输出</li>
<li><code>-t</code> 显示可读的时间戳</li>
<li><code>-X</code> 以<code>hex</code>和<code>ASCII</code>两种形式显示包内容</li>
<li><code>-v</code> <code>-vv</code> <code>-vvv</code> 显示更加多的包信息</li>
<li><code>-XX</code> 与 <code>-X</code> 类似、增加以太网header的显示</li>
<li><code>-c</code> 只读取<code>x</code>个包, 然后停止</li>
<li><code>-s</code> 指定每个包捕获的长度、单位是 <code>byte</code>, 可以使用 <code>-s0</code> 捕获整个包</li>
<li><code>-S</code> 输出绝对的序列号</li>
<li><code>-e</code> 获取以太网 <code>header</code></li>
<li><code>-w</code> 将捕获的数据包信息写入文件</li>
<li><code>-r</code> 加载之前保存的文件</li>
</ul>
<p><strong>表达式</strong><br>在<code>tcpdump</code>中可以使用表达式过滤指定类型的流量：</p>
<ul>
<li>类型type选项包含：<code>host</code>  <code>net</code> <code>port</code></li>
<li>方向dir包含：<code>src</code>  <code>dst</code></li>
<li>协议proto选项包含：<code>tcp</code> <code>udp</code> <code>ah</code>等</li>
</ul>
<p><strong>示例</strong></p>
<blockquote>
<p>捕获所有流量<br>tcpdump -i any</p>
</blockquote>
<blockquote>
<p>指定网卡接口、查看指定网卡发生了什么<br>tcpdump -i eth0</p>
</blockquote>
<blockquote>
<p>原生输出、不解析主机、端口、显示绝对序列号、可读的时间戳<br>tcpdump -ttttnnvvS</p>
</blockquote>
<blockquote>
<p>查看指定ip的流量<br>tcpdump host {ip}</p>
</blockquote>
<blockquote>
<p>使用<code>源</code>和<code>目的</code>过滤<br>tcpdump src {source ip}<br>tcpdump dst {dest ip}</p>
</blockquote>
<blockquote>
<p>过滤某个子网的数据包<br>tcpdump net 1.2.3.0&#x2F;24</p>
</blockquote>
<blockquote>
<p>过滤指定端口相关的流量<br>tcpdump port {port}<br>tcpdump src port {port} -&gt; 只显示发出</p>
</blockquote>
<blockquote>
<p>过滤指定协议的流量<br>tcpdump tcp</p>
</blockquote>
<blockquote>
<p>只显示ipv6流量<br>tcpdump ip6</p>
</blockquote>
<blockquote>
<p>基于包大小过滤流量<br>tcpdump less 32<br>tcpdump grater 64<br>tcpdump &lt;&#x3D;128</p>
</blockquote>
<blockquote>
<p>使用端口范围过滤<br>tcpdump portrange 21-23</p>
</blockquote>
<blockquote>
<p>保存到指定文件<br>tcpdump port 80 -w file</p>
</blockquote>
<blockquote>
<p>加载之前保存的文件<br>tcpdump -r file</p>
</blockquote>
<p><strong>高级使用</strong></p>
<ul>
<li><code>AND</code>: <code>and</code> or <code>&amp;&amp;</code></li>
<li><code>OR</code>: <code>or</code> or <code>||</code></li>
<li><code>except</code>: <code>not</code> or <code>!</code><blockquote>
<p>过滤指定源和目的端口<br>tcpdump -n src 1.1.1.2 and dst port 8080</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>过滤指定网络方向<br>tcpdump -n src net 1.1.1.2&#x2F;16 and dst net 1.1.1.3&#x2F;16</p>
</blockquote>
<blockquote>
<p>过滤到指定ip的非icmp报文<br>tcpdump dst 1.1.1.2 and src net and not icmp</p>
</blockquote>
<blockquote>
<p>构建规则过于复杂的时候、可以使用单引号将规则放到一起<br>tcpdump ‘src 1.1.1.1 and (dst port 80 or 22)’</p>
</blockquote>
<p><strong>隔离指定的TCP标识</strong><br><code>tcp[13]</code>表示在tcp header中的偏移位置13开始、后边代表的是匹配的字节数</p>
<blockquote>
<p>显示所有的urgent包(URG)<br>tcpdump ‘tcp[13] &amp; 32!&#x3D;0’</p>
</blockquote>
<blockquote>
<p>显示所有的ACK包<br>tcpdump ‘tcp[13] &amp; 16!&#x3D;0’</p>
</blockquote>
<blockquote>
<p>显示所有的push包<br>tcpdump ‘tcp[13] &amp; 8!&#x3D;0’</p>
</blockquote>
<blockquote>
<p>显示所有的reset包<br>tcpdump ‘[tcp13] &amp; 4!&#x3D;0’</p>
</blockquote>
<blockquote>
<p>显示所有的SYN包<br>tcpdump ‘[tcp13] &amp; 2!&#x3D;0’</p>
</blockquote>
<blockquote>
<p>显示所有的FIN包<br>tcpdump ‘[tcp13] &amp; 1!&#x3D;0’</p>
</blockquote>
<blockquote>
<p>显示所有的SYN&#x2F;ACK包<br>tcpdump ‘tcp[13]&#x3D;18’</p>
</blockquote>
<p><strong>识别重要流量</strong></p>
<blockquote>
<p>过滤同时设置SYN和RST标识的包（这在正常情况下不应该发生）<br>tcpdump ‘tcp[13] &#x3D; 6’</p>
</blockquote>
<blockquote>
<p>过滤明文的HTTP GET请求<br>tcpdump ‘tcp[32:4] &#x3D; 0x47455420’</p>
</blockquote>
<blockquote>
<p>通过横幅文本过滤任意端口的SSH连接<br>tcpdump ‘tcp[(tcp[12]&gt;&gt;2):4] &#x3D; 0x5353482D’</p>
</blockquote>
<blockquote>
<p>过滤TTL小于10的包（通常情况下是存在问题或者在使用traceroute）<br>tcpdump ‘ip[8] &lt; 10’</p>
</blockquote>
<blockquote>
<p>过滤恶意的包<br>tcpdump ‘ip[6] &amp; 128 !&#x3D; 0’</p>
</blockquote>
<p><strong>理解报文内容</strong></p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">08</span>:<span class="number">41</span>:<span class="number">13</span>.<span class="number">729687</span> IP <span class="number">192.168.64.28</span>.<span class="number">22</span> &gt; <span class="number">192.168.64.1</span>.<span class="number">41916</span>: Flags<span class="meta"> [P.], seq 196:568, ack 1, win 309, options [nop,nop,TS val 117964079 ecr 816509256], length 372</span></span><br></pre></td></tr></table></figure>
<p><code>08:41:13.729687</code> 本地时间戳<br><code>ip</code> 协议是ipv4、若是ipv6会显示为 ip6<br><code>192.168.64.28.22</code> 源ip和端口<br><code>192.168.64.1.41916</code> 目的ip和端口<br><code>Flags [P.]</code> 报文标记段<br><code>seq 196:568</code> 代表该数据包包含该数据流的第 196 到 568 字节<br><code>ack 1</code> 该数据包是数据发送方，ack 值为 1。在数据接收方，该字段代表数据流上的下一个预期字节数据，例如，该数据流中下一个数据包的 ack 值应该是 568<br><code>win 309</code> 表示接收缓冲区中可用的字节数，后跟 TCP 选项如 MSS（最大段大小）或者窗口比例值<br><code>length 372</code> 代表数据包有效载荷字节长度</p>
<blockquote>
<p>flag描述<br>S SYN Connection Start<br>F FIN Connection Finish<br>P PUSH Data Push<br>. ACK Acknowledment</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>如何了解自己的系统运行状态</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_%E5%A6%82%E4%BD%95%E4%BA%86%E8%A7%A3%E8%87%AA%E5%B7%B1%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81/</url>
    <content><![CDATA[<h4 id="平均负载-loadavg"><a href="#平均负载-loadavg" class="headerlink" title="平均负载 loadavg"></a>平均负载 loadavg</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">当系统变慢时、我们想到的很可能是 <span class="built_in">uptime</span> 或者 top</span><br><span class="line">它每一列的含义是什么 ？</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-7a4f7de3de8dc6be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="uptime"></p>
<p>so. mark<br><code>10:13:59</code> 是当前时间<br><code>up 303 days, 22:27</code> 是系统允许时间<br> <code>1 user</code> 是正在登录用户数<br>load average: 4.61, 4.37, 3.73 这三列呢 ？<br>依次是 过去<code>1min</code>、<code>5min</code>、<code>15min</code>的平均负载</p>
<h4 id="什么是平均负载-？？？"><a href="#什么是平均负载-？？？" class="headerlink" title="什么是平均负载 ？？？"></a>什么是平均负载 ？？？</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">知道了uptime是如何看的、那么平均负载多少算是合适 ？它又是代表什么含义呢 ？</span><br><span class="line"></span><br><span class="line">简单来说平均负载就是单位时间内、系统处于可运行状态和不可中断状态的平均进程数、也就是平均活跃进程数，</span><br><span class="line">之前、我以为是<span class="meta">cpu</span>的使用率来着的~~~xxxxx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">可运行状态的进程：指正在使用<span class="meta">CPU</span>或者等待<span class="meta">CPU</span>的进程、ps看到的、处于R状态(Runnable/Running)的进程</span><br><span class="line"></span><br><span class="line">不可中断进程：正处于内核关键流程中的进程、并且这些进程是不可打断的、eg. 等待硬件设备的io响应、也就是ps命令中的D状态(uninterrutible sleep)的进程</span><br><span class="line">不可中断状态其实是系统对进程包含和硬件设备的一种保护机制</span><br><span class="line"></span><br><span class="line">既然平均负载就是平均的活跃进程数、那么最理想的状态就是每个<span class="meta">CPU</span>上都刚好运行着一个进程(每个<span class="meta">cpu</span>充分利用、又不会过载)</span><br><span class="line"></span><br><span class="line">eg. loadavg为<span class="number">2</span>、意味着什么呢 ？</span><br><span class="line"><span class="number">1</span>) 假如系统有<span class="number">2</span>个<span class="meta">CPU</span>、则<span class="meta">cpu</span>刚好都被占用</span><br><span class="line"><span class="number">2</span>) 在<span class="number">4</span>个<span class="meta">CPU</span>的系统上、意味着<span class="number">50</span>%的<span class="meta">CPU</span>空闲</span><br><span class="line"><span class="number">3</span>) 在只有<span class="number">1</span>个<span class="meta">CPU</span>的系统上、则会有一半的进程竞争不到<span class="meta">CPU</span></span><br><span class="line"></span><br><span class="line">最理想的状态是、刚好等于<span class="meta">CPU</span>的核心数</span><br><span class="line">那么如何查询系统有几个<span class="meta">CPU</span> ？？</span><br><span class="line"><span class="number">1</span>) 使用top</span><br><span class="line"><span class="number">2</span>) 从/proc/cpuinfo 获取 </span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-4cf1dcfb4a79d551.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="cpuinfo.png"></p>
<h4 id="知道了cpu的核数和衡量指标、如何分析负载趋势？"><a href="#知道了cpu的核数和衡量指标、如何分析负载趋势？" class="headerlink" title="知道了cpu的核数和衡量指标、如何分析负载趋势？"></a>知道了cpu的核数和衡量指标、如何分析负载趋势？</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 若<span class="number">1</span><span class="keyword">min</span>、<span class="number">5</span><span class="keyword">min</span>、<span class="number">15</span><span class="keyword">min</span>的值基本相同或者相差不大、说明系统负载很平稳</span><br><span class="line"><span class="number">2.</span> 若<span class="number">1</span><span class="keyword">min</span>内的值远小于<span class="number">15</span><span class="keyword">min</span>的值、说明最近<span class="number">1</span><span class="keyword">min</span>的负载在减小、而过去<span class="number">15</span><span class="keyword">min</span>则负载很高</span><br><span class="line"><span class="number">3.</span> 反过来、若最近<span class="number">1</span>imn的值远高于过去<span class="number">15</span><span class="keyword">min</span>的负载、说明负载在明显升高、需要持续观察一下</span><br><span class="line"></span><br><span class="line">eg. 单核cpu的 loadavg为：<span class="number">1.73</span>  <span class="number">0.60</span>  <span class="number">7.98</span> </span><br><span class="line">说明过去<span class="number">1</span><span class="keyword">min</span>有<span class="number">73</span>%的超载、过去<span class="number">15</span><span class="keyword">min</span>有<span class="number">698</span>%的超载</span><br><span class="line">总体来看、负载在降低</span><br><span class="line"></span><br><span class="line">那么实际生产环境、负载达到多少的时候、我们应该开始关注呢 ？ 一般 超过<span class="number">70</span>%就要持续观察下、看看系统负载的平均趋势</span><br></pre></td></tr></table></figure>

<h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 命令</span><br><span class="line">stress 压力测试工具</span><br><span class="line">mpstat 多核CPU性能分析工具、可实时查看每个CPU的平均指标</span><br><span class="line">pidstat 实时查看进程的cpu、内存、io及上下文切换等指标</span><br><span class="line">watch 监控进程</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 模拟cpu密集型(需要准备<span class="number">3</span>个终端、每个终端执行一个命令)</span><br><span class="line">stress <span class="attr">--cpu</span> <span class="number">1</span> <span class="attr">--timeout</span> <span class="number">600</span></span><br><span class="line"></span><br><span class="line">watch -d uptime (-d代表高亮显示变化的区域)</span><br><span class="line"></span><br><span class="line">mpstat -<span class="selector-tag">P</span> <span class="attribute">ALL</span> <span class="number">5</span> (-<span class="selector-tag">p</span> <span class="attribute">ALL</span>代表监控所有CPU <span class="number">5</span>代表间隔<span class="number">5s</span>输出<span class="number">1</span>次)</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>. 模拟IO密集型</span><br><span class="line">stress -<span class="selector-tag">i</span> <span class="number">1</span> <span class="attr">--timeout</span> <span class="number">600</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span>. 大量进程的场景</span><br><span class="line">stress -c <span class="number">8</span> <span class="attr">--timeout</span> <span class="number">600</span></span><br><span class="line"></span><br><span class="line">附：安装stress</span><br><span class="line">sudo yum -y install epel-release</span><br><span class="line">sudo yum -y install stress</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-e8ae343bc07ff1ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="stress.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-e6c92ece83479acc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="uptime.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-5b6eb08f6768da70.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="mpstat.png"></p>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>常用命令</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p><code>cat /proc/cpuinfo | grep &#39;physical id&#39; |  sort| uniq| wc -l</code> 查看物理CPU的个数<br><code>cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq</code> 查看每个物理CPU中cores的个数<br><code>cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l</code> 查看逻辑CPU的个数</p>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>平均负载</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD/</url>
    <content><![CDATA[<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">uptime:</span><br><span class="line"> 输出: <span class="number">11</span>:<span class="number">39</span>:<span class="number">32</span> up <span class="number">13</span> days,  <span class="number">1</span>:<span class="number">51</span>, <span class="number">18</span> users,  <span class="built_in">load</span> <span class="built_in">average</span>: <span class="number">6.21</span>, <span class="number">5.86</span>, <span class="number">4.91</span></span><br><span class="line"> 说明: 当前时间、系统运行时间、正在登陆用户数、最近<span class="number">1</span><span class="built_in">min</span>、<span class="number">5</span><span class="built_in">min</span>、<span class="number">15</span><span class="built_in">min</span>的平均负载 <span class="built_in">load</span> <span class="built_in">average</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure>



<p><code>平均负载</code>: 是单位时间内、系统处于可运行状态和不可中断状态的平均进程数, 即: 平均活跃进程数、和CPU的使用率无直接关系</p>
<p><code>可运行状态的进程</code>: 正在使用CPU或者等待CPU的进程、ps的R(Runnning &#x2F; Runable) 状态</p>
<p><code>不可中断状态</code>: 正处于内核关键流程中的进程、且这些流程是不可打断的、eg. 等待硬件设备的IO响应、ps的D状态(Uninterruptible Sleep,即: Disk Sleep)</p>
<blockquote>
<p>eg. 当一个进程向磁盘写数据时, 为了保证数据一致性、在得到磁盘回复前、是不能被打断的、若被打断, 容易出现磁盘数据和进程数据不一致</p>
<p>其实: 不可中断状态其实是系统堆进程和硬件设备的一种保护机制</p>
</blockquote>
<h4 id="平均负载合理性评估"><a href="#平均负载合理性评估" class="headerlink" title="平均负载合理性评估"></a>平均负载合理性评估</h4><p>平均负载为2怎么解读 ？</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 在只有<span class="number">2</span>个<span class="meta">CPU</span>的系统上、意味着<span class="meta">CPU</span>刚好可以全部占用</span><br><span class="line"><span class="number">2</span>. 在<span class="number">4</span>个<span class="meta">CPU</span>的系统上、意味着有<span class="number">50</span>%的空闲</span><br><span class="line"><span class="number">3</span>. 在<span class="number">1</span>个<span class="meta">CPU</span>的系统上、意外着会有一半的进程竞争不到<span class="meta">CPU</span></span><br></pre></td></tr></table></figure>



<p>CPU核数查看</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /proc/cpuinfo | grep <span class="string">&#x27;model name&#x27;</span> | <span class="built_in">wc</span> -l</span><br><span class="line">lscpu</span><br></pre></td></tr></table></figure>



<blockquote>
<p>经验值: cpu 的负载到达70%的时候、就需要关注了</p>
</blockquote>
<p>平均负载与CPU使用率</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 平均负载: 单位时间内处于可运行状态和不可中断状态的进程数</span><br><span class="line">   包含 正在使用<span class="meta">CPU</span>的进程 + 等待<span class="meta">CPU</span>的进程 + 等待io的进程</span><br><span class="line"><span class="number">2</span>. <span class="meta">CPU</span>使用率: 单位时间内<span class="meta">CPU</span>繁忙情况的统计、不一定与平均负载对应</span><br><span class="line">   eg. <span class="meta">cpu</span>密集型、使用大量<span class="meta">CPU</span>会导致load升高、 - 变化趋势一致</span><br><span class="line">       io密集型、等待io也导致load升高、<span class="meta">CPU</span>使用率不一定很高</span><br><span class="line">       </span><br></pre></td></tr></table></figure>



<p>案例分析</p>
<p>一、CPU密集型进程</p>
<figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">终端一</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">stress --cpu 1 --timeout 600</span></span><br><span class="line"><span class="attribute">--cpu CPU压力测试</span></span><br><span class="line"><span class="attribute"></span></span><br><span class="line"><span class="attribute">终端二</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">watch -d uptime </span></span><br><span class="line"><span class="attribute">-d</span><span class="punctuation">:</span> <span class="string">高亮显示变化区域</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">终端三</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">mpstat -P ALL 5</span></span><br><span class="line"><span class="attribute">-P ALL</span><span class="punctuation">:</span> <span class="string">表示监控所有CPU</span></span><br><span class="line"><span class="attribute">5表示间隔5s输出一组数据</span></span><br><span class="line"><span class="attribute"></span></span><br><span class="line"><span class="attribute">终端四</span><span class="punctuation">:</span></span><br><span class="line">pidstat -u 5 1 间隔5s输出一组数据、查找CPU高的线程</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/14027542-e170f3f20c5f39de.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="stress.png"></p>
<p>二、IO密集型进程</p>
<p>查看方式同上</p>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux内核学习---1</title>
    <url>/2020/03/20/linux%E5%86%85%E6%A0%B8_Linux%E5%86%85%E6%A0%B8%E5%AD%A6%E4%B9%A0---1/</url>
    <content><![CDATA[<h4 id="开机加电-gt-main-函数执行"><a href="#开机加电-gt-main-函数执行" class="headerlink" title="开机加电 -&gt; main 函数执行"></a>开机加电 -&gt; main 函数执行</h4><blockquote>
<p>分3步完成、实现从启动盘加载操作系统、完成 main 函数加载所需要的准备工作</p>
</blockquote>
<h5 id="启动BIOS、完成实模式下的中断向量表和中断服务程序"><a href="#启动BIOS、完成实模式下的中断向量表和中断服务程序" class="headerlink" title="启动BIOS、完成实模式下的中断向量表和中断服务程序"></a>启动BIOS、完成实模式下的中断向量表和中断服务程序</h5><p>Q: RAM ？<br>A: Random Access Memory. 随机存取存储器、eg. 内存条<br>   特点是 在加电状态下、可随意读写、断电消失</p>
<p>Q: 加电瞬间、RAM中无任何程序、谁来完成 操作系统从软盘的加载 ？<br>A: BIOS</p>
<p>Q: 为什么必须把操作系统从软盘加载到RAM ？<br>A: CPU的逻辑电路被设计为只能从内存中运行、无法直接从软盘运行</p>
<p>Q: 为什么CPU的逻辑电路被设计为只能从内存运行 ？<br>A: … 暂未清楚</p>
<p>Q: BIOS本身是如何启动的 ？<br>A: 固定地址: 0xFFFF0、<br>   CPU逻辑上被设计为、在加电的瞬间、强行将 CS设为 0xF000, IP 设为 0xFFF0<br>   这样、CS:IP 就指向 0xFFFF0(BIOS程序的入口地址、BIOS程序就开始运行)</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-bc3706ad36a398b8.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="BIOS.jpg"></p>
<h5 id="从启动盘加载操作系统到内存、加载操作系统的工作就是利用-中断服务程序来完成的"><a href="#从启动盘加载操作系统到内存、加载操作系统的工作就是利用-中断服务程序来完成的" class="headerlink" title="从启动盘加载操作系统到内存、加载操作系统的工作就是利用 中断服务程序来完成的"></a>从启动盘加载操作系统到内存、加载操作系统的工作就是利用 中断服务程序来完成的</h5><p>开始加载操作系统….</p>
<blockquote>
<p>对Linux 0.11而言、是分3步、<br>  1: 有BIOS中断 0x19 将第一扇区bootsect的内容加载到内存<br>  2: 在bootsect的引导下、将后边的4个扇区和240个扇区的内容依次加载到内存中</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-8467ab9c24c4efbc.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="BIOS程序加载.jpg"></p>
<p>Q: 操作系统如何加载 ？<br>A: BIOS代码执行完毕、硬件完成开机自检、会和BIOS联手、让CPU收到 int 0x19中断、CPU在中断向量表中找到中断程序的位置(0x0E6F2)<br>   即: 启动记载服务程序的入口地址、<br>   so. in 0x19中断程序的作用就是把软盘第一扇区的代码512b加载到内存指定位置(BIOS设计、与操作系统无关) - 内存(0x07C00)处<br>   第一扇区的代码作用就是将软盘中的操作系统程序陆续加载到内存、所以称为引导程序(bootsect)<br>   第一扇区的载入、标记着操作系统代码要开始发挥作用<br><img src="https://upload-images.jianshu.io/upload_images/14027542-482d2aaafa61ffa8.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="响应int0x19中断.jpg"></p>
<h5 id="操作系统的内存规划"><a href="#操作系统的内存规划" class="headerlink" title="操作系统的内存规划"></a>操作系统的内存规划</h5><p>实模式下最大的寻址为1MB</p>
<pre><code>//代码路径：boot/bootsect.s  
    …  
.globl begtext, begdata, begbss, endtext, enddata, endbss  
.text  
begtext:  
.data  
begdata:  
.bss  
begbss:  
.text  
 
SETUPLEN= 4    ! nr of setup-sectors  
BOOTSEG = 0x07c0    ! original address of boot-sector  
INITSEG = 0x9000    ! we move boot here-out of the way  
SETUPSEG= 0x9020    ! setup starts here  
SYSSEG  = 0x1000    ! system loaded at 0x10000 (65536).  
ENDSEG  = SYSSEG + SYSSIZE  ! where to stop loading  
 
! ROOT_DEV:0x000 - same type of floppy as boot.  
!  0x301 - first partition on first drive etc  
ROOT_DEV= 0x306 
… 
![实模式下的内存使用规划.jpg](https://upload-images.jianshu.io/upload_images/14027542-2fd3e1e6ef913630.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
</code></pre>
<p><code>SETUPLEN</code> -&gt; <code>SETUPSEG 0x9020</code> (被加载到的位置)<br><code>BOOTSEG(0x07c0)</code>(BIOS加载的位置) -&gt; <code>INITSEG 0x9000</code>(被移动到的新的位置)<br><code>SYSSEG 0x1000</code> 内核被加载的位置<br><code>ENDSEG</code> 内核末尾位置<br><code>ROOT_DEV 0x306</code> 根文件设备号<br><strong>注意:</strong><br>CPU的段寄存器（CS）指向 <code>0x07C0</code> -&gt; 原来 BOOTSEG 所在的位置</p>
<h5 id="为执行32位的main函数做过度工作"><a href="#为执行32位的main函数做过度工作" class="headerlink" title="为执行32位的main函数做过度工作"></a>为执行32位的main函数做过度工作</h5><h4 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h4><blockquote>
<ol>
<li>实模式: 兼容80286之后80x86的兼容CPU的模式、特性是一个20位的存储器地址空间(2^20 1MB的存储器空间可被寻址)<br>可以直接软件访问BIOS及周边硬件、无硬件支持的分页机制和实时多任务概念<br>80286 开始、所有的CPU开机都是 实模式 、之前的CPU只有一种模式、类似 实模式</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>CPU: 计算机所有的计算操作都由它完成、可以理解为 一个有输入和输出功能的集成电路</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>CPU寻址: 使用CS、IP两个寄存器<br>  CS: Code Segment Register 即代码段寄存器、指向CPU当前执行代码在内存中的位置(代码段的起始位置)、<br>  实模式为绝对地址、16位、保护模式为线性地址 需要结合GDT才能找到段基址<br>  IP&#x2F;EIP: Intruction Pointer. 指令寄存器、存在于CPU中、记录将要执行的代码在代码段中的偏移地址<br>  实模式为绝对地址、指令指针为16位、即IP、保护模式为32位、即EIP、<br>  CS:IP 寻址规则: 段基址*16 + 偏移地址</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>中断向量表建立<br>  BIOS在最开始的位置(0x00000)用1k内存(0x00000 - 0x003FF)构建中断向量表、接下来256k(0x00400～0x004FF)构建BIOS数据区<br>  大概57k后的位置(0x0E05B)加载了大概8k左右的与中断向量表相关的中断服务程序</li>
</ol>
</blockquote>
<blockquote>
<ol start="5">
<li>中断向量表<br>  记录所有中断向量对应中断程序的位置、实模式中断机制实现的重要部分</li>
</ol>
</blockquote>
<blockquote>
<ol start="6">
<li>中断服务程序<br>  通过中断向量表的索引对中断程序进行响应、是一些具有特殊功能的代码</li>
</ol>
</blockquote>
<blockquote>
<ol start="7">
<li>磁盘磁头<br>  利用特殊材料的电阻值会随磁场变化的原来来读写盘片数据、将硬盘盘片上的磁信号转化为电信号向外传输</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>Linux内核</category>
      </categories>
      <tags>
        <tag>Linux内核</tag>
      </tags>
  </entry>
  <entry>
    <title>curd操作</title>
    <url>/2020/03/20/mongo_curd%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h4 id="聚合操作"><a href="#聚合操作" class="headerlink" title="聚合操作"></a>聚合操作</h4><p><code>$sum</code>: 计算总和</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">db.mycol.<span class="keyword">aggregate</span>([&#123;$<span class="keyword">group</span> : &#123;_id:&quot;$f1&quot;, num_tutorial:&#123;$sum:&quot;$f2&quot;&#125;&#125;&#125;])</span><br><span class="line">-&gt; <span class="keyword">select</span> count(<span class="number">1</span>) <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">group</span> <span class="keyword">by</span> f1; </span><br><span class="line"></span><br><span class="line">db.mycol.<span class="keyword">aggregate</span>([&#123;$<span class="keyword">group</span> : &#123;_id:&quot;$f1&quot;, num_tutorial:&#123;$sum:&quot;$f2&quot;&#125;&#125;&#125;])</span><br><span class="line">-&gt;<span class="keyword">select</span> field,sum(f2) <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">group</span> <span class="keyword">by</span> f1;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>$avg</code>: 计算平均值</p>
<figure class="highlight axapta"><table><tr><td class="code"><pre><span class="line">db.test.aggregate([&#123;$<span class="keyword">group</span>:&#123;_id:<span class="string">&quot;$field&quot;</span>, <span class="keyword">avg</span>:&#123;$<span class="keyword">avg</span>:$f&#125;&#125;&#125;])</span><br><span class="line">-&gt; <span class="keyword">select</span> field,<span class="keyword">avg</span>(f) <span class="keyword">from</span> table <span class="keyword">group</span> <span class="keyword">by</span> field;</span><br></pre></td></tr></table></figure>
<p><code>$min</code>: 获取集合中所有文档对应的最小值</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">db.test.<span class="keyword">aggregate</span>([&#123;$<span class="keyword">group</span>:&#123;_id:&quot;$field&quot;,min:&#123;$min:&quot;$f2&quot;&#125;&#125;&#125;])</span><br><span class="line">-&gt; <span class="keyword">select</span> min(f2) <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">group</span> <span class="keyword">by</span> field;</span><br></pre></td></tr></table></figure>
<p><code>$max</code>: 获取集合中所有文档对应的最大值</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">参考<span class="built_in">min</span></span><br></pre></td></tr></table></figure>
<p><code>$push</code>: 在结果文档中插入值到一个数组</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line">db.t.<span class="title function_ invoke__">aggregate</span>([&#123;<span class="variable">$group</span>:&#123;<span class="attr">_id</span>:<span class="string">&quot;<span class="subst">$by_user</span>&quot;</span>,<span class="attr">url</span>:&#123;<span class="variable">$push</span>:<span class="string">&quot;<span class="subst">$url</span>&quot;</span>&#125;&#125;&#125;])</span><br></pre></td></tr></table></figure>
<p><code>$first</code>: 根据资源文档的排序获取第一个文档数据</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line">db.t.<span class="title function_ invoke__">aggregate</span>([&#123;<span class="variable">$group</span>:&#123;<span class="attr">_id</span>:<span class="string">&quot;<span class="subst">$by_user</span>&quot;</span>,<span class="attr">first_url</span>:&#123;<span class="variable">$first</span>:<span class="string">&quot;<span class="subst">$url</span>&quot;</span>&#125;&#125;&#125;])</span><br></pre></td></tr></table></figure>
<p><code>$last</code>: 根据资源文档的排序获取最后一个文档数据</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">参考<span class="keyword">first</span></span><br></pre></td></tr></table></figure>

<p><code>$project</code> 修改输出文档的结构<br><code>$match</code> 用于过滤数据、<br><code>$limit</code> 限制返回条数<br><code>$skip</code> 跳过指定条数的文档<br><code>$unwind</code> 将某个数组类型字段拆分成多条<br><code>$group</code> 将集合中的文档分组、可用于统计结果<br><code>$sort</code> 将文档排序后输出</p>
<p>eg.</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line">db.t.<span class="title function_ invoke__">aggregate</span>(&#123;<span class="variable">$project</span>:&#123;<span class="attr">_id</span>:<span class="number">0</span>,<span class="attr">title</span>:<span class="number">1</span>,<span class="attr">tags</span>:<span class="number">1</span>&#125;&#125;)</span><br><span class="line">db.t.<span class="title function_ invoke__">aggregate</span>(&#123;<span class="variable">$project</span>:&#123;<span class="attr">_id</span>:<span class="number">0</span>,<span class="attr">title</span>:<span class="number">1</span>,<span class="attr">tags</span>:<span class="number">1</span>&#125;&#125;,[&#123;<span class="variable">$match</span>:&#123;<span class="attr">score</span>:&#123;<span class="variable">$gt</span>:<span class="number">70</span>,<span class="variable">$lte</span>:<span class="number">90</span>&#125;&#125;&#125;,&#123;<span class="variable">$group</span>:&#123;<span class="attr">_id</span>:<span class="literal">null</span>,<span class="attr">count</span>:&#123;<span class="variable">$sum</span>:<span class="number">1</span>&#125;&#125;&#125;])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="mapReduce"><a href="#mapReduce" class="headerlink" title="mapReduce"></a>mapReduce</h4><figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">map</span> ：映射函数 (生成键值对序列,作为 reduce 函数参数)。</span><br><span class="line">reduce 统计函数，reduce函数的任务就是将<span class="built_in">key</span>-<span class="built_in">values</span>变成<span class="built_in">key</span>-value，也就是把<span class="built_in">values</span>数组变成一个单一的值value。。</span><br><span class="line">out 统计结果存放集合 (不指定则使用临时集合,在客户端断开后自动删除)。</span><br><span class="line">query 一个筛选条件，只有满足条件的文档才会调用<span class="built_in">map</span>函数。（query。<span class="built_in">limit</span>，<span class="built_in">sort</span>可以随意组合）</span><br><span class="line"><span class="built_in">sort</span> 和<span class="built_in">limit</span>结合的<span class="built_in">sort</span>排序参数（也是在发往<span class="built_in">map</span>函数前给文档排序），可以优化分组机制</span><br><span class="line"><span class="built_in">limit</span> 发往<span class="built_in">map</span>函数的文档数量的上限（要是没有<span class="built_in">limit</span>，单独使用<span class="built_in">sort</span>的用处不大）</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>安装使用</title>
    <url>/2020/03/20/mongo_%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><figure class="highlight n1ql"><table><tr><td class="code"><pre><span class="line">database 数据库</span><br><span class="line">collection 数据表</span><br><span class="line">document 数据记录行/文档</span><br><span class="line">filed 数据域</span><br><span class="line"><span class="keyword">index</span> 索引</span><br><span class="line"><span class="keyword">primary</span> <span class="keyword">key</span> 主键、默认 _id</span><br></pre></td></tr></table></figure>

<h4 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h4><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">1. show dbs 查看所有数据的列表</span><br><span class="line">   <span class="keyword">db</span> 显示当前数据库对象或者集合</span><br><span class="line">   <span class="keyword">use</span> <span class="keyword">local</span> 切换到<span class="keyword">local</span>这个<span class="keyword">db</span></span><br><span class="line">2. <span class="keyword">use</span> niuniu  <span class="keyword">db</span>不存在时会自动创建</span><br><span class="line">3. <span class="keyword">db</span>.dropDatabase() 删除一个<span class="keyword">db</span></span><br><span class="line"></span><br><span class="line">4. <span class="keyword">db</span>.createCollection(<span class="string">&quot;niu&quot;</span>) # 先创建集合、类似<span class="keyword">db</span>中的表</span><br><span class="line">   show tables/collections 查看所有的表</span><br><span class="line">   <span class="keyword">db</span>.niu.<span class="keyword">drop</span>() # 删除一个<span class="keyword">table</span></span><br><span class="line"></span><br><span class="line">5. <span class="keyword">db</span>.niu.insert(&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;niu&quot;</span>&#125;) 插入文档</span><br><span class="line">6. <span class="keyword">db</span>.niu.<span class="keyword">save</span>() 若不指定id, 类似于insert、若指定、会执行更新</span><br><span class="line">7. <span class="keyword">db</span>.<span class="keyword">help</span>() 库的帮助信息</span><br><span class="line">8. <span class="keyword">db</span>.<span class="keyword">table</span>.<span class="keyword">help</span>() 表的帮助文档</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="远程连接"><a href="#远程连接" class="headerlink" title="远程连接"></a>远程连接</h4><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">mongo</span> <span class="number">192.168.1.100:27017</span>/test</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>常用命令</title>
    <url>/2020/03/20/mongo_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h4 id="查看版本"><a href="#查看版本" class="headerlink" title="查看版本"></a>查看版本</h4><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">db</span>.<span class="keyword">version</span>()</span><br><span class="line">mongo --<span class="keyword">version</span></span><br><span class="line">mongod --<span class="keyword">version</span></span><br></pre></td></tr></table></figure>

<h4 id="查看各节点的健康状态"><a href="#查看各节点的健康状态" class="headerlink" title="查看各节点的健康状态"></a>查看各节点的健康状态</h4><figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">复制集状态查看  rs<span class="selector-class">.status</span>()</span><br><span class="line">查看oplog状态 rs<span class="selector-class">.printReplicationInfo</span>();</span><br><span class="line">查看复制延迟 rs<span class="selector-class">.printSlaveReplicationInfo</span>();</span><br><span class="line">查看服务状态详情 db<span class="selector-class">.serverStatus</span>();</span><br></pre></td></tr></table></figure>
<h4 id="查看数据库空间大小"><a href="#查看数据库空间大小" class="headerlink" title="查看数据库空间大小"></a>查看数据库空间大小</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">db.stats() 默认返回字节</span><br><span class="line"><span class="string">&quot;dataSize&quot;</span> : <span class="number">20</span>,  <span class="regexp">//</span>所有数据的总大小</span><br><span class="line"><span class="string">&quot;storageSize&quot;</span> : <span class="number">21</span>, <span class="regexp">//</span>所有数据占的磁盘大小 </span><br><span class="line"><span class="string">&quot;fileSize&quot;</span> : <span class="number">23</span>,  <span class="regexp">//</span>预分配给数据库的文件大小</span><br><span class="line"></span><br><span class="line">db.stats(<span class="number">1073741824</span>) <span class="regexp">//</span> 得到的单位是 G</span><br><span class="line">这里的objects以及avgObjSize还是bytes为单位的，不受参数影响</span><br></pre></td></tr></table></figure>

<h4 id="查看总的记录数"><a href="#查看总的记录数" class="headerlink" title="查看总的记录数"></a>查看总的记录数</h4><figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">db<span class="selector-class">.dbname</span><span class="selector-class">.find</span>()<span class="selector-class">.count</span>()</span><br><span class="line">db<span class="selector-class">.dbname</span><span class="selector-class">.find</span>()<span class="selector-class">.skip</span>(n)<span class="selector-class">.limit</span>(m)<span class="selector-class">.count</span>(); 会返回所有的记录数</span><br><span class="line">db<span class="selector-class">.dbname</span><span class="selector-class">.find</span>()<span class="selector-class">.skip</span>(n)<span class="selector-class">.limit</span>(m)<span class="selector-class">.count</span>(true); 会返回limit的记录数</span><br></pre></td></tr></table></figure>

<h4 id="查看数据库信息"><a href="#查看数据库信息" class="headerlink" title="查看数据库信息"></a>查看数据库信息</h4><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">db</span>.getName 返回当前所在的<span class="keyword">db</span>名称</span><br></pre></td></tr></table></figure>

<h4 id="允许副本集上的查询"><a href="#允许副本集上的查询" class="headerlink" title="允许副本集上的查询"></a>允许副本集上的查询</h4><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">rs.slaveOk<span class="comment">()</span></span><br></pre></td></tr></table></figure>

<h4 id="参考"><a href="#参考" class="headerlink" title="参考:"></a>参考:</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">https:<span class="regexp">//</span>www.cnblogs.com<span class="regexp">/kevingrace/</span>p/<span class="number">8178549</span>.html</span><br><span class="line">https:<span class="regexp">//</span>stackoverflow.com<span class="regexp">/questions/</span><span class="number">30088833</span><span class="regexp">/strange-mongodb-and-mongoose-error-not-master-and-slaveok-false-error/</span><span class="number">30089063</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>查询计划简要分析</title>
    <url>/2020/03/20/mongo_%E6%9F%A5%E8%AF%A2%E8%AE%A1%E5%88%92%E7%AE%80%E8%A6%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h4 id="查看sql执行计划"><a href="#查看sql执行计划" class="headerlink" title="查看sql执行计划"></a>查看sql执行计划</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">在查询语句后添加 explain 即可</span><br><span class="line">eg. db.collection.find().explain()</span><br></pre></td></tr></table></figure>

<h4 id="返回信息解读"><a href="#返回信息解读" class="headerlink" title="返回信息解读"></a>返回信息解读</h4><figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">queryPlanner (查询计划)</span><span class="punctuation">:</span> <span class="string">查询优化选择的计划细节和被拒绝的计划</span></span><br><span class="line">    <span class="attribute">namespace 运行查询的指定命名空间</span></span><br><span class="line"><span class="attribute">    indexFilterSet Boolean值、表示mongodb在查询中是否使用索引过滤</span></span><br><span class="line"><span class="attribute">    winningPlan 由查询优化选择的计划文档</span></span><br><span class="line"><span class="attribute">         stage</span><span class="punctuation">:</span> <span class="string">表示查询阶段的字符串</span></span><br><span class="line">         <span class="attribute">inputStage</span><span class="punctuation">:</span> <span class="string">表示子查询的文档</span></span><br><span class="line">         <span class="attribute">inputStages</span><span class="punctuation">:</span> <span class="string">表示子过程的文档数组</span></span><br><span class="line"><span class="attribute">executionStats(执行状态)</span><span class="punctuation">:</span> <span class="string">被选中执行计划和被拒绝执行计划的详细说明</span></span><br><span class="line">     queryPlanner.nReturned－匹配查询条件的文档数</span><br><span class="line">     queryPlanner.executionTimeMillis－计划选择和查询执行所需的总时间（毫秒数）</span><br><span class="line">     queryPlanner.totalKeysExamined－扫描的索引总数</span><br><span class="line">     queryPlanner.totalDocsExamined－扫描的文档总数</span><br><span class="line">     queryPlanner.executionStages－显示执行成功细节的查询阶段树</span><br><span class="line">          executionStages.works－指定查询执行阶段执行的“工作单元”的数量</span><br><span class="line">          executionStages.advanced－返回的中间结果数</span><br><span class="line">          executionStages.needTime－未将中间结果推进到其父级的工作周期数</span><br><span class="line">          executionStages.needYield－存储层要求查询系统产生的锁的次数</span><br><span class="line">          executionStages.isEOF－指定执行阶段是否已到达流结束</span><br><span class="line">     queryPlanner.allPlansExecution－包含在计划选择阶段期间捕获的部分执行信息，包括选择计划和拒绝计划</span><br><span class="line"> serverInfo,（服务器信息）：MongoDB实例的相关信息：</span><br><span class="line">     winningPlan－使用的执行计划</span><br><span class="line">          shards－包括每个访问片的queryPlanner和serverInfo的文档数组</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>MQ性能</title>
    <url>/2020/03/20/mq_MQ%E6%80%A7%E8%83%BD/</url>
    <content><![CDATA[<h3 id="MQ消息积压如何处理"><a href="#MQ消息积压如何处理" class="headerlink" title="MQ消息积压如何处理"></a>MQ消息积压如何处理</h3><h4 id="优化性能避免消息积压"><a href="#优化性能避免消息积压" class="headerlink" title="优化性能避免消息积压"></a>优化性能避免消息积压</h4><p>MQ本身的处理能力是远大于业务系统的处理能力的、主流消息队列的单个节点、消息收发的性能可以达到每秒几万到几十万的水平、水平扩展Broker的实例数可以成倍的提升处理能力、应该更多的关注在消息的收发两端、让业务代码和MQ配合、达到最佳性能</p>
<ul>
<li>发送端性能优化<br>若代码发送消息的性能较弱、很可能是发MQ之前的逻辑太耗时导致、一般设置合理的并发和批量大小、就可以达到很好的性能</li>
</ul>
<p>MQ的完整交互: P -&gt; Broker -&gt; R<br>假设单线程发送、每秒处理请求 1000ms&#x2F;1ms*1条&#x2F;1ms &#x3D; 1000 条msg、并不能发挥MQ的实力</p>
<ol>
<li>增加batch大小、2. 并发请求 都可以提升性能<br>对于关注延时的RPC系统、可以选择增加并发量<br>对于关注吞吐量的离线分析系统、它不关心时延、可以选择批量发送</li>
</ol>
<ul>
<li>消费端性能优化<br>若消费的速度跟不上msg生产的速度、MQ存储被填满之后就会造成无法提供服务、消息丢失、对于整个系统都是严重故障</li>
</ul>
<p>消费端的性能优化除了优化消费业务逻辑之外、还可以通过简单的水平扩容来增加消费端的并发数来提高整体的消费性能<br><em>注意</em><br>在扩容consumer实例的同时、必须同步扩容主题中的分区(队列)数量、确保consumer的实例数和分区数相等、因为每个分区只支持单线程消费</p>
<ul>
<li>消息积压了如何处理？</li>
</ul>
<ol>
<li>若单位时间内发送的消息增多、最快的办法就是通过扩容消费端的实例来提升总体的消费能力，或者可以通过系统降级、减少生产者发送数据</li>
<li>若是消费和生产速度都无明显变化、需要检查消费端、数不胜数消费失败导致反复消费</li>
<li>若是消费变慢、可以快速排查消费日志、看看消费线程是不是卡着不动了</li>
</ol>
<h4 id="疑问点记录"><a href="#疑问点记录" class="headerlink" title="疑问点记录"></a>疑问点记录</h4><p>假如、有一个topic、Q为5、Broker为2</p>
<ol>
<li><p>有3个生产者实例、如何对应到5个Q ?<br> 不用对应、随便发或者指定Q选取规则</p>
</li>
<li><p>每个消费组都是单独的订阅、拥有队列的全部消息、消费完后消息不会删除</p>
</li>
<li><p>多个消费组订阅同一个topic彼此不影响、<br>eg. 消费组G0 | G1 、G0挂掉、积压很多消息、对G1也没有任何影响</p>
</li>
<li><p>消费位置<br> 每个消费组会维护一组消费位置、每个队列对应一个消费位置、并且消费位置和消费者无关、保存在服务端</p>
</li>
<li><p>如何实现单个队列的并行消费<br>eg. MQ中有10条消息、对应的编号是0-9、当前消费位置是5、同时有5、6、7三个消费者拉取消息、5、6、7三个消息给每个消费者一人一条、理想情况下、3个消费者成功响应、消费位置更新为8 实现并行消费<br>假如5卡着某个环节不动了、位置5就是消息空洞、为了避免整个队列卡住、将5复制到一个重试队列、然后更新消费位置、消费时优先给出重试队列的数据<br>这是实现并行消费的一种实现方式、但是开销很大、不应该作为常规手段、若需要增加消费者的并发数、还是需要扩容队列数</p>
</li>
</ol>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ简介</title>
    <url>/2020/03/20/mq_RocketMQ%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>组件:</p>
<p>nameSrv作用: </p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>.加载kv配置、创建nettyServer网络处理对象、</span><br><span class="line"><span class="number">2</span>.开启定时任务进行心跳监测</span><br><span class="line"><span class="symbol">task1:</span> nameSrv 每<span class="number">10</span>s扫描一次<span class="keyword">broker、移除处于不激活状态的broker</span></span><br><span class="line"><span class="keyword"></span><span class="symbol">task2:</span> nameSrv 每<span class="number">10</span>min打印一次kv配置</span><br><span class="line"><span class="number">3</span>.注册<span class="keyword">jvm钩子函数、监听broker、消息生产者的请求</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">broker如果挂掉、producer向broker的消息发送是否失败 </span>？ 如何处理 ？</span><br><span class="line"><span class="number">10</span>s之后才会更新nameSrv信息、producer才可以检测到</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>NameSrv功能实现</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 路由注册、故障剔除</span><br><span class="line">nameSrv 测主要作用是为Producer和Consumer提供topic信息、所以需要存储路由的基础信息、能够管理<span class="keyword">Broker节点、包括路由注册、故障剔除等</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">元信息:</span><br><span class="line"><span class="symbol">topicQueueTable:</span> topic 消息队列路由信息、消息发送时进行负载均衡</span><br><span class="line"><span class="keyword">brokerAddrTable: </span><span class="keyword">broker基础信息、包含BrokerName、所属集群地址、主备broker地址</span></span><br><span class="line"><span class="keyword"></span><span class="symbol">clusterAddrTable:</span> <span class="keyword">broker集群信息、存储集群中brokerName</span></span><br><span class="line"><span class="keyword"></span><span class="keyword">brokerLiveTable: </span><span class="keyword">broker状态信息、nameServer每次收到心跳包时更新</span></span><br><span class="line"><span class="keyword"></span><span class="symbol">filterServerTable:</span> <span class="keyword">broker上的FilterServer列表、用于消息过滤</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">一个topic有多个Queue、一个<span class="keyword">broker默认为每个topic创建4个读Q </span>和 <span class="number">4</span>个写Q、多个<span class="keyword">broker组成一个集群、多台相同brokerName的broker机器组成M-S架构、brokerId=0代表M、</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">BrokerLiveInfo中的lastUpdateTimestamp存储上次收到broker心跳包的时间</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">路由注册通过<span class="keyword">broker和nameSrv的心跳实现、broker每隔30s向所有nameSrv发送心跳、nameSrv收到心跳包更新brokerLiveTable中的BrokerLiveInfo的心跳时间、10s扫描一次brokerLiveTable、若连续120s未收到心跳包、nameSrv会移除该broker</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">路由删除:</span><br><span class="line"><span class="number">1</span>. nameSrv定时扫描 <span class="keyword">brokerLiveTable、超过120s未收到心跳包、会移除broker信息</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>. <span class="keyword">broker正常关闭时、主动调用unregisterBroker</span></span><br><span class="line"><span class="keyword"></span><span class="number">1</span>) 从<span class="keyword">brokerLiveTable、filterServerTable移除该broker</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>) 维护<span class="keyword">brokerAddrList信息</span></span><br><span class="line"><span class="keyword"></span><span class="number">3</span>) 维护clusterAddrTable信息</span><br><span class="line"><span class="number">4</span>) 遍历topic、从路由信息移除该<span class="keyword">broker</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">路由发现:</span><br><span class="line"><span class="number">1</span>. 非实时、topic路由信息变化、nameSrv不会主动推送、而是client主动定时拉取、</span><br><span class="line">从topicQueueTable、<span class="keyword">brokerAddrTable、filterServerTable中填充TopicQueueData的QueueData、BrokerData、filterServer地址表</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>. 若从topic找到对应的路由信息为顺序消息、则从nameServer kvConfig中获取关于顺序消息相关的配置填充路由信息</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Borker:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">提供消息存储、</span><br><span class="line">对于mq的消息存储、一般考虑 消息堆积能力 和 消息存储能力</span><br><span class="line">rocketmq 引入内存映射机制、所有主题的消息顺序存储在同一文件</span><br><span class="line">引入 消息文件过期机制 和 文件存储空间报警机制 - 避免消息无限堆积</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Producer启动流程</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 检查producerGroup是否符合要求、改变生产者的instanceName为进程id</span><br><span class="line"><span class="bullet">2.</span> 创建MQClientInstance实例、整个jvm中只存在一个MQClientManager实例、维护一个MQClientInstance的hashMap表、即: 同一个clientID只会创建一个MQClientInstance</span><br><span class="line">   instance是封装了rocketMQ的网络处理API、是Producer、Consumer与NameSrv、Broker打交道的网络通道</span><br><span class="line"><span class="bullet">3.</span> 将producer注册到MQClientInstance管理中、方便后续进行网络请求、心跳检测等</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>消息发送过程</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">支持<span class="number">3</span>种方式: 同步<span class="keyword">sync、异步async、单向oneway</span></span><br><span class="line"><span class="keyword"></span><span class="keyword">sync: </span>同步等待<span class="keyword">broker将结果返回</span></span><br><span class="line"><span class="keyword"></span><span class="symbol">async:</span> 指定回调函数、不阻塞producer线程、消息结果通过回调通知</span><br><span class="line"><span class="symbol">oneway:</span> 不等待消息存储结果、亦不提供回调函数、不关心是否存储成功</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>. 消息长度验证、消息长度最大<span class="number">4</span>M</span><br><span class="line"><span class="number">2</span>. 查找路由信息</span><br><span class="line">   首次发msg时、本地未缓存topic路由信息、查询nameSrv获取、未找到时会尝试创建、若路由信息变化则更新<span class="keyword">broker地址列表</span></span><br><span class="line"><span class="keyword"></span><span class="number">3</span>. queue选择</span><br><span class="line">若<span class="number">2</span>m<span class="number">-2</span>s架构、queueNum=<span class="number">4</span>、rocketmq会如何选择 ？</span><br><span class="line">消息发送时会多次执行queue选择算法、lastBrokerName是上次send failed的<span class="keyword">broker、第一次执行Q选择时、last为null、直接在所有Q中选择、</span></span><br><span class="line"><span class="keyword"></span>再次执行时、会先判断、选择<span class="keyword">brokerName!=lastBrokerName的来进行规避</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">如果再次选择、得到的依然是不可用的Queue呢 ？会再次重试、造成资源浪费</span><br><span class="line"><span class="keyword">broker故障不会立即摘除(nameSrv </span><span class="number">10</span>s才检测一次、Producer也是<span class="number">30</span>s才更新路由信息、最快感知也需要<span class="number">30</span>s)、</span><br><span class="line"></span><br><span class="line"><span class="keyword">broker延迟故障机制</span></span><br><span class="line"><span class="keyword"></span><span class="number">1</span>) 获取一个小小队列</span><br><span class="line"><span class="number">2</span>) 验证是否可用</span><br><span class="line"><span class="number">3</span>) 若可用、移除latencyFaultTolerance关于该topic的条目、表明<span class="keyword">broker故障恢复</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">消息发送</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>. 消息队列如何负载 ？</span><br><span class="line"><span class="number">2</span>. 如何实现高可用？</span><br><span class="line"><span class="number">3</span>. 批量消息如何实现一致性？</span><br></pre></td></tr></table></figure>

<p>Consumer消息消费</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">集群模式: 同一topic下一条消息只能允许被其中一个消费者消费、消费进度保存在broker端</span></span><br><span class="line"><span class="section">广播模式: 同一topic下一条消息可以被同一消费组的所有消费者消费、消息消费进度保存在消费端</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">消息队列负载与重新分布</span><br><span class="line">消息消费模式</span><br><span class="line">消息拉取方式</span><br><span class="line">消息进度反馈</span><br><span class="line">消息过滤</span><br><span class="line">顺序消息</span><br></pre></td></tr></table></figure>
<p>消费者启动流程</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 构建订阅主题信息SubscriptionData并加入到RebalanceImpl的订阅消息中、订阅关系来自:</span><br><span class="line">   1) 调用subscribe方法</span><br><span class="line">   2) 订阅重试主题消息 以消费组为单位 命名: %RETRY%+消费组名</span><br><span class="line"><span class="bullet">2.</span> 初始化MQClientInstance、RebalanceImpl等</span><br><span class="line"><span class="bullet">3.</span> 初始化消费进度、broadcast保存在broker、cluster保存在consumer</span><br><span class="line"><span class="bullet">4.</span> 根据是否顺序消费、创建消费端消费线程服务、ConsumeMessageService主要负责消息消费、内部维护一个线程池</span><br><span class="line"><span class="bullet">5.</span> 向MQClientInstance注册消费者、并启动MQInstance、在一个JVM中的所有消费者、生产者持有同一个MQClientInstance、只启动一次</span><br></pre></td></tr></table></figure>

<p>消息可用性保障</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> Broker 正常关机</span><br><span class="line"><span class="bullet">2.</span> Broker 异常Crash</span><br><span class="line"><span class="bullet">3.</span> OS Crash</span><br><span class="line"><span class="bullet">4.</span> 机器断电、可立即恢复供电</span><br><span class="line"><span class="bullet">5.</span> 机器无法开机、可能是CPU、主板、内存等关键设备损坏</span><br><span class="line"><span class="bullet">6.</span> 磁盘设备损坏</span><br><span class="line"></span><br><span class="line">1-4 在同步刷盘机制下、可以确保不丢失消息、异步刷盘模式下丢失少量消息</span><br><span class="line">5、6属于单点故障、一旦发生、节点上的消息全部丢失、若开启了异步复制可保证只丢失少量消息、双写机制下 不会丢失消息</span><br></pre></td></tr></table></figure>

<p>消息延迟</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">在正常不发生消息堆积的情况下、以长轮询方式实现准实时消息推送</span><br></pre></td></tr></table></figure>

<p>消息堆积</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">rocketmq</span>消息存储使用磁盘文件(内存映射)并且在物理布局上为多个大小相等的文件组成逻辑文件组、可无限循环使用、提供消息过期机制、默认保留<span class="number">3</span>天</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>消息过滤:</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> broker端过滤、</span><br><span class="line"><span class="bullet">2.</span> consumer过滤、</span><br></pre></td></tr></table></figure>

<p>msg status 说明:</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">SEND_OK, <span class="regexp">//</span> 发送成功</span><br><span class="line">FLUSH_DISK_TIMEOUT, <span class="regexp">//</span> 在规定时间内没有完成刷盘、在 flushDiskType 为 SYNC_FLUSH 时才出现 </span><br><span class="line">FLUSH_SLAVE_TIMEOUT, <span class="regexp">//</span> 在主备方式下、broker被设置为 sync_master方式时、未在指定时间内完成主从同步</span><br><span class="line">SLAVE_NOT_AVAILABLE, <span class="regexp">//</span> 在主备方式下、broker被设置为 sync_master方式时、未找到slave</span><br></pre></td></tr></table></figure>

<p>疑问</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> broker收到消息会先写commitlog、为什么producer发消息的时候会选择一个Queue去发 ？而不是broker ？再由broker分发到Queue ？</span><br><span class="line"></span><br><span class="line"><span class="bullet">2.</span> 写commitlog的时候、同步刷盘指针和异步刷盘指针写的是同一个commitlog文件、如何保证消息的有序存储？</span><br><span class="line"></span><br><span class="line"><span class="bullet">3.</span> 文件清除何时进行 ？</span><br><span class="line"></span><br><span class="line"><span class="bullet">4.</span> 消息队列如何进行负载均衡？</span><br><span class="line"></span><br><span class="line"><span class="bullet">5.</span> 消息发送如何保证高可用</span><br><span class="line"></span><br><span class="line"><span class="bullet">6.</span> 批量消息如何保持一致性</span><br><span class="line"></span><br><span class="line"><span class="bullet">7.</span> broker失效后120s才能将该broker从路由表中移除、若生产者获取到的路由信息包含已宕机的broker如何处理？</span><br><span class="line"></span><br><span class="line"><span class="bullet">8.</span> </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>MQ的消息模型和事务</title>
    <url>/2020/03/20/mq_MQ%E7%9A%84%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%E5%92%8C%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<h4 id="消息队列架构演进"><a href="#消息队列架构演进" class="headerlink" title="消息队列架构演进"></a>消息队列架构演进</h4><p><strong>早期mq就是按照队列的数据结构来设计的</strong><br><img src="https://upload-images.jianshu.io/upload_images/14027542-7491db81233d4005.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="早期MQ架构"></p>
<p>若有多个生产者往同一队列发送消息、这个队列可以消费到生产者消息的集合、顺序为生产者发送消息的自然顺序<br>若多个消费者消费一个队列、这些消费者是竞争关系、只消费到队列的一部分数据<br>需要每个消费者消费全量消息时、只能创建多个Queue、让生产者发送多份数据、并且生产者必须知道有多少消费者、违背了消息队列解耦的初衷</p>
<p><strong>演进架构</strong><br>发布 - 订阅模型(Publish-Subscribe Pattern)<br><img src="https://upload-images.jianshu.io/upload_images/14027542-83faa4bba38ebc69.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="发布-订阅模型"></p>
<p>在P-S架构中、msg发送方称为发布者Publisher、接收方称为订阅者Subscriber、服务端存放消息的容器称为主题Topic、消费之前必须先订阅主题</p>
<p>其实和队列模式没有本质区别、最大的区别在于: 一份数据能不能被消费多次</p>
<h4 id="RabbitMQ的消息模型"><a href="#RabbitMQ的消息模型" class="headerlink" title="RabbitMQ的消息模型"></a>RabbitMQ的消息模型</h4><p>RabbitMQ是少数坚持使用队列模型的产品之一、它如何解决多个消费者的问题呢 ？<br>Exchange: 位于生产者和队列之间、生产者不关心将消息发送给哪个队列、而是将消息发送给Exchange、由Exchange上配置的策略来决定将消息投递到哪些队列中<br><img src="https://upload-images.jianshu.io/upload_images/14027542-9c144b17627ba919.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="RabbitMQ消息模型"></p>
<p>同一份消息需要被多个消费者消费时、需要配置exchange将消息发送到多个队列、每个队列中存放一份完整的消息数据、</p>
<h4 id="RocketMQ的消息模型"><a href="#RocketMQ的消息模型" class="headerlink" title="RocketMQ的消息模型"></a>RocketMQ的消息模型</h4><p>RocketMQ使用的是标准的发布-订阅模型、</p>
<p>普通的MQ都是使用的请求-确认机制、确保消息不会再传递过程中由于网络故障或服务器故障丢失. 在生产端、生产者将消息发给服务端Broker、Broker在收到消息并将消息写入主题或者队列后、会给生产者发送确认的响应、若生产者未收到服务端的确认或者收到失败的响应、会重新发消息; 在消费端、消费者收到消息并完成消费逻辑后也会给服务端发送消费成功的确认、服务端只有在收到消费确认后、才会认为一条消息被成功消费、否则会重发消息</p>
<p>为了保证消息有序性、在消息被成功消费前、下一条消息不能被消费、否则就出现了消息空洞、违背了有序性的原则、所以 MQ增加了队列的概念、只在队列层面保证消息的有序性、主题层面不保证</p>
<p>消息会被不同消费组消费、消费完的消息不会立即删除、MQ为每个队列维护了一个消费位置Consumer Offset、每成功消费一条消息、位置就+1</p>
<h4 id="Kafka的消息模型"><a href="#Kafka的消息模型" class="headerlink" title="Kafka的消息模型"></a>Kafka的消息模型</h4><p>Kafka的消费模型和RocketMQ的模型是完全一样的、唯一的区别是 在Kafka中队列这个概念的名称不同、Kafka对应的概念叫 <code>分区</code> - <code>Partition</code> </p>
<p>注意:<br>RocketMQ 和 Kafka 的业务模型一样、不代表实现一致、其实实现是完全不同的、就像MySQL和hbase存放数据的单元都是表、实现完全不同、MySQL使用B+树来存储、HBase 使用KV结构存储</p>
<h4 id="MQ的事务实现"><a href="#MQ的事务实现" class="headerlink" title="MQ的事务实现"></a>MQ的事务实现</h4><p>Kafka 和 RocketMQ 都提供了事务的实现<br>在消息队列上开启一个事务、给服务器发送一个<code>半消息</code>状态、它包含完整的消息内容、但对于消费者不可见、本地事务提交后再提交消息事务<br>但: 如果提交消息事务失败怎么办 ？</p>
<ol>
<li>kafka的方案简单粗暴、直接抛异常、用户自行处理</li>
<li>RocketMQ提供了事务反查机制、若Broker未收到提交或者回滚的请求、Broker会定期去Producer上反查本地事务对应状态、来决定事务提交还是回滚<br><img src="https://upload-images.jianshu.io/upload_images/14027542-40c0cd530d78849e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></li>
</ol>
<h4 id="消息可靠性保证"><a href="#消息可靠性保证" class="headerlink" title="消息可靠性保证"></a>消息可靠性保证</h4><p><strong>检测消息丢失</strong><br>1.若基础设施比较完善、一般会有分布式链路追踪系统、可以追踪消息流<br>2.利用消息有序性校验: 给每个发出的消息附加一个连续的序号、若序号不连续、就可以判定为消息丢失<br>注意: 多个producer 和 多个consumer的情况、需要判定每个分区的序列有效性<br><strong>如何保证</strong><br>1.生产阶段、根据不同mq的确认机制、进行对应的处理 eg: kafka -&gt; 捕获异常<br>2.存储阶段、正常broker运行的时候、不会出现消息丢失、但若broker出现了故障或者宕机、是可能丢消息的. 单节点broker可以配置broker在收到消息后立即落盘、broker是集群的时候、可以配置至少2个节点收到消息再确认<br>3.消费阶段、同生产阶段、消费端<em>业务逻辑</em>成功后再回传确认<br>有可能消息再网络传输过程中发生错误、发送方收不到确认就会重发消息、所以Broker 和 Consumer 都可能会收到重复消息、需要注意接口的幂等性</p>
<p><strong>业务变相实现</strong><br>1.利用数据库的唯一约束实现幂等、<br>2.为更新的数据设置前置条件、满足某种条件才更新<br>3.记录并检查操作(需要考虑唯一ID的生成和多步操作的原子性)</p>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>幂等方案、不止是可以解决消息重复的问题、也同样适用于其它场景.eg: 将HTTP服务设计成幂等的、解决前端或者APP重复提交表单数据问题、也可以将一个微服务设计成幂等的、解决RPC框架自动重试导致的重复调用问题</p>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>mq何时使用</title>
    <url>/2020/03/20/mq_mq%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul>
<li>异步处理</li>
<li>流量控制(令牌桶)</li>
<li>服务解耦</li>
</ul>
<p><strong>局限</strong></p>
<ul>
<li>增加系统复杂度</li>
<li>增加部分延迟</li>
<li>可能导致数据不一致</li>
</ul>
<p><strong>思考</strong></p>
<ol>
<li>CPU的运算速度 远大于 内存读写速度 –&gt; CPU缓存(L1 &#x2F; L2 &#x2F; L3)</li>
<li>内存的读写速度 远大于 硬盘 –&gt; 内存缓存系统 (redis &#x2F; memcache 等) 和 本地缓存 、线程缓存</li>
<li>上游系统的处理速度大于下游依赖系统 –&gt; mq(缓存上游请求)</li>
<li>网络请求、磁盘操作比较耗时 –&gt; 出现了缓存系统 &#x2F; 协程 &#x2F; 多线程等概念来解决</li>
<li>CPU写内存的速度小于写cache -&gt; 先写cache、定时刷新 -&gt; 出现了线程同步问题</li>
<li>写内存的速度大于写磁盘 –&gt; redis 、mysql等系统应用的日志都是先写cache、按照指定规则刷新 –&gt; 有了系统崩溃短时间内log不能恢复的问题</li>
<li>生产者和消费者速度不一致 –&gt; 有了broker暂存消息</li>
</ol>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>索引简单使用</title>
    <url>/2020/03/20/mongo_%E7%B4%A2%E5%BC%95%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>###索引管理</p>
<h4 id="索引创建"><a href="#索引创建" class="headerlink" title="索引创建"></a>索引创建</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">db.COLLECTION_NAME.ensureIndex(keys[,<span class="keyword">options</span>])</span><br><span class="line"></span><br><span class="line">keys: 要建立索引的参数列表 key字段名、<span class="number">1</span>升序 <span class="number">-1</span>降序</span><br><span class="line"></span><br><span class="line"><span class="keyword">options</span>: 可选参数</span><br><span class="line">background: <span class="type">Boolean</span> 在后台建立索引</span><br><span class="line"><span class="keyword">unique</span>: <span class="type">boolean</span> 创建唯一索引、默认<span class="keyword">false</span></span><br><span class="line"><span class="type">name</span> String指定索引名称</span><br><span class="line">dropDups <span class="type">Boolean</span>创建唯一索引时、若若出现重复、删除后续出现的相同索引、只保留第一个</span><br><span class="line">sparse <span class="type">Boolean</span> 对文档中不存在的字段数据不启用索引、默认<span class="keyword">false</span></span><br><span class="line">v <span class="keyword">index</span> <span class="keyword">version</span> 索引的版本号</span><br><span class="line">weights document索引权重值、表示改索引相对其它索引字段的得分权重值</span><br></pre></td></tr></table></figure>

<h4 id="重建索引"><a href="#重建索引" class="headerlink" title="重建索引"></a>重建索引</h4><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">db<span class="selector-class">.collectionName</span><span class="selector-class">.reIndex</span>()</span><br><span class="line">作用类似于mysql的optimize、修复多次修改产生的文件空洞</span><br></pre></td></tr></table></figure>

<h4 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a>查看索引</h4><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">db<span class="selector-class">.collectionName</span><span class="selector-class">.getIndexes</span>()</span><br><span class="line">查看索引大小</span><br></pre></td></tr></table></figure>

<h4 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h4><figure class="highlight pf"><table><tr><td class="code"><pre><span class="line">db.collectionName.<span class="keyword">drop</span>Index(IndexName)</span><br><span class="line"></span><br><span class="line">删除所有索引</span><br><span class="line">db.collectionName.<span class="keyword">drop</span>Indexes;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="基础索引与复合索引"><a href="#基础索引与复合索引" class="headerlink" title="基础索引与复合索引"></a>基础索引与复合索引</h3><h4 id="基础索引"><a href="#基础索引" class="headerlink" title="基础索引"></a>基础索引</h4><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 为一个集合中的某个字段创建索引</span><br><span class="line">eg. db<span class="selector-class">.useers</span><span class="selector-class">.ensureIndex</span>(&#123;age:<span class="number">1</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 当数据很多时、索引创建会比较慢、可以指定 <span class="attribute">background</span>: true</span><br><span class="line">eg. db.users.<span class="built_in">ensureIndex</span>(&#123;age:<span class="number">1</span>&#125;, &#123;<span class="attribute">background</span>: true&#125;)</span><br></pre></td></tr></table></figure>

<h4 id="组合索引"><a href="#组合索引" class="headerlink" title="组合索引"></a>组合索引</h4><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">为users表的age和city字段、创建联合索引、分表按照升序和降序排列</span><br><span class="line">eg. db.useers.ensure<span class="constructor">Index(&#123;<span class="params">age</span>:1, <span class="params">city</span>:-1&#125;)</span></span><br></pre></td></tr></table></figure>

<h4 id="查看索引-1"><a href="#查看索引-1" class="headerlink" title="查看索引"></a>查看索引</h4><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">db<span class="selector-class">.dbname</span><span class="selector-class">.getIndexes</span>() 返回当前集合所有的索引</span><br><span class="line"><span class="number">1</span>:升序  -<span class="number">1</span>:降序</span><br></pre></td></tr></table></figure>

<h3 id="文档索引"><a href="#文档索引" class="headerlink" title="文档索引"></a>文档索引</h3><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. mongodb可以为多个字段创建索引、当字段是子文档时、同样可以创建</span><br><span class="line">eg. mongo中有下列数据</span><br><span class="line">&#123;name:<span class="string">&quot;aaa&quot;</span>, address:&#123;city:<span class="string">&quot;bj&quot;</span>,district:<span class="string">&quot;海淀&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line">可以为<span class="selector-tag">address</span>创建索引如下:</span><br><span class="line">db.users.<span class="built_in">ensureIndex</span>(&#123;<span class="selector-tag">address</span>:<span class="number">1</span>&#125;)</span><br><span class="line"></span><br><span class="line">建立索引后、查询时子文档的字段顺序要和查询顺序一致、才可使用索引</span><br><span class="line"></span><br><span class="line">// 会使用索引</span><br><span class="line">db<span class="selector-class">.users</span><span class="selector-class">.find</span>(&#123;<span class="selector-tag">address</span>:&#123;city:<span class="string">&quot;bj&quot;</span>,district:<span class="string">&quot;海淀&quot;</span>&#125;&#125;)</span><br><span class="line"></span><br><span class="line">// 不会使用索引</span><br><span class="line">db<span class="selector-class">.users</span><span class="selector-class">.find</span>(&#123;<span class="selector-tag">address</span>:&#123;district:<span class="string">&quot;海淀&quot;</span>,city:<span class="string">&quot;bj&quot;</span>&#125;&#125;)</span><br><span class="line"></span><br><span class="line">也可以只对子文档的某一个或者部分字段创建索引</span><br><span class="line">db<span class="selector-class">.users</span><span class="selector-class">.ensureIndex</span>(&#123;&quot;<span class="selector-tag">address</span><span class="selector-class">.city</span>&quot;:<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>

<h3 id="唯一索引与强制索引"><a href="#唯一索引与强制索引" class="headerlink" title="唯一索引与强制索引"></a>唯一索引与强制索引</h3><h4 id="创建唯一索引"><a href="#创建唯一索引" class="headerlink" title="创建唯一索引"></a>创建唯一索引</h4><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">添加索引时、指定 unique:<span class="literal">true</span> 等效于唯一索引</span><br><span class="line">eg. 为users表的email字段添加唯一索引</span><br><span class="line">db.users.ensure<span class="constructor">Index(&#123;<span class="params">email</span>:1&#125;,&#123;<span class="params">unique</span>:<span class="params">true</span>&#125;)</span></span><br><span class="line"></span><br><span class="line">创建唯一索引后、插入重复值时、mongo会报错..</span><br></pre></td></tr></table></figure>

<h4 id="强制使用索引"><a href="#强制使用索引" class="headerlink" title="强制使用索引"></a>强制使用索引</h4><figure class="highlight php"><table><tr><td class="code"><pre><span class="line">db.users.<span class="title function_ invoke__">find</span>(&#123;<span class="attr">name</span>:<span class="string">&#x27;aaa&#x27;</span>, <span class="attr">age</span>:<span class="number">3</span>&#125;).<span class="title function_ invoke__">hint</span>(&#123;<span class="attr">age</span>:<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>mq本地搭建</title>
    <url>/2020/03/20/mq_mq%E6%9C%AC%E5%9C%B0%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>启动:<br>进入到编译target目录<br>eg. 我的下载路径是 &#x2F;Users&#x2F;nj&#x2F;build&#x2F;rocketmq-all-4.4.0<br>cd &#x2F;Users&#x2F;nj&#x2F;build&#x2F;rocketmq-all-4.4.0&#x2F;distribution&#x2F;target&#x2F;apache-rocketmq&#x2F;</p>
<p>1.启动namesrv<br>sh bin&#x2F;mqnamesrv &amp;</p>
<ol start="2">
<li><p>启动broker<br>sh bin&#x2F;mqbroker &amp;</p>
</li>
<li><p>测试:<br>sh bin&#x2F;tools.sh org.apache.rocketmq.example.quickstart.Producer<br>报错:</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="number">17</span>:<span class="number">28</span>:<span class="number">23.123</span> <span class="selector-attr">[main]</span> DEBUG <span class="selector-tag">i</span><span class="selector-class">.n</span><span class="selector-class">.u</span><span class="selector-class">.i</span><span class="selector-class">.l</span><span class="selector-class">.InternalLoggerFactory</span> - Using SLF4J as the default logging framework</span><br><span class="line">org<span class="selector-class">.apache</span><span class="selector-class">.rocketmq</span><span class="selector-class">.client</span><span class="selector-class">.exception</span><span class="selector-class">.MQClientException</span>: No route info of this topic, TopicTest1</span><br><span class="line">See http:<span class="comment">//rocketmq.apache.org/docs/faq/ for further details.</span></span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.rocketmq</span><span class="selector-class">.client</span><span class="selector-class">.impl</span><span class="selector-class">.producer</span><span class="selector-class">.DefaultMQProducerImpl</span><span class="selector-class">.sendDefaultImpl</span>(DefaultMQProducerImpl<span class="selector-class">.java</span>:<span class="number">610</span>)</span><br><span class="line"><span class="number">17</span>:<span class="number">28</span>:<span class="number">29.595</span> <span class="selector-attr">[NettyClientSelector_1]</span> INFO  RocketmqRemoting - closeChannel: close the connection to remote <span class="selector-tag">address</span><span class="selector-attr">[]</span> result: true</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.rocketmq</span><span class="selector-class">.client</span><span class="selector-class">.impl</span><span class="selector-class">.producer</span><span class="selector-class">.DefaultMQProducerImpl</span><span class="selector-class">.send</span>(DefaultMQProducerImpl<span class="selector-class">.java</span>:<span class="number">1223</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.rocketmq</span><span class="selector-class">.client</span><span class="selector-class">.impl</span><span class="selector-class">.producer</span><span class="selector-class">.DefaultMQProducerImpl</span><span class="selector-class">.send</span>(DefaultMQProducerImpl<span class="selector-class">.java</span>:<span class="number">1173</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.rocketmq</span><span class="selector-class">.client</span><span class="selector-class">.producer</span><span class="selector-class">.DefaultMQProducer</span><span class="selector-class">.send</span>(DefaultMQProducer<span class="selector-class">.java</span>:<span class="number">214</span>)</span><br><span class="line">	at com<span class="selector-class">.lct</span><span class="selector-class">.quickstart</span><span class="selector-class">.Producer</span><span class="selector-class">.main</span>(Producer<span class="selector-class">.java</span>:<span class="number">56</span>)</span><br><span class="line">	at sun<span class="selector-class">.reflect</span><span class="selector-class">.NativeMethodAccessorImpl</span><span class="selector-class">.invoke0</span>(Native Method)</span><br><span class="line">	at sun<span class="selector-class">.reflect</span><span class="selector-class">.NativeMethodAccessorImpl</span><span class="selector-class">.invoke</span>(NativeMethodAccessorImpl<span class="selector-class">.java</span>:<span class="number">62</span>)</span><br><span class="line">	at sun<span class="selector-class">.reflect</span><span class="selector-class">.DelegatingMethodAccessorImpl</span><span class="selector-class">.invoke</span>(DelegatingMethodAccessorImpl<span class="selector-class">.java</span>:<span class="number">43</span>)</span><br><span class="line">	at java<span class="selector-class">.lang</span><span class="selector-class">.reflect</span><span class="selector-class">.Method</span><span class="selector-class">.invoke</span>(Method<span class="selector-class">.java</span>:<span class="number">498</span>)</span><br><span class="line">	at com<span class="selector-class">.intellij</span><span class="selector-class">.rt</span><span class="selector-class">.execution</span><span class="selector-class">.application</span><span class="selector-class">.AppMain</span><span class="selector-class">.main</span>(AppMain<span class="selector-class">.java</span>:<span class="number">140</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>原因:<br>mac本地搭建使用VPN时、会有两个内网ip、用telnet找到可以访问的那个、<br>修改broker.conf<br>指定brokerIP的地址:<br>brokerIP1 &#x3D; 192.168.10.54<br>brokerIP2 &#x3D; 192.168.10.54</p>
<p>查看broker启动参数:<br>sh bin&#x2F;mqbroker -m</p>
<p>mqAdmin使用:<br>####查看集群情况<br>.&#x2F;mqadmin clusterList -n 127.0.0.1:9876</p>
<p>####查看broker状态<br>.&#x2F;mqadmin brokerStatus -n 127.0.0.1:9876 -b 192.168.10.54:10911</p>
<p>####查看topic列表<br>.&#x2F;mqadmin topicList -n 192.168.10.54:9876</p>
<p>####查看topic状态<br>.&#x2F;mqadmin topicStatus -n 127.0.0.1:9876 -t PushTopic</p>
<p>####查看topic路由<br>.&#x2F;mqadmin topicRoute -n 127.0.0.1:9876 -t PushTopic</p>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>mq网络传输模型</title>
    <url>/2020/03/20/mq_mq%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>实现通过网络来传输数据、需要网络通信类库, 大部分网络通信基础类库都是同步的. 一个TCP连接建立后、用户代码会得到用于收发数据的通道、每个通道会在内存开辟两片区域用于收发数据的缓存</p>
<p>发数据比较简单:<br>用户代码在发送时写入的数据会暂存在缓存中、然后操作系统会通过网卡、把发送缓存中的数据传输到对端的服务器上<br>       只要缓存不满、或者发送数据的速度未超过网卡传输速度的上限、发送数据的操作耗时就只是写入一次内存的时间、同步发送即可、无需异步</p>
<p>接收数据比较麻烦、它不知道什么时候会收到数据<br><code>同步IO</code>: 用一个线程阻塞、等待数据、数据到来、操作系统会先把数据写入到接收缓存、然后给接收数据的线程发通知、接收线程收到通知结束等待、开始读取数据、处理完将继续阻塞、等待下次数据到来<br><img src="https://upload-images.jianshu.io/upload_images/14027542-31618a43c52ff67d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>同步IO处理少量连接没问题、但同时处理大量连接的时候、每个连接都会阻塞一个线程来等待数据、这些连接都在收发数据的时候就会有大量的线程来抢占CPU的世界、造成频繁的CPU上下文切换、导致CPU的负载升高、系统性能下降</p>
<p>期望值:<br>事先定义好收到数据后的处理逻辑、将它作为一个回调方法、收到数据后、网络通信框架直接回调这个方法就好</p>
<h4 id="Java网络模型"><a href="#Java网络模型" class="headerlink" title="Java网络模型"></a>Java网络模型</h4><p>极客时间留言区看到一个很不错的评论、收藏下<br>举例: 有一个养鸡的农场、里边养着各个农户Thread的鸡Socket、每个农户都在农场中建立了自己的鸡舍SocketCahnnel</p>
<ol>
<li><code>BIO</code>: Bolck IO, 每个农户盯着自己的鸡舍、有下蛋、就去捡</li>
<li><code>NIO</code>: No-Block IO, 单 Selector、农户们花钱请了一个饲养员 <code>Selector</code>, 并且告诉饲养员Register 若哪家的鸡下蛋要向农户报告 select keys</li>
<li><code>NIO</code>: No-Block IO - 多Selector、鸡舍增多时、一个饲养员巡视(轮询)一次的时间增大、延迟较大、多请几个、每个饲养员分配几个鸡舍管理、减小延迟</li>
<li><code>epoll</code>: 饲养员不巡查鸡舍、听到有鸡打鸣(活跃连接)就知道下单了</li>
<li><code>AIO</code>: Asynchronous IO、鸡下单后、饲养员负责取蛋、通知农户来取即可、不需要农户自己到鸡舍取蛋</li>
</ol>
<h4 id="序列化和反序列化"><a href="#序列化和反序列化" class="headerlink" title="序列化和反序列化"></a>序列化和反序列化</h4><p>TCP连接上、传输数据的基本形式是二进制流、0和1、在一般编程语言或者框架提供的api中、传输数据的基本形式是字节Byte、本质上是二进制流</p>
<p>编写的程序是结构化的数据, eg. 类或者结构体<br><strong>显然, 要使用网络框架的API来传输结构化的数据、必须先实现结构化的数据和字节流之间的双向转换</strong></p>
<p>文件内保存数据的形式也是二进制序列、所以、也需要序列化结构化数据才能实现</p>
<h4 id="如何选择序列化方式"><a href="#如何选择序列化方式" class="headerlink" title="如何选择序列化方式"></a>如何选择序列化方式</h4><p>需要权衡的因素:</p>
<ul>
<li>序列化后的数据易于阅读</li>
<li>实现复杂度低</li>
<li>序列化和发序列化越快越好</li>
<li>序列化后的信息密度越大越好、即同一个结构化刷数据、序列化后占用的空间越小越好</li>
</ul>
<p>而 1和4 是矛盾的、2 和 3是矛盾的、所以需要根据业务场景合理选择</p>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>在内存中存放的数据、最基础的存储单元也是二进制比特、也就是说应用程序操作的对象、在内存中也是使用二进制存储的、既然都是二进制、为什么不直接把二进制数据通过网络发送出去 ？</p>
<p>内存里的内容、不通用、不同系统不同语言的组织可能都是不一样的、而且存在很多引用、指针、并不是直接数据块<br>序列化、反序列化其实是约定一种标准、大家都遵守就能实现跨语言、跨平台</p>
<h4 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h4><p><strong>高并发下的内存管理技巧</strong></p>
<ol>
<li><p>优化代码中处理请求的业务逻辑、减少创建一次性对象、eg. 可以将受到请求的Request对象在业务流程中尽量传递下去、而不是执行一个步骤就创建一个内容和Request对象差不多的新对象</p>
</li>
<li><p>使用频繁的对象、可以考虑建立一个对象池、收到请求后在对象池内申请一个对象、使用完放回对象池</p>
</li>
<li><p>可能的话、直接使用更大内存的服务器、也可以非常有效的缓解这个问题</p>
</li>
</ol>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>mq选择</title>
    <url>/2020/03/19/mq_mq%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<h4 id="基本标准"><a href="#基本标准" class="headerlink" title="基本标准"></a>基本标准</h4><ol>
<li>开源:  遇到有问题的bug可以通过修改源码的方式来修复或者规避、而不是只能等待下一个官方版本发版来修复</li>
<li>产品社区有一定活跃度: 遇到问题的时候、可以快速找到类似场景、快速修复, 相比于每一个bug都需要自己通过阅读源码来解决、毕竟线上问题挂着的的成本很高<br>社区活跃度较高的产品、与周边应用的兼容性也会比较好、省去很多造轮子的时间</li>
<li>性能要求:<ol>
<li>确保消息可靠传递、不丢失消息</li>
<li>支持集群、确保某个节点宕掉不会影响整个服务</li>
<li>性能、能满足大部分实际需求场景的需要</li>
</ol>
</li>
</ol>
<h4 id="目前可选方案"><a href="#目前可选方案" class="headerlink" title="目前可选方案"></a>目前可选方案</h4><h5 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">源码实现 : Erlang</span><br><span class="line">特点: 轻量级、性能好、方便部署和使用、维护简单</span><br><span class="line"><span class="code">         支持灵活的路由配置、相对其它MQ、在Producer和Queue之间增加Exchange模块、可根据配置规则将生产者发出的Msg发送到不同队列</span></span><br><span class="line"><span class="code">         Client支持多种语言</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">短处: </span><br><span class="line"><span class="bullet">1.</span> 消息堆积处理支持不好、消息大量堆积时会导致MQ的性能急速下降</span><br><span class="line"><span class="bullet">2.</span> 处理消息的性能比较一般、根据硬件配置不同、每秒大概可以处理的消息数量为: 几w ~ 十几w</span><br><span class="line"><span class="bullet">3.</span> 源码语言为Erlang、比较小众、扩展开发成本增加</span><br></pre></td></tr></table></figure>

<h5 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h5><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">2012年阿里开源出来的产品、17年交给apache维护</span><br><span class="line"><span class="section">源码: Java</span></span><br><span class="line"><span class="section">性能: 稳定性、可靠性和性能都不错、对响应延迟也做了优化、大多数情况可以做到ms级的响应、每秒可处理消息 几十万(性能比RabbitMQ高一个数量级)</span></span><br><span class="line"></span><br><span class="line"><span class="section">短处: 相比国外同类产品、与周边生态系统的集成度和兼容性稍低</span></span><br></pre></td></tr></table></figure>

<h5 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h5><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">最初设计是为了处理海量日志、早期版本不保证消息可靠性、也不支持集群、但对于处理海量日志这个诉求是比较好的选择</span><br><span class="line"></span><br><span class="line">近期版本、在数据可靠性、稳定性和功能特性上都可以满足大多数的场景需求</span><br><span class="line"></span><br><span class="line"><span class="section">源码实现: Java + Scala</span></span><br><span class="line"><span class="section">优势:</span></span><br><span class="line">1. 与周边生态系统的兼容性最好、尤其是大数据和流计算领域、几乎所有相关开源软件都优先支持Kafka</span><br><span class="line">2.  异步收发性能最好、在服务器配置高时、极限情况每秒可处理2000w消息</span><br><span class="line"></span><br><span class="line"><span class="section">短处:</span></span><br><span class="line"><span class="section">异步批量处理带来的问题是: 同步收发响应延时较高、它是攒一批然后批量发送、每秒消息数没那么高的时候、kafka的延时反而会高、</span></span><br><span class="line"></span><br><span class="line">不适合在线业务场景</span><br></pre></td></tr></table></figure>

<h4 id="第二梯队mq"><a href="#第二梯队mq" class="headerlink" title="第二梯队mq"></a>第二梯队mq</h4><h5 id="ZeroMQ"><a href="#ZeroMQ" class="headerlink" title="ZeroMQ"></a>ZeroMQ</h5><p>严格来说不能算是消息队列、而是一个基于消息队列的多线程网络库<br>如果需求是将消息队列的功能集成到系统进程中、可以考虑ZeroMQ</p>
<h5 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h5><p>社区已经不活跃、进入了老年期</p>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>rocketMQ实例上的定时任务</title>
    <url>/2020/03/20/mq_rocketMQ%E5%AE%9E%E4%BE%8B%E4%B8%8A%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</url>
    <content><![CDATA[<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 120s更新一次nameSrv地址表</span><br><span class="line"><span class="bullet">2.</span> 30s或指定配置时间pollNameServerInterval 更新一次 topic路由信息</span><br><span class="line"><span class="bullet">3.</span> 30s或指定时间 heartbeatBrokerInterval 更新一次broker信息</span><br><span class="line"><span class="bullet">4.</span> 5s或persistConsumerOffsetInterval时间、持久化一次消费偏移量信息</span><br><span class="line"><span class="bullet">5.</span> 每分钟动态调整一个threadpool大小</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>rocketMQ消息存储</title>
    <url>/2020/03/20/mq_rocketMQ%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line">rocketmq消息格式</span><br><span class="line"><span class="symbol">totalSize:</span> 消息长度、<span class="number">4</span>字节</span><br><span class="line"><span class="symbol">magicCode:</span> 魔术 <span class="number">4</span>字节</span><br><span class="line"><span class="symbol">bodycrc:</span> 消息体crc校验码 <span class="number">4</span>字节</span><br><span class="line"><span class="symbol">queueId:</span> 消息队列id <span class="number">4</span>字节</span><br><span class="line"><span class="symbol">flag:</span> 消息flag、mq不处理、</span><br><span class="line"><span class="symbol">ququeoffset:</span> 消息在队列中的偏移量</span><br><span class="line"><span class="symbol">physicaloffset:</span> 消息在commitlog中的偏移量</span><br><span class="line"><span class="symbol">sysflag:</span> 消息系统flag、eg 是否压缩、是否是事务消息等 <span class="number">4</span>字节</span><br><span class="line"><span class="symbol">bronTimeStamp:</span> 生产者调用消息发送API时的时间戳 <span class="number">8</span>字节</span><br><span class="line"><span class="symbol">bornHost:</span> 消息发送者ip、端口 <span class="number">8</span>字节</span><br><span class="line"><span class="symbol">storeTimeStamp:</span> 消息存储时间戳  <span class="number">8</span>字节</span><br><span class="line"><span class="symbol">storeHostAddress:</span> broker服务器ip+port <span class="number">8</span>字节</span><br><span class="line"><span class="symbol">reconsumetimes:</span> 消息重试次数 <span class="number">4</span>字节</span><br><span class="line"><span class="symbol">bodylength:</span> 消息长度</span><br><span class="line"><span class="symbol">body:</span> 消息内容</span><br><span class="line"><span class="symbol">topicLength:</span> 主题存储长度</span><br><span class="line"><span class="symbol">topic:</span> 主题</span><br><span class="line"><span class="symbol">propertiesLength:</span> 消息属性长度、<span class="number">2</span>字节</span><br><span class="line"><span class="symbol">Properties:</span> 消息属性</span><br></pre></td></tr></table></figure>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="number">1.</span> 存储设计</span><br><span class="line">   commitLog: 消息存储文件、所有topic的消息都存储在commitLog</span><br><span class="line">   大小默认<span class="number">1</span>G、以文件中第一个偏移量为文件名、偏移量小于<span class="number">20</span>位、用<span class="number">0</span>补全</span><br><span class="line">   </span><br><span class="line">   consumeQueue: 消息消费队列、消息到达commitLog后悔异步转发到Queue、</span><br><span class="line">   indexFile: 消息索引文件、主要存储key与<span class="keyword">offset</span>的对应关系</span><br><span class="line">   </span><br><span class="line">   事务状态服务: 存储每条消息的事务状态</span><br><span class="line">   定时消息服务: 每一个延迟级别对应一个消息消费队列、存储延迟队列的消息拉取进度</span><br><span class="line">   </span><br><span class="line"><span class="number">2.</span> msg发送存储流程</span><br><span class="line">   若当前broker挂掉或者broker为slave或者不支持写入时、拒绝写入</span><br><span class="line">   若topic的长度&gt;<span class="number">256</span>个字符、或者msg的属性长度&gt;<span class="number">65535</span>时、拒绝写入</span><br><span class="line">   </span><br><span class="line">   若消息的延迟级别&gt;<span class="number">0</span>, 将消息的原主题名称和原消息队列id存入消息属性、使用延迟消息队列schedule_topic</span><br><span class="line">   </span><br><span class="line">   transientStorePoolEnable 是否开启缓存池. rocketmq单独创建一个mappedByteBuffer内存缓存池、临时存储数据、数据会先写入该内存映射、然后由<span class="keyword">commit</span>线程复制到与物理文件对应的内存映射中、主要是提供一种内存锁定、将当前堆外内存一直锁定在内存中、避免被进程将该内存交互到磁盘、提高存储性能</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line"><span class="number">3.</span> 存储文件组织与内存映射机制</span><br><span class="line">   doAppend只是将消息存储到byteBuffer中、然后创建AppendMessageResult、只是将消息存储在MappedFile对应的内存映射buffer中、并未刷到磁盘</span><br><span class="line">   handleDiskFlush方法会处理数据持久化</span><br><span class="line">   handleHA会处理m-s</span><br><span class="line">   </span><br><span class="line"><span class="number">4.</span> 存储文件</span><br><span class="line">   commitlog: 消息存储目录</span><br><span class="line">   config运行期间配置信息</span><br><span class="line">   consumequque 消息消费队列存储目录</span><br><span class="line">   <span class="keyword">index</span> 消息索引文件存储目录</span><br><span class="line">   <span class="keyword">abort</span> 启动时创建、正常退出之前删除</span><br><span class="line">   <span class="keyword">checkpoint</span> 文件检测点、存储commitlog文件最后一次刷盘时间戳、consumeQueue最后一次刷盘时间、<span class="keyword">index</span>文件最后一次刷盘时间戳</span><br><span class="line">   </span><br><span class="line"><span class="number">5.</span> 消费队列、索引文件构成和机制</span><br><span class="line"><span class="number">6.</span> 文件恢复机制</span><br><span class="line">   rocketmq将消息全量存储在commitlog中、然后异步转发任务更新consumeQueue、<span class="keyword">index</span>文件、若消息成功存储在commitLog转发任务执行失败、eg. broker宕机、则存储三者不一致的情况、commitlog中的消息可能永远不会被消费、rocketmq是如何保障最终一致性的 ？</span><br><span class="line">   <span class="number">1</span>) 判断上次退出是否正常、在broker启动时<span class="keyword">check</span>是否存储<span class="keyword">abort</span>文件、若存在、说明是非正常退出、需要修复</span><br><span class="line">   <span class="number">2</span>) 加载延迟队列</span><br><span class="line">   <span class="number">3</span>) 加载commitlog文件</span><br><span class="line">   <span class="number">4</span>) 加载消息消费队列</span><br><span class="line">   <span class="number">5</span>) 加载<span class="keyword">checkpoint</span>文件、</span><br><span class="line">   <span class="number">6</span>) 加载索引文件、索引文件上次刷盘时间&lt;该索引文件最大的消息时间戳时 说明索引文件不完备、立即销毁</span><br><span class="line">   <span class="number">7</span>) 根据broker是否正常停止、执行不同的恢复策略</span><br><span class="line">   </span><br><span class="line"><span class="number">7.</span> 刷盘机制</span><br><span class="line">   rocketMQ的刷盘是基于NIO的内存映射机制MappedByteBuffer、消息存储时先将消息追加到内存、再根据配置的刷盘策略在不同时间进行刷写磁盘。</span><br><span class="line">   同步刷盘时: 消息追加到内存后悔同步调用force()方法</span><br><span class="line">   消息生产者将在消息服务器端将消息内容追加到内存映射文件后、需同步将内存内容立刻刷到磁盘、调用内存映射文件MapppedByteBuffer的force方法可将内存中的数据写入磁盘</span><br><span class="line">   </span><br><span class="line">   异步刷盘时: 消息写到内存后、会立即返回给producer、mq单独起一个线程按照固定频率刷盘</span><br><span class="line">   若开启 transientStorePoolEnable机制、RocketMQ会单独申请一个与目标物理文件commitlog相同大小的堆外内存、它将会使用内存锁定、不会被置换到虚拟内存中、消息先追加到堆外内存、然后提交到与物理文件的内存映射内存中、再flush到磁盘</span><br><span class="line">   若未开启transientStorePoolEnable机制、消息直接追加到与物理文件直接映射内存中、然后刷写到磁盘</span><br><span class="line">   <span class="number">1</span>) 先将消息直接追加到ByteBuffer(堆外内存DirectlyByteBuffer), WrotePosition随消息增加不断向后移动</span><br><span class="line">   <span class="number">2</span>) CommiteRealTimeService线程默认每<span class="number">200</span>ms将ByteBuffer中新追加的内容(WritePosition-commitedPosition)提交到MappedByteBuffer中</span><br><span class="line">   <span class="number">3</span>) MappedByteBuffer在内存中追加提交的内存、wrotePosition向前后移动、然后返回</span><br><span class="line">   <span class="number">4</span>) <span class="keyword">commit</span>操作成功返回、将commitedPosition想前后移动本次提交的内容长度、此时wrotePosition指针依然可以向前推进</span><br><span class="line">   <span class="number">5</span>) flushRealTimeService线程默认每<span class="number">500</span>ms将MappedByteBuffer中新追加的内容wrotePosition-上次刷写位置 flushedPositiont通过调研MappedByteBuffer#force方法讲数据刷写到磁盘</span><br><span class="line">   </span><br><span class="line"><span class="number">8.</span> 文件删除机制</span><br><span class="line">   rocketMQ操作commitLog、conssumeQueue是基于内存映射机制并在启动的时候加载commitLog、consumeQueue下所有的文件、为了避免内存与磁盘浪费、引入文件过期机制:</span><br><span class="line">   超过一定时间间隔内没有更新的文件被认为过期文件、默认<span class="number">72</span>h、可通过fileReservedTime来修改</span><br><span class="line">   满足以下条件会删除:</span><br><span class="line">   <span class="number">1</span>) 指定删除文件的时间点、固定时间执行删除 默认凌晨<span class="number">4</span>点</span><br><span class="line">   <span class="number">2</span>) 磁盘不足时、主动触发过期文件删除操作 磁盘分区使用率超过<span class="number">90</span>%不可写入</span><br><span class="line">   <span class="number">3</span>) 预留、手工触发</span><br><span class="line">   </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>rocketMq入门</title>
    <url>/2020/03/20/mq_rocketMq%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h4 id="专业术语"><a href="#专业术语" class="headerlink" title="专业术语"></a>专业术语</h4><ul>
<li><p><code>Producer</code> </p>
<p>消息生产者、负责生产消息、一般由业务系统负责生产消息</p>
</li>
<li><p><code>Consumer</code></p>
<p>消息消费者、负责消费消息、一般由后台系统负责异步消费</p>
<ul>
<li><p><code>Push Consumer</code></p>
<p>Consumer的一种、通常向consumer对象注册一个Listener接口、一旦收到消息、Consumer对象立即回调Listener接口方法</p>
</li>
<li><p><code>Pull Consumer</code></p>
<p>Consumer的一种、应用通常主动调用Consumer的拉取消息放啊从Broker拉取消息、主动权由应用控制</p>
</li>
</ul>
</li>
<li><p><code>Producer Group</code></p>
<p>一类Producer的集合名称、这类Producer通常发送一类消息、且发送逻辑一致</p>
</li>
<li><p><code>Consumer Group</code></p>
<p>一类Consumer的集合名称、消费同一类消息、消费逻辑一致</p>
</li>
<li><p><code>Broker</code></p>
<p>消息中转角色、负责存储消息、转发消息、一般也称为<code>Server</code>、在JMS规范中称为<code>Provider</code></p>
</li>
<li><p><code>广播消费</code></p>
<p>一条消息被多个Consumer消费、即使这些Consumer属于同一个group、可以认为在消息划分方面无意义</p>
</li>
<li><p><code>集群消费</code></p>
<p>一个Consumer Group中的Consumer实例平均分摊消费消息、eg. 某个topic有9条消息、其中一个Consumer Group有3个实例、则 每个实例只消费其中的3条消息</p>
</li>
<li><p><code>顺序消息</code></p>
<p>消费消息的顺序要同发送消息的顺序一致、在RocketMQ中、主要指的是局部顺序、即: 同一类消息为满足顺序性、必须Producer单线程顺序发送、且发送到同一个队列、</p>
</li>
<li><p><code>普通顺序消费</code></p>
</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-720659236fc9c351.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="RocketMQ物理部署结构.png"></p>
<h4 id="RocketMQ网络部署特点"><a href="#RocketMQ网络部署特点" class="headerlink" title="RocketMQ网络部署特点"></a>RocketMQ网络部署特点</h4><ul>
<li><p>NameServer 几乎无状态节点、可集群部署、节点间无任何信息同步</p>
</li>
<li><p>Broker部署相对复杂、分为master和slave、0表示master、非0表示slave、</p>
<p>每个Broker与Name Server集群中的所有节点建立长连接、定时注册Topic信息到所有的Name Server</p>
</li>
<li><p>Producer 与NameServer中的随机一个节点建立长连接、定期从NameServer取topic信息、并向提供topic服务的Master建立长连接、定时向master发送心跳、Producer完全无状态、可集群部署</p>
</li>
<li><p>Consumer与NameServer中随机一个节点建立长连接、从NameServer取topic路由信息、并向提供topic服务的Master、Slave建立长连接、定时向master、slave发送心跳、即可以从master订阅消息、也可以从slave订阅消息</p>
</li>
</ul>
<h4 id="RocketMQ逻辑部署结构"><a href="#RocketMQ逻辑部署结构" class="headerlink" title="RocketMQ逻辑部署结构"></a>RocketMQ逻辑部署结构</h4><p>(<img src="https://upload-images.jianshu.io/upload_images/14027542-0a5961f3b407c08b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="逻辑部署结构.png"></p>
]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql是如何保障高可用的</title>
    <url>/2020/03/20/mysql_Mysql-%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E9%9A%9C%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-242e0ecf16d359cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="MySQL主备切换流程.png"></p>
<p>一、主备延迟<br>数据同步的关键时间节点:</p>
<ol>
<li>主库A执行完一个事务、写入binlog、记为 T1;</li>
<li>传给备库B、将备库B接收完binlog的时刻记为 T2;</li>
<li>备库B执行完事务的时刻记为 T3;<br>主备延迟: 同一个事务在备库执行完的时间和主库执行完的时间之间的差值: T3 - T1<br>show slave status; - seconds_behind_master表示当前备库延迟时间</li>
</ol>
<p>注: 主备机的系统时间不一致时、会不会导致主备延迟值不准 ?<br>不会. 备库连接主库时、会通过执行 select unix_timestamp 获得当前主库的系统时间、与本机不一致时、会在执行 seconds_behind_master 时扣除差值</p>
<p>二、主备延迟的来源</p>
<ol>
<li>有些部署条件下、备库所在机器的性能较差<br>此时一般将备库设为<code>非双1模式</code>. 现在一般会使用对称部署(主备规格相同).</li>
<li>使用对称部署、为何仍然存在主备延迟 ?<br>备库可能压力较大、存在一些慢查询、导致备库查询消耗大量CPU资源、影响数据同步、造成主备延迟.<br>解决: <ol>
<li>使用一主多从、分担读压力 </li>
<li>通过binlog输出到外部系统、如: hadoop, 提供统计类查询</li>
</ol>
</li>
<li>采用了一主多从、备库的压力不超过主库的情况下、还有什么情况会导致主备延迟呢 ?<ol>
<li>可能存在大的事务, 因为主库上必须等事务执行完成才会写入binlog、再传给备库、若一个SQL执行10min、这个事务就很可能会导致从库延迟10min.(所以最好不要一次delete太多数据)</li>
<li>大表DDL也是一个大事务的场景</li>
</ol>
</li>
<li>如果备库上也不做大事务了、还有什么原因会导致主备延迟吗 ?<br>备库的并行复制能力.</li>
</ol>
<p>三、主备切换策略:</p>
<ol>
<li><p>可靠性优先.</p>
<ol>
<li>先判断备库B的 seconds_behind_master 是否小于指定值, 若否、持续观察</li>
<li>把主库A改成只读状态, readonly设为true.</li>
<li>判断备库B的 seconds_behind_master 值、直到变为0</li>
<li>把备库B改为可写入, readonly设为false.</li>
<li>将业务请求切到B<br>2~5 的过程、系统处于不可用状态.</li>
</ol>
</li>
<li><p>可用性优先<br>将1中、4)、5) 调整到最开始执行、直接让备库可读写、系统就无不可用时间、但会产生数据不一致. 暂时称为<code>可用性优先策略</code><br>此时若 binlog_format 为: statement、则会发生数据不一致的线下<br>若 binlog_format 为: row、会提示错误</p>
</li>
</ol>
<p>所以、MySQL高可用系统的可用性是依赖于主备延迟的、延迟的时间越小、在主库故障时、服务恢复需要的时间就越短, 可用性就越高.</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL有哪些`饮鸩止渴`的提高性能的方法</title>
    <url>/2020/03/20/mysql_MySQL%E6%9C%89%E5%93%AA%E4%BA%9B%60%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%60%E7%9A%84%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>一、短链接风暴<br>正常的短连接模式是连接到数据库后、执行很少的SQL语句就断开、下次需要再重连、若使用的是短连接、在业务高峰期、可能会出现连接数暴涨的情况. MySQL建联的成本是比较高的、除正常的网络三次握手外、还需要登录权限判断和获得这个连接的数据读写权限.</p>
<p>DB压力小时、这些成本并不明显、但DB处理较慢时、连接数就会暴涨、max_connections参数、用来控制一个MySQL实例同时存在的连接数的上限、超过该值、系统会拒绝接下来的连接请求. 此时一个自然的想法是: 调高max_connections的值、但更多请求进来、可能会导致系统的负载进一步变大、大量的资源消耗在鉴权等逻辑上、已经拿到连接的线程拿不到CPU资源去执行请求, 适得其反. </p>
<p>可以怎么做呢 ?</p>
<ol>
<li><p>先处理掉那些占着连接、但不工作的线程.<br>通过kill_connection主动踢掉. 类似提前设置wait_timeout参数(一个线程空闲wait_timeout秒之后、MySQL会主动断开连接)<br>information_schema.innodb_trx 表可以查看事务具体状态.<br>从服务端断开: kill connection + id. 此时Client处于sleep状态、连接被服务端主动断开后、Client不会马上知道、直到Client发起下一个请求, 才会收到 Lost Connection的错误.<br>此时若Client不重新建联、而直接使用原连接重试、会觉得MySQL一直没恢复</p>
</li>
<li><p>减少连接过程的消耗<br>有的业务代码会在短时间内先申请大量数据库连接备用、若现在数据库确认是被连接打挂了、可以先让DB跳过鉴权. 重启DB、使用 –skip-grant-tables 参数启动.<br>但这样MySQL会跳过所有的鉴权、包括连接过程和语句执行过程, 风险极高、尤其是允许外网访问时.<br>Mysql8.0, 跳过鉴权时、会默认打开–skip-networking只允许本地Client可见.</p>
</li>
</ol>
<p>二、慢查询性能问题.<br>可能引发慢查询一般有3种可能:</p>
<ol>
<li><p>索引没设计好</p>
</li>
<li><p>SQL没写好</p>
</li>
<li><p>MySQL选错了索引</p>
</li>
<li><p>索引未设计好、MySQL5.6以后创建索引都支持Online了、一般高峰期DB被SQL打挂时、最高效的做法就是快速添加索引. 若有主备、最高在备库先执行、</p>
</li>
</ol>
<ol>
<li>在备库执行set sql_bin_log&#x3D;off, 关闭binlog写入、执行alter语句添加索引</li>
<li>执行主备切换、</li>
<li>此时主库是B、备库是A、在A上执行 set sql_log_bin&#x3D;off, 执行alter语句添加索引<br>平时做变更时、应考虑 gh-ost 更稳妥、但紧急处理时、上边的方案最高效.</li>
</ol>
<ol start="2">
<li>语句没写好<br>Mysql5.7以上的版本、提供了 query_rewrite 功能、可以将输入的语句改写成另外一种模式.<br>eg. select * from t where id+1&#x3D;10000 会让索引失效、可以通过一个改写语句解决</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> query_rewrite.rewrite_rules(<span class="keyword">pattern</span>, replacement, pattern_database) </span><br><span class="line"><span class="keyword">values</span> (&quot;select * from t where id + 1 = ?&quot;, &quot;select * from t where id = ? - 1&quot;, &quot;db1&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">call</span> query_rewrite.flush_rewrite_rules(); <span class="operator">/</span><span class="operator">/</span> 让新插入的规则生效</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>索引没选对、可以通过上线前的SQL分析来提早发现.</li>
</ol>
<p>三、QPS突增问题<br>有时业务突然出现高峰、或者应用程序bug导致某个语句的QPS暴涨、也可能导致MySQL压力过大、影响服务. </p>
<ol>
<li>若是新业务bug导致、且新业务可以下掉、只是时间没那么快、可以直接从DB上把白名单禁掉.</li>
<li>若这个新功能使用的是独立账号、可以将该账号禁用, 这样由它引发的QPS就会降到0</li>
<li>若新功能是跟主体功能部署在一起的、只能通过处理语句来限制, 可以使用上边的重写功能、将压力最大的SQL重写为 select 1.<br>当然该操作的风险很高、它可能导致:</li>
<li>若别的功能也用到了该SQL、会被误伤</li>
<li>很多业务不是靠一个SQL就完成逻辑的、这样会导致后边的业务一起失败.</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql是怎么保证数据不丢的</title>
    <url>/2020/03/20/mysql_Mysql-%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E7%9A%84/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-56a40a40793fd005.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/440" alt="binlog写盘状态.png"></p>
<p>一、binlog的写入机制</p>
<ol>
<li>binlog写入逻辑: <ol>
<li>事务执行过程中、先写日志导binlog cache、事务提交时、再把binlog cache写入到binlog文件中.</li>
<li>一个事务的binlog不能被拆开、因此不论事务有多大、也要确保一次性写入. 系统给binlog cache每个线程分配一片内存(binlog_cache_size大小), 超过会先暂存到磁盘.</li>
<li>事务提交时、执行器会把binlog cache里的完整事务写入binlog、清空binlog cache.</li>
</ol>
</li>
<li>每个线程有自己的binlog cache、但共用binlog文件.<br>事务提交、先写入到文件系统的page cache(write), 然后调用fsync写入磁盘(占用IOPS)<br>write和fsync的时机:<br>sync_binlog&#x3D;0, 每次事务提交只write、不fsync<br>sync_binlog&#x3D;1, 每次事务提交都执行fsync<br>sync_binlog&#x3D;N, 每次事务提交都write、累积N个事务才fsync<br>所以、在出现IO瓶颈的场景里、可以将sync_binlog设置为一个比较大的值、可以提升性能.<br>风险: 若主机异常重启、会丢失最近N个事务的binlog.</li>
</ol>
<p>二、redo log的写入机制<br>事务执行过程中会先写redo log buffer, 然后才写redo log<br><img src="https://upload-images.jianshu.io/upload_images/14027542-c93a7e2e48dc724e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="redo log存储状态.png"><br>从redo log的三种状态说起:</p>
<ol>
<li>存在redo log buffer中、物理上是在 mysql 进程内存中.</li>
<li>写到磁盘write、但未持久化fsync、物理上是在文件系统的Page Cache中</li>
<li>持久化到磁盘</li>
</ol>
<p>1、2的过程都很快、但3的速度就慢很多了. InnoDB提供了三种策略, 通过 innodb_flush_log_at_trx_commit参数控制:</p>
<ol>
<li>0, 表示每次事务提交只把redo log留在redo log buffer中</li>
<li>1, 表示每次事务提交都将redo log直接持久化到磁盘</li>
<li>2, 表示每次事务提交都把redo log写到Page Cache.<br>InnoDB 有一个后台线程、每隔1s、会把redo log buffer中的日志调用write写到FS Pae Cache、然后调用 fsync 持久化到磁盘.</li>
</ol>
<p>注意: 事务执行过程中的redo log也是在buffer中、可能会被后台线程一起持久化到磁盘<br>还有两种场景会将一个未提交的事务redo log写入磁盘:</p>
<ol>
<li>redo log buffer占用的空间即将达到innodb_log_buffer_size 一半的时候、后台线程会主动写盘. (此时事务未提交、只是write、并未fsync, 即: 只留在FS Page Cache)</li>
<li>并行事务提交时, 顺带将该事务的 redo log buffer持久化到磁盘、eg. Trx A执行到一半、Trx B要把buffer数据写入磁盘、会顺带把Trx A的日志一起持久化到磁盘<br>注意: 若将 innodb_flush_log_at_trx_commit 设为1, redo log在prepare阶段就要持久化一次、因为有一个崩溃恢复依赖于prepare的redo log + binlog.<br>通常说的<code>双1</code>配置、是redo log 和binlog的刷盘机制都设为1, 即: 一个事务完整提交前、需要等待两次刷盘: redo log(prepare阶段) 和 binlog</li>
</ol>
<p>思考: TPS 2w&#x2F;s 的话、写盘就是 4w&#x2F;s, 但磁盘能力只有2w&#x2F;s, 是怎么实现的呢 ?<br>组提交: 三个并发事务trx1, trx2, trx3, 对应LSN(日志逻辑序列化、单调递增)分别为:50, 120, 160, trx1写盘时、这组(trx1-&gt;3)已经有3个事务、LSN也变成了160, 去写盘时、带的LSN&#x3D;160, 等trx1返回时、所有LSN&lt;160的redo log都已持久化到磁盘, trx2,trx3可直接返回.<br><img src="https://upload-images.jianshu.io/upload_images/14027542-1044eab2470e5e22.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="两阶段提交细化.png"></p>
<p>在并发更新场景下、第一个事务写完 redo log buffer、调用fsync越晚、组员越多、节约IOPS效果越好.<br>binlog的write 和 fsync的时间间隔短、组提交优化不如redo log.<br>可以通过设置以下参数来提升效果:</p>
<ol>
<li>binlog_group_commit_sync_delay, 延迟x 微秒后才调用fsync</li>
<li>binlog_group_commit_sync_no_delay_count, 累积x次以后调用fsync<br>二者满足其一就调用 fsync</li>
</ol>
<p>另: 不建议设置 innodb_flush_log_at_trx_commit&#x3D;0, 因为这样redo log只保存在内存中、MySQL异常重启会丢失数据、风险太大. 而redo log写到 FS Page Cache的速度也是很快的、不会损失很多性能, 可以保证异常重启不丢数据、风险小很多.</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL执行</title>
    <url>/2020/03/20/mysql_SQL%E6%89%A7%E8%A1%8C/</url>
    <content><![CDATA[<p>[toc]</p>
<h3 id="SQL执行流程"><a href="#SQL执行流程" class="headerlink" title="SQL执行流程"></a>SQL执行流程</h3><h4 id="MySQL架构图"><a href="#MySQL架构图" class="headerlink" title="MySQL架构图"></a>MySQL架构图</h4><p><img src="https://upload-images.jianshu.io/upload_images/14027542-4270d2d72dee925f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<h4 id="server层、"><a href="#server层、" class="headerlink" title="server层、"></a>server层、</h4><blockquote>
<p>包含连接器、查询缓存、分析器、优化器、执行器等、涵盖mysql大部分核心功能、<br>及mysql所有的内置函数(日期、时间、数学和加密函数等)、所有跨存储引擎的功能<br>(视图、存储过程、触发器等)都在这一层实现</p>
</blockquote>
<h5 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h5><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">mysql -h<span class="variable">$ip</span> -P<span class="variable">$port</span> -u<span class="variable">$user</span> -p</span><br><span class="line">若 用户名和密码 认证失败、会返回 Access denied <span class="keyword">for</span><span class="built_in"> user </span>的错误</span><br><span class="line">若认证通过、这个连接里的权限都会依赖此时权限表查到的权限</span><br><span class="line">此时用admin账号修改该用户的权限、不会立即生效、会在重新连接时生效</span><br><span class="line"></span><br><span class="line">连接完成后、无后续动作、则连接处于sleep状态、</span><br><span class="line"><span class="built_in"></span></span><br><span class="line"><span class="built_in">client </span>长时间(wait_time参数控制)不操作、连接器会断开连接</span><br><span class="line"></span><br><span class="line">连接断开之后、再发送请求、会收到 Lost<span class="built_in"> connection </span><span class="keyword">to</span> mysql<span class="built_in"> server </span>during query的响应</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-60a2493de769f5b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-18905125b398ebe6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-ee3accb459dc1246.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h5 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h5><figure class="highlight gauss"><table><tr><td class="code"><pre><span class="line"><span class="built_in">key</span> 是 sql、value是查询结果 - 任意更新会导致缓存失效</span><br><span class="line">不建议使用</span><br></pre></td></tr></table></figure>

<h5 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h5><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">词法分析: 根据关键词识别语句类型 <span class="keyword">select</span>/<span class="keyword">update</span>/<span class="keyword">insert</span></span><br><span class="line">语法分析: 若有语法错误、会返回 You have an error <span class="keyword">in</span> your <span class="keyword">SQL</span> </span><br><span class="line"></span><br><span class="line">elect <span class="number">1</span> <span class="keyword">from</span> t <span class="keyword">where</span> id=<span class="number">1</span>;</span><br><span class="line">ERROR <span class="number">1064</span> (<span class="number">42000</span>): You have an error <span class="keyword">in</span> your <span class="keyword">SQL</span> syntax; <span class="keyword">check</span> the manual that corresponds <span class="keyword">to</span> your MySQL <span class="keyword">server</span> <span class="keyword">version</span> <span class="keyword">for</span> the right syntax <span class="keyword">to</span> use near <span class="string">&#x27;elect 1 from t where id=1&#x27;</span> at <span class="type">line</span> <span class="number">1</span></span><br><span class="line">                         </span><br></pre></td></tr></table></figure>

<h5 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">经过分析器、mysql知道了想要做什么、优化器干什么呢 ？</span><br><span class="line"><span class="bullet">1.</span> 表中有多个索引的时候、决定使用哪个索引</span><br><span class="line"><span class="bullet">2.</span> 多表join的时候、决定连表顺序</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/14027542-b2765ac683595a26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h5 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">在分析器、优化器之后、mysql知道了要做什么、怎么做、就开始进入到执行器阶段、开始执行</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 命中查询缓存、会在查询缓存返回结果时进行权限验证</span><br><span class="line"><span class="number">2.</span> 非命中 先验证权限、无 <span class="operator">-</span><span class="operator">&gt;</span> 直接返回错误</span><br><span class="line">                    有 <span class="operator">-</span><span class="operator">&gt;</span> 执行<span class="keyword">SQL</span></span><br><span class="line"><span class="number">3.</span> eg. mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> T <span class="keyword">where</span> ID<span class="operator">=</span><span class="number">10</span>;</span><br><span class="line">       </span><br><span class="line">    若 id 无索引:</span><br><span class="line">    <span class="number">1</span>) 调用innodb引擎接口查询第一行、若id <span class="operator">=</span> <span class="number">10</span>、存入结果集、否则 跳过、继续</span><br><span class="line">    <span class="number">2</span>) 调用引擎接口取下一行、直至最后一行</span><br><span class="line">    <span class="number">3</span>) 执行器将满足结果的行作为结果集返回给client</span><br><span class="line">    </span><br><span class="line">    若id 有索引:</span><br><span class="line">    <span class="number">1</span>) 调用innodb查询 满足条件的 第一行、放入结果集</span><br><span class="line">    <span class="number">2</span>) 查询满足条件的下一行..</span><br><span class="line">    <span class="number">3</span>) 将结果集返回给client</span><br><span class="line">  </span><br><span class="line">  在db慢<span class="keyword">SQL</span>中、有一个 rows_examined 字段、表示在<span class="keyword">SQL</span>执行过程中扫描了多少行、</span><br><span class="line">  是在 执行器 调用 引擎 获取数据行的时候累计的、</span><br><span class="line">  注：有些情况下、执行器调用一次会扫描很多行、所以 实际扫描行数 <span class="operator">!=</span> rows_examined</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL更新</title>
    <url>/2020/03/20/mysql_SQL%E6%9B%B4%E6%96%B0/</url>
    <content><![CDATA[<h4 id="redolog-重做日志-innodb引擎层特有"><a href="#redolog-重做日志-innodb引擎层特有" class="headerlink" title="redolog(重做日志 - innodb引擎层特有)"></a>redolog(重做日志 - innodb引擎层特有)</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">MySQL使用AWL(<span class="keyword">Write</span>-Ahead Logging)技术, 当有记录需要更新的时候、innodb就先把记录写到redo <span class="keyword">log</span>、并更新内存、这时、更新就算完成. 当innodb引擎比较空闲的时候、会将操作更新到磁盘</span><br><span class="line"></span><br><span class="line">触发更新的点:</span><br><span class="line"><span class="number">1.</span> redo <span class="keyword">log</span> 写满时(redo <span class="keyword">log</span>文件大小是固定的 - 循环覆盖) </span><br><span class="line">   <span class="keyword">write</span> pos: 当前位置 </span><br><span class="line">   <span class="keyword">check</span> <span class="type">point</span>: 当前要擦除的位置</span><br><span class="line">   <span class="keyword">write</span>和<span class="keyword">check</span>间有空间、就代表可更新、否则、就要先擦除记录、推进<span class="keyword">checkpoint</span>、</span><br><span class="line"><span class="number">2.</span> </span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-e22222b71aa4fb6f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<h4 id="binlog-归档日志-MySQL-server层实现"><a href="#binlog-归档日志-MySQL-server层实现" class="headerlink" title="binlog(归档日志 - MySQL server层实现)"></a>binlog(归档日志 - MySQL server层实现)</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">mysql引擎实现的日志、与<span class="keyword">redo</span> <span class="keyword">log</span> 的差异？</span><br><span class="line"><span class="number">1.</span> <span class="keyword">redo</span> <span class="keyword">log</span> 是innodb特有的; binlog是mysql server层实现、所有引擎可以使用</span><br><span class="line"><span class="number">2.</span> <span class="keyword">redo</span> <span class="keyword">log</span> 记录的是物理日志、记录的是<span class="string">&quot;在某个数据页上做了什么修改&quot;</span></span><br><span class="line">   binlog 是逻辑日志、记录的是原始逻辑、eg. 给id=<span class="number">2</span>的c字段+<span class="number">1</span></span><br><span class="line"><span class="number">3.</span> <span class="keyword">redo</span> <span class="keyword">log</span> 循环写、空间固定 </span><br><span class="line">    binlog 是追加写、日志写满会切换到下一个</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="为什么有redo-log-和-binlog-？"><a href="#为什么有redo-log-和-binlog-？" class="headerlink" title="为什么有redo log 和 binlog ？"></a>为什么有redo log 和 binlog ？</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">sync_binlog: <span class="number">1</span> - 每次都持久化到磁盘</span><br><span class="line">binlog: statment格式、记录的是<span class="keyword">sql</span>语句、</span><br><span class="line">           <span class="keyword">row</span>格式、记录的是行内容、更新前后都有</span><br><span class="line"></span><br><span class="line">mysql整体包含: </span><br><span class="line"><span class="keyword">server</span>层 - 主要做的是mysql功能层面的事情、</span><br><span class="line">引擎层 - 负责存储</span><br><span class="line">最初、mysql无innodb引擎、MySQL自带的引擎是myisam、但它没有crash-safe的能力、<span class="keyword">server</span>层的binlog日志、只能用于归档、innodb是另外一个公司以插件形式引入、用redo <span class="keyword">log</span> 来实现crash-safe能力</span><br></pre></td></tr></table></figure>

<h4 id="update语句执行"><a href="#update语句执行" class="headerlink" title="update语句执行"></a>update语句执行</h4><figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">update table <span class="keyword">set</span> c=c+<span class="number">1</span> <span class="keyword">where</span> <span class="built_in">id</span>=<span class="number">2</span></span><br><span class="line"><span class="number">1.</span> 执行器先找引擎取 <span class="built_in">id</span>=<span class="number">2</span> 这一行、<span class="built_in">id</span>是主键、引擎可以直接使用树搜索找到. 若 <span class="built_in">id</span> = <span class="number">2</span> 所在的数据页本来就在内存中、直接返回给执行器; 否则、先从磁盘读入内存、再返回</span><br><span class="line"><span class="number">2.</span> 执行器拿到引擎给出的数据行、把值 +<span class="number">1</span> 、得到新的一行数据、再调用引擎接口写入新的数据行</span><br><span class="line"><span class="number">3.</span> 引擎将新的数据行更新到内存、同时将更新操作记录到 redo <span class="built_in">log</span>. 此时redo <span class="built_in">log</span> 处于 prepare 状态、然后告诉执行器、执行完成、随时可以提交事务.</span><br><span class="line"><span class="number">4.</span> 执行器生成操作的binlog、并把binlog写入磁盘</span><br><span class="line"><span class="number">5.</span> 执行器调用引擎的提交事务接口、引擎把刚刚写入的redo <span class="built_in">log</span>改成commit状态、更新完成</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-7b1034b758d49c13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="update.png"></p>
<h4 id="为什么需要两阶段提交"><a href="#为什么需要两阶段提交" class="headerlink" title="为什么需要两阶段提交"></a>为什么需要两阶段提交</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">redo</span> <span class="keyword">log</span> 和 binlog 是两个独立的逻辑、若不使用两阶段提交、则会是<span class="number">2</span>种情况</span><br><span class="line"><span class="number">1.</span> 先 <span class="keyword">redo</span> <span class="keyword">log</span>、 后binlog</span><br><span class="line">   若redolog完成、binlog未完成、进程异常重启、<span class="keyword">redo</span> <span class="keyword">log</span>生效、为修改后的值 </span><br><span class="line">  若使用binlog恢复临时库、由于binlog未写完就崩溃、会少一条记录、源库和备库就会出现不一致</span><br><span class="line"><span class="number">2.</span> 先binlog、后 <span class="keyword">redo</span> <span class="keyword">log</span></span><br><span class="line">    binlog写完后crash、<span class="keyword">redo</span> <span class="keyword">log</span>未写、在恢复时、认为事务无效、</span><br><span class="line">    binlog已写完、恢复备份库时、认为有效、出现不一致...</span><br><span class="line">所以、为了保证<span class="keyword">redo</span> <span class="keyword">log</span> 和 binlog提交状态的逻辑一致性</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h4><figure class="highlight n1ql"><table><tr><td class="code"><pre><span class="line">1. binlog 是每次<span class="keyword">update</span>都会写磁盘？</span><br><span class="line"><span class="number">2.</span> 如果 redo <span class="built_in">log</span> 第一阶段完成(<span class="keyword">prepare</span>状态)、binlog完成、此时crash、在系统重启之后、这个<span class="built_in">log</span>会被重放吗</span><br><span class="line">   会、满足<span class="keyword">prepare</span> 和 binlog的完整、在重启时、会自动执行<span class="keyword">commit</span></span><br><span class="line"><span class="number">3.</span> 极端情况下、redo <span class="built_in">log</span>被写满、新的事务进入、需要擦除redo <span class="built_in">log</span>(被修改的脏页被迫刷新到磁盘) -&gt; 数据在 <span class="keyword">commit</span> 之前被持久化、此时如何处理 ？</span><br><span class="line">这些数据在内存中属于无效事务、其它事务读不到、即时被写入磁盘也没关系、再次读入内存时、依然是原逻辑</span><br><span class="line"><span class="number">4.</span> redo <span class="built_in">log</span> 是顺序写 ？ binlog是随机写 ？</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>innodb还是memory</title>
    <url>/2020/03/25/mysql_innodb%E8%BF%98%E6%98%AFmemory/</url>
    <content><![CDATA[<blockquote>
<p> 都说innodb好、还要不要用memory引擎 ?</p>
</blockquote>
<h4 id="内存表的数据组织结构"><a href="#内存表的数据组织结构" class="headerlink" title="内存表的数据组织结构"></a>内存表的数据组织结构</h4><p>innodb表的数据就放在主键索引树上、主键索引是 B+ 树、主键索引上是有序存储的, 在执行select  * 时、会按照叶子节点从左到右扫描、得到的结果 0 出现在第一行</p>
<p>memory引擎的数据和索引是分开的. 主键id的索引里、存放的是每个数据的位置. 主键id是hash索引、索引上的key是乱序的. select * 也是全表扫描、也是顺序扫描数组、0就是最后一个被读到、并放入结果集的数据. </p>
<p>innodb把数据放到主键索引上、其它索引保存的是主键id、是索引组织表(Index Organizied Table)<br>memory引擎采用的是数据单独存放、是堆组织表(Heap Organizied Table)</p>
<p>两者之间的差异:</p>
<ol>
<li>innodb的数据总是有序存储的、内存表的数据是按照写入顺序存储的.</li>
<li>当数据文件有空洞的时候、innodb表在插入新数据时、为了保证数据有序性、只能在固定位置写入新值, 而内存表找到空位置就可以插入新值.</li>
<li>数据位置发生变化的时候、innodb表只需要修改主键索引、而内存表需要修改所有索引.s</li>
<li>innodb表用主键索引查询时、需要走一次索引查询、普通索引查询时、要走两次索引查找.<br>memory表无分别、所有的索引地位都是相同的.</li>
<li>innodb支持变长数据类型、不同记录的长度可能不同、内存表不支持Blob和Text字段、并且即使定义varchar(N)实际也是char(N), 即固定长度存储、所以: 每行数据长度相同.</li>
</ol>
<p>所以: 内存表每行数据被删除以后、空出的位置可以被接下来要插入的数据复用.<br>注意: 内存表的索引是hash索引、范围查询 <code>select * from t1 where id&lt;5</code> 是无法用到主键索引的, 会全表扫描.</p>
<h4 id="hash索引-和-B-Tree索引"><a href="#hash索引-和-B-Tree索引" class="headerlink" title="hash索引 和 B-Tree索引"></a>hash索引 和 B-Tree索引</h4><p>内存表也可以支持B-Tree索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t1 <span class="keyword">add</span> index a_btree_index <span class="keyword">using</span> btree(id);</span><br></pre></td></tr></table></figure>
<p>内存表优势是速度快. 一方面它支持hash索引、另一方面、它的数据都在内存; 那么、为什么不建议生产环境使用内存表呢 ?</p>
<ol>
<li>锁粒度问题</li>
<li>数据持久化问题.</li>
</ol>
<h4 id="内存表的锁"><a href="#内存表的锁" class="headerlink" title="内存表的锁"></a>内存表的锁</h4><p>内存表不支持行锁、只支持表锁、导致并发性太低.</p>
<h4 id="数据持久性问题"><a href="#数据持久性问题" class="headerlink" title="数据持久性问题"></a>数据持久性问题</h4><p>数据放在内存中是内存表的优势、也是劣势、因为DB重启时、所有的内存表都会被清空.</p>
<h5 id="M-S-架构场景"><a href="#M-S-架构场景" class="headerlink" title="M-S 架构场景"></a>M-S 架构场景</h5><ol>
<li>业务正常访问s主库</li>
<li>备库硬件升级、备库重启、内存表t1内容被清空</li>
<li>备库重启后、客户端发送一条update语句、修改表t1的数据行、此时备库应用线程就会找不到要更新的数据.</li>
</ol>
<h5 id="双M架构"><a href="#双M架构" class="headerlink" title="双M架构"></a>双M架构</h5><p>MySQL知道重启后、内存表的数据会丢失、所以担心主库重启后、出现主备不一致、在实现上、会在DB重启后写入一行 delete from t1的binlog记录.<br>备库重启时、备库的binlog里的delete语句就会传到主库、然后把主库内存表的内容删除, 出现主库内存表数据突然被清空的现象.</p>
<p>所以不适合在生产上使用.</p>
<ol>
<li>若选择内存表是因为更新量大、那么并发度是重要的参考指标、innodb支持行锁、并发度更好</li>
<li>若考虑读性能、一个读QPS很高、且数据量不大的表、即使是innodb、数据也都是缓存在buffer pool的、因此innodb表性能也不差.</li>
</ol>
<h4 id="一个适合用内存表的场景"><a href="#一个适合用内存表的场景" class="headerlink" title="一个适合用内存表的场景"></a>一个适合用内存表的场景</h4><p>内存临时表: 不会被其它线程访问、无并发问题; 重启需要删除、清空数据问题不存在; 备库的临时表不影响主库用户线程, 所以刚好可以无视内存表的两个不足.</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>java-jdbc参数</title>
    <url>/2020/03/20/mysql_java-jdbc%E5%8F%82%E6%95%B0/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>参数名称</th>
<th>参数说明</th>
<th>缺省值</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>user</td>
<td>数据库用户名</td>
<td></td>
<td>all</td>
</tr>
<tr>
<td>password</td>
<td>密码</td>
<td></td>
<td>all</td>
</tr>
<tr>
<td>useUnicode</td>
<td>是否使用unicode字符集、若characterEncoding设置为gb2312或者gbk、则必须设置为true</td>
<td>false</td>
<td>&gt;1.1</td>
</tr>
<tr>
<td>characterEncoding</td>
<td>指定字符编码</td>
<td>false</td>
<td>&gt;1.1</td>
</tr>
<tr>
<td>autoReconnect</td>
<td>db异常时、是否自动重连？</td>
<td>false</td>
<td>1.1</td>
</tr>
<tr>
<td>autoReconnectForPools</td>
<td>是否使用针对db 连接池的重连策略</td>
<td>false</td>
<td>1.1</td>
</tr>
<tr>
<td>failOverReadOnly</td>
<td>自动重连成功后、连接是否设为只读</td>
<td>true</td>
<td>3.0.12</td>
</tr>
<tr>
<td>maxReconnects</td>
<td>autoReconnect设为true时、重试次数</td>
<td>3</td>
<td>1.1</td>
</tr>
<tr>
<td>initalTimeout</td>
<td>autoReconnect为true时、两次重试之间的时间间隔</td>
<td>2s</td>
<td>1.1</td>
</tr>
<tr>
<td>connectTimeOut</td>
<td>和数据库建立socket连接的超时时间ms</td>
<td>0-永不超时</td>
<td>3.0.1</td>
</tr>
<tr>
<td>socketTimeOut</td>
<td>socket读写超时ms</td>
<td>0-永不超时</td>
<td>3.0.1</td>
</tr>
<tr>
<td>zeroDateTimeBehavior</td>
<td>将db 0值转化为null</td>
<td></td>
<td>3.1.4</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql索引</title>
    <url>/2020/03/20/mysql_mysql-%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<h4 id="常见的索引模型"><a href="#常见的索引模型" class="headerlink" title="常见的索引模型"></a>常见的索引模型</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> hash 一种key-value结构、k-v映射、写入、等值查询很快、但范围查询比较慢、但适用于 等值查询的场景</span><br><span class="line"><span class="bullet">2.</span> 有序数组在等值查询和范围查询的性能表现上都很优秀</span><br><span class="line">   但在插入时必须要挪动后续所有记录、成本太高、</span><br><span class="line">   所以只适用于静态存储. eg. 城市信息表这种不经常变动的数据</span><br><span class="line"><span class="bullet">3.</span> 树 在查询和写入的效率上都还不错</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-378ce5505cc95e86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="hash表示意图.png"></p>
<h4 id="innodb的索引模型"><a href="#innodb的索引模型" class="headerlink" title="innodb的索引模型"></a>innodb的索引模型</h4><blockquote>
<p>在innodb中、表都是根据主键顺序、以索引的形式存放的, 这种存储方式的表称为索引组织表<br>innodb使用了B+树索引模型，数据都是存储在B+树的、每个索引对应一颗B+树</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> T<span class="operator">-</span>inx(</span><br><span class="line">id <span class="type">int</span> <span class="keyword">primary</span> key ,</span><br><span class="line">k <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span> ,</span><br><span class="line">name <span class="type">varchar</span>(<span class="number">16</span>) ,</span><br><span class="line">index (k)</span><br><span class="line">)engine<span class="operator">=</span>innodb</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-4047d1069d4fce5c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="i索引树示意图.png"></p>
<figure class="highlight axapta"><table><tr><td class="code"><pre><span class="line">从图中可以看出、索引树分为主键索引和非主键索引两种类型、</span><br><span class="line">主键索引存储的是整行数据、在innodb里, 主键索引也被称为聚簇索引(clustered <span class="keyword">index</span>).</span><br><span class="line">非主键索引的叶子节点内容是主键值, 也称为二级索引(secondary <span class="keyword">index</span>).</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Q: 那么基于主键索引 和 基于普通索引的查询有什么区别 ?</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">若 <span class="keyword">sql</span> 是 <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> T <span class="keyword">where</span> ID<span class="operator">=</span><span class="number">500</span>; 即主键查询的方式、则只需要搜索ID这颗 B<span class="operator">+</span> 树</span><br><span class="line">若 <span class="keyword">sql</span> 是 <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> T <span class="keyword">where</span> k<span class="operator">=</span><span class="number">5</span>, 则需要先搜索k这颗索引树、得到id的值为<span class="number">500</span>, 再到ID索引树搜索一次、这个过程称为 回表</span><br><span class="line"></span><br><span class="line">也就是: 基于非主键索引的查询需要多扫描一颗索引树, 所以需要尽量的使用主键查询</span><br></pre></td></tr></table></figure>

<p>Q: 索引维护</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">B+ 树为了维护索引有序性、在插入新值的时候需要做必要的维护.</span><br><span class="line">若插入的新值较大、只需要再最后插入新的记录、若插入的值为中间值、则相对麻烦,需要先挪动后边的数据、腾出位置</span><br><span class="line"><span class="section">更糟糕的是: 若最后一个数据所在的数据页已经满了、根据B+树的算法、需要申请一个新的数据页、然后挪动部分数据过去</span></span><br><span class="line">这个过程称为 页分裂, 除了性能外、页分裂还影响数据页的利用率</span><br><span class="line"></span><br><span class="line">当相邻页有数据删除之后、由于数据页的利用率很低、会进行页合并</span><br><span class="line"></span><br><span class="line"><span class="section">场景: 自增主键的作用？</span></span><br><span class="line">插入新的记录时、系统会获取当前最大值+1 作为下一条记录的id</span><br><span class="line"><span class="section">即: 自增主键的插入数据模式、正好符合了递增插入、不涉及挪动其它记录、也不会触发叶子节点的分裂</span></span><br><span class="line">而有业务逻辑的字段做主键、则往往不能保证有序写入、这样写数据的成本相对高</span><br><span class="line"></span><br><span class="line">从存储上看、主键长度越小、普通索引的叶子节点就越小、索引占用的空间也就越小</span><br><span class="line"></span><br><span class="line">so. 从性能和存储上来看、自增主键往往是最合理的选择</span><br></pre></td></tr></table></figure>


<p>表初始化语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> T<span class="operator">-</span>index(</span><br><span class="line">ID <span class="type">int</span> <span class="keyword">primary</span> key, </span><br><span class="line">k <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">default</span> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">index k(k)</span><br><span class="line">)engine<span class="operator">=</span>Innodb;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> T<span class="operator">-</span>index <span class="keyword">values</span> (<span class="number">100</span>, <span class="number">1</span>, <span class="string">&#x27;aa&#x27;</span>), (<span class="number">200</span>, <span class="number">2</span>, <span class="string">&#x27;bb&#x27;</span>), (<span class="number">300</span>, <span class="number">3</span>, <span class="string">&#x27;cc&#x27;</span>), , (<span class="number">500</span>, <span class="number">5</span>, <span class="string">&#x27;ee&#x27;</span>), (<span class="number">600</span>, <span class="number">6</span>,<span class="string">&#x27;ff&#x27;</span>),(<span class="number">700</span>,<span class="number">7</span>,<span class="string">&#x27;gg&#x27;</span>);</span><br><span class="line">                                                                                                     </span><br></pre></td></tr></table></figure>

<p>Q: 执行sql<code>select * from T-index where k between 3 and 5</code>需要执行几次树的搜搜操作、会扫描多少行 ？<br>A: 执行流程:</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">1. 在 k 索引树上找到 <span class="attribute">k</span>=3 的记录、取得<span class="attribute">id</span>=300;</span><br><span class="line">2. 再到 id 索引树上查找 <span class="attribute">id</span>=300 对应的记录R3;</span><br><span class="line">3. 在 k 索引树上找到 下一个值 <span class="attribute">k</span>=5, 取得 <span class="attribute">id</span>=500;</span><br><span class="line">4. 再回到 id 索引树上找到 <span class="attribute">id</span>=500 对应的记录 R4;</span><br><span class="line">5. 在k索引树上取下一个值 <span class="attribute">k</span>=6, 不满足条件、循环两次.</span><br><span class="line"></span><br><span class="line">在步骤 2、4中、回到主键索引查找数据的过程、称为回表</span><br></pre></td></tr></table></figure>
<p>所以、一共执行了 <code>3次</code>搜索、<code>2次</code>回表、扫描<code>3行</code></p>
<h4 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h4><blockquote>
<p>若执行的语句是<br>select ID from T-index where k between 3 and 5;<br>此时只需要查询 ID 的值、而ID的值已经在 K 索引树上了、可以直接提供查询结果、<br>无需回表、即: 在本次查询中、索引 k 已经覆盖了查询需求、<br>称为覆盖索引</p>
</blockquote>
<ul>
<li>在引擎内部使用覆盖索引在索引 k 上其实读了3个记录、R3~R5、<br>但是对于 MySQL的server来说、只从引擎拿到了2条记录、认为扫描行是2</li>
</ul>
<p>so. 覆盖索引在一定程度上可以减少回表扫描的次数</p>
<p>Q: 在一个市民表上、是否有必要将身份证和名字建立联合索引 ?</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span>  <span class="keyword">table</span> `<span class="keyword">user</span>` (</span><br><span class="line">`id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span> ,</span><br><span class="line">`id_card` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">default</span> <span class="keyword">null</span> ,</span><br><span class="line">`name` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">default</span> <span class="keyword">null</span> ,</span><br><span class="line">`age` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span> , </span><br><span class="line">`ismale` tinyint(<span class="number">1</span>) <span class="keyword">default</span> <span class="keyword">null</span> ,</span><br><span class="line"><span class="keyword">PRIMARY</span> key (`id`) ,</span><br><span class="line">key `id_card` (`id_card`),</span><br><span class="line">key `name_age` (`name`, `age`)</span><br><span class="line">) engine<span class="operator">=</span>Innodb</span><br></pre></td></tr></table></figure>
<p>A: </p>
<figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">这种情况需要看实际的业务场景</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">1. 若经常的查询需求是</span><span class="punctuation">: </span></span><br><span class="line">   <span class="attribute">根据身份证号查询市民信息、则 只需要在身份证字段上建立索引, 再建(id,name)的联合索引就会浪费空间</span></span><br><span class="line"><span class="attribute">   </span></span><br><span class="line"><span class="attribute">2. 若经常的查询需求是</span><span class="punctuation">:</span></span><br><span class="line">   根据身份证号查询name, 则建立联合索引就有很大的意义、它可以在这个高频请求上用到覆盖索引, </span><br><span class="line">   不在需要回表查询， 提高查询速度</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Q: 如果现在有一个非高频请求、根据身份证号查询家庭地址, 需要再设计一个联合索引么 ?<br>A: </p>
<figure class="highlight delphi"><table><tr><td class="code"><pre><span class="line">索引项是按照索引出现的字段排序的:</span><br><span class="line">eg. 利用(<span class="keyword">name</span>, age)的联合索引查找所有名字是 zhangsan 的人时, 可快速定位到 ID4, 然后向后遍历得到所有结果</span><br><span class="line">    不只是索引的全部定义. 只要满足最左前缀原则、就可以利用索引来加速检索</span><br><span class="line">所以: 基于已经建立了 (id_card, <span class="keyword">name</span>) 的联合索引、无需再建立 (id_card, addr)的联合索引、</span><br><span class="line">利用最左前缀的原则、它可以使用 (id_card, <span class="keyword">name</span>) 的联合索引</span><br></pre></td></tr></table></figure>

<h4 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h4><p>思考:<br>以(name, age)联合索引为例、需要检索所有 <strong>名字第一个字为张,且年龄为10的男孩</strong><br>SQL如下:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> name <span class="keyword">like</span> `张<span class="operator">%</span>` <span class="keyword">and</span> age<span class="operator">=</span><span class="number">10</span> <span class="keyword">and</span> ismale<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>拿到记录行之后、还要进一步判断其它条件是否满足、这个怎么处理的呢?</p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 在MySQL <span class="number">5.6</span> 之前、只能从 ID3 开始、一个个回表. 在主键索引上找到数据行、再对比字段值</span><br><span class="line"><span class="number">2</span>. 在<span class="number">5.6</span> 引入了索引下推(index condition pushdown), 可以在索引遍历的过程中对索引包含的字段优先判断</span><br><span class="line">   过滤掉不满足条件的记录、减少回表次数</span><br><span class="line">   </span><br><span class="line">   在无索引下推时、innodb不会看age的值、只是顺序把 `name`第一个字是`张`的记录取出、回表、需要回表<span class="number">4</span>次</span><br><span class="line">   有索引下推时、innodb在(name, age)内部就判断了age是否=<span class="number">10</span>，不等于<span class="number">10</span>的记录、直接判断并跳过</span><br><span class="line">   只需要取回ID4、ID5两条记录、所以只需要回表<span class="number">2</span>次</span><br></pre></td></tr></table></figure>
<p>Q: 为什么需要重建索引？</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">索引因为删除、或者页分裂等原因、导致数据页有空洞、重建索引的过程会创建一个新的索引、把数据按顺序插入、这样页面的利用率最高、</span><br><span class="line">也就是索引更紧凑、更省空间</span><br></pre></td></tr></table></figure>
<p>Q: </p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="title">场景:</span> DBA入职时、发现自己接手维护的库、有一个表定义：</span><br><span class="line"></span><br><span class="line">create table `geek`(</span><br><span class="line">`a` int(<span class="number">11</span>) <span class="literal">not</span> null,</span><br><span class="line">`b` int(<span class="number">11</span>) <span class="literal">not</span> null,</span><br><span class="line">`c` int(<span class="number">11</span>) <span class="literal">not</span> null,</span><br><span class="line">`d` int(<span class="number">11</span>) <span class="literal">not</span> null,</span><br><span class="line">primary key(`a`, `b`),</span><br><span class="line">key `c`(`c`),</span><br><span class="line">key `ca`(`c`, `a`),</span><br><span class="line">key `cb`(`c`, `b`)</span><br><span class="line">)engine=innodb<span class="comment">;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>为什么需要ca、cb这两个联合索引呢 ？同事的解释是: 因为业务常用下边的sql:</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> geek <span class="keyword">where</span> c<span class="operator">=</span>N <span class="keyword">order</span> <span class="keyword">by</span> a limit <span class="number">1</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> geek <span class="keyword">where</span> c<span class="operator">=</span>N <span class="keyword">order</span> <span class="keyword">by</span> b limit <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>那么这种解释对么 ？</p>
</blockquote>
<figure class="highlight less"><table><tr><td class="code"><pre><span class="line">主键<span class="selector-tag">a</span>、<span class="selector-tag">b</span>的聚簇索引组织顺序相当于 <span class="selector-tag">order</span> <span class="selector-tag">by</span> <span class="selector-tag">a</span>, <span class="selector-tag">b</span> 即: 先按<span class="selector-tag">a</span>排序、再按<span class="selector-tag">b</span>排序、<span class="selector-tag">c</span>无序</span><br><span class="line">索引 <span class="selector-tag">ca</span>的组织是先按<span class="selector-tag">c</span>排序、再按<span class="selector-tag">a</span>排序、同时记录主键<span class="selector-tag">b</span></span><br><span class="line">索引 <span class="selector-tag">cb</span>的组织是先按<span class="selector-tag">c</span>排序、再按<span class="selector-tag">b</span>排序、同时记录主键<span class="selector-tag">a</span></span><br><span class="line"><span class="selector-tag">so</span>. <span class="selector-tag">ca</span>可以去掉、<span class="selector-tag">cb</span>需要保留</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Q: using where的时候、需要回表查询数据、然后把数据传输给server层、server来过滤数据、那么这些数据是存在哪儿的呢 ？</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">无需存储、就是一个临时表、读出来立马判断、然后扫描下一行是否可以复用</span><br></pre></td></tr></table></figure>

<p>Q: limit起到限制扫描行数的作用、并且有using where的时候、limit这个操作在存储引擎层做的、还是在server层做的 ？</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">server</span>层、接上面一个Q、读完以后、顺便判断一下<span class="keyword">limit</span>够不够就可以了、够了就结束循环</span><br></pre></td></tr></table></figure>

<p>Q: extra列线上 using index condition 代表使用了索引下推 ?</p>
<figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">ICP代表可以下推、但 &#x27;可以、不一定是&#x27;</span><br></pre></td></tr></table></figure>

<p>Q: 备库使用 –single-transaction 做逻辑备份的时候、若从主库的binlog传来一个DDL语句会如何?<br>A:备份关键语句:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Q1:<span class="keyword">SET</span> SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;</span><br><span class="line">Q2:<span class="keyword">START</span> TRANSACTION  <span class="keyword">WITH</span> CONSISTENT SNAPSHOT;</span><br><span class="line"><span class="comment">/* other tables */</span></span><br><span class="line">Q3:<span class="keyword">SAVEPOINT</span> sp;</span><br><span class="line"><span class="comment">/* 时刻 1 */</span></span><br><span class="line">Q4:<span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> `t1`;</span><br><span class="line"><span class="comment">/* 时刻 2 */</span></span><br><span class="line">Q5:<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `t1`;</span><br><span class="line"><span class="comment">/* 时刻 3 */</span></span><br><span class="line">Q6:<span class="keyword">ROLLBACK</span> <span class="keyword">TO</span> <span class="keyword">SAVEPOINT</span> sp;</span><br><span class="line"><span class="comment">/* 时刻 4 */</span></span><br><span class="line"><span class="comment">/* other tables */</span></span><br></pre></td></tr></table></figure>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line">在备份开始的时候、为了确保RR(可重复读)、再设置一次隔离级别<span class="built_in">Q1</span></span><br><span class="line">启动事务、用 with consistent snapshot 来确保这个语句执行完可以得到一个一致性视图 <span class="built_in">Q2</span></span><br><span class="line">设置保存点 <span class="built_in">Q3</span></span><br><span class="line"><span class="symbol">show</span> create 是为了那点表结构 <span class="built_in">Q4</span>、正式导数据 <span class="built_in">Q5</span> 回滚到savepoint ap是为了释放t1的MDL锁 <span class="built_in">Q6</span></span><br><span class="line"></span><br><span class="line"><span class="symbol">DDL</span>从主库传过来的时间不同、则影响不同</span><br><span class="line"><span class="number">1</span>. 若在<span class="built_in">Q4</span>之前到达: 无影响、那点的是DDL后的表结构</span><br><span class="line"><span class="number">2</span>. 若在时刻<span class="number">2</span>到达、表结构被修改过、<span class="built_in">Q5</span>执行的时候、报 Table definition has changed. please retry transaction. mysqldump 终止</span><br><span class="line"><span class="number">3</span>. 在时刻<span class="number">2</span> 和 <span class="number">3</span>之间到达、mysqldump占着t1的MDL锁、binlog被阻塞、现象: 主从延迟、直到 <span class="built_in">Q6</span> 完成.</span><br><span class="line"><span class="number">4</span>. 从时刻<span class="number">2</span>开始、mysqldump释放了 MDL锁、现象: 无影响、备份拿到的是 DDL前 的表结构</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Q: </p>
<blockquote>
<p>删除100000行表记录时,有3种做法</p>
</blockquote>
<ol>
<li>直接delete from T limit 100000;</li>
<li>在一个连接中 delete from T limit 5000; loop 20</li>
<li>在20个连接中 delete from T limit 5000; 20 connections;<br>如何选择?</li>
</ol>
<p>A:</p>
<figure class="highlight n1ql"><table><tr><td class="code"><pre><span class="line">尽量的选择第二种方式</span><br><span class="line">1. 单个语句占用的时间较长、锁的时间也会较长、而且打的事务也会造成主从延迟</span><br><span class="line">3. 在20个连接中同时执行 <span class="keyword">delete</span> <span class="keyword">from</span> T <span class="keyword">limit</span> <span class="number">5000</span>, 可能会造成认为锁冲突</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql事务</title>
    <url>/2020/03/20/mysql_mysql%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<h3 id="mysql-事务"><a href="#mysql-事务" class="headerlink" title="mysql 事务"></a>mysql 事务</h3><ol>
<li><p>ACID原则:</p>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Automicity:</span> 原子性</span><br><span class="line"><span class="symbol">Consistency:</span> 一致性</span><br><span class="line"><span class="symbol">Isolation:</span> 隔离性</span><br><span class="line"><span class="symbol">Durability:</span> 持久性</span><br></pre></td></tr></table></figure>

</li>
<li><p>SQL隔离级别</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 读未提交: read uncommited, 事务未提交时、别的事务就能读到它的变更</span><br><span class="line"><span class="bullet">2.</span> 读提交: read commited, 事务提交之后、才能被别的事务读到变更</span><br><span class="line"><span class="bullet">3.</span> 可重复读: repeatable read, 事务在执行过程中看到的数据、始终保持跟事务启动时看到的一致</span><br><span class="line"><span class="bullet">4.</span> 串行化: seriable, 对同一记录、写会加写锁、读会加读锁、读写锁冲突的时候、必须等到前一个锁释放才能执行</span><br></pre></td></tr></table></figure></li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-374aecc9f9ddf1bd.png?imageMogr2/auto-orient/strip%7CimageView2/1/w/240" alt="image.png"></p>
<h4 id="不同事物隔离级别下、事物A的返回结果"><a href="#不同事物隔离级别下、事物A的返回结果" class="headerlink" title="不同事物隔离级别下、事物A的返回结果"></a>不同事物隔离级别下、事物A的返回结果</h4><ul>
<li>若隔离级别是<code>读未提交</code>, 则 <code>V1</code> 的值是<code>2</code>、此时、B未提交A可以读到、<br><code>V2</code>, <code>V3</code> 的值也都是2</li>
<li>若.. 是<code>读提交</code>, 则<code>V1</code>是1、<code>V2</code> 是2、事物B的更新在提交后可以被A读到、则<code>V3</code>的值也是2</li>
<li>若隔离级别是<code>可重复读</code>、则<code>V1</code>, <code>V2</code>的值是1、<code>V3</code>的值2、因为<code>V2</code>在<code>事务A</code>提交之前、所以、<code>V1</code>, <code>V2</code> 的值为1</li>
<li>若隔离级别是<code>可串行化</code> 则<code>事务B</code>在执行<code>1-&gt;2</code>的过程会被锁、直到A提交、所以<code>V1</code>, <code>V2</code>是1 、</li>
</ul>
<h4 id="查看事务隔离级别"><a href="#查看事务隔离级别" class="headerlink" title="查看事务隔离级别"></a>查看事务隔离级别</h4><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="section">mysql&gt; show variables like &#x27;transaction_isolation&#x27;;</span></span><br><span class="line"><span class="section">+-----------------------+-----------------+</span></span><br><span class="line"><span class="section">| Variable_name         | Value           |</span></span><br><span class="line"><span class="section">+-----------------------+-----------------+</span></span><br><span class="line"><span class="section">| transaction_isolation | REPEATABLE-READ |</span></span><br><span class="line"><span class="section">+-----------------------+-----------------+</span></span><br><span class="line">1 row in set (0.04 sec)</span><br></pre></td></tr></table></figure>

<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="section">mysql&gt; select @@transaction_isolation;</span></span><br><span class="line"><span class="section">+-----------------+</span></span><br><span class="line"><span class="section">| @@transaction_isolation  |</span></span><br><span class="line"><span class="section">+-----------------+</span></span><br><span class="line"><span class="section">| REPEATABLE-READ |</span></span><br><span class="line"><span class="section">+-----------------+</span></span><br></pre></td></tr></table></figure>

<h5 id="mysql-全局事务隔离级别修改后、在本会话不会生效、只影响后续会话"><a href="#mysql-全局事务隔离级别修改后、在本会话不会生效、只影响后续会话" class="headerlink" title="mysql 全局事务隔离级别修改后、在本会话不会生效、只影响后续会话"></a>mysql 全局事务隔离级别修改后、在本会话不会生效、只影响后续会话</h5><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">mysql&gt; set global transaction isolation level read committed;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line"><span class="section">mysql&gt; select @@transaction_isolation;</span></span><br><span class="line"><span class="section">+-------------------------+</span></span><br><span class="line"><span class="section">| @@transaction_isolation |</span></span><br><span class="line"><span class="section">+-------------------------+</span></span><br><span class="line"><span class="section">| REPEATABLE-READ         |</span></span><br><span class="line"><span class="section">+-------------------------+</span></span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="mysql-session级别事务修改、只影响当前会话"><a href="#mysql-session级别事务修改、只影响当前会话" class="headerlink" title="mysql session级别事务修改、只影响当前会话"></a>mysql session级别事务修改、只影响当前会话</h5><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">mysql&gt; set session  transaction isolation level read uncommitted;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="section">mysql&gt; select @@transaction_isolation;</span></span><br><span class="line"><span class="section">+-------------------------+</span></span><br><span class="line"><span class="section">| @@transaction_isolation |</span></span><br><span class="line"><span class="section">+-------------------------+</span></span><br><span class="line"><span class="section">| READ-UNCOMMITTED        |</span></span><br><span class="line"><span class="section">+-------------------------+</span></span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>
<p>*Q: </p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">1.合适需要RR级别呢 ？</span><br><span class="line">   假设正在对数据做校对、是不是希望在校对过程中、用户产生的交易不会影响校对的结果 ？~~</span><br><span class="line"><span class="bullet">2.</span> 回滚日志什么时候删除？</span><br><span class="line">系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除</span><br><span class="line"><span class="bullet">3.</span> 什么时候不需要了？</span><br><span class="line">  当系统里么有比这个回滚日志更早的read-view的时候</span><br><span class="line"><span class="bullet">4.</span> 为什么尽量不要使用长事务</span><br><span class="line">  长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库</span><br><span class="line"><span class="bullet">5.</span> </span><br></pre></td></tr></table></figure>

<h4 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h4><figure class="highlight"><table><tr><td class="code"><pre><span class="line">事务隔离的实现：每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）</span><br></pre></td></tr></table></figure>

<p>Q: 由上所述、若事务隔离级别为RR、事务T启动的时候会创建一个一致性视图read-view、执行期间、若有其它事务修改了数据、事务T看到的数据不变<br>但: 这个事务要更新R1时、恰好R1被T2占有行锁、则T会进入等待状态、此时: 当它拿到行锁、可以执行更新的时候、读到的值是什么呢 ？</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t`(</span><br><span class="line">`id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span> , </span><br><span class="line">`k` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span> ,</span><br><span class="line"><span class="keyword">primary</span> key (`id`)</span><br><span class="line">)engine<span class="operator">=</span>innodb;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t(id, k) <span class="keyword">values</span> (<span class="number">1</span>, <span class="number">1</span>),(<span class="number">2</span>, <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p>SQL执行顺序如下：<br><img src="https://upload-images.jianshu.io/upload_images/14027542-cd319103b6d27133.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="image.png"></p>
<p>那么两个查询语句得到的结果分表是什么呢？</p>
<p>A: 先看下几个概念:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="keyword">begin</span><span class="operator">/</span><span class="keyword">start</span> transaction 并不是事务的七点、在执行到它们之后的第一个innodb表语句、事务才真正启动、马上执行事务、可以使用：</span><br><span class="line">   <span class="keyword">start</span> transaction <span class="keyword">with</span> consistent snapshot;</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> mysql中两个视图的概念</span><br><span class="line">   <span class="number">1</span>) <span class="keyword">view</span>: 是用查询语句创建的虚拟表、在调用的时候执行查询语句并生成结果、<span class="keyword">create</span> <span class="keyword">view</span> ... </span><br><span class="line">   <span class="number">2</span>) innodb在实现MVCC时用到的一致性读视图、即 cinsistent read <span class="keyword">view</span>, 用于执行 RC(Read Committed, 读提交)</span><br><span class="line">       和RR(Repeatable Read, 可重复读)隔离级别的实现</span><br><span class="line">   </span><br></pre></td></tr></table></figure>
<blockquote>
<p>两种启动事务的方式<br>  1.一致性视图是在执行第一个快照语句时创建<br>  2 在执行 start transaction with consistent snapshot 时创建</p>
</blockquote>
<p>大前提:</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 事务隔离级别为RR</span><br><span class="line"><span class="bullet">2.</span> autocommit=1</span><br><span class="line"><span class="bullet">3.</span> 注意事务启动的时机</span><br></pre></td></tr></table></figure>
<p>结果:</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">A</span> 查询得到<span class="number">1</span> B查询得到<span class="number">3</span> C更新成功</span><br></pre></td></tr></table></figure>

<p>so. 一脸迷茫了、^.^…<br>来看下: 快照在MVCC里是如何工作的</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">在RR级别下、事务在启动的时候就拍了个快照(基于db)</span><br><span class="line"></span><br><span class="line">快照如何实现？</span><br><span class="line"><span class="number">1.</span> innodb每个事务有一个唯一<span class="built_in">id</span>、叫 <span class="keyword">transaction</span> <span class="built_in">id</span>. 在事务开始时向事务系统申请、严格递增</span><br><span class="line"><span class="number">2.</span> 每行数据有多个版本、每次更新都会生成一个新的数据版本、并把trx <span class="built_in">id</span>赋值给这个数据版本的事务<span class="built_in">id</span>、记为: row trx_id</span><br><span class="line">   旧的数据版本要保留、且在新的数据版本中可以拿到、即: 表中一行记录、有多个版本row、每个版本有自己的row trx_id</span><br><span class="line">   一个记录被连续更新后的状态如下:</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-249460f611087ba6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">虚线内是同一行数据的<span class="number">4</span>个版本、当前最新版本是V4、k的值是<span class="number">22</span>、是被 <span class="keyword">transaction</span> <span class="built_in">id</span> 为<span class="number">25</span>的事务更新的</span><br><span class="line"></span><br><span class="line">undo <span class="built_in">log</span>呢? </span><br><span class="line">上图中的三个虚线就是undo <span class="built_in">log</span>、而V1 V2 V3 并不是物理存在的、而是在需要的时候根据当前版本和undo <span class="built_in">log</span>计算的</span><br><span class="line">事务只认、事务启动之前提交的内容、如果提交之后的并不认、必须要找到它的上一个版本、若上一个版本也不可见、则继续查找</span><br><span class="line"></span><br><span class="line">实现: </span><br><span class="line">innodb为每个事务构造了一个数组、用来保存事务启动的瞬间、当前正在活跃(启动但未提交)的所有事务<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">数组里<span class="built_in">id</span>的最小值即为 低水位、当前系统已创建过的事务<span class="built_in">id</span>的最大值+<span class="number">1</span> 即为 高水位</span><br><span class="line">视图数组和高水位组成了当前事务的一致性视图 <span class="built_in">read</span>-view</span><br><span class="line">数据版本的可见性规则、就是基于row trx_id和一致性视图的对比结果得到的</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-be120e1119794bcf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">对于当前事务启动的瞬间、一个数据版本的<span class="built_in">row</span> trx_id有几种情况</span><br><span class="line"><span class="number">1</span>. 若落在绿色部分、表示已提交事务或当前事务自己生成的、可见</span><br><span class="line"><span class="number">2</span>. 红色部分、表示这个版本是将来启动的事务生成的、不可见</span><br><span class="line"><span class="number">3</span>. 黄色部分、</span><br><span class="line">   a. 若 <span class="built_in">row</span> trx_id 在数组中、表示由未提交的事务生成的、不可见</span><br><span class="line">   b. 若不在数组中、表示已提交事务生成、可见</span><br><span class="line">   </span><br><span class="line">   有了<span class="built_in">row</span> trx_id、事务的快照就是静态的了...</span><br></pre></td></tr></table></figure>

<p>假设:</p>
<ol>
<li>事务开启前、系统只有一个活跃事务id 99</li>
<li>事务A、B、C的版本号 100、101、102 且当前系统只有这4个事务</li>
<li>事务开始前、(1,1)这行数据的 row trx_id是90</li>
</ol>
<p>事务查询逻辑图:<br><img src="https://upload-images.jianshu.io/upload_images/14027542-7602ef99ebe62a71.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<p>所以、事务A的查询流程:</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">1. 找到(1,3) 判断<span class="attribute">trx_od</span>=101 比高水位大、处于红色区域、不可见</span><br><span class="line">2. 找到上个版本、row <span class="attribute">trx_id</span>=102 比高水位大、处于红色区域、不可见</span><br><span class="line">3. 继续、找到(1,1) row <span class="attribute">trx_id</span>=90、比低水位小、处于绿色区域、可见</span><br><span class="line"></span><br><span class="line">虽然这行数据被修改过、但事务A无论在何时查询、结果都是一致的、称为一致性读</span><br></pre></td></tr></table></figure>

<h4 id="更新逻辑"><a href="#更新逻辑" class="headerlink" title="更新逻辑"></a>更新逻辑</h4><p>那么是不是有个疑问:<br>按照一致性读、好像 事务B的update语句、是不对的 ？</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-9c0c0ec70b636639.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="image.png"></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">B进行<span class="keyword">update</span>时、是不是看不到(<span class="number">1</span>,<span class="number">2</span>)？怎么计算出来的(<span class="number">1</span>,<span class="number">3</span>) ？</span><br><span class="line"></span><br><span class="line">是的: 如果在事务B更新之前查询一次数据、会发现、返回的 k 的确是<span class="number">1</span></span><br><span class="line">但是更新数据的时候、就不能再历史版本上更新了、否则、事务C的更新就丢失了</span><br><span class="line">so. 事务B此时的更新是在(<span class="number">1</span>,<span class="number">2</span>) 的基础上进行的操作</span><br><span class="line"></span><br><span class="line">规则:</span><br><span class="line">更新都是先读后写的、这个读是当前读(<span class="keyword">current</span> <span class="keyword">read</span>)、只能读当前的值</span><br><span class="line"></span><br><span class="line">其实、除了<span class="keyword">update</span>、若<span class="keyword">select</span>加锁、也是当前读</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id=<span class="number">1</span> <span class="keyword">lock</span> <span class="keyword">in</span> <span class="keyword">share mode</span>; // 读锁(S锁、共享锁)</span><br><span class="line">mysql&gt; <span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id=<span class="number">1</span> <span class="keyword">for</span> <span class="keyword">update</span>; // 写锁(X锁、排他锁)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>再往前一步：<br>若 C不是马上提交的、而是事务C’ 会如何？</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-11fddfc9015b0955.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">事务 c<span class="string">&#x27; 不同的是、未马上提交、在它提交前、事务B的更新发起、而此时 C&#x27;</span> 未提交、但是<span class="comment">(1,2)</span>这个版本也生成了、并且是当前最新版本</span><br><span class="line">那么B如何处理？</span><br><span class="line"></span><br><span class="line">此时就要考虑 两阶段锁协议、事务C<span class="string">&#x27;未提交、则写锁未释放、事务B是当前读、必须读最新版本、且必须加锁、</span></span><br><span class="line"><span class="string">则B被阻塞、必须等到C&#x27;</span>释放、才可继续</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Q: 为何表结构不支持 可重复读?</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">表结构无对应的数据行、也没有 <span class="built_in">row</span> trx_id 所以、只能遵循当前读</span><br></pre></td></tr></table></figure>

<p>Q: 使用如下表结构和初始化语句作为实验环境、事务隔离级别是可重复读、想把 字段 c和id 等值的行 的c值清零、发现 并未改掉<br>解释这种情况出现的场景及原理, 及如何避免？</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t`(</span><br><span class="line">`id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span> ,</span><br><span class="line">`c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span> ,</span><br><span class="line"><span class="keyword">primary</span> key (`id`)</span><br><span class="line">)engine<span class="operator">=</span>innodb</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t(id, c) <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">1</span>), (<span class="number">2</span>,<span class="number">2</span>), (<span class="number">3</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<p>A: 场景一</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">会话A</span><br><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="section">mysql&gt; select * from t;</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line"><span class="section">| id | c    |</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line">|  1 |    1 |</span><br><span class="line">|  2 |    2 |</span><br><span class="line">|  3 |    3 |</span><br><span class="line"><span class="section">|  4 |    4 |</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line">4 rows in set (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; update t set c=0 whete id=c;</span><br><span class="line"></span><br><span class="line">会话B</span><br><span class="line">mysql&gt; update t set c=c+1;</span><br><span class="line">Query OK, 4 rows affected (0.01 sec)</span><br><span class="line">Rows matched: 4  Changed: 4  Warnings: 0</span><br><span class="line"></span><br><span class="line">会话A</span><br><span class="line"><span class="section">mysql&gt; select * from t;</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line"><span class="section">| id | c    |</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line">|  1 |    1 |</span><br><span class="line">|  2 |    2 |</span><br><span class="line">|  3 |    3 |</span><br><span class="line"><span class="section">|  4 |    4 |</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line">4 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">会话A</span><br><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="section">mysql&gt; select * from t;</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line"><span class="section">| id | c    |</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line">|  1 |    2 |</span><br><span class="line">|  2 |    3 |</span><br><span class="line">|  3 |    4 |</span><br><span class="line"><span class="section">|  4 |    5 |</span></span><br><span class="line"><span class="section">+----+------+</span></span><br><span class="line">4 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>
<p>即：<br><img src="https://upload-images.jianshu.io/upload_images/14027542-eae83ec8f3ccedc4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="image.png"></p>
<p>场景二：<br><img src="https://upload-images.jianshu.io/upload_images/14027542-7b63a20e1a0be038.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="image.png"></p>
<p><strong>记住:update时、为当前读 current read</strong></p>
<h4 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 在 可重复读 RR 隔离级别下、普通的查询是快照读、是不会看到别的事务插入数据的、</span><br><span class="line">   因此 幻读是在 当前读 下才会发生</span><br><span class="line"><span class="bullet">2.</span> 数据被修改、在当前读可以看到修改后的结果、这个不叫幻读、</span><br><span class="line">   幻读 专指 新插入的行被当前读读到</span><br></pre></td></tr></table></figure>

<h4 id="间隙锁-gaps-lock"><a href="#间隙锁-gaps-lock" class="headerlink" title="间隙锁-gaps lock"></a>间隙锁-gaps lock</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">间隙锁: 锁的是两个值之间的空隙</span></span><br><span class="line"><span class="section">跟间隙锁存在冲突关系的是: 往这个间隙插入记录、间隙锁之间不存在冲突关系</span></span><br><span class="line"> </span><br><span class="line"><span class="section">行锁冲突关系: 读-读: no 读-写:no 写写: yes</span></span><br><span class="line"><span class="section">即: 跟间隙锁存在冲突关系的、是另外一个行锁</span></span><br><span class="line"></span><br><span class="line">间隙锁的引入会导致同样的语句锁住更大的范围、影响并发</span><br><span class="line">间隙锁只有在RR的隔离级别下才会生效、</span><br><span class="line"></span><br><span class="line">把隔离级别设为读提交的话、就没有间隙锁了、但是、要解决可能出现的数据和日志不一致的问题、</span><br><span class="line">需要把binlog的格式设置为row</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql常用命令</title>
    <url>/2020/03/20/mysql_mysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h4 id="lock"><a href="#lock" class="headerlink" title="lock"></a>lock</h4><ol>
<li>查看事务隔离级别</li>
</ol>
<blockquote>
<p>select @@transaction_isolation;</p>
</blockquote>
<ol start="2">
<li>设置全局事务(影响新的会话、不影响本会话)</li>
</ol>
<blockquote>
<p>set global transaction isolation level read committed; </p>
</blockquote>
<ol start="3">
<li>设置会话事务(影响本会话)</li>
</ol>
<blockquote>
<p>set session transaction isolation level read committed; </p>
</blockquote>
<ol start="4">
<li>查看mysql默认读取的 my.cnf 的命令</li>
</ol>
<blockquote>
<p>mysql –help | grep ‘my.cnf’</p>
</blockquote>
<p>查看mysql是否使用了指定目录的 my.cnf </p>
<blockquote>
<p>ps aux | grep ‘my.cnf’</p>
</blockquote>
<ol start="4">
<li><p>查看mysqlbinlog</p>
<blockquote>
<p>mysqlbinlog –no-defaults  &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysqld-bin.000001 –start-position&#x3D;2425</p>
</blockquote>
</li>
<li><p>查看binlog的位置</p>
<blockquote>
<p>show variables like ‘%log_bin%’;</p>
</blockquote>
</li>
</ol>
<p> 开启binlog<br>  <figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">server-id</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">log_bin</span>=<span class="literal">ON</span></span><br><span class="line"><span class="attr">log_bin_basename</span>=/var/lib/mysql/mysql-bin</span><br><span class="line"><span class="attr">log_bin_index</span>=/var/lib/mysql/mysql-bin.index</span><br></pre></td></tr></table></figure></p>
<p>   查看所有的binlog文件</p>
<blockquote>
<p>show binary logs;</p>
</blockquote>
<p>   查看指定binlog文件的内存</p>
<blockquote>
<p>show binlog events in ‘{name}’;</p>
</blockquote>
<p>   当前日志的文件名和偏移位置</p>
<blockquote>
<p>show master status;</p>
</blockquote>
<p>   刷新日志文件</p>
<blockquote>
<p>flush logs;</p>
</blockquote>
<p>   查看死锁配置</p>
<blockquote>
<p>show variables like ‘%deadlock%’</p>
</blockquote>
<ol start="6">
<li><p>mysqlbinlog工具查看<br>基于时间: </p>
<blockquote>
<p>mysqlbinlog –start-datetime&#x3D;’2019-05-19 13:00’ –stop-datetime&#x3D;’2019-05-19 14:00’</p>
</blockquote>
<p>基于偏移量</p>
<blockquote>
<p>mysqlbinlog –start-postion&#x3D;107 –stop-position&#x3D;1000 -d {db} {binlog}</p>
</blockquote>
<p>row格式文件的查看 添加<code>-vv</code>参数</p>
</li>
<li><p>开启一致性视图</p>
<blockquote>
<p>start transaction with consistent snapshot;</p>
</blockquote>
</li>
<li><p>查看innodb页大小</p>
<blockquote>
<p>show global status like ‘innodb_page_size’;<br>show variables like ‘innodb_page_size’;</p>
</blockquote>
</li>
<li><p>查看表基本信息</p>
</li>
</ol>
<blockquote>
<p>select * from information_schema.tables where TABLE_NAME like ‘car_order_finished_collect_2019’;</p>
</blockquote>
<ol start="10">
<li>开启profile</li>
</ol>
<blockquote>
<p> show variables like ‘profiling’; set profiling&#x3D;1;</p>
</blockquote>
<ol start="11">
<li>显示所有的profile</li>
</ol>
<blockquote>
<p>show profiles;</p>
</blockquote>
<ol start="12">
<li><p>显示第n个profile的详情</p>
<blockquote>
<p>show profile for query n;<br>show profile all for query n; </p>
</blockquote>
</li>
<li><p>查看innodb redo log配置</p>
<blockquote>
<p>show variables like ‘%innodb_log_file%’;<br>   innodb_log_file_size 单个redo log大小、<br>   innodb_log_files_in_group redo log文件数量</p>
</blockquote>
</li>
<li><p>查看innodb io控制</p>
</li>
</ol>
<blockquote>
<p>show variables like ‘innodb_io_capacity’</p>
</blockquote>
<ol start="15">
<li>innodb脏页比例</li>
</ol>
<blockquote>
<p>show variables like ‘innodb_max_dirty_pages_pct’</p>
</blockquote>
<ol start="16">
<li>计算innodb当前脏页比例<blockquote>
<p> show global status like ‘Innodb_buffer_pool_pages_%’;<br>   Innodb_buffer_pool_pages_dirty&#x2F;Innodb_buffer_pool_pages_total</p>
</blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql笔记</title>
    <url>/2020/03/20/mysql_mysql%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>感谢林老师的mysql实战45讲<br><a href="https://time.geekbang.org/column/intro/139">https://time.geekbang.org/column/intro/139</a><br><img src="http://upload-images.jianshu.io/upload_images/14027542-227879153c0c3275.jpg" alt="图片发自简书App"></p>
<p>希望老师越来越好、也希望自己能学得一二~</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql索引相关问题整理</title>
    <url>/2020/03/20/mysql_mysql%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h4 id="count-1-count-count-id"><a href="#count-1-count-count-id" class="headerlink" title="count(1) count(*) count(id)"></a>count(1) count(*) count(id)</h4><blockquote>
<p>mysiam:<br>将表的总行数保存到了磁盘上、所以对于无条件的count(*) 是很快返回的</p>
</blockquote>
<blockquote>
<p>innodb实现：<br>count(*) 是把数据记录一行行的拿出来判断、<br>(innodb是索引组织表、主键索引的叶子节点是数据记录、普通索引的叶子节点是主键值、会小很多、mysql会选择最小的那颗索引树来遍历、在保证逻辑正确的情况下、尽量减少扫描的数据量)<br>count(1) 遍历表、但不取值、扫描记录时、返回1给server<br>count(id) 会把id返回给server<br>count(field)<br>若定义为非null、会先判断该字段记录是否为null、非null才累加<br>若定义为null、从记录读出字段、累加</p>
</blockquote>
<h4 id="为什么mysql不直接记录count数？"><a href="#为什么mysql不直接记录count数？" class="headerlink" title="为什么mysql不直接记录count数？"></a>为什么mysql不直接记录count数？</h4><blockquote>
<p>innodb要保证事务执行、不同会话、commit前后 总行数是会发生改变的</p>
</blockquote>
<h4 id="show-table-status-替代？"><a href="#show-table-status-替代？" class="headerlink" title="show table status 替代？"></a>show table status 替代？</h4><blockquote>
<p>得到的结果是通过采样估算得到的、不精准、最高偏差有40%-50%</p>
</blockquote>
<h4 id="采样缓存系统保存计数"><a href="#采样缓存系统保存计数" class="headerlink" title="采样缓存系统保存计数?"></a>采样缓存系统保存计数?</h4><blockquote>
<p>1.redis重启、数据丢失<br>2.redis和db本身记录增加先后的问题会导致短时间的不精准</p>
</blockquote>
<h4 id="使用mysql表保存总记录？"><a href="#使用mysql表保存总记录？" class="headerlink" title="使用mysql表保存总记录？"></a>使用mysql表保存总记录？</h4><blockquote>
<p>可以、使用mysql的事务来保证、但是会影响性能</p>
</blockquote>
<p>mysql两阶段提交的过程：<br><img src="https://upload-images.jianshu.io/upload_images/14027542-0f3b96cc0f6f0519.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<h4 id="在不同阶段crash对于系统的影响"><a href="#在不同阶段crash对于系统的影响" class="headerlink" title="在不同阶段crash对于系统的影响"></a>在不同阶段crash对于系统的影响</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 图中A时刻(<span class="keyword">redo</span> <span class="keyword">log</span>写完、binlog还没写的时候)crash、binlog还没写、<span class="keyword">redo</span> <span class="keyword">log</span>也没提交、重启事务会回滚~</span><br><span class="line"><span class="number">2.</span>若是在B、binlog写完、<span class="keyword">redo</span> <span class="keyword">log</span>还未commit时、crash会发生什么？</span><br><span class="line">   a. 若<span class="keyword">redo</span> <span class="keyword">log</span>也是完整的-有了commit标识、直接提交</span><br><span class="line">   b. 若<span class="keyword">redo</span> <span class="keyword">log</span>只有完整的prepare、则判断对应的binlog是否完整、</span><br><span class="line">      完整-提交事务; 否则: 回滚事务</span><br></pre></td></tr></table></figure>

<h4 id="mysql如何知道binlog是完整的？"><a href="#mysql如何知道binlog是完整的？" class="headerlink" title="mysql如何知道binlog是完整的？"></a>mysql如何知道binlog是完整的？</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">一个事务的binlog有完整的格式:</span></span><br><span class="line"><span class="section">statement格式的: 最后会有commit</span></span><br><span class="line"><span class="section">row格式的: 最后会有Xid event</span></span><br><span class="line">MySQL5.6.2 之后、还引入了checksum检查日志中间出错的情况</span><br></pre></td></tr></table></figure>

<h4 id="redo-log和binlog是如何关联的"><a href="#redo-log和binlog是如何关联的" class="headerlink" title="redo log和binlog是如何关联的"></a>redo log和binlog是如何关联的</h4><figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">有一个共同的字段XID、crash恢复的时候会按顺序扫描redo <span class="built_in">log</span>:</span><br><span class="line"><span class="number">1.</span> 遇到既有<span class="built_in">prepare</span> 又有commit的redo <span class="built_in">log</span>直接提交</span><br><span class="line"><span class="number">2.</span> 遇到只有<span class="built_in">prepare</span>的、就拿XID去对应的binlog查找事务</span><br></pre></td></tr></table></figure>

<h4 id="处于prepare阶段的redo-log-完整的binlog重启就能恢复、为什么这么设计"><a href="#处于prepare阶段的redo-log-完整的binlog重启就能恢复、为什么这么设计" class="headerlink" title="处于prepare阶段的redo log + 完整的binlog重启就能恢复、为什么这么设计?"></a>处于prepare阶段的redo log + 完整的binlog重启就能恢复、为什么这么设计?</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">在时刻B、binlog就已经被写入了、若是应用于从库、从库就有了这条记录、为了保证主从数据的一致性、就必须保证主库也有这条记录、所以把<span class="keyword">redo</span> <span class="keyword">log</span>提交</span><br></pre></td></tr></table></figure>

<h4 id="为什么不是先写完redo-log再写binlog-？"><a href="#为什么不是先写完redo-log再写binlog-？" class="headerlink" title="为什么不是先写完redo log再写binlog ？"></a>为什么不是先写完redo log再写binlog ？</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">比较典型的分布式问题</span><br><span class="line">若<span class="keyword">redo</span> <span class="keyword">log</span>提交了、又不能回滚(回滚可能会覆盖掉其它的事务)、所以<span class="keyword">redo</span> <span class="keyword">log</span>直接提交、binlog写入失败的时候、由于不能回滚、就会比从库多一个事务</span><br></pre></td></tr></table></figure>

<h4 id="为什么不直接使用binlog、不用redo-log-？"><a href="#为什么不直接使用binlog、不用redo-log-？" class="headerlink" title="为什么不直接使用binlog、不用redo log ？"></a>为什么不直接使用binlog、不用redo log ？</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">若是历史原因: innodb本身不是mysql的原生引擎、原生引擎是mysiam、不支持崩溃恢复</span><br><span class="line">innodb在加入mysql之前、就可以支持崩溃恢复和事务</span><br><span class="line">innodb发现<span class="keyword">binlog没有崩溃恢复的能力、那就直接使用redo </span>log吧、</span><br><span class="line">如果用<span class="keyword">binlog支持崩溃恢复呢 </span>？流程如下图</span><br><span class="line">在这样的流程下、<span class="keyword">binlog还是不能支持崩溃恢复、不能支持恢复数据页</span></span><br><span class="line"><span class="keyword"></span>若<span class="keyword">binlog2写完、未commit的时候crash、引擎内部事务2会回滚、应用binlog2可以补回来、但对于binlog1事务已经提交、不会再应用binlog1</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">innodb使用的是WAL、在写完内存和日志的时候、事务就算完成了、若以后崩溃、依赖日志恢复数据页、图中<span class="number">1</span>位置crash 事务<span class="number">1</span>可能会丢失、且是数据页级的丢失、<span class="keyword">binlog未记录数据页的更新细节、不支持数据页恢复</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-9b6ac9029bcb1485.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<h4 id="能只用redo-log不用binlog吗？"><a href="#能只用redo-log不用binlog吗？" class="headerlink" title="能只用redo log不用binlog吗？"></a>能只用redo log不用binlog吗？</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 只从崩溃恢复的角度来讲、可以关掉binlog、系统依然是crash-safe的、但binlog有<span class="keyword">redo</span> <span class="keyword">log</span>不可替代的功能</span><br><span class="line">a. 归档. <span class="keyword">redo</span> <span class="keyword">log</span>是循环写、日志无法保留</span><br><span class="line">b. mysql系统依赖于binlog、binlog作为mysql本身就有的功能、</span><br><span class="line">c. 一些异构系统、需要消费binlog来更新数据</span><br></pre></td></tr></table></figure>

<h4 id="redo-log一般设置多大？"><a href="#redo-log一般设置多大？" class="headerlink" title="redo log一般设置多大？"></a>redo log一般设置多大？</h4><figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">redo <span class="built_in">log</span>过小、会导致很快写满、不得不强行刷盘、这样WAL的能力就发挥不出来了、若磁盘在<span class="built_in">T</span>级别、就直接设置为G级别吧~</span><br></pre></td></tr></table></figure>

<h4 id="正常运行的实例、数据写入后的最终落盘是从redo-log更新的还是从buffer-poll更新的？"><a href="#正常运行的实例、数据写入后的最终落盘是从redo-log更新的还是从buffer-poll更新的？" class="headerlink" title="正常运行的实例、数据写入后的最终落盘是从redo log更新的还是从buffer poll更新的？"></a>正常运行的实例、数据写入后的最终落盘是从redo log更新的还是从buffer poll更新的？</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line"><span class="keyword">redo</span> <span class="keyword">log</span> 并没有记录数据页的完整数据、所以本身没有能力更新磁盘数据页、</span><br><span class="line"><span class="number">1.</span> 数据页被修改后与磁盘数据页不一致、最终落盘就是把内存中的数据写入磁盘、与<span class="keyword">redo</span> <span class="keyword">log</span>无关</span><br><span class="line"><span class="number">2.</span> 崩溃恢复的场景中、innodb如果判断到一个数据页可能在崩溃恢复的时候丢失了更新就会将它读入内存、然后让<span class="keyword">redo</span> <span class="keyword">log</span>更新内存内容、更新完、内存变成脏页、回到<span class="number">1</span>的情况</span><br></pre></td></tr></table></figure>

<h4 id="redo-log-buffer是什么？是先修改内存、还是写写redo-log-？"><a href="#redo-log-buffer是什么？是先修改内存、还是写写redo-log-？" class="headerlink" title="redo log buffer是什么？是先修改内存、还是写写redo log ？"></a>redo log buffer是什么？是先修改内存、还是写写redo log ？</h4><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">在事务更新过程中 <span class="keyword">redo</span> <span class="keyword">log</span> 是要多次写的、</span><br><span class="line">eg. begin;</span><br><span class="line">      insert into t1...;</span><br><span class="line">      insert into t2...;</span><br><span class="line">     commit;</span><br><span class="line">这个事务要在两个表中插入记录、在插入的过程中、生成的日志都得先保存起来、但又不能在还没commit的时候写<span class="keyword">redo</span> <span class="keyword">log</span></span><br><span class="line"></span><br><span class="line">所以 <span class="keyword">redo</span> <span class="keyword">log</span> buffer就是一块内存、用来保存 <span class="keyword">redo</span> <span class="keyword">log</span>日志的. 即 在执行第一个insert的时候、数据的内存被修改了、<span class="keyword">redo</span> <span class="keyword">log</span> buffer也写入了日志</span><br><span class="line">但真正写入<span class="keyword">redo</span> <span class="keyword">log</span>(ib_logfile+日志)是在执行commit语句的时候做的、</span><br></pre></td></tr></table></figure>

<h4 id="update记录为原值的时候、mysql如何操作？"><a href="#update记录为原值的时候、mysql如何操作？" class="headerlink" title="update记录为原值的时候、mysql如何操作？"></a>update记录为原值的时候、mysql如何操作？</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> update是先读后写、发现值本来就是原值、不操作、直接返回</span><br><span class="line"><span class="bullet">2.</span> mysql调用innodb引擎接口修改、引擎发现与原值相同、不更新、直接返回</span><br><span class="line"><span class="bullet">3.</span> innodb认真的执行了更新、改加锁的加锁?</span><br><span class="line"></span><br><span class="line">答案是3、可以通过事务来验证</span><br></pre></td></tr></table></figure>
<p>过程请参考: <a href="https://time.geekbang.org/column/article/73479">https://time.geekbang.org/column/article/73479</a></p>
<p><strong>varchar(255)是边界、&gt;255需要两个字节存储、小于需要1个字节</strong></p>
<ol start="4">
<li><p>mysql 源码编译启动报错</p>
<figure class="highlight vhdl"><table><tr><td class="code"><pre><span class="line">mysql启动报错：Starting MySQL... <span class="literal">ERROR</span>! The server quit without updating PID <span class="keyword">file</span></span><br><span class="line"></span><br><span class="line">看errlog 发现:</span><br><span class="line"><span class="number">2018</span>-<span class="number">01</span>-<span class="number">24</span> <span class="number">07</span>:<span class="number">57</span>:<span class="number">03</span> <span class="number">67547</span> [<span class="literal">ERROR</span>] Fatal <span class="literal">error</span>: Can<span class="symbol">&#x27;t</span> <span class="keyword">open</span> <span class="keyword">and</span> lock privilege tables: Table <span class="symbol">&#x27;mysql</span>.user&#x27; doesn<span class="symbol">&#x27;t</span> exist</span><br><span class="line"><span class="keyword">or</span>: <span class="number">2018</span>-<span class="number">01</span>-<span class="number">24</span> <span class="number">07</span>:<span class="number">57</span>:<span class="number">03</span> [<span class="literal">ERROR</span>]   Can<span class="symbol">&#x27;t</span> locate the language directory.</span><br><span class="line"></span><br><span class="line">重新初始化db:</span><br><span class="line">mysql_install_db <span class="comment">--user=mysql --basedir=/home/devil/mysql57/ --datadir=/home/devil/mysql57/data/</span></span><br><span class="line"></span><br><span class="line">出现:</span><br><span class="line"><span class="number">2019</span>-<span class="number">04</span>-<span class="number">18</span> <span class="number">21</span>:<span class="number">23</span>:<span class="number">16</span> [<span class="literal">WARNING</span>] mysql_install_db <span class="keyword">is</span> deprecated. Please consider switching <span class="keyword">to</span> mysqld <span class="comment">--initialize</span></span><br><span class="line"></span><br><span class="line">so. </span><br><span class="line">mysqld <span class="comment">--initialize --user=mysql --basedir=/home/devil/mysql57/ --datadir=/home/devil/mysql57/data/</span></span><br><span class="line"></span><br><span class="line">可以看到初始化成功. 并生成了临时密码</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>mysql binlog 查看</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">a. 登录mysql查看</span><br><span class="line">   1) 只查看第一个binlog文件的内容</span><br><span class="line">        show binlog events;</span><br><span class="line">   2) 查看指定binlog文件的内容</span><br><span class="line">        show binlog events <span class="keyword">in</span> <span class="string">&#x27;mysql-binlog.000001&#x27;</span>;</span><br><span class="line">   3) 查看当前正在写入的binlog</span><br><span class="line">        show master status;</span><br><span class="line">    4) 获取binlog文件列表</span><br><span class="line">        show binary logs;</span><br><span class="line"></span><br><span class="line"> b. 使用mysqlbinlog工具查看</span><br><span class="line">     1) 本地查看 </span><br><span class="line">         基于开始/结束时间: </span><br><span class="line">         mysqlbinlog <span class="attribute">--start-datatime</span>=<span class="string">&#x27;2019-04-10 00:00:00&#x27;</span> <span class="attribute">--stop-datatime</span>=<span class="string">&#x27;2019-04-10 01:00:00&#x27;</span>  </span><br><span class="line">         基于pos值</span><br><span class="line">         mysqlbinlog <span class="attribute">--start-postion</span>=107 <span class="attribute">--stop-position</span>=1000 -d 库名 二进制文件</span><br><span class="line"></span><br><span class="line">      2)  远程查看</span><br><span class="line">           mysqlbinlog -u&#123;uname&#125; -p&#123;pass&#125; -htest.com -P3306 \</span><br><span class="line">--read-from-remote-server <span class="attribute">--start-datetime</span>=<span class="string">&#x27;2013-09-10 23:00:00&#x27;</span> <span class="attribute">--stop-datetime</span>=<span class="string">&#x27;2013-09-10 23:30:00&#x27;</span> mysql-bin.000001 &gt; t.binlog</span><br></pre></td></tr></table></figure></li>
</ol>
<figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">set optimizer_trace=<span class="string">&#x27;enabled=on&#x27;</span> 打开<span class="keyword">trace</span>记录</span><br><span class="line"><span class="keyword">select</span>  <span class="keyword">trace</span> from   <span class="string">`information_schema`</span>.<span class="string">`optimizer_trace`</span>; 查看<span class="keyword">trace</span>记录</span><br><span class="line"></span><br><span class="line">tmp_table_size 内存临时表大小</span><br><span class="line">sort_buffer_size 用于排序的内存大小、超过会使用文件排序</span><br><span class="line">max_length_for_sort_data 单行数据量超过这个值会使用rowid排序</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">查看<span class="keyword">sql</span>被哪个语句阻塞</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t sys.innodb_lock_waits <span class="keyword">where</span> locked_table<span class="operator">=</span>`<span class="string">&#x27;test&#x27;</span>.<span class="string">&#x27;t&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> blocking_pid <span class="keyword">from</span> sys.schema_table_lock_waits 可以找到阻塞的pid</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql索引选择</title>
    <url>/2020/03/20/mysql_mysql%E7%B4%A2%E5%BC%95%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<h4 id="普通索引和唯一索引"><a href="#普通索引和唯一索引" class="headerlink" title="普通索引和唯一索引"></a>普通索引和唯一索引</h4><h5 id="场景："><a href="#场景：" class="headerlink" title="场景："></a>场景：</h5><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">假设维护一个市民系统、每个人有一个唯一的身份证号、经常会根据身份证号查询、<span class="keyword">sql</span>如下:</span><br><span class="line"><span class="keyword">select</span> <span class="type">name</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id_card=<span class="string">&#x27;xxx&#x27;</span>;</span><br><span class="line">一定会考虑在id_card上建立索引、那么、这个索引应该是唯一索引还是普通索引呢 ？</span><br></pre></td></tr></table></figure>
<h5 id="思考"><a href="#思考" class="headerlink" title="思考:"></a>思考:</h5><blockquote>
<p>id_card字段比较大、不建议作为主键、那么、1.普通索引 2.唯一索引 如何选择？依据又是什么呢 ？</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-a869a323d23b3991.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="mysql索引结构组织树.png"></p>
<h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p><strong>查询过程</strong></p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">假设执行的语句为 select t <span class="keyword">from</span> T where <span class="attribute">k</span>=5;</span><br><span class="line">搜索从根开始、按层搜索到叶子节点、可以认为数据页内部通过二分法来定位</span><br><span class="line">1. 对于普通索引、查找到第一条记录(5, 500) 之后、需要查找下一个记录、直到碰到第一个不满足<span class="attribute">k</span>=5的记录</span><br><span class="line">2. 对于唯一索引】由于定义了唯一性、查找到(5, 500) 之后、停止检索、直接返回</span><br><span class="line">那么带来的性能差异呢 ？ - 微乎其微</span><br><span class="line"></span><br><span class="line">innodb的数据是按照数据页为单位来读写的、即: 当需要读一条记录的时候、不是讲记录本身从磁盘读出、而是以页为单位、</span><br><span class="line">将整个数据页读取到内存、数据页大小默认为16k</span><br><span class="line"></span><br><span class="line">因为是按页读取、当找到<span class="attribute">k</span>=5时、它所在的数据页已经在内存了、对于普通索引来说、多做的一次&#x27;查找和判断下一条记录&#x27;只需要一次指针查找和一次计算</span><br><span class="line">不幸的是、恰好<span class="attribute">l</span>=5是数据页的最后一条记录呢 ？<span class="built_in">..</span><span class="built_in">..</span></span><br><span class="line">必须读取下一个数据页, 对于整型字段、16k可以放近千个key、出现这种情况的概率很低、所以计算平均性能差异时、可认为这个操作成本对于现在的CPU来说可以忽略不计</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>更新过程</strong></p>
<h5 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change_buffer"></a>change_buffer</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">先说下change<span class="emphasis">_buffer的概念：</span></span><br><span class="line"><span class="emphasis">更新数据页时，若数据页在内存中 -&gt; 直接更新，</span></span><br><span class="line"><span class="emphasis">不在内存 -&gt; 在不影响一致性读的情况下、会讲更新操作缓存在change_</span>buffer</span><br><span class="line">这样就不需要从磁盘读入数据页, 下次查询需要访问这个数据页时、将数据页读到内存、与change<span class="emphasis">_buffer合并(称为merge)</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">虽然名字叫change_</span>buffer、实际可持久化、在内存中有copy、也会被写入磁盘</span><br><span class="line"></span><br><span class="line">触发merge:</span><br><span class="line"><span class="bullet">1.</span> 访问数据页</span><br><span class="line"><span class="bullet">2.</span> 后台线程定期merge</span><br><span class="line"><span class="bullet">3.</span> db正常关闭、shutdown</span><br><span class="line"><span class="bullet">4.</span> 达到change<span class="emphasis">_buffer的可用最大内存、触发merge、然后淘汰</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">显然、如果更新操作先记录在change_</span>buffer、减少读磁盘、可以提高sql执行效率</span><br><span class="line">而且、数据读入内存、是需要占用buffer<span class="emphasis">_pool的、这种方式还可以避免占用内存、提高内存使用效率</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">那么什么时候可以使用buffer_</span>pool?</span><br><span class="line"><span class="bullet">1.</span> change<span class="emphasis">_buffer 占用 buffer_</span>pool 的内存、通过 innodb<span class="emphasis">_change_</span>buffer<span class="emphasis">_max_</span>size 调整、设为50、</span><br><span class="line">   表示change<span class="emphasis">_buffer 最多占用buffer_</span>pool的50%</span><br><span class="line"><span class="bullet">2.</span> 不能无限增大、不能 &gt; buffer<span class="emphasis">_pool</span></span><br><span class="line"><span class="emphasis">3. 对唯一索引来说、所有的更新都要判断操作是否违反唯一约束、</span></span><br><span class="line"><span class="emphasis">   eg. 要插入(4, 400)这个记录、必须先判断记录是否存在、必须先将数据页读入内存</span></span><br><span class="line"><span class="emphasis">   若已读入内存、直接更新内存更快、无需使用 change_</span>buffer、</span><br><span class="line">   实际上、唯一索引的更新也不能使用change<span class="emphasis">_buffer、只有普通索引可用</span></span><br></pre></td></tr></table></figure>

<h5 id="理解了-change-buffer、看下插入-4，400"><a href="#理解了-change-buffer、看下插入-4，400" class="headerlink" title="理解了 change_buffer、看下插入(4，400)"></a>理解了 change_buffer、看下插入(4，400)</h5><figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">1. 更新的记录目标页在内存 - 无差别(只有一个判断的差别)</span></span><br><span class="line"><span class="attribute">   1) 唯一索引</span><span class="punctuation">:</span> <span class="string">找到3、5之间位置、判断无冲突、直接插入</span></span><br><span class="line">   <span class="attribute">2) 普通索引</span><span class="punctuation">:</span> <span class="string">找到3、5之间、直接插入</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">2. 更新记录目标页不在内存</span></span><br><span class="line"><span class="attribute">   1) 唯一索引</span><span class="punctuation">:</span> <span class="string">将数据页读入内存、判断无冲突、插入</span></span><br><span class="line">   <span class="attribute">2) 普通索引</span><span class="punctuation">:</span> <span class="string">将记录更新在change_buffer、执行结束</span></span><br><span class="line">   <span class="attribute">将数据从磁盘读到内存、涉及io随机访问、change_buffer减少了随意访问磁盘、性能会明显提升</span></span><br><span class="line"><span class="attribute">   </span></span><br><span class="line"><span class="attribute">3. 案例：</span></span><br><span class="line"><span class="attribute">   业务库的内存命中率突然下降、整个系统处于阻塞状态、更新全部阻塞、</span></span><br><span class="line"><span class="attribute">   深入排查后发现</span><span class="punctuation">:</span> <span class="string">业务有大量的插入操作、而、前一天晚上上、将普通索引改成了唯一索引、使写操作的效率下降</span></span><br></pre></td></tr></table></figure>

<h5 id="change-buffer使用场景"><a href="#change-buffer使用场景" class="headerlink" title="change_buffer使用场景"></a>change_buffer使用场景</h5><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">change_buffer对于查询无明显效果、也只适用于普通索引、那么 普通索引的所有场景、change_buffer都能起到加速作用么 ？</span><br><span class="line"></span><br><span class="line">1. <span class="keyword">merge</span> 的时候是真正数据更新的时刻、change_buffer主要是将记录变更的动作缓存、<span class="keyword">so</span>.<span class="keyword">merge</span>前变更越多、收益越大</span><br><span class="line">   对于写多、读少的业务、change_buffer的效果最好、常见业务模型: 账单类、日志类系统</span><br><span class="line">   </span><br><span class="line">2. 若业务场景是、写完立马会有查询、由于立马访问数据页、会立即触发<span class="keyword">merge</span>、随机访问的io次数不会减少、</span><br><span class="line">  反而增加了change_buffer的维护代价、不适合使用</span><br></pre></td></tr></table></figure>

<h5 id="索引选择和实践"><a href="#索引选择和实践" class="headerlink" title="索引选择和实践"></a>索引选择和实践</h5><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">1. 若所有更新后跟着记录的查询、应关闭change<span class="emphasis">_buffer</span></span><br><span class="line"><span class="emphasis">2. 若有一个机械硬盘的历史库、应尽量使用普通索引、调大change_</span>buffer、确保历史数据的写入效率</span><br></pre></td></tr></table></figure>

<h5 id="change-buffer-和-redo-log"><a href="#change-buffer-和-redo-log" class="headerlink" title="change_buffer 和 redo log"></a>change_buffer 和 redo log</h5><figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">假设执行更新</span><br><span class="line">insert into <span class="built_in">t</span>(id, k) <span class="built_in">values</span>(id1, k1), (id2, k2)</span><br><span class="line">当前k索引树的状态、k1所在的数据页在内存(innodb buffer pool)中、</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/14027542-0d07c7e2f5c7640c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="带change_buffer的数据更新.png"></p>
<figure class="highlight isbl"><table><tr><td class="code"><pre><span class="line">涉及: 内存、<span class="function"><span class="title">redolog</span>(<span class="variable">ib_log_fileX</span>)、数据表空间(<span class="variable">t.ibd</span>)、系统表空间(<span class="variable">ibdata1</span>) 四个部分</span></span><br><span class="line"><span class="function">更新做了如下操作:</span></span><br><span class="line"><span class="function"><span class="number">1</span>. page1在内存、直接更新内存 (图中<span class="number">1</span>)</span></span><br><span class="line"><span class="number">2</span>. page2不在内存、在内存的<span class="variable">change_buffer</span>区域、记录下 <span class="string">&#x27;往page2插入1行&#x27;</span> 这个信息 (图中<span class="number">2</span>)</span><br><span class="line"><span class="number">3</span>. 将<span class="number">1</span>、<span class="number">2</span>两个动作写入<span class="variable">redo</span> <span class="function"><span class="title">log</span>(图中<span class="number">3</span>、<span class="number">4</span>)</span></span><br><span class="line"></span><br><span class="line">所以、这条更新写了两处内存、一次磁盘(两次操作合写一次磁盘)还是顺序写、</span><br><span class="line"></span><br><span class="line">图中两个虚线、是后台操作、不影响更新的响应时间</span><br></pre></td></tr></table></figure>

<p><strong>读请求</strong><br><img src="https://upload-images.jianshu.io/upload_images/14027542-ae14a2d3a50f1d8c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="带change_buffer的读.png"></p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">select * from t where <span class="keyword">k</span> in (k1, k2)</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>. 假设、读发生在更新不久、内存中数据还在、此时与系统表空间和redolog无关、直接读即可</span><br><span class="line"><span class="number">2</span>. 读page1时、从内存返回、读page2时、需要把page2从磁盘读入内存、然后应用<span class="keyword">change</span> <span class="keyword">buffer</span>的操作日志、合并数据</span><br><span class="line"></span><br><span class="line"><span class="keyword">so</span>. 简单对比这两个机制在提升更新性能上的收益的话、</span><br><span class="line"><span class="keyword">redo</span> <span class="built_in">log</span>节省的是随机写 IO 的消耗、转为顺序写</span><br><span class="line"><span class="keyword">change</span> <span class="keyword">buffer</span>节省的是随机读io的消耗</span><br></pre></td></tr></table></figure>

<p>Q: change_buffer一开始是写内存的、此时若掉电重启、会导致change_buffer丢失么 ？ 若丢失、从磁盘读入时、就丢了merge、相当于丢了数据…</p>
<p>A:</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">虽然只是更新内存、但: 事务提交时、把<span class="keyword">change</span> <span class="keyword">buffer</span>的操作记录到了 <span class="keyword">redo</span> <span class="built_in">log</span>. 所以恢复时、<span class="keyword">change</span> <span class="keyword">buffer</span>可以找回</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>.<span class="keyword">change</span> <span class="keyword">buffer</span>有一部分在内存有一部分在ibdata.</span><br><span class="line">做purge操作,应该就会把<span class="keyword">change</span> <span class="keyword">buffer</span>里相应的数据持久化到ibdata</span><br><span class="line"><span class="number">2</span>.<span class="keyword">redo</span> <span class="built_in">log</span>里记录了数据页的修改以及<span class="keyword">change</span> <span class="keyword">buffer</span>新写入的信息</span><br><span class="line">如果掉电,持久化的<span class="keyword">change</span> <span class="keyword">buffer</span>数据已经purge,不用恢复。主要分析没有持久化的数据</span><br><span class="line">情况又分为以下几种:</span><br><span class="line">(<span class="number">1</span>)<span class="keyword">change</span> <span class="keyword">buffer</span>写入,<span class="keyword">redo</span> <span class="built_in">log</span>虽然做了fsync但未commit,binlog未fsync到磁盘,这部分数据丢失</span><br><span class="line">(<span class="number">2</span>)<span class="keyword">change</span> <span class="keyword">buffer</span>写入,<span class="keyword">redo</span> <span class="built_in">log</span>写入但没有commit,binlog以及fsync到磁盘,先从binlog恢复<span class="keyword">redo</span> <span class="built_in">log</span>,再从<span class="keyword">redo</span> <span class="built_in">log</span>恢复<span class="keyword">change</span> <span class="keyword">buffer</span></span><br><span class="line">(<span class="number">3</span>)<span class="keyword">change</span> <span class="keyword">buffer</span>写入,<span class="keyword">redo</span> <span class="built_in">log</span>和binlog都已经fsync.那么直接从<span class="keyword">redo</span> <span class="built_in">log</span>里恢复</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">merge流程：</span><br><span class="line"><span class="number">1</span>. 从磁盘读入数据页到内存</span><br><span class="line"><span class="number">2</span>. 从<span class="keyword">change</span> <span class="keyword">buffer</span>找出这个数据页的<span class="keyword">change</span> <span class="keyword">buffer</span>记录(可能是多个)、依次应用、得到新版数据页</span><br><span class="line"><span class="number">3</span>. 写<span class="keyword">redo</span> <span class="built_in">log</span>. 这个<span class="keyword">redo</span> <span class="built_in">log</span>包含了数据的变更和<span class="keyword">change</span> <span class="keyword">buffer</span>的变更</span><br><span class="line">merge流程完成、哈哈、此时 数据页和内存中<span class="keyword">change</span> <span class="keyword">buffer</span>对应的磁盘位置都还没修改、属于脏页、之后各自刷回自己的物理数据 -&gt; 另外一个流程</span><br></pre></td></tr></table></figure>

<h5 id=""><a href="#" class="headerlink" title=""></a></h5><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">内存命中率: ib_bp_hit=<span class="number">1000</span> – (t2.iReads – t1.iReads)/(t2.iReadRequest – t1.iReadRequest)*<span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">change</span> <span class="keyword">buffer</span>相当于推迟更新、对于MVCC是否有影响?比如加锁？</span><br><span class="line">锁是单独的数据结构、若数据页上有锁、<span class="keyword">change</span> <span class="keyword">buffer</span>在判断能否使用时、会认为否</span><br><span class="line"></span><br><span class="line"><span class="keyword">change</span> <span class="keyword">buffer</span>中、有此行记录的条件下、再次修改、是增加还是原地修改?</span><br><span class="line">增加</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql锁</title>
    <url>/2020/03/20/mysql_mysql%E9%94%81/</url>
    <content><![CDATA[<h3 id="锁的种类和概念"><a href="#锁的种类和概念" class="headerlink" title="锁的种类和概念"></a>锁的种类和概念</h3><p><em>Shared and Exclusive Locks</em></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">Shard <span class="keyword">Lock</span>: 共享锁</span><br><span class="line">官方: permits the <span class="keyword">transaction</span> that holds the <span class="keyword">lock</span> <span class="keyword">to</span> <span class="keyword">read</span> a <span class="keyword">row</span>.</span><br><span class="line">eg. <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> id=<span class="number">1</span> <span class="keyword">lock</span> <span class="keyword">in</span> <span class="keyword">share mode</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">Exclusive</span> Locks: 排他锁</span><br><span class="line">官方: permits the <span class="keyword">transaction</span> that holds the <span class="keyword">lock</span> <span class="keyword">to</span> <span class="keyword">update</span> <span class="keyword">or</span> <span class="keyword">delete</span> a <span class="keyword">row</span></span><br><span class="line">eg. <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> id=<span class="number">1</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><em>Intention Locks</em></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">锁是加在<span class="keyword">table</span>上的、表示要对下一个层级(记录)加锁</span><br><span class="line">Intention shared(<span class="keyword">IS</span>): <span class="keyword">Transaction</span> T intends <span class="keyword">to</span> <span class="keyword">set</span> S locks <span class="keyword">on</span> individual <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">table</span> t</span><br><span class="line">Intention <span class="keyword">exclusive</span>(IX): <span class="keyword">Transaction</span> T intends <span class="keyword">to</span> <span class="keyword">set</span> X <span class="keyword">lock</span> <span class="keyword">on</span> those <span class="keyword">rows</span></span><br><span class="line">在db层看到的是：</span><br><span class="line"><span class="keyword">Table</span> <span class="keyword">Lock</span> <span class="keyword">table</span> `db`.`<span class="keyword">table</span>` trx_id <span class="number">12121212</span> <span class="keyword">lock</span> mode IX</span><br></pre></td></tr></table></figure>

<p><em>Record Locks</em></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">在db层看到的是:</span><br><span class="line"><span class="type">Record</span> Locks space id <span class="keyword">in</span> <span class="number">281</span> page <span class="keyword">no</span> <span class="number">3</span> n bits <span class="number">72</span> <span class="keyword">index</span> <span class="keyword">PRIMARY</span> <span class="keyword">of</span> <span class="keyword">table</span> `db`.`<span class="keyword">table</span>` trx id <span class="number">12121212</span> lock_mode X rec but <span class="keyword">not</span> gap</span><br><span class="line">锁是加在索引上的(从 <span class="keyword">index</span> <span class="keyword">primary</span> <span class="keyword">of</span> <span class="keyword">table</span> `db`.`<span class="keyword">table</span>` ) 可以看出</span><br><span class="line">记录锁有两种类型: </span><br><span class="line"><span class="number">1.</span> lock_mode X locks rec but <span class="keyword">not</span> gap</span><br><span class="line"><span class="number">2.</span> lock_mode S locks rect bot <span class="keyword">not</span> gap</span><br></pre></td></tr></table></figure>

<p><em>Gap Locks</em></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">在db层看到的是:</span><br><span class="line"><span class="type">Record</span> Locks space id <span class="number">281</span> pages <span class="keyword">no</span> <span class="number">5</span> n bits <span class="number">72</span> <span class="keyword">index</span> idx_c <span class="keyword">of</span> <span class="keyword">table</span> `lc_3`.`a` trx id <span class="number">133588125</span> lock_mode X locks gap <span class="keyword">before</span> rec</span><br><span class="line">gap锁是用来防止<span class="keyword">insert</span>的</span><br><span class="line">锁的不是记录、而是记录之间的间隙、eg. (<span class="number">10</span>,<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p><em>Insert intention Locks</em></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">在db层看到的是:</span><br><span class="line"><span class="type">Record</span> Locks space id <span class="number">279</span> page <span class="keyword">no</span> <span class="number">3</span> n bits <span class="number">72</span> <span class="keyword">index</span> <span class="keyword">primary</span> <span class="keyword">of</span> <span class="keyword">table</span> `lc_3`.`t1` trx id <span class="number">133587907</span> lock_mode X <span class="keyword">insert</span> intention waiting</span><br></pre></td></tr></table></figure>

<p><em>next-Key locks</em></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">在db看到的是:</span><br><span class="line"><span class="type">Record</span> Locks space id <span class="number">281</span> page <span class="keyword">no</span> <span class="number">5</span> n bits <span class="keyword">index</span> idx_c <span class="keyword">of</span> <span class="keyword">table</span> `lc_3`.`t1` trx id <span class="number">133587907</span> lock_mode X</span><br><span class="line">Next-Key Locks = Gap Locks + <span class="type">Record</span> Locks会同时锁住记录和间隙</span><br></pre></td></tr></table></figure>

<p><em>Anto-inc Locks</em></p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">在db层看到的结果是:</span><br><span class="line">Table Lock table xx trx id <span class="number">7498948</span> lock mode auto-inc waiting </span><br><span class="line">属于表级别的锁 http:<span class="regexp">//</span>keithlan.github.io<span class="regexp">/2017/</span><span class="number">03</span><span class="regexp">/03/</span>auto_increment_lock/</span><br></pre></td></tr></table></figure>

<p><em>显式锁 vs 隐式锁</em></p>
<figure class="highlight fortran"><table><tr><td class="code"><pre><span class="line">显式锁(explicit lock)</span><br><span class="line">显式加的锁, 在 show engine innoDB <span class="keyword">status</span> 中能够看到、会在内存中产生对象、占用内存</span><br><span class="line">eg. <span class="keyword">select</span> ... for update, <span class="keyword">select</span> ... lock <span class="keyword">in</span> share mode ....</span><br><span class="line"></span><br><span class="line">隐式锁(<span class="keyword">implicit</span> lock)</span><br><span class="line">是在索引中对记录逻辑的加锁、但实际上不产生锁对象、不占用内存空间</span><br><span class="line">eg. insert into xx values(xx)</span><br><span class="line">      update xx set t=t+<span class="number">1</span> <span class="keyword">where</span> id=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">implicit</span> lock -&gt; explicit lock</span><br><span class="line">eg. 只有当<span class="keyword">implicit</span> lock 产生冲突的时候、会自动转换成 explicit lock、降低锁开销</span><br><span class="line">eg. A会话插入记录<span class="number">10</span>、本身会加上 <span class="keyword">implicit</span> lock、但是如果B 会话更新<span class="number">10</span>这条记录、就会转换为 explicit lock</span><br></pre></td></tr></table></figure>

<p><em>metadata lock</em></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">是<span class="keyword">server</span>层实现的锁、与引擎无关</span><br><span class="line">执行<span class="keyword">select</span>时、若有ddl语句、会被阻塞、因为 <span class="keyword">select</span> 会加上 metadata <span class="keyword">lock</span>、防止元数据在访问过程中被修改</span><br></pre></td></tr></table></figure>

<p><em>锁迁移</em></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">锁迁移、又叫锁继承</span><br><span class="line"><span class="selector-tag">A</span>锁住的记录是一条已经被标记为删除的记录、但是还没有被puge、然后这条被标记为删除的记录、被purge掉了、上边的锁就会给了下边一条记录、称为锁迁移</span><br></pre></td></tr></table></figure>

<p><em>锁升级</em></p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">一条全表更新的语句、<span class="built_in">db</span>可能会对所有记录加锁、可能造成锁的开销很大、升级为页锁、或者表锁(mysql无锁升级)</span><br></pre></td></tr></table></figure>

<p><em>锁分裂</em></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> innodb 实现的加锁、其实是在页上边做的、没办法直接对记录加锁</span><br><span class="line"><span class="bullet">2.</span> 一个页被读取到内存、会产生锁对象、锁对象里会有位图信息记录哪些heap no被锁住、heapno 表示的就是堆的序列号、可以认为就是定位到某一条记录</span><br><span class="line"><span class="bullet">3.</span> insert的时候、可能会产生页分裂</span><br><span class="line"><span class="bullet">4.</span> 若页分裂、原来对页上边的加锁位图信息也就变了、为了保持这种变化和锁信息、锁对象也会分裂、继续维护分裂后页的锁信息</span><br></pre></td></tr></table></figure>

<p><em>锁合并</em></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">参考锁分裂</span><br></pre></td></tr></table></figure>

<p><em>latch vs lock</em></p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">latch:</span> mutex、rw-<span class="keyword">lock</span>、临界资源用完就释放、不支持死锁检测、应用程序维护 非<span class="built_in">db</span>锁</span><br><span class="line"><span class="symbol">lock:</span> 事务结束后释放、支持死锁检测、<span class="built_in">db</span>锁</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql锁简析</title>
    <url>/2020/03/20/mysql_mysql%E9%94%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<h3 id="mysql锁"><a href="#mysql锁" class="headerlink" title="mysql锁"></a>mysql锁</h3><blockquote>
<p>根据加锁的范围、MySQL里边的锁可以分为全局锁、表级锁和行锁三类</p>
</blockquote>
<h4 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h4><figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">全局锁: 就是要对整个db实例加锁. mysql提供了一个全局锁支持: </span><br><span class="line">flush tables <span class="keyword">with</span> read <span class="keyword">lock</span>;(FTWRL)</span><br><span class="line">此时: update、ddl、dml语句会被阻塞</span><br><span class="line"></span><br><span class="line">典型场景: 全库逻辑备份</span><br><span class="line"></span><br><span class="line">但是让整个db处于只读状态、比较危险:</span><br><span class="line">若是操作主库、则在整个备份期间、都不能执行更新】整个业务基本上处于停滞状态</span><br><span class="line">若操作从库、则备份期间从库不能执行主库同步过来的binlog、会导致主从延迟</span><br><span class="line"></span><br><span class="line">那么、如果实现不影响业务的备份呢 ？</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> innodb引擎可以使用一致性读</span><br><span class="line">   mysql自带备份工具mysqldump使用参数 --single-transaction 时、mysql就好启动一个事务、来确保拿到一致性视图</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> 为何不选择 <span class="keyword">set</span> <span class="keyword">global</span> <span class="keyword">readonly</span>=<span class="literal">true</span> ?</span><br><span class="line">   <span class="number">1</span>) 在某些系统中、<span class="keyword">readonly</span>可能被用来做其它逻辑、比如用来判断db是主还是备库 ？</span><br><span class="line">   <span class="number">2</span>) 在异常处理上的差异</span><br><span class="line">      若执行FTWRL之后、mysql异常断开、mysql会自动释放这个全局锁、整个库可以回到正常更新的状态</span><br><span class="line">      设置<span class="keyword">readonly</span>、若client异常、则db会一直保持<span class="keyword">readonly</span>状态、会导致整个库长时间不可写、风险较高</span><br><span class="line">   <span class="number">3</span>) MDL 在slave库上对super权限无效</span><br><span class="line">      </span><br></pre></td></tr></table></figure>

<h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">mysql的表级锁有<span class="number">2</span>种: mysql表锁 和 元数据锁(meta data <span class="keyword">lock</span>, MDL)</span><br><span class="line"></span><br><span class="line">表锁的语法是: <span class="keyword">lock</span> <span class="keyword">tables</span> .. <span class="keyword">read</span>/<span class="keyword">write</span>. 与FTWRL类似、使用unlock <span class="keyword">tables</span>主动释放锁、也可以在client断开时自动释放</span><br><span class="line">既限制别的线程、也限制本线程</span><br><span class="line">eg. 某个线程A中执行 <span class="keyword">lock</span> <span class="keyword">tables</span> t1 <span class="keyword">read</span>, t2 <span class="keyword">write</span>; </span><br><span class="line">则其它线程写t1, 读写t2 都会被阻塞、同时、线程A在执行unlock <span class="keyword">tables</span>之前、也只能执行读t1, 读写t2的操作</span><br><span class="line">但innodb可以支持行锁、一般就不使用 <span class="keyword">lock</span> <span class="keyword">tables</span>了、毕竟影响还是很大的</span><br><span class="line"></span><br><span class="line">元数据锁:</span><br><span class="line">不需要显式使用、在访问一个表的时候会被自动加上、MDL的作用是 保证读写的正确性</span><br><span class="line">eg. 正在遍历某表的数据、在执行期间另外一个线程对这个表的结构做了变更、减少了一列、查询结果就会有问题</span><br><span class="line"></span><br><span class="line">在mysql5<span class="number">.5</span>的版本中引入了MDL、当对表curd操作时、会加MDL读锁、对表结构变更时、会加MDL写锁</span><br><span class="line"></span><br><span class="line">* 读锁之间不互斥、可以同时对一张表增删改查</span><br><span class="line">* 写锁、读写锁之间互斥、用来保证表结构变更操作的安全性</span><br><span class="line">so. 两个线程同时对一个表做结构变更时、其中一个要等另外一个执行完才开始执行 </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h5><p>case: 给一个小表加字段、却导致db挂掉</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">no<span class="symbol">te:</span> 给表加字段或者修改字段或者加索引、都会导致全表扫描数据</span><br><span class="line">在对大表操作时、都会特别小心、避免对线上造成影响、小表一般认为很快结束、会比较大意、其实、小表操作不当也会造成<span class="built_in">db</span>挂掉</span><br><span class="line"></span><br><span class="line">实验环境<span class="symbol">:</span> mysql5.<span class="number">6</span> <span class="built_in">t</span>是小表</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-94717b6aa177cad2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<blockquote>
<p>可以看到: session A先启动、这时会对t加MDL读锁、session B操作不被影响<br>session C需要MDL写锁、blocked、此时db表现为 不可读写<br>若: 此时db的写十分频繁、且client有重试机制、超时后起一个新的session、这些session很快就会把连接打满</p>
</blockquote>
<p>Q: 那么如何安全的给表加字段呢 ？</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">首先要解决长事务、事务不提交、就会一直占着MDL锁. 在mysql的information_schema库的innodb_trx表中、可以看到当前</span><br><span class="line">正在执行的事务、若要做ddl变更的表刚好有长事务在执行、要考虑先暂停DDL或者kill掉事务</span><br><span class="line"></span><br><span class="line">若要变更的是热点表、请求频繁、虽然数据量不大、但请求特别频繁、而不得不加字段、如何做 ?</span><br><span class="line"></span><br><span class="line">此时kill未必管用、因为新的请求马上就进来了、此时比较理想的机制是: </span><br><span class="line">在<span class="keyword">alter</span> <span class="keyword">table</span>语句里设定等待时间、若在这个等待时间里能拿到MDL写锁最好、拿不到也不要阻塞后边的业务、先放弃</span><br><span class="line">之后再重复</span><br><span class="line"></span><br><span class="line">语法: </span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> <span class="keyword">table</span> nowait <span class="keyword">add</span> column...</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> <span class="keyword">table</span> wait n <span class="keyword">add</span> column...</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="查看锁表情况"><a href="#查看锁表情况" class="headerlink" title="查看锁表情况"></a>查看锁表情况</h4><blockquote>
<p>show status like ‘table%’;</p>
</blockquote>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">table<span class="emphasis">_locks_immediate 指能够立即获取表级锁的次数</span></span><br><span class="line"><span class="emphasis">table_locks_</span>waited 指的是不能立即获取表级锁而需要等待的次数、num越大、锁等待越多、有锁争用的情况</span><br></pre></td></tr></table></figure>

<h4 id="查看正在被锁定的表"><a href="#查看正在被锁定的表" class="headerlink" title="查看正在被锁定的表"></a>查看正在被锁定的表</h4><blockquote>
<p>show open tables where in_use&gt;0;</p>
</blockquote>
<h4 id="锁涉及表说明"><a href="#锁涉及表说明" class="headerlink" title="锁涉及表说明"></a>锁涉及表说明</h4><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">information<span class="emphasis">_shcema库</span></span><br><span class="line"><span class="emphasis">innodb_trx 当前innodb内核中的活跃事务</span></span><br><span class="line"><span class="emphasis">innodb_locks 当前状态下产生的innodb锁、仅在有锁等待时打印</span></span><br><span class="line"><span class="emphasis">innodb_lock_</span>waits 当前状态产生的innodb锁等待 仅在有锁等待时打印</span><br></pre></td></tr></table></figure>

<p><strong>innodb_trx表结构说明</strong></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">字段名                 说明</span><br><span class="line"></span><br><span class="line">trx_id innodb          存储引擎内部唯一的事物ID </span><br><span class="line">trx_state              当前事务状态（running和<span class="keyword">lock</span> wait两种状态） </span><br><span class="line">trx_started            事务的开始时间 </span><br><span class="line">trx_requested_lock_id  等待事务的锁ID，如trx_state的状态为<span class="keyword">Lock</span> wait，那么该值带表当前事物等待之前事物占用资源的ID，若trx_state不是<span class="keyword">Lock</span> wait 则该值为<span class="keyword">NULL</span> </span><br><span class="line">trx_wait_started       事务等待的开始时间 </span><br><span class="line">trx_weight             事务的权重，在innodb存储引擎中，当发生死锁需要回滚的时，innodb存储引擎会选择该值最小的进行回滚 </span><br><span class="line">trx_mysql_thread_id     mysql中的线程id, 即<span class="keyword">show</span> processlist显示的结果 </span><br><span class="line">trx_query               事务运行的<span class="keyword">SQL</span>语句 </span><br></pre></td></tr></table></figure>

<p><strong>innodb_locks表结构说明</strong></p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">字段名       说明</span><br><span class="line"></span><br><span class="line">lock_id      锁的ID </span><br><span class="line">lock_trx_id  事务的ID </span><br><span class="line">lock_mode    锁的模式（S锁与X锁两种模式） </span><br><span class="line">lock_type    锁的类型 表锁还是行锁（RECORD） </span><br><span class="line">lock_table   要加锁的表 </span><br><span class="line">lock_index   锁住的索引 </span><br><span class="line">lock_space   锁住对象的<span class="literal">space</span> id </span><br><span class="line">lock_page    事务锁定页的数量，若是表锁则该值为<span class="literal">NULL</span> </span><br><span class="line">lock_rec     事务锁定行的数量，若是表锁则该值为<span class="literal">NULL</span> </span><br><span class="line">lock_data    事务锁定记录主键值，若是表锁则该值为<span class="literal">NULL</span>（此选项不可信)</span><br></pre></td></tr></table></figure>

<p><strong>innodb_lock_waits表结构说明</strong></p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">字段名             说明 </span><br><span class="line"></span><br><span class="line">requesting_trx_id  申请锁资源的事物ID </span><br><span class="line">requested_lock_id  申请的锁的ID </span><br><span class="line"><span class="keyword">blocking_trx_id </span>   阻塞其他事物的事物ID </span><br><span class="line"><span class="keyword">blocking_lock_id </span>  阻塞其他锁的锁ID</span><br></pre></td></tr></table></figure>

<h4 id="加锁的原则"><a href="#加锁的原则" class="headerlink" title="加锁的原则"></a>加锁的原则</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 基本单位 nex-key-lock</span><br><span class="line"><span class="bullet">2.</span> 查找过程中访问到的对象才加锁</span><br><span class="line"><span class="bullet">3.</span> 索引上的等值查询、给唯一错音加锁的时候、next-key lock退化为行锁</span><br><span class="line"><span class="bullet">4.</span> 索引上的等值查询、向右遍历时且最后一个值不满足等值条件时、退化为间隙锁</span><br><span class="line"><span class="bullet">5.</span> 唯一索引上的范围查询会访问到不满足条件的第一个值为止</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql问题梳理</title>
    <url>/2020/03/20/mysql_mysql%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86/</url>
    <content><![CDATA[<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 备份一般都会在备库上执行，在用–single-<span class="keyword">transaction</span> 方法做逻辑备份的过程中</span><br><span class="line">   若主库的一个小表做了DDL、eg 添加一列</span><br><span class="line">   在从库会看到什么样的现象 ？</span><br><span class="line">   </span><br><span class="line">   Q1:<span class="keyword">SET</span> <span class="keyword">SESSION</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">REPEATABLE</span> <span class="keyword">READ</span>;</span><br><span class="line">   Q2:<span class="keyword">START</span> <span class="keyword">TRANSACTION</span>  <span class="keyword">WITH</span> CONSISTENT <span class="keyword">SNAPSHOT</span>；</span><br><span class="line">   <span class="comment">/* other tables */</span></span><br><span class="line">   Q3:<span class="keyword">SAVEPOINT</span> sp;</span><br><span class="line">   <span class="comment">/* 时刻 1 */</span></span><br><span class="line">   Q4:<span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> `t1`;</span><br><span class="line">   <span class="comment">/* 时刻 2 */</span></span><br><span class="line">   Q5:<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> `t1`;</span><br><span class="line">   <span class="comment">/* 时刻 3 */</span></span><br><span class="line">   Q6:<span class="keyword">ROLLBACK</span> <span class="keyword">TO</span> <span class="keyword">SAVEPOINT</span> sp;</span><br><span class="line">   <span class="comment">/* 时刻 4 */</span></span><br><span class="line">   <span class="comment">/* other tables */</span></span><br><span class="line"></span><br><span class="line">   Q1、确保事务隔离级别为可重复读</span><br><span class="line">   Q2、确保得到一个一致性视图</span><br><span class="line">   Q3、设置一个保存点、Q6 回滚到这个保存点</span><br><span class="line">   </span><br><span class="line">   若DDL语句在Q4之前到达、无影响、备份表结构为修改后的表结构</span><br><span class="line">   若在Q5之前到达、则<span class="keyword">insert</span>和<span class="keyword">create</span>的结构不一致、会提示 <span class="keyword">Table</span> definition has changed, </span><br><span class="line">   retry <span class="keyword">transaction</span>、mysqldump终止</span><br><span class="line">   若在时刻<span class="number">2</span>和<span class="number">3</span>之间到达、会造成主从延时 </span><br><span class="line">   若在Q6之前到达、不影响、备份结构是修改前的表结构</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> 删除表数据的比较好的方式？</span><br><span class="line">   <span class="number">1</span>) <span class="keyword">delete</span> <span class="keyword">from</span> T <span class="keyword">limit</span> <span class="number">100000</span>；</span><br><span class="line">   <span class="number">2</span>）<span class="keyword">delete</span> <span class="keyword">from</span> T <span class="keyword">limit</span> <span class="number">5000</span>；执行<span class="number">20</span>次</span><br><span class="line">   <span class="number">3</span>）分<span class="number">20</span>个线程去执行</span><br><span class="line">   <span class="number">1</span>会造成大事务、单语句占用时间长、锁的时间比较长、可能造成主从延迟</span><br><span class="line">   <span class="number">3</span>可能会人为造成锁冲突</span><br><span class="line">   <span class="number">2</span>相对比较好一些</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> 唯一索引和普通索引如何选择？</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> change buffer 一开始是写内存的、然后写磁盘</span><br><span class="line">   假如刚写入内存就断电重启、会不会导致change buffer丢失 ？</span><br><span class="line">   不会丢失、虽然只是更新内存、但在事务提交的时候、把change buffer的操作也记录在了redo <span class="keyword">log</span>里、崩溃恢复的时候可以找回</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line"><span class="number">5.</span> 扫描行数如何判断 ？</span><br><span class="line">   mysql在真正执行前并不能精确的知道满足条件的记录有多少条、只能根据统计信息来预估</span><br><span class="line">   这个统计信息就是索引的区分度、称为 索引基数(cardinality)、也就是索引基数越大、索引的区分度越好</span><br><span class="line">   <span class="keyword">show</span> <span class="keyword">index</span> <span class="keyword">from</span> tt; </span><br><span class="line">   可以看到索引信息</span><br><span class="line">   </span><br><span class="line"><span class="number">6.</span> mysql是如何得到索引基数的呢 ？</span><br><span class="line">   将整张表取出来一行行统计 - 可以得到精确值、单代价太高</span><br><span class="line">   所以采用 采样统计、当表数据持续变更的时候、变更的数据行超过 <span class="number">1</span>/M 时、自动触发索引重新统计</span><br><span class="line">   <span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;innodb_stats_persistent&#x27;</span>; 查看存储索引统计方式</span><br><span class="line">   <span class="keyword">on</span> 代表统计信息会持久化存储、默认 N=<span class="number">20</span> M=<span class="number">10</span></span><br><span class="line">   <span class="keyword">off</span> 的时候、代表统计信息只存储在内存中， 默认 N=<span class="number">8</span> M=<span class="number">16</span></span><br><span class="line">   由于是采样统计、不管N是多少、基数都很容易不准</span><br><span class="line">   索引统计值虽然不够精准、大体上还是差不多的、选错索引还有别的原因</span><br><span class="line">   </span><br><span class="line"><span class="number">7.</span> 如何修正索引？</span><br><span class="line">   <span class="number">1</span> 使用force <span class="keyword">index</span> 强制选择一个索引</span><br><span class="line">   <span class="number">2</span> 使用语句引导索引 <span class="keyword">order</span> <span class="keyword">by</span> b, a</span><br><span class="line">   <span class="number">3</span> 新建更合适的索引或者删掉无用索引</span><br><span class="line"></span><br><span class="line"><span class="number">8.</span> 何时会出现mysql抖动、平时很快执行的<span class="keyword">sql</span>在某些瞬间执行很慢？</span><br><span class="line">   <span class="number">1.</span> redo <span class="keyword">log</span> <span class="keyword">log</span>大小超过配置值时、需要刷新到磁盘、此时系统会停止所有的更新操作、应尽可能的避免</span><br><span class="line">   <span class="number">2.</span> 系统内存不足的时候、当需要新的内存页、内存不够用的时候、就淘汰一些数据页、给别的数据页使用、</span><br><span class="line">      若淘汰的是脏页、就需要将脏页写到磁盘</span><br><span class="line">      innodb使用缓冲池 buffer pool来管理内存、缓冲池中的内存页有<span class="number">3</span>种状态</span><br><span class="line">      <span class="number">1</span>）暂未使用的  <span class="number">2</span>）使用了、并且是干净页(内存数据页和磁盘数据页内容一致) <span class="number">3</span>）使用了、并且是脏页</span><br><span class="line">      innodb的策略是尽量使用内存、对一个长时间运行的库来说、未被使用的页面很少</span><br><span class="line">      当要读入的数据页没有在内存的时候、要到缓冲池申请一个数据页、只能把最久不使用的数据页从内存淘汰</span><br><span class="line">      若淘汰掉的是一个干净页、就直接释放出来复用、若淘汰的是脏页、就先刷新到磁盘</span><br><span class="line">      </span><br><span class="line">      所以：</span><br><span class="line">      <span class="number">1.</span> 一个查询要淘汰的脏页个数过多的时候、会导致查询时间明显变长</span><br><span class="line">      <span class="number">2.</span> 日志写满会将更新全部堵塞、写性能跌为<span class="number">0</span>、应尽可能的避免</span><br><span class="line">      </span><br><span class="line">      那么innodb是如何控制刷脏页的策略的呢 ？</span><br><span class="line">      一个是系统io能力、可以使用  fio -filename=$filename -direct=<span class="number">1</span> -iodepth <span class="number">1</span> -thread -rw=randrw -ioengine=psync -bs=<span class="number">16</span>k -size=<span class="number">500</span>M -numjobs=<span class="number">10</span> -runtime=<span class="number">10</span> -group_reporting -<span class="type">name</span>=mytest 来测试</span><br><span class="line">      一个是脏页比例上限：<span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;innodb_max_dirty_pages_pct&#x27;</span>; 默认<span class="number">75</span>%</span><br><span class="line">      </span><br><span class="line">      另外：mysql在刷脏页的时候、若 innodb_flush_neighbors = <span class="number">1</span> 恰好连着的页也是脏页</span><br><span class="line">      会被一起刷掉、若 情况不妙、连着的连着页也是脏页。。。。会导致你的查询更慢</span><br><span class="line">      这个策略在机械硬盘时代是有意义的、可以减少io、但SSD设备的话、可以设置为<span class="number">0</span> 减少<span class="keyword">sql</span>执行时间</span><br><span class="line">      <span class="number">8.0</span> 已默认为<span class="number">0</span></span><br><span class="line">      </span><br><span class="line">   <span class="number">3.</span> mysql认为系统空闲的时候、</span><br><span class="line">   <span class="number">4.</span> mysql正常关闭的时候</span><br><span class="line"></span><br><span class="line"><span class="number">9.</span> 为什么数据删除、表空间确没有释放</span><br><span class="line">   数据删除流程：假如删除 <span class="number">2</span>、<span class="number">10</span>之间的<span class="number">6</span>记录、它只被标记删除、并不会之间删除</span><br><span class="line">   之后需要<span class="keyword">insert</span> <span class="number">1</span>~<span class="number">10</span>之间的数据时、会复用这个位置</span><br><span class="line">   若删掉了一个数据页上的所有记录、整个数据页可以被直接复用</span><br><span class="line">   记录的复用 只限于符合范围条件的数据、</span><br><span class="line">   页的复用、可以用于任何数据</span><br><span class="line">   若相邻页利用率都很小、系统会把这两个页合并到其中一个数据页、另外一个标记为可复用</span><br><span class="line">   这些可以被复用、而未被复用的空间、称为空洞</span><br><span class="line">   </span><br><span class="line">   不止<span class="keyword">delete</span>会造成空洞、<span class="keyword">insert</span>也会、随机插入会造成索引的数据页分裂</span><br><span class="line">   所以、大量增删改的表是可能存在空洞的、若能去掉空洞、就可以达到收缩表空间的目的</span><br><span class="line">   <span class="number">1.</span> 重建表 可以新建一个与表A结构相同的表B、按照主键ID递增的顺序、把数据行一行一行的从表A读出、再插入到B</span><br><span class="line">      若将B作为临时表、数据从A导入B的操作完成后、用B替换A、就起到了收缩表A空间的作用</span><br><span class="line">      可以使用 <span class="keyword">alter</span> <span class="keyword">table</span> A engine=innodb 来重建、</span><br><span class="line">      执行流程类似、只是不需要自己创建临时表(是在<span class="keyword">server</span>完成的、需要数据导入)、mysql自己完成转存数据、交换表名、删除旧表</span><br><span class="line">      </span><br><span class="line">      显然整个过程最耗时的是、插入数据、在整个DDL过程、A表不能有更新、非online</span><br><span class="line">      </span><br><span class="line">      mysql <span class="number">5.6</span> 版本引入 online ddl</span><br><span class="line">      流程：新建临时表、扫描A主键的所有数据页、</span><br><span class="line">           使用数据页中的A的记录生成B+树、存储到临时文件(存储引擎创建、整个DDL过程在innodb内部完成、无需数据挪到临时表、是原地操作)</span><br><span class="line">           生成临时文件的过程中、将所有对A的操作记录在一个日志文件中、<span class="keyword">row</span> <span class="keyword">log</span>、</span><br><span class="line">           临时文件生成后、将日志文件中的操作应用到临时文件、得到一个逻辑数据上与表A相同的数据文件、</span><br><span class="line">           用临时文件替换表A的数据文件</span><br><span class="line">      </span><br><span class="line">      iplace和online是同一概念 ？？</span><br><span class="line">      <span class="keyword">no</span>、只是ddl过程若是 online 的、一定是 inplace 的</span><br><span class="line">      若、inplace的DDL、可能不是online的、</span><br><span class="line">      eg 给一个innodb的表字段加fulltext索引、整个过程是inplace的、会阻塞 增删改查操作、不是online的</span><br><span class="line">      </span><br><span class="line">            </span><br><span class="line"><span class="number">10.</span> <span class="keyword">alter</span> <span class="keyword">table</span> t engine=innodb 其实是 recreate 重建表的过程、非online</span><br><span class="line">    <span class="keyword">analyze</span> <span class="keyword">table</span> t 不是重建表、不修改数据、只是对表的索引信息进行重新统计、会加MDL 读锁</span><br><span class="line">    optimize <span class="keyword">table</span> t =&gt; recreate + <span class="keyword">analyze</span></span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line"><span class="number">11.</span> 若一个高配的机器、redo <span class="keyword">log</span>设置的太小、会发生什么 ？</span><br><span class="line">    每次事务提交都有些redo <span class="keyword">log</span>、若设置太小、会被很快写满、系统不得不停止所有更新、去刷新redo <span class="keyword">log</span></span><br><span class="line">    同时、change buffer的优化作用也会失效、因为<span class="keyword">checkpoint</span>一直往前推进、会触发merge操作、然后又进一步的触发脏页刷新</span><br><span class="line">    看到的现象会是 磁盘压力小、但是数据库出现间歇性的性能下降</span><br><span class="line">    </span><br><span class="line"><span class="number">12.</span> count(*) 是怎么工作的 ？</span><br><span class="line">    mysiam将数据总行记录在了磁盘上、所以查询 count(*) 会直接返回</span><br><span class="line">    innodb 因为考虑事务的原因、不能这么记录、是从记录一条条遍历出来的、但是会遍历最小的那颗树</span><br><span class="line">    </span><br><span class="line">    so：</span><br><span class="line">    mysiam count(*) 快、但是不支持事务、</span><br><span class="line">    <span class="keyword">show</span> <span class="keyword">table</span> status 返回快、但不准确</span><br><span class="line">    count(*) 会遍历全表、导致性能问题</span><br><span class="line">    </span><br><span class="line">    那么如何自己实现计数？</span><br><span class="line">    <span class="number">1</span>）使用缓存系统 - 数据易丢失、统计不精准(先写redis、记录未插入、则多<span class="number">1</span>、先写db redis未写入 则少<span class="number">1</span>)</span><br><span class="line">    <span class="number">2</span>）使用统计表 使用事务保存</span><br><span class="line">    </span><br><span class="line">    count(*)、count(id)、count(<span class="number">1</span>) 都标识返回满足条件的结果集的总行数</span><br><span class="line">    count(field)表示 filed不为<span class="keyword">null</span>的总个数</span><br><span class="line">    </span><br><span class="line">    count(id) innodb会遍历整张表、取出每行的id值、返回给<span class="keyword">server</span>层、<span class="keyword">server</span>拿到id后、判断不为空、累计行</span><br><span class="line">    count(<span class="number">1</span>) inndb会遍历整张表、但不取值、<span class="keyword">server</span>对于返回的每一行、放数字<span class="number">1</span>进去、判断不为空、按行累加</span><br><span class="line">    所以、count(<span class="number">1</span>)比count(id)快、因为从引擎返回id会涉及到数据行解析、及<span class="keyword">copy</span>字段值得操作</span><br><span class="line">    </span><br><span class="line">    count(field) <span class="keyword">not</span> <span class="keyword">null</span>字段、独处记录、判断不能为<span class="keyword">null</span>、按行累加</span><br><span class="line">    允许为<span class="keyword">null</span>的字段、执行的时候判断到有可能为<span class="keyword">null</span>、会先取出值、判断、不为<span class="keyword">null</span>才累加</span><br><span class="line">    </span><br><span class="line">    count(*) 不会取出全部字段、专门做了优化、不取值</span><br><span class="line">    所以 效率： count(field) &lt; count(主键) &lt; count(<span class="number">1</span>) ~ count(*)    </span><br><span class="line">    </span><br><span class="line"><span class="number">13.</span> mysql 怎么知道binlog是完整的 ？</span><br><span class="line">    一个事务的binlog是有完整格式的、<span class="keyword">statement</span>格式的binlog最后会有<span class="keyword">commit</span></span><br><span class="line">    raw格式的binlog、最后会有一个 xid</span><br><span class="line">    <span class="number">5.6</span>之后的版本、还引入了 binlog-checksum 来保证内容的正确性</span><br><span class="line">    </span><br><span class="line"><span class="number">14.</span> redo <span class="keyword">log</span> 和 binlog 如何关联：</span><br><span class="line">    有一个共同的数据段、xid、崩溃修复的时候会按顺序扫描 redo <span class="keyword">log</span></span><br><span class="line">    若既有<span class="keyword">prepare</span>又有<span class="keyword">commit</span>、则直接提交</span><br><span class="line">    若只有<span class="keyword">prepare</span> 则拿 xid去找binlog 对应的事务</span><br><span class="line">    </span><br><span class="line">    处于<span class="keyword">prepare</span>阶段的redo <span class="keyword">log</span> + 完整binlog 重启就能恢复、why ？</span><br><span class="line">    binlog写完之后、mysql崩溃、此时binlog已经写入、就会被从库使用</span><br><span class="line">    所以在主库上也要提交这个事务、保证主从数据的一致性</span><br><span class="line">    </span><br><span class="line">    为何不是先写 redo <span class="keyword">log</span>再写binlog、然后直接两个<span class="keyword">log</span>完整时才恢复数据 ？</span><br><span class="line">    对于innodb来说、redo <span class="keyword">log</span>提交完成、事务就不能回滚(会覆盖到别的事务的更新)、</span><br><span class="line">    而如果redo <span class="keyword">log</span> 直接提交、然后binlog失败的时候、inndo回滚不了、数据和binlog就又不一致了</span><br><span class="line">    两阶段提交就是为了给所有人一个机会、啊哈~</span><br><span class="line">    </span><br><span class="line"><span class="number">15.</span> 对于正常运行的实例、数据写入后的最终落盘、是从redo <span class="keyword">log</span>更新的还是buffer pool ？</span><br><span class="line">    redo <span class="keyword">log</span> 并未记录数据页的完整数据、所以、没有能力自己去更新磁盘数据页、不存在redo <span class="keyword">log</span>更新进去的情况</span><br><span class="line">    a.若数据页被修改之后、跟磁盘的数据页不一致、称为脏页、最终数据落盘就是把内存中的数据页写盘</span><br><span class="line">    b.若在崩溃恢复的场景中、innodb判断到一个数据页可能在崩溃中丢失了更新、就将其读到内存、</span><br><span class="line">    然后让redo <span class="keyword">log</span>更新内存内容、回到 a 的情况</span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line">   fio -filename=$filename -direct=<span class="number">1</span> -iodepth <span class="number">1</span> -thread -rw=randrw -ioengine=psync -bs=<span class="number">16</span>k -size=<span class="number">500</span>M -numjobs=<span class="number">10</span> -runtime=<span class="number">10</span> -group_reporting -<span class="type">name</span>=mytest </span><br><span class="line"> </span><br><span class="line"><span class="number">16.</span> <span class="keyword">order</span> <span class="keyword">by</span> 是如何工作的 ？</span><br><span class="line">    <span class="keyword">explain</span> 中的 <span class="keyword">using</span> filesort 代表需要排序</span><br><span class="line">    mysql 会给每个线程分配一块内存用于排序、称为 sort_buffer</span><br><span class="line">    </span><br><span class="line">    <span class="number">1</span>) 初始化sort_buffer 确定放入 <span class="type">name</span> city age 三个字段、</span><br><span class="line">    <span class="number">2</span>) 从索引 city 找到 第一个满足 city=xx 条件的主键id</span><br><span class="line">    <span class="number">3</span>) 从主键id索引取出整行、取<span class="type">name</span> city age 三个字段的值、写入 sort_buffer 中</span><br><span class="line">    <span class="number">4</span>) 从索引city取下一条满足条件的记录id</span><br><span class="line">    <span class="number">5</span>) 重复<span class="number">3</span>、<span class="number">4</span> 直到无满足条件的记录</span><br><span class="line">    <span class="number">6</span>) 对sort buffer中的数据按照<span class="type">name</span>进行快排</span><br><span class="line">    <span class="number">7</span>) 取结果集前<span class="number">1000</span>行返回给client</span><br><span class="line">    </span><br><span class="line">    若单行数据超过 max_length_for_sort_data 的值、则会先排序、再回表取数据</span><br><span class="line">    <span class="number">1</span>) 初始化sort_buffer 确定放入 <span class="type">name</span> city age 三个字段、</span><br><span class="line">    <span class="number">2</span>) 从索引 city 找到 第一个满足 city=xx 条件的主键id</span><br><span class="line">    <span class="number">3</span>) 从主键id索引取出整行、取<span class="type">name</span> &amp; id 两个个字段的值、写入 sort_buffer 中</span><br><span class="line">    <span class="number">4</span>) 从索引city取下一条满足条件的记录id</span><br><span class="line">    <span class="number">5</span>) 重复<span class="number">3</span>、<span class="number">4</span> 直到无满足条件的记录</span><br><span class="line">    <span class="number">6</span>) 对sort buffer中的数据按照<span class="type">name</span>进行快排</span><br><span class="line">    <span class="number">7</span>) 取结果集前<span class="number">1000</span>行、回原表扫描city、<span class="type">name</span>和age三个字段值 返回给client  </span><br><span class="line">    </span><br><span class="line">    此时假如 <span class="type">name</span>本身有索引、天然有序、则不需要额外排序、会变成</span><br><span class="line">    <span class="number">1</span>) 从索引 city <span class="type">name</span> 找到满足 city=杭州的 条件的主键</span><br><span class="line">    <span class="number">2</span>) 回主键id索引查出正行、取<span class="type">name</span>、city、age的值 作为结果集的一部分直接返回</span><br><span class="line">    <span class="number">3</span>) 从索引 <span class="type">name</span> city取出下一个满足记录的主键id</span><br><span class="line">    <span class="number">4</span>) 重复<span class="number">2</span>、<span class="number">3</span>、直到足够<span class="number">1000</span>条记录、或者无满足条件的记录</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    使用 optimizer_trace 进行<span class="keyword">sql</span>追踪、一般情况下、一个新的跟踪会覆盖掉以前的跟踪</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 打开 optimizer_trace，只对本线程有效 */</span></span><br><span class="line">    <span class="keyword">SET</span> optimizer_trace=<span class="string">&#x27;enabled=on&#x27;</span>; </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* @a 保存 Innodb_rows_read 的初始值 */</span></span><br><span class="line">    <span class="keyword">select</span> VARIABLE_VALUE <span class="keyword">into</span> @a <span class="keyword">from</span>  performance_schema.session_status <span class="keyword">where</span> variable_name = <span class="string">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 执行语句 */</span></span><br><span class="line">    <span class="keyword">select</span> city, <span class="type">name</span>,age <span class="keyword">from</span> t <span class="keyword">where</span> city=<span class="string">&#x27;杭州&#x27;</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="type">name</span> <span class="keyword">limit</span> <span class="number">1000</span>; </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 查看 OPTIMIZER_TRACE 输出 */</span></span><br><span class="line">    <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> `information_schema`.`OPTIMIZER_TRACE`\G</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* @b 保存 Innodb_rows_read 的当前值 */</span></span><br><span class="line">    <span class="keyword">select</span> VARIABLE_VALUE <span class="keyword">into</span> @b <span class="keyword">from</span> performance_schema.session_status <span class="keyword">where</span> variable_name = <span class="string">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 计算 Innodb_rows_read 差值 */</span></span><br><span class="line">    <span class="keyword">select</span> @b-@a;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">   <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `tt` (</span><br><span class="line">     `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">     `a` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">     `b` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">     <span class="keyword">PRIMARY KEY</span> (`id`),</span><br><span class="line">     KEY `a` (`a`),</span><br><span class="line">     KEY `b` (`b`)</span><br><span class="line">   ) ENGINE=InnoDB；</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">delimiter</span> ;;</span><br><span class="line">   <span class="keyword">create</span> <span class="keyword">procedure</span> idata()</span><br><span class="line">   <span class="keyword">begin</span></span><br><span class="line">     <span class="keyword">declare</span> i <span class="type">int</span>;</span><br><span class="line">     <span class="keyword">set</span> i=<span class="number">1</span>;</span><br><span class="line">     <span class="keyword">while</span>(i&lt;=<span class="number">100000</span>)<span class="keyword">do</span></span><br><span class="line">       <span class="keyword">insert</span> <span class="keyword">into</span> tt <span class="keyword">values</span>(i, i, i);</span><br><span class="line">       <span class="keyword">set</span> i=i+<span class="number">1</span>;</span><br><span class="line">     <span class="keyword">end</span> <span class="keyword">while</span>;</span><br><span class="line">   <span class="keyword">end</span>;;</span><br><span class="line">   <span class="keyword">delimiter</span>;</span><br><span class="line">   <span class="keyword">call</span> idata();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> a <span class="keyword">between</span> <span class="number">10000</span> <span class="keyword">and</span> <span class="number">20000</span>;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">set</span> long_query_time=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> a <span class="keyword">between</span> <span class="number">10000</span> <span class="keyword">and</span> <span class="number">20000</span>; <span class="comment">/*Q1*/</span></span><br><span class="line">    <span class="keyword">select</span> * <span class="keyword">from</span> t force <span class="keyword">index</span>(a) <span class="keyword">where</span> a <span class="keyword">between</span> <span class="number">10000</span> <span class="keyword">and</span> <span class="number">20000</span>;<span class="comment">/*Q2*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> IFNULL(driver_id, <span class="number">0</span>) driverId, count(*) serviceCnt, MAX(booking_start_time) lastBookingDate <span class="keyword">FROM</span> car_order_finished_collect_2018 <span class="keyword">WHERE</span> driver_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>  <span class="keyword">AND</span> order_status &gt; <span class="number">43</span> <span class="keyword">AND</span> order_status &lt; <span class="number">60</span> <span class="keyword">AND</span> booking_user_id = <span class="number">1148735</span> <span class="keyword">AND</span> driver_id <span class="keyword">in</span> (<span class="number">25311</span>)  <span class="keyword">GROUP</span> <span class="keyword">BY</span> driver_id <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT(*) <span class="keyword">DESC</span>, MAX(booking_start_time) <span class="keyword">DESC</span>\G;</span><br><span class="line"><span class="keyword">SELECT</span> IFNULL(driver_id, <span class="number">0</span>) driverId, count(*) serviceCnt, MAX(booking_start_time) lastBookingDate <span class="keyword">FROM</span> car_order_finished_collect_2018 <span class="keyword">WHERE</span> driver_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>  <span class="keyword">AND</span> order_status &gt; <span class="number">43</span> <span class="keyword">AND</span> order_status &lt; <span class="number">60</span> <span class="keyword">AND</span> booking_user_id = <span class="number">80004692</span> <span class="keyword">AND</span> driver_id <span class="keyword">in</span> (<span class="number">10101406</span>)  <span class="keyword">GROUP</span> <span class="keyword">BY</span> driver_id <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT(*) <span class="keyword">DESC</span>, MAX(booking_start_time) <span class="keyword">DESC</span>\G;</span><br><span class="line">                                     </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>order-by是怎么工作的</title>
    <url>/2020/03/20/mysql_order-by%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/</url>
    <content><![CDATA[<h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><figure class="highlight delphi"><table><tr><td class="code"><pre><span class="line">假设有一张市民表、需要查询 城市是 杭州 的所有人的名字、以<span class="keyword">name</span>排序、返回前<span class="number">1000</span>个</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `city` <span class="type">varchar</span>(<span class="number">16</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `name` <span class="type">varchar</span>(<span class="number">16</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `age` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `addr` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  KEY `city` (`city`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line">#查询<span class="keyword">sql</span></span><br><span class="line"><span class="keyword">select</span> city,name,age <span class="keyword">from</span> t <span class="keyword">where</span> city<span class="operator">=</span><span class="string">&#x27;杭州&#x27;</span> <span class="keyword">order</span> <span class="keyword">by</span> name limit <span class="number">1000</span>  ;</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/14027542-c6445f922b6b14ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="全字段排序.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-ad05011df1ab8624.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> filesort 表示需要排序、mysql会给每个线程分配一块内存用于排序、sort_buffer</span><br><span class="line"></span><br><span class="line"><span class="keyword">sql</span>执行流程:</span><br><span class="line"><span class="number">1.</span> 初始化sort_buffer、确定放入<span class="type">name</span>、city、age字段</span><br><span class="line"><span class="number">2.</span> 从索引city找到第一个满足 city=<span class="string">&#x27;杭州&#x27;</span> 条件的主键id、也就是图中的ID_X</span><br><span class="line"><span class="number">3.</span> 到主键ID索引取出整行、取<span class="type">name</span>、city、age的值 放入sort_buffer、</span><br><span class="line"><span class="number">4.</span> 从索引city找到下一个满足条件的记录、</span><br><span class="line"><span class="number">5.</span> 重复<span class="number">3</span>、<span class="number">4</span>直到无满足条件的记录、对应的主单id就是图中的ID_Y</span><br><span class="line"><span class="number">6.</span> 对sort_buffer中的数据、按<span class="type">name</span>做快排</span><br><span class="line"><span class="number">7.</span> 按排序结果取前<span class="number">1000</span>行给client</span><br><span class="line"></span><br><span class="line">按<span class="type">name</span>排序可以在内存完成、或者靠外部排序，取决于排序所需内存和sort_buffer_size</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 打开 optimizer_trace，只对本线程有效 */</span></span><br><span class="line"><span class="keyword">SET</span> optimizer_trace<span class="operator">=</span><span class="string">&#x27;enabled=on&#x27;</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">/* @a 保存 Innodb_rows_read 的初始值 */</span></span><br><span class="line"><span class="keyword">select</span> VARIABLE_VALUE <span class="keyword">into</span> <span class="variable">@a</span> <span class="keyword">from</span>  performance_schema.session_status <span class="keyword">where</span> variable_name <span class="operator">=</span> <span class="string">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 执行语句 */</span></span><br><span class="line"><span class="keyword">select</span> city, name,age <span class="keyword">from</span> t <span class="keyword">where</span> city<span class="operator">=</span><span class="string">&#x27;杭州&#x27;</span> <span class="keyword">order</span> <span class="keyword">by</span> name limit <span class="number">1000</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">/* 查看 OPTIMIZER_TRACE 输出 */</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `information_schema`.`OPTIMIZER_TRACE`\G</span><br><span class="line"></span><br><span class="line"><span class="comment">/* @b 保存 Innodb_rows_read 的当前值 */</span></span><br><span class="line"><span class="keyword">select</span> VARIABLE_VALUE <span class="keyword">into</span> <span class="variable">@b</span> <span class="keyword">from</span> performance_schema.session_status <span class="keyword">where</span> variable_name <span class="operator">=</span> <span class="string">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 计算 Innodb_rows_read 差值 */</span></span><br><span class="line"><span class="keyword">select</span> <span class="variable">@b</span><span class="operator">-</span><span class="variable">@a</span>;</span><br><span class="line"></span><br><span class="line">其中number_of_files 表示的是使用的临时文件的个数、需要外部临时文件排序时、mysql会分散到多个文件中进行排序、然后进行归并排序、</span><br><span class="line">examined_rows 表示参与排序的行数</span><br></pre></td></tr></table></figure>

<h4 id="rowid排序"><a href="#rowid排序" class="headerlink" title="rowid排序"></a>rowid排序</h4><figure class="highlight xquery"><table><tr><td class="code"><pre><span class="line">单行数据较大时(超过 max_length_for_sort_data)、sort_buffer中存放的字段过多、内存能同时放下的行较少、需要很多临时文件、排序性能会特别差、innodb会采用另外一种排序、只在sort_buffer放入排序字段<span class="built_in">和id</span>、然后流程变为:</span><br><span class="line"><span class="number">1</span>. 初始化sort_buffer、放<span class="built_in">入name</span><span class="built_in">和id</span></span><br><span class="line"><span class="number">2</span>. 从索引city找到第一个满足 city=<span class="string">&#x27;杭州&#x27;</span> 条件的主<span class="built_in">键id</span>、也就是图中的ID_X</span><br><span class="line"><span class="number">3</span>. 回到主键索引取出整行、<span class="built_in">取id</span><span class="built_in">、name</span>这两个字段、放入sort_buffer</span><br><span class="line"><span class="number">4</span>. 从索引city取下一条满足条件的记录、</span><br><span class="line"><span class="number">5</span>. 重复<span class="number">3</span>、<span class="number">4</span>直到无满足条件的记录</span><br><span class="line"><span class="number">6</span>. 对sort_buffer中的记录按<span class="built_in">照name</span>排序、取前<span class="number">1000</span>行</span><br><span class="line"><span class="number">7</span>. <span class="built_in">回id</span>索引取出所有满足条件的记录<span class="built_in">的name</span>、age、city返回client</span><br><span class="line"></span><br><span class="line">SET max_length_for_sort_data = <span class="number">16</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><figure class="highlight"><table><tr><td class="code"><pre><span class="line">对于innodb表、会优先选择内存排序、内存不足时、会优先选择全字段排序</span><br></pre></td></tr></table></figure>

<p>那么对于内存表呢 ？</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">回表只是简单的根据行的位置得到数据、所以排序行会越小越好、优先选择rowid排序</span><br></pre></td></tr></table></figure>

<p><code>tmp_table_size</code> 内存临时表的大小、默认16M</p>
<p>Q: 假设表中已有city name的联合索引、sql如下: </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> city <span class="keyword">in</span> (<span class="string">&#x27;杭州&#x27;</span>,&quot; 苏州 &quot;) <span class="keyword">order</span> <span class="keyword">by</span> name limit <span class="number">100</span>;</span><br></pre></td></tr></table></figure>
<p>这个sql执行需要排序吗<br>A: </p>
<figure class="highlight delphi"><table><tr><td class="code"><pre><span class="line">对于不同city、<span class="keyword">name</span>不是有序的、需要排序</span><br><span class="line">可以将结果拿到业务层去排  </span><br></pre></td></tr></table></figure>

<p><strong>总结</strong></p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">tmp_table_size 会影响是否使用内存临时表(否则使用磁盘临时表)</span><br><span class="line">sort_buffer_size 使用使用内存完成排序(否则需要文件排序)</span><br><span class="line">max_length_for_sort_data 会影响排序策略(全字段/rowid)</span><br><span class="line">内存排序时、&gt;<span class="number">5.6</span>版本会使用优先队列排序</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么mysql会偶尔抖动一下</title>
    <url>/2020/03/20/mysql_%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E5%81%B6%E5%B0%94%E6%8A%96%E5%8A%A8%E4%B8%80%E4%B8%8B/</url>
    <content><![CDATA[<h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><blockquote>
<p>脏页: 内存页跟磁盘数据页内容不一致的时候、称这个内存页为 脏页<br>干净页: 内存数据写入磁盘后、内存和磁盘上的数据页的内容一致、称为 干净页</p>
</blockquote>
<p><strong>干净页和脏页都在内存</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">不难想象、平时操作很快的<span class="keyword">sql</span>、其实就是在写内存和日志、而mysql抖动的那一瞬间、可能就是在刷脏页</span><br></pre></td></tr></table></figure>

<h4 id="什么场景下会引发数据库的flush过程呢-？"><a href="#什么场景下会引发数据库的flush过程呢-？" class="headerlink" title="什么场景下会引发数据库的flush过程呢 ？"></a>什么场景下会引发数据库的flush过程呢 ？</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> innodb的redo <span class="keyword">log</span>满了: 此时系统会停止所有更新、把<span class="keyword">checkpoint</span>推进、redo <span class="keyword">log</span>留出空间</span><br><span class="line">   此时需要把原<span class="keyword">write</span> pos和<span class="keyword">checkpoint</span>之间的所有脏页都flush到磁盘上</span><br><span class="line"><span class="number">2.</span> 系统内存不足: 当需要新的内存页、而内存不够用的时候、就需要淘汰一些数据页、空出内存给别的数据页使用</span><br><span class="line">   若淘汰的是脏页、则需要先将内容flush到磁盘</span><br><span class="line">   为什么不直接淘汰内存页 ？ </span><br><span class="line">   若刷脏页、一定会写磁盘、就保证了每个数据页有两种状态</span><br><span class="line">   <span class="number">1</span>) 在内存里存在、内存肯定是正确的结果、直接返回</span><br><span class="line">   <span class="number">2</span>) 在内存里无数据、在磁盘数据文件上肯定是正确的结果、直接读入内存后返回、这样的效率最高 </span><br><span class="line"><span class="number">3.</span> mysql系统空闲的时候</span><br><span class="line"><span class="number">4.</span> mysql正常关闭的时候、mysql会把内存的脏页全部flush到磁盘、下次启动的时候、直接从磁盘读取、启动很快</span><br><span class="line"></span><br><span class="line">其中：<span class="number">1</span>、<span class="number">2</span>会影响性能</span><br><span class="line">   <span class="number">1.</span> 会停止所有更新、性能会跌为<span class="number">0</span>、应该尽可能的避免</span><br><span class="line">   <span class="number">2.</span> 是内存不够用、需要将脏页写到磁盘、其实是常态、innodb使用buffer pool来管理内存、缓存池中的内存页有<span class="number">3</span>种状态</span><br><span class="line">      <span class="number">1</span>) 暂未使用的 <span class="number">2</span>) 已用&amp;干净页 <span class="number">3</span>)已用&amp;脏页</span><br><span class="line">   innodb的策略是尽量使用内存、对一个长时间运行的db来说、未被使用的页面很少</span><br><span class="line">   当需要读入的数据页不在内存的时候、就必须到缓存池申请一个数据页、只能把最久不使用的数据页从内存淘汰</span><br><span class="line">   若淘汰的是干净页、直接释放出来复用、若淘汰的是脏页、需要先flush到磁盘</span><br><span class="line">   </span><br></pre></td></tr></table></figure>

<h4 id="innodb刷脏页的控制策略"><a href="#innodb刷脏页的控制策略" class="headerlink" title="innodb刷脏页的控制策略"></a>innodb刷脏页的控制策略</h4><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">innodb_io_capacity 告诉innodb所在主机的io能力、innodb才知道全力刷脏页时、可以刷多块、</span><br><span class="line">    建议设置为磁盘的iops、测试:  fio <span class="attribute">-filename</span>=<span class="variable">$filename</span> <span class="attribute">-direct</span>=1 -iodepth 1 -thread <span class="attribute">-rw</span>=randrw <span class="attribute">-ioengine</span>=psync <span class="attribute">-bs</span>=16k <span class="attribute">-size</span>=500M <span class="attribute">-numjobs</span>=10 <span class="attribute">-runtime</span>=10 -group_reporting <span class="attribute">-name</span>=mytest </span><br><span class="line"></span><br><span class="line">innodb并不是一直全力脏页、毕竟还要服务用户请求、那么是如何控制的呢 ？</span><br><span class="line">1. 脏页比例(innodb_max_dirty_pages_pct)  2.redo log写盘速度</span><br><span class="line">要合理设置io能力、关注脏页比例、当前脏页比例是通过 <span class="built_in">..</span>_dirty/<span class="built_in">..</span>_total 计算的</span><br><span class="line">innodb_buffer_pool_pages_dirty 当前脏页数量</span><br><span class="line">innodb_buffer_pool_pages_total 总的页数量</span><br><span class="line"> </span><br><span class="line">innodb刷页策略: innodb_flush_neighbors 为1: 代表若刷脏页时、临近页也是脏页、则一并刷到磁盘</span><br><span class="line">为0、则只刷本页、</span><br><span class="line">1的策略在机械硬盘时期比较有用、可以减少很多随机io、现在iops都不是问题、设置0即可、减少sql响应时间</span><br><span class="line">mysql8.0 默认为0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Q: 访问某条记录时、mysql是如何知道记录是否在内存中 ？<br>A: </p>
<blockquote>
<p>每个数据页都是有编号的、到内存中查看对应页的编号、若不在内存、去磁盘查找即可</p>
</blockquote>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么临时表可以重名</title>
    <url>/2020/03/25/mysql_%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%B4%E6%97%B6%E8%A1%A8%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%90%8D/</url>
    <content><![CDATA[<blockquote>
<p>内存表: 指的是使用Memory引擎的表、创建语法是: create table … engine&#x3D;memory. 这种表的数据都保存在内存里、系统重启的时候会被清空, 但表结构还在. 而、临时表是可以使用各种引擎类型. 若使用的是innodb引擎或者mysiam引擎、写数据的时候是写到磁盘的、当前, 临时表也可以使用memory引擎.</p>
</blockquote>
<h4 id="临时表的特性"><a href="#临时表的特性" class="headerlink" title="临时表的特性"></a>临时表的特性</h4><ol>
<li><p>创建语法是: create temporary table…</p>
</li>
<li><p>一个临时表只能被创建它的session访问、对其它线程不可见. (A线程创建的临时表t、B线程不可见). 在session结束时自动删除.</p>
</li>
<li><p>临时表可以与普通表同名</p>
</li>
<li><p>session A内具有同名的临时表和普通表时、show create 语句、及增删改查语句、访问的是临时表</p>
</li>
<li><p>show tables. 不显示临时表.</p>
</li>
</ol>
<h4 id="临时表的应用"><a href="#临时表的应用" class="headerlink" title="临时表的应用"></a>临时表的应用</h4><h5 id="分库分表的跨库查询"><a href="#分库分表的跨库查询" class="headerlink" title="分库分表的跨库查询."></a>分库分表的跨库查询.</h5><p>  一般分库分表的场景、就是要把一个逻辑上的大表分散到不同的数据库实例上. eg. 将大表ht、按照字段f、拆分成1024个分表、然后分布到32个DB实例</p>
<p>  一般有两种查询场景. 1) 可直接定位分表. 2) 无法定位分表、需要多表数据重组.</p>
<p>  此时一般有两种思路解决:</p>
<ol>
<li>在proxy层进行代码排序</li>
</ol>
<p>   优势: 处理速度快、拿到分库的数据后、直接在内存中参与计算. 但: </p>
<p>   开发工作量大, eg. group by, join 等的操作、对中间层开发要求高.</p>
<p>   对proxy的压力较大、容易出现内存不够用和CPU瓶颈问题.</p>
<ol start="2">
<li>将各表拿到的数据、汇总到一个MySQL实例的一个表、然后在汇总实例上进行逻辑操作.</li>
</ol>
<h5 id="join优化的场景"><a href="#join优化的场景" class="headerlink" title="join优化的场景"></a>join优化的场景</h5><ol>
<li><p>不同session临时表命名是可以重复的、若有多个session同时执行join优化、无需担心表名重复建表失败.</p>
</li>
<li><p>无需担心数据删除问题. 若使用临时表、在执行流程过程中Client异常断开、或者DB异常重启、还需要专门清理中间过程生成的数据表、而临时表会自动回收、不需要这个额外的操作.</p>
</li>
</ol>
<h4 id="为什么临时表可以重名"><a href="#为什么临时表可以重名" class="headerlink" title="为什么临时表可以重名 ?"></a>为什么临时表可以重名 ?</h4><p>在执行 create temporary table tmp(id int primary key)engine&#x3D;innodb; 这个语句时、Mysql会给innodb表创建一个 frm 文件保存表结构定义、还要有地方保存表数据. frm放在临时文件目录下 <code>#sql&#123;进程id&#125;_&#123;线程id&#125;_序列号</code>、 select @@temdir 可以查看临时文件目录.</p>
<p>5.6之前、MySQL会在临时文件目录下创建一个相同前缀、.ibd 为后缀的文件、用来存放数据文件;</p>
<p>5.7开始、MySQL引入临文件表空间、专门存放临时文件数据、不需要创建ibd文件.</p>
<p>其实创建一个叫t1的innodb临时表、MySQL在存储上认为跟普通表t1不同、可以与普通表重名.</p>
<p>MySQL维护数据表、除了物理上要有文件外、内存里也有一套机制区别不同的表、每个表对应一个table_def_key. 普通表的table_def_key是<code>库名 + 表名</code>得到、而临时表的table_def_key是<code>库名 + 表名 + server_id + thread_id</code>, 所以, 临时表不能重名而临时表是可以的.</p>
<p>在实现上、每个线程都维护了自己的临时表链表. 这样每次session内操作表的时候、先遍历链表、检查是否有对应临时表、有: 优先操作、无: 再操作临时表; session结束时、对链表里的每个临时表都执行 <code>drop temporary table + tb_name</code>的操作. 此时会发现: binlog也记录了 drop temporary操作</p>
<p>`&#96;&#96;</p>
<p>SET TIMESTAMP&#x3D;1584267384&#x2F;<em>!</em>&#x2F;;</p>
<p>SET @@session.pseudo_thread_id&#x3D;19&#x2F;<em>!</em>&#x2F;;</p>
<p>DROP &#x2F;*!40005 TEMPORARY *&#x2F; TABLE IF EXISTS <code>x</code>,<code>tmp</code></p>
<p>`&#96;&#96;</p>
<p>临时表只有在县城内可以访问、为什么要写binlog呢 ? –这就需要考虑主备复制了.</p>
<h4 id="临时表和主备复制"><a href="#临时表和主备复制" class="headerlink" title="临时表和主备复制."></a>临时表和主备复制.</h4><p>既然写binlog, 就意味着备库需要. eg. 下边的语句序列</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_normal(id <span class="type">int</span> <span class="keyword">primary</span> key, c <span class="type">int</span>)engine<span class="operator">=</span>innodb; <span class="operator">/</span><span class="operator">/</span> Q1</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> temporary <span class="keyword">table</span> tmp_t <span class="keyword">like</span> t_normal; <span class="operator">/</span><span class="operator">/</span> Q2</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tmp_t <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">1</span>); <span class="operator">/</span><span class="operator">/</span> Q3</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_normal <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tmp_t; <span class="operator">/</span><span class="operator">/</span> Q4</span><br></pre></td></tr></table></figure>



<p>若关于临时表的操作不记录、在备库重放binlog时、就会报错: tmp_t不存在</p>
<p>如果把binlog设为row格式能解决吗 ? binlog是row时、记录的是操作的数据 <code>插入一行数据(1,1)</code>. 确实如此、若binlog_format&#x3D;row、那么跟临时表有关的操作不会记录到binlog、</p>
<p>即: 只有binlog_format&#x3D;statement &#x2F; mixed时、binlog才会记录临时表的操作.</p>
<p>此时, 创建临时表的语句会传到备库执行、备库同步时也会创建临时表、所以、也需要在主库上记录 drop temporary table、传给备库.</p>
<p>MySQL在记录binlog时、不论是create 还是 alter都会原样不变、但drop确会变成 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> `t_normal` <span class="comment">/*generated by server*/</span></span><br></pre></td></tr></table></figure>

<p>也就是改成了标准格式. 为什么呢 ?</p>
<p>因为 drop是可以一次删除多个表. eg. 若设置 binlog_format&#x3D;row, 若主库执行 <code>drop table t_normal,tmp_t</code>, 则binlog只记录 <code>drop table t_normal</code>; 因为备库无tmp_t、备库执行会出错、所以, 必须将语句改写.</p>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考:"></a>思考:</h4><h5 id="备库如何处理不同线程同名临时表"><a href="#备库如何处理不同线程同名临时表" class="headerlink" title="备库如何处理不同线程同名临时表"></a>备库如何处理不同线程同名临时表</h5><p>MySQL在记录binlog时、会把线程id写入binlog、这样备库的应用线程就能知道每个语句的主库线程id、并利用这个线程id来构造临时表的table_def_key. </p>
<h5 id="临时表可使用-alter修改表名、不能使用rename"><a href="#临时表可使用-alter修改表名、不能使用rename" class="headerlink" title="临时表可使用 alter修改表名、不能使用rename ?"></a>临时表可使用 alter修改表名、不能使用rename ?</h5><p>因为在<code>rename table</code>时、是按照 db&#x2F;table.frm 的规则去磁盘找文件、但临时表在磁盘上的frm文件是放在tmpdir目录下的、并且命名规则是: <code>#sql&#123;进程id&#125;_&#123;线程id&#125;_序列号.frm</code>, 所以会找不到.</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么只查一行数据也很慢</title>
    <url>/2020/03/20/mysql_%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AA%E6%9F%A5%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E4%B9%9F%E5%BE%88%E6%85%A2/</url>
    <content><![CDATA[<ol>
<li><p>可能在等待锁</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show </span>process list;</span><br><span class="line">如果看到 State列为: <span class="keyword">waiting </span>for table metata lock<span class="comment">; 则证明在等待MDL表锁</span></span><br><span class="line"></span><br><span class="line">select <span class="keyword">blocking_pid </span>from sys.<span class="keyword">schema_table_lock_waits </span>可以找到阻塞的pid</span><br></pre></td></tr></table></figure>
</li>
<li><p>可能在等待flush</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">State列为: waiting <span class="keyword">for</span> <span class="built_in">table</span> <span class="built_in">flush</span></span><br></pre></td></tr></table></figure>
<p>Mysql对表的flush一般有两种方式</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> flush <span class="keyword">tables</span> t <span class="keyword">with</span> <span class="keyword">read</span> <span class="keyword">lock</span>. - 只关闭表t</span><br><span class="line"><span class="number">2.</span> flush <span class="keyword">tables</span> <span class="keyword">with</span> <span class="keyword">read</span> <span class="keyword">lock</span>. - 关闭所有表</span><br></pre></td></tr></table></figure>
<p>正常情况下、这两个操作都很快、除非被阻塞…</p>
</li>
<li><p>等行锁</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">mysql&gt; <span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> id=<span class="number">1</span> <span class="keyword">lock</span> <span class="keyword">in</span> <span class="keyword">share mode</span>; </span><br><span class="line"></span><br><span class="line">&gt;<span class="number">5.7</span> 版本可以通过看到被哪个<span class="keyword">sql</span>阻塞了</span><br><span class="line">mysql&gt; <span class="keyword">select</span> * <span class="keyword">from</span> t sys.innodb_lock_waits <span class="keyword">where</span> locked_table=`<span class="string">&#x27;test&#x27;</span>.<span class="string">&#x27;t&#x27;</span>`\G</span><br></pre></td></tr></table></figure>
</li>
<li><p>sql慢</p>
</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么自增主键不连续</title>
    <url>/2020/03/25/mysql_%E4%B8%BA%E4%BB%80%E4%B9%88%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%8D%E8%BF%9E%E7%BB%AD/</url>
    <content><![CDATA[<h4 id="自增值保存在哪儿"><a href="#自增值保存在哪儿" class="headerlink" title="自增值保存在哪儿"></a>自增值保存在哪儿</h4><p>实际上表的结构定义保存在 .frm 文件里、但是不会保存自增值、自增值的保存跟具体引擎有关:<br>MySIAM 引擎保存在数据文件中.<br>Innodb的自增保存在内存, 8.0版本之后、提供持久化.<br>8.0 之前的版本只保存在内存中、每次重启、第一次打开表的时候、会找自增值的最大值 max(id), 将 max(id) + 1, 作为当前表的自增值.<br>8.0将自增值的变更记录在了redo log中、重启时依靠redo log恢复重启之前的值.</p>
<h4 id="自增值修改机制"><a href="#自增值修改机制" class="headerlink" title="自增值修改机制"></a>自增值修改机制</h4><p>MySQL、若字段id被定义为 auto_increment, 在插入一行数据的时候、自增值的行为如下:</p>
<ol>
<li>若插入数据时id字段指定为0、null或者未指定值、那么就把这个表当前 auto_increment值填到自增字段.</li>
<li>若插入数据时、id字段指定了具体值 、直接使用语句指定值.<br>若待插入值是 X、当前自增是 Y</li>
</ol>
<ol>
<li>X&lt;Y, 自增保持不变</li>
<li>若X&gt;&#x3D;Y, 将自增修改为新的值<br>从auto_increment_offset 开始、以 auto_increment_increment为步长、持续叠加、直到找到第一个大于X的值、作为新的自增值</li>
</ol>
<h4 id="自增值的修改时机"><a href="#自增值的修改时机" class="headerlink" title="自增值的修改时机"></a>自增值的修改时机</h4><p>若表t已有记录(1,1,1)、再执行</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>语句执行流程是:</p>
<ol>
<li>调用innodb引擎接口、写入一行、传入值(0, 1, 1);</li>
<li>innodb发现用户没有指定自增id值、获取表t当前的自增值为2;</li>
<li>将传入行的值改为 (2,1,1);</li>
<li>将表的自增改为3</li>
<li>继续执行插入、由于已经存在c&#x3D;1的记录、出现唯一键冲突、报错返回.<br>所以、主键自增修改是在真正的插入操作之前、真正执行的时候唯一键冲突、id&#x3D;2插入失败、但自增值不会回退. 这之后的数据插入自增基础就是3、所以, 唯一键冲突是导致自增id不连续的第一种原因.</li>
</ol>
<p>事务回滚也会产生类似的现象、这是第二种原因.</p>
<h4 id="那么为什么MySQL不设计自增值可以回滚呢"><a href="#那么为什么MySQL不设计自增值可以回滚呢" class="headerlink" title="那么为什么MySQL不设计自增值可以回滚呢 ?"></a>那么为什么MySQL不设计自增值可以回滚呢 ?</h4><p>假设有两个并行事务、在申请自增值的时候、为了避免两个事务申请到相同的自增id、就需要加锁、顺序申请.</p>
<ol>
<li>假设事务A申请到id&#x3D;2、事务B申请到id&#x3D;3, 此时表t的自增值是4, 之后继续执行</li>
<li>事务B正确提交、事务A出现唯一键冲突.</li>
<li>若允许事务A将自增值回退、则出现、表里已有id&#x3D;3的行、而当前自增是2 的现象</li>
<li>接下来其它语句申请到 id&#x3D;2、然后再申请到id&#x3D;3、就会出现主键冲突.<br>解决这个冲突有两个办法:</li>
<li>每次申请id之前、先判断表里是否已存在这个id、若存在、就跳过、但成本较高、本来申请id是一个很快的操作、现在还要去主键索引上判断id是否存在</li>
<li>把自增id的锁范围扩大、必须等上一个事务执行完成、下一个才能申请. 但会大大的影响并发性能.<br>所以、MySQL放弃了自增值回退、只保证自增、不保证连续.</li>
</ol>
<h4 id="自增锁优化"><a href="#自增锁优化" class="headerlink" title="自增锁优化"></a>自增锁优化</h4><p>自增锁并不是事务锁、每次申请完就释放、以便别的事务再申请. 一起看下自增锁演进的过程:</p>
<p>5.0版本、自增锁是语句级别、若一个语句申请了一个表自增锁、锁会等语句结束才释放. 影响并发度.<br>5.1.22新增参数 innodb_autoinc_lock_mode, 默认1<br>设为0: 表示采用5.0版本策略、语句执行结束释放锁<br>设为1: 普通insert、自增锁申请之后、立即释放; 类似insert…select批量插入语句、要等语句结束才释放<br>设为2: 所有语句都是申请后就释放.</p>
<p>批量插入语句、预先不知道要申请多少个自增id、一种直接想法是: 需要是就申请一个. 但若需要10w个自增的话、就需要申请10w次、会速度很慢、且影响并发插入性能.所以、批量申请的话、Mysql会使用指数级分配.</p>
<p>这是自增出现不连续的第三个原因.</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么还有kill不掉的语句</title>
    <url>/2020/03/25/mysql_%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E6%9C%89kill%E4%B8%8D%E6%8E%89%E7%9A%84%E8%AF%AD%E5%8F%A5/</url>
    <content><![CDATA[<blockquote>
<p>为什么还要kill不掉的语句 ?</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Mysql 中有两个<span class="built_in">kill</span>命令: </span><br><span class="line"><span class="built_in">kill</span> query + 线程<span class="built_in">id</span>; // 终止线程中正在执行的语句; </span><br><span class="line"><span class="built_in">kill</span> connection + 线程<span class="built_in">id</span>; // 断开线程的连接、里边若有语句郑州执行、也会停止执行</span><br><span class="line">那么什么情况下、会出现: 使用了<span class="built_in">kill</span>命令、未断开连接、show processlist显示的是killed状态的现象呢 ?</span><br></pre></td></tr></table></figure>



<h4 id="收到kill以后、线程做什么"><a href="#收到kill以后、线程做什么" class="headerlink" title="收到kill以后、线程做什么 ?"></a>收到kill以后、线程做什么 ?</h4><p>kill 若直接终止、退出、会导致原来占有的锁无法释放、所以: kill 不会马上停止、而是告诉线程<code>可以执行停止的逻辑了</code>. 实际上执行<code>kull query thread_id_B</code>时、处理了两件事:</p>
<ol>
<li><p>将session B的运行状态改成 THD::KILL_QUERY(将killed赋值为THD::KILL_QUERY);</p>
</li>
<li><p>给session B的执行线程发一个信号.</p>
</li>
</ol>
<h4 id="kill不掉的场景"><a href="#kill不掉的场景" class="headerlink" title="kill不掉的场景"></a>kill不掉的场景</h4><h5 id="线程并发数不够"><a href="#线程并发数不够" class="headerlink" title="线程并发数不够"></a>线程并发数不够</h5><p> innodb_thread_concurrency 不够用、线程未执行到判断线程逻辑的状态.</p>
<p>  此时command列会显示killed, 但实际上服务端该语句还在执行中. 为什么不会直接退出呢 ?</p>
<ol>
<li>执行kill query时、</li>
</ol>
<p>  在实现上、等行锁、使用的是pthread_cond_timedwait函数、这个等待状态可以被唤醒. 虽然线程状态已经被置为kill_query, 但在这个等待进入innodb的循环过程中、并未判断线程状态、所以不会进入终止逻辑</p>
<ol start="2">
<li>kill connection</li>
</ol>
<p>  将线程状态置为 kill_connection、关掉线程的网络连接、所以被kill的session收到断开连接的提示. 为什么command列会显示为killed呢 ?</p>
<p>  show processlist 有一个特别逻辑: 若线程状态为 kill_connection、就显示为 killed.</p>
<p>  所以、即使Client退出了、线程状态仍然是等待中、直到满足进入innodb的条件后 session C才继续执行、然后才有可能判断到线程状态已经变成了kill_query 或者 kil_connection状态、再进入终止逻辑.</p>
<h5 id="终止逻辑耗时长"><a href="#终止逻辑耗时长" class="headerlink" title="终止逻辑耗时长."></a>终止逻辑耗时长.</h5><p>  此时从processlist结果列上来看也是Killed、需要等终止逻辑完成、才算真正完成. 场景:</p>
<ol>
<li><p>超大事务执行期间被Kill、此时回滚事务需要对事务执行期间生成的所有数据版本做回收操作、耗时很长</p>
</li>
<li><p>大查询回滚、若查询过程中生成了较大的临时文件、加上此时文件系统压力大、删除临时文件可能需要等待IO资源、导致耗时较长</p>
</li>
<li><p>DDL命令执行到最后阶段、若被Kill、需要删除中间过程的临时文件、可能也要受到IO资源耗时久的影响.</p>
</li>
</ol>
<h5 id="直接在客户端Ctrl-C是否可以终止线程呢"><a href="#直接在客户端Ctrl-C是否可以终止线程呢" class="headerlink" title="直接在客户端Ctrl+C是否可以终止线程呢 ?"></a>直接在客户端Ctrl+C是否可以终止线程呢 ?</h5><p>  不可以. 客户端只能操作客户端线程、Client和Server通过网络交互、不可能操作Server线程.</p>
<p>  而由于MySQL是停等协议、所以、线程执行的语句还未返回的时候、再往连接发命令也是无效的. 实际上、Ctrl+C时、Mysql Client是另外启动一个连接、发送 kill query 命令.</p>
<h4 id="两个关于Client的误解"><a href="#两个关于Client的误解" class="headerlink" title="两个关于Client的误解"></a>两个关于Client的误解</h4><h5 id="若库里包含的表特别多、连接就会很慢"><a href="#若库里包含的表特别多、连接就会很慢" class="headerlink" title="若库里包含的表特别多、连接就会很慢."></a>若库里包含的表特别多、连接就会很慢.</h5><p>  实际上、每个Client和Server建立连接时、需要做的事情就是 TCP握手、用户校验、获取权限、与库里表的数量无关. 但: 使用默认参数连接时、Mysql Client会提供本地库名和表名补全功能. 为了实现这个功能、Client在连接成功后、需要多一些操作:</p>
<ol>
<li><p>show databases;</p>
</li>
<li><p>切到db1、执行show tables;</p>
</li>
<li><p>将两个命令的结果构建一个本地hash表.</p>
</li>
</ol>
<p>  最耗时的是操作(3). 所以、我们感知到的连接过程慢、其实不是连接慢、也不是Server慢、而是Client慢. 若不使用 或者很少使用 自动补全的话、建议默认加 -A</p>
<p>  其实-quick(-q) 也可以跳过这个阶段. 但这个参数可能会降低Server性能. Mysql 发送请求后、接收Sever返回结果的方式有两种:</p>
<ol>
<li><p>本地缓存: 在本地开一片内存、将结果缓存、若使用API开发、对应:mysql_store_result.</p>
</li>
<li><p>不缓存: 读一个处理一个、若使用API、对应: mysql_use_result.</p>
</li>
</ol>
<p>  MySQL默认采用本地缓存、若加上-quick会采用第二种. 此时、若本地处理的较慢、就会导致服务端发送结果被阻塞、让服务端变慢.</p>
<h5 id="为什么叫-quick呢"><a href="#为什么叫-quick呢" class="headerlink" title="为什么叫 -quick呢 ?"></a>为什么叫 -quick呢 ?</h5><ol>
<li><p>可以跳过表名自动补全</p>
</li>
<li><p>mysql_store_result需要申请本地内存来缓存查询结果、若结果太大、会耗费较多本地内存、影响Client本机性能.</p>
</li>
<li><p>不会把执行命令结果记录到本地的命令历史文件.</p>
</li>
</ol>
<p>  所以: -quick 是让Client变得更快.</p>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考:"></a>思考:</h4><p>若碰到一个被Killed的事务一直处于回滚状态、应该把Mysql进程强制重启、还是让它执行完呢 ?</p>
<p>因为重启后依然会继续回滚操作、所以 从恢复速度的角度来说、应该让它自己执行结束.</p>
<p>若这个语句可能会占用别的锁、或者由于占用IO资源过多、影响到别的语句执行、就需要做主备切换、切到新的主库提供服务. 切换之后别的线程都断开了连接、自动停止执行, 接下来还是等它自己执行完成(减少系统压力、加速终止逻辑).</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>主库异常、从库怎么办</title>
    <url>/2020/03/20/mysql_%E4%B8%BB%E5%BA%93%E5%BC%82%E5%B8%B8%E3%80%81%E4%BB%8E%E5%BA%93%E6%80%8E%E4%B9%88%E5%8A%9E/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-d8b11878314944da.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/440" alt="一主多从基本架构.png"><br>说明: 虚箭头表示主备关系、从库B、C、D指向主库A</p>
<blockquote>
<p>那么、当主库A发生故障时、A’会成为新的主库、具体怎么切换的呢 ?</p>
</blockquote>
<p>一、基于位点的主备复制<br>当需要把节点B设置为A’的从库时、需要执行<code>change master</code>命令</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">change master <span class="keyword">to</span></span><br><span class="line"><span class="attribute">master_host</span>=<span class="variable">$host_name</span></span><br><span class="line"><span class="attribute">master_port</span>=<span class="variable">$port</span></span><br><span class="line"><span class="attribute">master_user</span>=<span class="variable">$user_name</span></span><br><span class="line"><span class="attribute">master_password</span>=<span class="variable">$password</span></span><br><span class="line"><span class="attribute">master_log_file</span>=<span class="variable">$master_log_name</span></span><br><span class="line"><span class="attribute">master_log_pos</span>=<span class="variable">$master_log_pos</span></span><br></pre></td></tr></table></figure>
<p>其中, <code>master_log_file</code>和<code>master_log_pos</code>表示要从从库的<code>master_log_name</code>文件的<code>master_log_pos</code>位置开始同步, 即: 主库对应文件名和日志偏移量</p>
<ol>
<li>如何获取同步位点(偏移量)呢 ?<br>方法一：<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 等待新主库`A&#x27;` 把中转日志 relay <span class="built_in">log</span>全部同步完成</span><br><span class="line"><span class="number">2.</span> 在`A&#x27;`上执行 show master status命令、得到`A&#x27;`上最新的File和Position</span><br><span class="line"><span class="number">3.</span> 取原主库A故障的时刻<span class="built_in">T</span></span><br><span class="line"><span class="number">4.</span> 用mysqlbinlog工具解析`A&#x27;`的File、得到<span class="built_in">T</span>时刻的位点</span><br><span class="line"></span><br><span class="line">mysqlbinlog File <span class="operator">-</span><span class="operator">-</span>stop<span class="operator">-</span>datatime<span class="operator">=</span><span class="built_in">T</span> <span class="operator">-</span><span class="operator">-</span>start<span class="operator">-</span>datetime<span class="operator">=</span><span class="built_in">T</span>， 如下图所示 end_log_pos的值</span><br></pre></td></tr></table></figure>
<img src="https://upload-images.jianshu.io/upload_images/14027542-11317714a2bf6581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>但这样得到的值并不精准、假设 T时刻、主库A完成insert操作、插入行R、将binlog传给了A’ 和 B、传完的瞬间A故障, 此时系统状态为:<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 从库B已经同步了binlog、R已存在</span><br><span class="line"><span class="bullet">2.</span> 在新的主库<span class="code">`A&#x27;`</span>, R也存在、且是写在123这个位置后的、</span><br><span class="line"><span class="bullet">3.</span> 在从库B上执行 change master时、指向<span class="code">`A&#x27;`</span>的123位置、R的binlog再次同步到从库B、造成主键冲突.</span><br></pre></td></tr></table></figure>
通常情况下会主动跳过错误, 有两种方式可以主动跳过:</li>
<li>主动跳过一个事务<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> sql_slave_skip_counter<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"><span class="keyword">start</span> slave;</span><br></pre></td></tr></table></figure></li>
<li>跳过指定类型的错误<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">1062</span> <span class="keyword">insert</span>唯一键冲突</span><br><span class="line"><span class="number">1032</span> 删除数据时、找不到行</span><br><span class="line">slave_skip_errors<span class="operator">=</span><span class="string">&#x27;1032,1062&#x27;</span>; 会主动跳过这两类的错误</span><br></pre></td></tr></table></figure></li>
</ol>
<p>方法二、GTID<br>通过sql_slave_skip_counter跳过事务和slave_skip_errors忽略错误的方法、虽然最终可以建立新的主备关系、但操作复杂、容易出错、Mysql5.6引入了<code>GTID(Global Transaction Identifier)</code>. 格式:<code>GTID=server_uuid:gno</code><br>其中:</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">server_uuid</span> 是实例第一次启动时生成的, 全局唯一</span><br><span class="line"><span class="attribute">gno</span>是一个整数、初始值是<span class="number">1</span>, 每次提交事务时分配给这个事务、并+<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>官方定义: <code>GTID=source_id:transaction_id</code></p>
<p>GTID模式的启动很简单、只需要启动是增加参数:<br>gtid_mode&#x3D;on 和 enforce_gtid_consistency&#x3D;on 即可.</p>
<p>GTID模式下、每个事务都会跟一个GTID对应、有两种生成方式, 具体使用哪种取决于 session 变量和 gtid_next 的值</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">1. 若 <span class="attribute">gtid_next</span>=automatic, 代表使用默认值、Mysql会把server_uuid:gno 分配给它</span><br><span class="line">   a. 记录binlog时、先记录一行<span class="built_in">set</span></span><br><span class="line">       @@session.gtid_mext = <span class="string">&#x27;server_uuid.gno&#x27;</span></span><br><span class="line">   b. 把这个gtid加入到本实例的gtid集合 </span><br><span class="line">2. 若gtid是固定的值、eg. 通过<span class="built_in">set</span> <span class="attribute">gtid_next</span>=<span class="string">&#x27;current_gtid&#x27;</span>指定、会有两种可能性:</span><br><span class="line">   a. 若current_gtid已存在实例的gtid集合、接下来的事务会被系统忽略</span><br><span class="line">   b. 若不再、就将该值分配给要执行的事务、系统不需要生成、gno也不用+1</span><br></pre></td></tr></table></figure>
<p>这样、MySQL维护了一个GTID集合、用来对应<code>实例执行过的所有事务</code></p>
<p>当出现主键冲突时、可以通过GTID加入的方式、跳过事务</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">set gtid_next=<span class="string">&#x27;conflict gtid&#x27;</span>; </span><br><span class="line">begin;</span><br><span class="line">commit; <span class="regexp">//</span> 通过提交一个空事务、将gtid加入到实例X的GTID集合</span><br><span class="line">set gtid_next=automatic; <span class="regexp">//</span> 恢复GTID自动分配模式</span><br><span class="line">start slave; <span class="regexp">//</span> 启动从库</span><br></pre></td></tr></table></figure>


<p>二、基于GTID的主备切换</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">change master <span class="keyword">to</span></span><br><span class="line">master_host<span class="operator">=</span>$host_name</span><br><span class="line">master_port<span class="operator">=</span>$port</span><br><span class="line">master_user<span class="operator">=</span>$user_name</span><br><span class="line">master_password<span class="operator">=</span>$password</span><br><span class="line">master_auto_position<span class="operator">=</span><span class="number">1</span> <span class="operator">/</span><span class="operator">/</span> 表示主备关系使用的是gtid协议</span><br></pre></td></tr></table></figure>
<p>主备切换逻辑:</p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 实例B指向主库`A&#x27;`, 基于主备协议建立连接</span><br><span class="line"><span class="number">2</span>. 实例B把 set_b 发送给主库 `A&#x27;`</span><br><span class="line"><span class="number">3</span>. 实例`A&#x27;`算出 set_a 与 set_b的差集、即: 所有存在于 set_a、但不存在于 set_b 的gtid集合、判断`A&#x27;`本地是否包含了这个差集需要的所有binlog事务</span><br><span class="line">   a. 若不包含、表示 `A&#x27;` 已经把实例B需要的binlog删除掉、直接返回错误</span><br><span class="line">   b. 若包含、`A&#x27;`从自己的binlog找到第一个不在 set_b 的事务、发给B</span><br><span class="line"><span class="number">4</span>. 从该事务开始、往后读文件、按顺序读取binlog发送给B执行.</span><br></pre></td></tr></table></figure>
<p>其实、这里边包含了一个设计思想: 在基于GTID的主备关系里、系统认为只要建立主备关系、就必须要保证主库发给备库的日志是完整的、若实例B需要的日志已经不存在、<code>A&#39;</code>就拒绝发送给B</p>
<p>这跟基于位点的主备协议不同. 基于位点的协议、是由备库决定的、备库指定哪个位点、主库就发送哪个位点、不做日志的完整性判断. GTID是备库自动判断的.</p>
<p>思考:</p>
<blockquote>
<p>若在GTID模式下设置主从关系的时候、从库执行start slave命令后、主库发现需要的binlog已经被删除掉了、导致主备创建不成功. 怎么处理呢 ?</p>
</blockquote>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 若业务允许主从不一致、可以在主库上执行 `<span class="keyword">show</span> <span class="keyword">global</span> variables <span class="keyword">like</span> gtid_purged`、得到主库已经删除的gtid集合、假设是 gtid_purged1, 然后先在从库执行 <span class="keyword">reset</span> master, 再执行 <span class="keyword">set</span> <span class="keyword">global</span> gtid_purged=gtid_purged1; 最后执行 <span class="keyword">start</span> slave, 就会从现存binlog开始同步.</span><br><span class="line"><span class="number">2.</span> 若需要主从数据一致的话、最好还是通过重新搭建从库来做</span><br><span class="line"><span class="number">3.</span> 若其它从库有全量binlog的话、可以把新的从库先接到全量binlog的从库、追上日志以后、若有需要、再切回主库</span><br><span class="line"><span class="number">4.</span> 若binlog有备份、可以先在从库应用缺失的binlog、然后再执行<span class="keyword">start</span> slave.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>什么时候使用内部临时表</title>
    <url>/2020/03/25/mysql_%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/</url>
    <content><![CDATA[<h4 id="union执行流程"><a href="#union执行流程" class="headerlink" title="union执行流程"></a>union执行流程</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1(id <span class="type">int</span> <span class="keyword">primary</span> key, a <span class="type">int</span>, b <span class="type">int</span>, index(a));</span><br><span class="line"></span><br><span class="line">delimiter ;;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">procedure</span> idata()</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">declare</span> i <span class="type">int</span>;</span><br><span class="line">  <span class="keyword">set</span> i<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">  while(i<span class="operator">&lt;=</span><span class="number">1000</span>) do</span><br><span class="line">    <span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span>(i, i, i);</span><br><span class="line">    <span class="keyword">set</span> i<span class="operator">=</span>i<span class="operator">+</span><span class="number">1</span>;</span><br><span class="line">  <span class="keyword">end</span> while;</span><br><span class="line"><span class="keyword">end</span>;;</span><br><span class="line">delimiter ;</span><br><span class="line"><span class="keyword">call</span> idata();</span><br></pre></td></tr></table></figure>
<p>然后执行</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">(<span class="keyword">select</span> <span class="number">1000</span> <span class="keyword">as</span> f) <span class="keyword">union</span> (<span class="keyword">select</span> id <span class="keyword">from</span> t1 <span class="keyword">order</span> <span class="keyword">by</span> id <span class="keyword">desc</span> limit <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p>获取两个子查询结果的并集(非重复).</p>
<p>使用explain分析发现:<br>在做union的时候、使用了临时表(Using temporary)</p>
<p>执行流程如下:</p>
<ol>
<li>创建一个内存临时表、只有一个整型字段f、且f是主键字段</li>
<li>执行第一个子查询、得到1000这个值、写入临时表</li>
<li>执行第二个子查询:<br>获取id&#x3D;1000, 插入临时表、由于主键冲突、插入失败、取id&#x3D;999.</li>
<li>从临时表按行取出数据、返回结果、并清除临时表、结果中包含的两行数据 1000 和 999.</li>
</ol>
<p>若union改成union all、无需去重、就不需要临时表了.</p>
<h4 id="group-by执行流程"><a href="#group-by执行流程" class="headerlink" title="group by执行流程"></a>group by执行流程</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id<span class="operator">%</span><span class="number">10</span> <span class="keyword">as</span> m, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> c <span class="keyword">from</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> m;</span><br></pre></td></tr></table></figure>

<p>explain的extra字段、可以看到三个信息:<br>using index, 表示语句使用了覆盖索引、选择了索引a、不需要回表;<br>uusing temporary, 表示使用了临时表<br>using filesort, 表示需要排序.</p>
<p>SQL执行流程:</p>
<ol>
<li>创建内存临时表、表里有两个字段 m 和 c, 主键是 m;</li>
<li>扫描表t1的索引a、依次取出叶子节点上id的值、计算 id%10的结果、记为x;<br>若临时表没有主键为x的行、就插入一个记录(x,1);<br>若表中有主键x的行、就将c的值+1;</li>
<li>遍历完成后、根据字段m做排序、得到结果集返回给客户端.</li>
</ol>
<p>若实际需求不需要排序、可以加上 order by null. 这样就会跳过排序阶段.</p>
<h4 id="group-by优化方法-–-索引"><a href="#group-by优化方法-–-索引" class="headerlink" title="group by优化方法 – 索引"></a>group by优化方法 – 索引</h4><p>不论是内存临时表还是磁盘临时表、group by逻辑都需要构造一个带唯一索引的表、执行代价较高.<br>group by为什么需要临时表呢 ? group by是统计不同值出现的次数, 但每一行的 id%100 的结果是无序的、所以需要一个临时表、记录统计结果. 如果保证 出现的数据是有序的呢 ?<br>就不需要额外排序了. 索引, 可以通过添加冗余字段、记录 id%10 的值、并在该列 添加索引来优化.</p>
<p>四、group by优化方法 – 直接排序<br>若碰到无法使用加索引完成group by的逻辑、就只能老老实实排序, 此时 group by如何优化呢 ?<br>若明知group by 语句的结果集很大、依然要 先存到内存临时表、插入部分数据后、发现临时内存不够再转成磁盘临时表、这样倒不如直接使用磁盘临时表.</p>
<p>在group by中加入 sql_big_result 可以告诉优化器、结果集很大、直接使用磁盘临时表就好. 磁盘临时表使用的是 B+ 树存储、存储效率不如数组. 既然数据量大、那不如使用数组存储.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> sql_big_result id<span class="operator">%</span><span class="number">100</span> <span class="keyword">as</span> m, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> c <span class="keyword">from</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> m;</span><br></pre></td></tr></table></figure>

<p>执行流程如下:</p>
<ol>
<li>初始化 sort_buffer、确定放入一个整型字段m;</li>
<li>扫描t1的索引a、依次取出id的值、将id%100 的值、存入sort_buffer;</li>
<li>扫描完成后、对sort_buffer的字段m做排序(若sort_buffer不够用、就利用磁盘临时文件辅助排序)</li>
<li>排序完成、得到有序数组.</li>
</ol>
<p>那么、MySQL什么时候会使用内部临时表呢 ?</p>
<ol>
<li>若语句执行过程是一边读数据、一边直接得到结果、是不需要额外内存的、否则就需要额外内存存储中间结果.</li>
<li>join_buffer是无序数组、sort_buffer是有序数据、临时表是二维表结构.</li>
<li>若执行逻辑需要用到二维表特性、就要优先考虑临时表.</li>
</ol>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考:"></a>思考:</h4><p>为什么同样是使用 order by null. 内存临时表得到的结果 0在最后一行、而使用磁盘临时表得到的结果、0在第一行 ?</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>备库为什么会延迟好几个小时</title>
    <url>/2020/03/20/mysql_%E5%A4%87%E5%BA%93%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6/</url>
    <content><![CDATA[<blockquote>
<p>若备库执行日志的速度低于主库生成日志的速度、备库有可能很久都追不上主库<br>MySQL5.6版本之前、MySQL只支持单线程复制、主库并发高、TPS较高时、可能会出现主备延迟<br>5.6版本之后、sql_thread不会直接更新数据、而是交给 coordinator 来中转日志和分发事务、由worker进程来更新数据. worker的线程数由 slave_parallel_works 决定.<br>一般32核机器设置为 8~16、备库还要提供查询、不能把CPU都吃光了.</p>
</blockquote>
<p>思考: </p>
<ol>
<li><p>事务能不能轮询分发给各个worker ?<br>不可以. 事务分发给worker以后、不同worker就独立执行了、但由于CPU的调度策略、第二个事务可能会比第一个先执行、此时、若两个事务更新的是同一行数据、就会导致主备不一致.</p>
</li>
<li><p>同一个事务的多个更新语句、能不能分发给多个worker执行 ?<br>不可以. 若Trx1 更新了t1和t2 两个表的各一行数据、若分发到不同的worker执行、虽然备库最终结果是一致的、但 t1更新完成的瞬间、会出现不一致, 破坏了事务的隔离性</p>
</li>
</ol>
<p>所以: 分发器 coordinator 需要满足:</p>
<ol>
<li>不能造成覆盖更新、更新同一行数据的两个事务必须分发到同一个worker</li>
<li>同一个事务必须分发到同一个worker.</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-6992c49571630b74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="主备流程图.png"></p>
<p>不同版本的并行复制策略:</p>
<ol>
<li>5.5版本<br>官方5.5版本不支持并行复制. <ol>
<li><p>按表分发. 每个worker线程维护一个hash表、用来保存当前正在这个worker上执行的事务所涉及的表. 有事务分配给该worker时、涉及的表会加入到对应hash表、worker执行完成、从hash表移除. 若与多个worker冲突、coordinator进入等待.<br>事务分发时、与worker冲突情况:<br>a. 跟所有worker都不冲突、coordinator直接分发给最空闲的worker线程<br>b. 跟多于一个worker冲突、coordinator进入等待、直到和该事务冲突的worker进程只有1个<br>c. 若只跟一个worker冲突、分配给存在冲突关系的worker.<br>按表分发、在多表负载均匀的场景下效果不错、但若碰到热点表、比如: 所有的更新事务都涉及同一张表时、所有事务都会分发到同一个worker、就变成单线程了.</p>
</li>
<li><p>按行分发. 若两个事务没有更新相同行、可以在备库并行执行、要求binlog格式必须是row.<br>此时判断冲突规则就是 库名 + 表名 + 唯一键值(还要考虑唯一索引)<br>相比于按表分发、按行分发在决定线程分发的时候、需要消耗更多的计算资源.</p>
</li>
</ol>
</li>
</ol>
<p> 按表分发和按行分发都有约束:</p>
<ol>
<li><p>binlog格式必须是Row</p>
</li>
<li><p>表必须要有主键</p>
</li>
<li><p>不能有外键、有外键时、级联更新的行不会记录binlog、这样冲突检测就不准确.<br> 按行分发有个问题: 大事务耗费CPU和内存.<br> 解决: 会设置一个阈值、若单事务超过设置行阈值(eg. 单事务更新行数超过10w)、就退化为单线程模式: 1. coordinator暂时hold住事务、2. 等所有worker变成空队列、coordinator直接执行事务 3. 恢复并行模式</p>
</li>
<li><p>5.6按库并行<br>原理同上、并行效果取决于压力模型. 若主库上有多个DB、并且多个DB的压力均衡、使用库级别分发效果较好. 相对表级别和行级别优势:</p>
</li>
</ol>
<ol>
<li>构造hash值很快、只需要库名、且一个实例上DB数量不会过多</li>
<li>不要求binlog格式为row、statement也可以拿到库名.<br>但: 若主库上的所有表都放在同一个DB里、这个策略就没用了、若不同DB热点不同、也起不到并行效果.</li>
</ol>
<ol start="3">
<li>MariaDB的并行复制策略<br>利用的是组提交的特性.</li>
</ol>
<ol>
<li>能够在同一组里提交的事务、一定不会修改同一行</li>
<li>主库上可以并行执行的事务、备库上也一定可以并行执行</li>
</ol>
<ol>
<li><p>在一组提交的事务、有一个相同的commit_id、下一组就是 commit_id + 1</p>
</li>
<li><p>commit_id直接写入binlog</p>
</li>
<li><p>传到备库应用时、相同commit_id的事务分发到多个worker执行</p>
</li>
<li><p>一组全部执行完、coordinator再取下一组数据.<br>可以模拟主库的并行模式. 但: 并未完全实现<code>模拟主库并发度</code>这个目标, 在主库上、一组事务commit时、下一组事务是同时处于<code>执行中</code>的. 而备库需要第一组事务执行完、第二组才能开始执行、这样系统的吞吐量就不够、另外、容易被大事务拖后腿.<br>假设 trx1 &#x2F; trx2 &#x2F; trx3为一组事务、trx2为大事务、这样、trx1&#x2F;trx3执行完后也必须等待trx2执行完成、下一组才能开始执行、这段时间只有一个worker线程在工作、是对资源的浪费.</p>
</li>
<li><p>MySQL5.7的并行复制策略<br>MySQL5.7提供了 slave-parallel-type 控制并行复制策略<br>slave-parallel-type&#x3D;database; 表示使用mysql5.6的按库并行复制<br>slave-parallel-type&#x3D;logical_clock; 表示使用类似mariadb的策略、但做了改进</p>
</li>
</ol>
<p>思考: 同时处于<code>执行状态</code>的所有事务、是不是可以并行 ?<br>不能. 可能有由于锁冲突而处于锁等待状态的事务、若这些事务在备库上分配到不同的worker、会出现主备不一致. 所以、MariaDB的核心是、处于commit状态的事务并行处理.</p>
<p>而实际上: 处于redo log prepare阶段的事务、都已经通过了锁冲突检验、<br>所以, Mysql5.7的并行复制策略思想是:</p>
<ol>
<li>同时处于prepare状态的事务、在备库可以并行执行</li>
<li>处于prepare状态的事务、与处于commit状态的事务之间、在备库执行时、也是可以并行的.<br>binlog_group_commit_sync_delay表示延迟多少微秒后调用fsync<br>binlog_group_commit_sync_no_Delay_count表示累积多少次后才调用fsync<br>这两个参数可以用于故意拉长binlog从write到fsync的时间、减少binlog的写盘次数、在5.7的复制策略里、可以用来制造更多处于<code>prepare阶段的事务</code>、增加备库并行度</li>
</ol>
<ol start="5">
<li>Mysql5.7.22并行复制策略<br>18.4月发布的5.7.22版本、增加一个机遇writeset的并行复制<br>binlog-transaction-dependency-tracking控制是否使用新的策略</li>
</ol>
<ol>
<li>commit_order、根据同时进入prepare和commit来判断是否可以并行的策略</li>
<li>writeset、表示对于事务涉及更新的每一行计算hash值、组成writeset、若两个事务没有操作相同行、就可以并行复制</li>
<li>writeset_session、在主库上同一个线程先后执行的两个事务、在备库执行时、要保证相同的先后顺序、hash值是通过 db+table+index+value计算的、类似5.5按行复制<br>但: 1. writeset是在主库生成后直接写入binlog的、在备库执行时、不需要解析binlog、节省计算量</li>
</ol>
<ol start="2">
<li>不需要把整个事务的binlog都扫一遍、才决定分发到哪个worker、更省内存</li>
<li>备库的分发策略不依赖binlog内容、binlog格式可以不局限于row<br>通用性更有保证.</li>
</ol>
<p>思考: 假设5.7.22版本的主库、单线程插入很多数据、过了3个小时、想给这个主库搭一个相同版本的备库. 为了更快的追上主库、需要怎么选择并行复制策略呢 ?</p>
<ol>
<li>commit_order 由于是单线程执行、每个事务的commit_id不同、从库也只能是单线程执行<br>2、 writeset_order 要求同一个线程的日志必须要与主库上的先后顺序相同、也会导致退化为单线程<br>所以应该选择 writeset 并行复制策略.</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>如何判定一个数据库出了问题</title>
    <url>/2020/03/20/mysql_%E5%A6%82%E4%BD%95%E5%88%A4%E5%AE%9A%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E5%87%BA%E4%BA%86%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<blockquote>
<p>主备切换有两种场景: 主动切换 和 被动切换. 被动切换大多是主库出了问题、由HA系统引发的. 那么: 如何判定主库出了问题呢 ?</p>
</blockquote>
<p>一、 select 1 判定<br>实际上, select 1 成功返回、只能说明这个库的进程还在、并不能说明主库没问题. eg. 以下场景:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> innodb_thread_concurrency<span class="operator">=</span><span class="number">3</span>; <span class="operator">/</span><span class="operator">/</span> 控制innodb并发线程上限. 超过、进入等待. 来避免线程数过多、上下文切换的成本过高.</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t`(</span><br><span class="line"> `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">`c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span></span><br><span class="line">) engine<span class="operator">=</span>innodb;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-a908616fd039d681.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>在session D里、select 1是可执行成功的, 但查询表t会被堵住.<br>注意:</p>
<blockquote>
<p>并发连接和并发查询不是一个概念. show processlist看到的几千个连接、指的就是并发连接.<br>当前正在执行的语句、才是并发查询.<br>连接多顶多占一些内存、而并发查询多、才是造成CPU压力的根本. 在线程进入锁等待之后、并发线程的计数会-1, 行锁(包括间隙锁)不占用CPU资源.</p>
</blockquote>
<p>思考:</p>
<blockquote>
<p>Mysql会什么设计锁等待不计入并发线程数呢 ?</p>
</blockquote>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">假设以下场景:</span><br><span class="line">1. 线程1 执行begin; update t <span class="built_in">set</span> <span class="attribute">c</span>=c+1 where <span class="attribute">id</span>=1; 启动事务trx1, 然后保持、此时线程处于空闲</span><br><span class="line">状态、不计入并发线程</span><br><span class="line">2.  线程2~129执行 update t <span class="built_in">set</span> <span class="attribute">c</span>=c+1 where <span class="attribute">id</span>=1; 由于等行锁、进入等待、这样就有128个</span><br><span class="line">线程处于等待状态.</span><br><span class="line">3. 若处于等待状态线程计数不-1, innodb会认为线程用满、阻止其他查询语句进入引擎执行、线程1不能</span><br><span class="line">提交、而另外的128个线程又处于锁等待状态、整个系统就阻塞了. 如下图:</span><br><span class="line">此时innodb不能响应任何请求、且所有线程都处于等待状态、此时占用CPU为0, 很不合理、所以 </span><br><span class="line">设计进入锁等待、将并发线程的计数器-1, 是合理的.</span><br><span class="line"></span><br><span class="line">但: 若真的执行查询、还是计入并发线程的. eg. select sleep(100) <span class="keyword">from</span> t;</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-facf6013361bf644.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="等待并发线程不减1, 系统锁死.png"></p>
<p>二、查表判断<br>在系统库(mysql)新建一个表, eg. 命名为 health_check, 里边只放一行数据、定期检测, 可以发现由于并发线程数过多导致的db不可用.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mysql.health_check;</span><br></pre></td></tr></table></figure>
<p>但: 若空间满了、这种方法又不好使.<br>更新事务要写binlog、而一旦binlog所在磁盘空间占用率达到100%, 那所有的更新和事务提交的commit语句都会被堵住, 但可以正常读取. </p>
<p>三、更新判断</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> mysql.headlth_check <span class="keyword">set</span> t_modified<span class="operator">=</span>now();</span><br></pre></td></tr></table></figure>
<p>节点可用性的检测都应该包含主库和备库、若用来检测主库的话、备库也要进行更新检测. 但: 备库的检测也是要写binlog的、一般会把A和B的主备关系、设计为双M架构、所以在备库B上执行的检测命令、也会发回给主库A.<br>但若A、B更新同一条数据、就可能发生行冲突、导致主备同步停止. 可以插入多条数据、使用A、B的server_id做主键.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `headlth_check`(</span><br><span class="line"> `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">`t_modified` <span class="type">timestamp</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">default</span> <span class="built_in">current_timestamp</span>,</span><br><span class="line"><span class="keyword">primary</span> key(`id`)</span><br><span class="line">) engine<span class="operator">=</span>innodb;</span><br><span class="line"># 检测命令</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> mysql.health_check(id, t_modified) <span class="keyword">values</span>(@<span class="variable">@server</span>_id, now()) <span class="keyword">on</span> duplicate</span><br></pre></td></tr></table></figure>
<p>这是一个比较常见的方案、但还存在一些问题, <code>判定慢</code>.<br>eg. 所有的检测逻辑都需要一个超时时间N、执行update、超过Ns不返回、认为系统不可用.<br>但: 假设日志盘IO利用率已经100%, 这个时候系统响应很慢、需要主备切换. 但检测使用的update需要的资源很少、拿到io就可以提交成功、超时之前就返回了、于是得到了<code>系统正常</code>的结论, 显然这是不合理的判定.</p>
<p>四、内部统计<br>针对磁盘利用率、若Mysql 可以告知每次请求的io时间、就靠谱多了.<br>5.6版本以后的performance_schema库、file_summay_by_event_name表里就统计了每次IO请求时间.<br>event_name&#x3D;’wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file’ 统计的是redo log的写入时间. 第一列 event_name表示统计的类型.<br>接下来3组、统计的是redo log操作时间</p>
<p>第一组5列、是所有IO类型的统计:<br>count_star 是所有IO总次数<br>sum、min、avg、max是统计的总和、最小、平均和最大值.(单位ps)</p>
<p>第二组6列、是读操作的统计<br>最后一列 sum_number_of_bytes_read统计的是、总共从redo log读多少个字节</p>
<p>第三组6列, 是写操作统计</p>
<p>最后四组时间、是对其它类型数据的统计、在redo log里、可以认为是对 fsync的统计.</p>
<p>binlog对应的event_name是: wait&#x2F;io&#x2F;file&#x2F;sql&#x2F;binlog 这行、统计逻辑同 redo log. 额外的统计这些信息、是有性能耗损的、大概在10%左右. 建议只开启需要的项. </p>
<p>打开统计项之后、可以通过判断MAX_TIMER的值来判断数据库是否有问题.<br>eg. 设定阈值、单次IO超过200ms属于异常、出现异常把之前的统计值清空、再次出现这个异常就可以加入监控累计值了.</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>幻读是什么,-幻读有什么问题</title>
    <url>/2020/03/20/mysql_%E5%B9%BB%E8%AF%BB%E6%98%AF%E4%BB%80%E4%B9%88,-%E5%B9%BB%E8%AF%BB%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<blockquote>
<p>Innodb默认事务隔离级别是可重复读. 接下来的场景设定在可重复读隔离级别(特殊说明除外)</p>
</blockquote>
<p>一、幻读是什么 ?<br><img src="https://upload-images.jianshu.io/upload_images/14027542-a05959ed4d3c5fed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="假设只在id=5这行加锁.png"></p>
<ol>
<li>在Q1只返回id&#x3D;5这一行</li>
<li>在T2时刻、session B把id&#x3D;0 这行的d值改为5、T3时刻Q2查询出来 id&#x3D;5 和 id&#x3D;0 这两行</li>
<li>T4时刻、session C 又插入一行 (1,1,5), 因此T5时刻、查出 id&#x3D;0, 1, 5三行.<br>Q3读到id&#x3D;1 这一行的现象被称为<code>幻读</code>.</li>
</ol>
<p><code>幻读</code>: 一个事务在前后两次查询同一个范围的时候、后一次查询看到了前一次查询未看到的行. 两点说明: </p>
<ol>
<li>在可重复读隔离级别下、普通查询是快照读、不会看到别的事务插入数据, 所以、只会在当前读下才会出现.</li>
<li>幻读 仅指新插入的行被读到、修改后满足条件、而被读取到、不能称为<code>幻读</code>.</li>
</ol>
<p>二、幻读有什么问题 ?</p>
<ol>
<li>首先是语义上的. 前一次查询已经声明要把d&#x3D;5的行加锁、不许别的事务进行读写操作, 而幻读却破坏了这个语义.</li>
<li>是数据一致性的问题. 锁的设计是为了保证数据的一致性. 这个一致性、不止是数据库内部数据状态此刻的一致性、还包含了数据和日志在逻辑上的一致性.</li>
</ol>
<p>三、如何解决幻读?<br>产生幻读的原因是: 行锁只能锁住行、但是新插入记录这个动作、要更新的是记录之间的间隙、为了解决幻读、就引入了间隙锁(Gap Lock).<br>跟行锁产生冲突的是、另外一个行锁. 跟间隙锁存在冲突关系的是: 往间隙中插入一个记录这个操作. 间隙锁之间不存在冲突关系.<br><img src="https://upload-images.jianshu.io/upload_images/14027542-e275608aeb25fad2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="两种行锁之间的冲突关系.png"></p>
<p>间隙锁和行锁合称 next-key lock, 每个next-key lock是前开后闭的区间. 即: 若表t初始化后、若用select * from t for update. 将整个记录锁起来、就会形成7个next-key lock, 分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum].<br><img src="https://upload-images.jianshu.io/upload_images/14027542-84514755a22c141e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表t主键索引上的行锁和间隙锁.png"></p>
<p>但: 间隙锁的引入会降低db的并发度.</p>
<p>如果事务隔离级别是: RC(Read Committed)就不会有间隙锁了.<br>那线上业务该如何选择隔离级别呢 ?</p>
<ol>
<li>若读提交隔离级别够用、业务不需要可重复读的保证、这样考虑读提交下操作数据的锁范围更小(没有间隙锁), 这个选择是合理的.</li>
<li>业务逻辑使用读提交、逻辑备份时、mysqldump为什么把备份线程设置为 可重复读呢 ?</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>死锁日志分析</title>
    <url>/2020/03/20/mysql_%E6%AD%BB%E9%94%81%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h3 id="innodb基于系统参数开启监控"><a href="#innodb基于系统参数开启监控" class="headerlink" title="innodb基于系统参数开启监控"></a>innodb基于系统参数开启监控</h3><figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="keyword">set</span> <span class="keyword">global</span>  innodb_status_output=<span class="keyword">on</span>; <span class="comment">#开启innodb标准监控</span></span><br><span class="line"><span class="number">2.</span> <span class="keyword">set</span> <span class="keyword">global</span> innodb_status_output_locks=<span class="keyword">on</span>; <span class="comment"># 开启innodb锁监控</span></span><br><span class="line"><span class="number">3.</span> <span class="keyword">set</span> <span class="keyword">global</span> innodb_print_all_deadlocks=<span class="keyword">on</span>; <span class="comment"># 将死锁日志记录到错误日志文件</span></span><br></pre></td></tr></table></figure>

<h3 id="死锁分析"><a href="#死锁分析" class="headerlink" title="死锁分析"></a>死锁分析</h3><figure class="highlight gams"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span><span class="number">-05</span><span class="number">-21</span> <span class="number">21</span>:<span class="number">46</span>:<span class="number">44</span> <span class="number">7</span>f9ac2fff700</span><br><span class="line"><span class="comment">*** (1) TRANSACTION:</span></span><br><span class="line">TRANSACTION <span class="number">14234356386</span>, ACTIVE <span class="number">0</span> sec fetching rows</span><br><span class="line">mysql tables in use <span class="number">1</span>, locked <span class="number">1</span></span><br><span class="line">LOCK WAIT <span class="number">4</span> lock struct(s), heap size <span class="number">1184</span>, <span class="number">2</span> row lock(s)</span><br><span class="line">MySQL thread id <span class="number">101287388</span>, OS thread handle <span class="number">0x7f9ac472c700</span>, query id <span class="number">15913830552</span> <span class="number">10.20</span><span class="number">.00</span><span class="number">.217</span> zop Searching rows <span class="keyword">for</span> update</span><br><span class="line">update driver_statistics <span class="keyword">set</span> statistics_status=0 , statistics_time=NOW() <span class="comment">where statistics_status=1 and statistics_time &lt;= DATE_SUB(NOW(),INTERVA</span></span><br><span class="line">L <span class="comment">120 SECOND)</span></span><br><span class="line"><span class="comment">*** (1) WAITING FOR THIS LOCK TO BE GRANTED:</span></span><br><span class="line">RECORD <span class="comment">LOCKS space id 65 page no 203 n bits 208 index</span> `<span class="comment">PRIMARY</span>` <span class="comment">of table</span> `<span class="comment">platform</span>`<span class="comment">.</span>`<span class="comment">driver_statistics</span>` <span class="comment">trx id 14234356386 lock_mode X loc</span></span><br><span class="line">ks <span class="comment">rec but not gap waiting</span></span><br><span class="line"><span class="comment">*** (2) TRANSACTION:</span></span><br><span class="line">TRANSACTION <span class="comment">14234356375, ACTIVE 0 sec updating or deleting, thread declared inside InnoDB 0</span></span><br><span class="line">mysql <span class="comment">tables in use 1, locked 1</span></span><br><span class="line">3 lock <span class="comment">struct(s), heap size 1184, 2 row lock(s), undo log entries 1</span></span><br><span class="line">MySQL <span class="comment">thread id 101570708, OS thread handle 0x7f9ac2fff700, query id 15913830539 10.20.00.217 zop updating</span></span><br><span class="line">update <span class="comment">driver_statistics</span></span><br><span class="line">     <span class="keyword">SET</span> <span class="comment">status = 2,time =</span> <span class="comment">&#x27;2019-05-21 21:46:44.96&#x27;</span><span class="comment">,d_id = 44201,</span></span><br><span class="line">        d_phone <span class="comment">=</span> <span class="comment">&#x27;15601237231&#x27;</span><span class="comment">, d_name =</span> <span class="comment">&#x27;k&#x27;</span></span><br><span class="line">    where <span class="comment">id = 54145</span></span><br><span class="line"><span class="comment">*** (2) HOLDS THE LOCK(S):</span></span><br><span class="line">RECORD <span class="comment">LOCKS space id 65 page no 203 n bits 208 index</span> `<span class="comment">PRIMARY</span>` <span class="comment">of table</span> `<span class="comment">platform</span>`<span class="comment">.</span>`<span class="comment">driver_statistics</span>` <span class="comment">trx id 14234356375 lock_mode X loc</span></span><br><span class="line">ks <span class="comment">rec but not gap</span></span><br><span class="line"><span class="comment">*** (2) WAITING FOR THIS LOCK TO BE GRANTED:</span></span><br><span class="line">RECORD <span class="comment">LOCKS space id 65 page no 7749 n bits 1616 index</span> `<span class="comment">idx_statistics_status</span>` <span class="comment">of table</span> `<span class="comment">platform</span>`<span class="comment">.</span>`<span class="comment">driver_statistics</span>` <span class="comment">trx id 14234356375</span></span><br><span class="line"> lock_mode <span class="comment">X locks rec but not gap waiting</span></span><br><span class="line"><span class="comment">*** WE ROLL BACK TRANSACTION (2)</span></span><br><span class="line">------------</span><br></pre></td></tr></table></figure>

<h4 id="先看事务一的信息"><a href="#先看事务一的信息" class="headerlink" title="先看事务一的信息"></a>先看事务一的信息</h4><blockquote>
<p>***(1) TRANSACTION:<br>TRANSACTION 14234356386, ACTIVE 0 sec fetching rows</p>
</blockquote>
<p><code>active 0 sec</code> 表示事务活跃时间<br><code>fetching rows</code> 表示事务正在做的事儿</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">可能的事务有 inserting、updating、deleting、fetching <span class="built_in">rows</span>等</span><br></pre></td></tr></table></figure>
<blockquote>
<p>mysql tables in use 1, locked 1<br>LOCK WAIT 4 lock struct(s), heap size 1184, 2 row lock(s)</p>
</blockquote>
<p><code>mysql tables in use 1</code> 表示mysql有一个表被使用<br><code>locked 1</code> 表示有一个表锁<br><code>LOCK WAIT</code> 表示事务正在等待锁<br><code>4 lock struct(s)</code> 表示该事务的锁链表长度为 4, 表示该事务的锁链表的长度为 11，每个链表节点代表该事务持有的一个锁结构，包括表锁，记录锁以及 autoinc 锁等。<br><code>heap size 1184</code> 为事务分配的锁堆内存大小<br><code>2 row lock(s)</code> 表示当前事务持有的行锁个数, 通过遍历上边的4个锁结构、找到其中类型为LOCK_REC的记录数、</p>
<blockquote>
<p>MySQL thread id 101287388, OS thread handle 0x7f9ac472c700, query id 15913830552 10.20.00.217 zop Searching rows for update</p>
</blockquote>
<p><code>MySQL thread id .. OS...</code> 当前事务线程信息<br><code>10.20.00.217 zop</code> 数据库的ip和dbname<br><code>Searching rows for update</code> 当前事务的状态</p>
<blockquote>
<p>update d_statistics set statistics_status&#x3D;0, statistics_time&#x3D;now() where statistics_status&#x3D;1 and statistics_time &lt;&#x3D;date_sub(now(),interval 120 seconds)</p>
</blockquote>
<blockquote>
<p>当前正在执行的sql语句</p>
</blockquote>
<blockquote>
<p>*** (1) WAITING FOR THIS LOCK TO BE GRANTED:<br>RECORD LOCKS space id 65 page no 203 n bits 208 index <code>PRIMARY</code> of table <code>platform</code>.<code>driver_statistics</code> trx id 14234356386 lock_mode X loc<br>ks rec but not gap waiting</p>
</blockquote>
<p><code>lock_mode X</code> 表示改记录锁为排他锁<br><code>RECORD LOCKS</code> 表示正在等待的是记录锁<br><code>index PRIMARY</code> 表示要加锁的索引为主键索引<br><code>n bits 208</code> 表示这个记录锁结构上保留有208个bit位(改page上的记录数+64)、<br><code>lock_mode X</code>表示该记录锁为排他锁、<br><code>locks rec but not gap waiting</code>表示要加的锁为记录锁、并且处于锁等待状态</p>
<h4 id="再看事务二的分析"><a href="#再看事务二的分析" class="headerlink" title="再看事务二的分析"></a>再看事务二的分析</h4><p><code>undo log entries 1</code>表示当前事务有1个undo log记录、因为二级索引不记undo log、表示该事务更新了1个聚簇索引</p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="title"> (2) HOLDS THE LOCK(S):</span></span><br><span class="line">RECORD LOCKS space id <span class="number">65</span> page no <span class="number">203</span> n bits <span class="number">208</span> index `PRIMARY` of table `platform`.`driver_statistics` trx id <span class="number">14234356375</span> lock_mode X loc</span><br><span class="line">ks rec but <span class="literal">not</span> gap</span><br></pre></td></tr></table></figure>
<p>表示事务2 持有主键索引的X记录锁、</p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="title">(2) WAITING FOR THIS LOCK TO BE GRANTED:</span></span><br><span class="line">RECORD LOCKS space id <span class="number">65</span> page no <span class="number">7749</span> n bits <span class="number">1616</span> index `idx_statistics_status` of table `platform`.`driver_statistics` trx id <span class="number">14234356375</span></span><br><span class="line"> lock_mode X locks rec but <span class="literal">not</span> gap waiting</span><br></pre></td></tr></table></figure>
<p>表示事务2正在等待二级索引上的X记录锁</p>
<h4 id="mysql-加锁方式"><a href="#mysql-加锁方式" class="headerlink" title="mysql 加锁方式"></a>mysql 加锁方式</h4><p><a href="https://www.aneasystone.com/archives/2017/11/solving-dead-locks-two.html">https://www.aneasystone.com/archives/2017/11/solving-dead-locks-two.html</a></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">批量<span class="keyword">update</span>时、mysql <span class="keyword">server</span>会根据<span class="keyword">where</span>条件读取第一条满足条件的记录、innodb引擎返回第一条记录、并加锁(<span class="keyword">current</span> <span class="keyword">read</span>)、待mysql <span class="keyword">server</span>收到这条加锁的记录后、再发起<span class="keyword">update</span>请求、更新记录</span><br><span class="line"><span class="keyword">server</span>和innodb的交互是一条一条进行的、加锁也是一条一条进行的、</span><br><span class="line">在给二级索引加X锁的同时、会给主键索引也加上X锁、</span><br><span class="line">记录锁是加在索引上的、若表未建索引、db也会隐式的创建一个索引</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">若<span class="keyword">sql</span>无法使用索引时会走主索引实现全表扫描、mysql会给全表所有的记录行加记录锁、若一个<span class="keyword">where</span>条件无法索引快速过滤、存储引擎就会将所有的记录加锁后返回、mysql <span class="keyword">server</span>在进行过滤时、若发现不满足、会调用unlock_row把不满足的记录释放、但是每条记录的加锁操作还是不能省略的、so在没有索引时、会消耗大量的锁资源、增加db开销、降低db的并发性</span><br><span class="line"></span><br><span class="line">RC级别不会加间隙锁</span><br></pre></td></tr></table></figure>

<h4 id="加锁情况分析"><a href="#加锁情况分析" class="headerlink" title="加锁情况分析"></a>加锁情况分析</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 主键索引命中:</span><br><span class="line"><span class="code">    RR和RC 一样、都只加记录锁</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">2.</span> 主键索引非命中</span><br><span class="line"><span class="code">    RC不加锁、RR加 gap 锁</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">3.</span> 唯一二级索引、查询命中</span><br><span class="line">   RC和RR都只加记录锁、加二级索引锁的同时会加主键索引锁</span><br><span class="line"></span><br><span class="line"><span class="bullet">4.</span> 唯一二级索引、查询非命中</span><br><span class="line">   RC不加锁、RR会加GAP锁、但只加二级索引、不加主键索引</span><br><span class="line"></span><br><span class="line">5.二级非唯一索引、查询命中</span><br><span class="line">  RC会加记录锁、RR还会加GAP锁、</span><br><span class="line"></span><br><span class="line">6.二级非唯一索引、查询未命中</span><br><span class="line">  RC不加锁、RR会加GAP锁、</span><br><span class="line"></span><br><span class="line"><span class="bullet">7.</span> 无索引</span><br><span class="line">   若where条件不能走索引、只能走全表扫描</span><br><span class="line">   RC会给所有记录加行锁、RR会给所有记录加行锁 + 所有聚簇索引之间加GAP锁</span><br><span class="line"></span><br><span class="line">8.聚簇索引范围查询</span><br><span class="line">   包含等于时、会给下一条记录也加上next-key lock</span><br><span class="line"></span><br><span class="line">9.二级索引范围查询</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://www.aneasystone.com/archives/2018/04/solving-dead-locks-four.html">https://www.aneasystone.com/archives/2018/04/solving-dead-locks-four.html</a><br><a href="https://www.aneasystone.com/archives/2017/12/solving-dead-locks-three.html">https://www.aneasystone.com/archives/2017/12/solving-dead-locks-three.html</a><br><a href="https://blog.csdn.net/enweitech/article/details/52447006">https://blog.csdn.net/enweitech/article/details/52447006</a><br><a href="https://blog.csdn.net/miyatang/article/details/78227344">https://blog.csdn.net/miyatang/article/details/78227344</a><br><a href="https://time.geekbang.org/column/article/75659">https://time.geekbang.org/column/article/75659</a><br><a href="https://my.oschina.net/u/2408025/blog/535941">https://my.oschina.net/u/2408025/blog/535941</a><br><a href="https://dbarobin.com/2015/01/27/innodb-lock-wait-under-mysql-5.5/">https://dbarobin.com/2015/01/27/innodb-lock-wait-under-mysql-5.5/</a><br><a href="https://www.aneasystone.com/archives/2018/04/solving-dead-locks-four.html">https://www.aneasystone.com/archives/2018/04/solving-dead-locks-four.html</a><br><a href="https://www.cnblogs.com/LBSer/p/5183300.html">https://www.cnblogs.com/LBSer/p/5183300.html</a></p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>误删数据库后该怎么办</title>
    <url>/2020/03/25/mysql_%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8E%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</url>
    <content><![CDATA[<blockquote>
<p> 误删数据库后除了跑路、还能怎么办 ?</p>
</blockquote>
<h4 id="使用delete误删数据行"><a href="#使用delete误删数据行" class="headerlink" title="使用delete误删数据行"></a>使用delete误删数据行</h4><p>可以使用Flashback工具把数据恢复. 原理是: 修改binlog的内容、拿回原库重放. 前提是: 确保 binlog_format&#x3D;row 和 binlog_row_image&#x3D;FULL.</p>
<h5 id="单行事务处理"><a href="#单行事务处理" class="headerlink" title="单行事务处理:"></a>单行事务处理:</h5><p> insert: binlog event的类型 Write_rows event -&gt; Delete_rows event</p>
<p> delete: 反之</p>
<p> update: 对调binlog位置即可</p>
<h5 id="多行事务"><a href="#多行事务" class="headerlink" title="多行事务:"></a>多行事务:</h5><p>(A)delete … (B)insert … (C)update …</p>
<p>写回的顺序应该是: </p>
<p>(revert C)update … (revert B)delete … (revert A)insert …</p>
<p>但: 以上方案只能作为<code>万一</code>的紧急预案、平时应该尽可能的做到提前预防、建议:</p>
<p> 把sql_safe_updates 参数设置为 on、这样一来、若忘记在delete或者update时写where条件、或者where条件中不包含索引字段的话、SQL执行会报错</p>
<p> 代码上线前、必须经过SQL审计</p>
<p><strong>注意:</strong> </p>
<p>\1. delete 全表是很慢的、需要生成undo log、写 redo log、binlog、从性能角度来看、应该优先考虑 truncate table或者drop table.</p>
<p>\2. truncate&#x2F;drop table, drop database,即时配置binlog_format&#x3D;row、执行这3个命令、记录的还是statement</p>
<h4 id="使用drop-table或者truncate-table误删数据表"><a href="#使用drop-table或者truncate-table误删数据表" class="headerlink" title="使用drop table或者truncate table误删数据表"></a>使用drop table或者truncate table误删数据表</h4><p>这种情况就要使用全量备份 + 增量日志的方式了, 必须要有定期的全量备份, 并实时备份binlog才行. 两者都具备时、恢复流程:</p>
<ol>
<li><p>取最近一次全量备份、假设是一天一备、上次备份是当天凌晨</p>
</li>
<li><p>用备份恢复出一个临时库</p>
</li>
<li><p>从日志备份里、取出0点之后的日志</p>
</li>
<li><p>把这些日志、除了误删数据的语句之外、全部应用到临时库.</p>
</li>
</ol>
<p><strong>注意:</strong></p>
<ol>
<li><p>为了加快数据恢复、若临时库有多个数据库、可在使用mysqlbinlog时、加上-database指定库.</p>
</li>
<li><p>应用日志时、需要跳过误操作语句的binlog、</p>
</li>
</ol>
<p>  非gtid: –stop-position执行到误操作之前的日志、–start-position再从它之后开始操作</p>
<p>  gtid: 假设误操作的gtid是gtid1, set gtid_next&#x3D;gtid1;begin;commit; 将gtid1先加入gtid集合、之后按顺序执行binlog时、会自动跳过误操作的语句.</p>
<p>不过、即使这样、mysqlbinlog方法恢复数据还是不够快、因为:</p>
<ol>
<li><p>mysqlbinlog不能只解析其中一个表的日志</p>
</li>
<li><p>mysqlbinlog解析出日志、应用日志的过程只能是单线程.</p>
</li>
</ol>
<p>一种加速方法是: 在用备份恢复出临时实例之后、将这个临时库设为线上备库的从库、这样:</p>
<ol>
<li><p>在start slave之前、先通过执行 change replication filter replication_do_table &#x3D; tb、就可以让临时表只同步误操作的表</p>
</li>
<li><p>也可以用上并行复制、加速数据恢复</p>
</li>
</ol>
<h4 id="使用drop-database误删数据库"><a href="#使用drop-database误删数据库" class="headerlink" title="使用drop database误删数据库"></a>使用drop database误删数据库</h4><h5 id="搭建延迟备库"><a href="#搭建延迟备库" class="headerlink" title="搭建延迟备库:"></a>搭建延迟备库:</h5><p>虽然可以通过并行复制来加速恢复数据、但恢复时间依然不可控, 若一个库的备份特别大、或者距离上一个全量备份的时间较长、恢复时间就特别长、若核心业务是无法等待这么久的、可以考虑搭建延迟复制的备库(MySQL 5.6引入)</p>
<p>change master to master_delay&#x3D;n, 让备库与主库有Ns的延迟.</p>
<p>eg. 设为3600s、代表若主库数据被删、且在1h内发现、其它备库已同时被删除时、可到延迟复制备库执行 stop slave、跳过误删除目录、恢复出需要的数据.</p>
<h5 id="预防误删库的方法"><a href="#预防误删库的方法" class="headerlink" title="预防误删库的方法:"></a>预防误删库的方法:</h5><ol>
<li><p>账号分离、避免写错命令</p>
</li>
<li><p>指定操作规范. 避免写错要删除的表名. 先重命名待删除表、业务无影响再操作删除</p>
</li>
</ol>
<h4 id="使用rm命令、误删数据库实例"><a href="#使用rm命令、误删数据库实例" class="headerlink" title="使用rm命令、误删数据库实例"></a>使用rm命令、误删数据库实例</h4><p>对一个有HA机制的Mysql集群、只要不恶意删除整个集群、只删除单节点的话、HA系统会开始工作、选出一个新的主库、保证集群正常工作. 这时、需要把节点数据恢复、再接入整个集群.</p>
<p>建议: 尽量把备份跨机房、最好跨城市保存.</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis读书笔记</title>
    <url>/2020/03/20/redis_Redis%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<!-- MarkdownTOC -->

<ul>
<li>一些说明</li>
<li>书籍资源</li>
</ul>
<!-- /MarkdownTOC -->


<h4 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a>一些说明</h4><figure class="highlight llvm"><table><tr><td class="code"><pre><span class="line">最近读了一本书、感觉有些部分还不错、希望分享出来、</span><br><span class="line">是读书笔记、可能提炼度不够、希望以后的自己做的越来越好~~.~~</span><br><span class="line">书籍：Redis<span class="number">-4</span>.<span class="keyword">x</span> CookBook</span><br><span class="line">除特别说明外、本系列文档都是针对 redis <span class="number">4</span>.<span class="keyword">x</span> 的版本</span><br></pre></td></tr></table></figure>

<h4 id="书籍资源"><a href="#书籍资源" class="headerlink" title="书籍资源"></a>书籍资源</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">原项目代码git托管地址：</span><br><span class="line">https:<span class="regexp">//gi</span>thub.com<span class="regexp">/PacktPublishing/</span>Redis-<span class="number">4</span>.x-Cookbook</span><br><span class="line"></span><br><span class="line">书中相关图文：</span><br><span class="line">https:<span class="regexp">//</span>www.packtpub.com<span class="regexp">/sites/</span>default<span class="regexp">/files/</span>downloads/Redis4xCookbook_ColorImages.pdf</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis数据结构-字典</title>
    <url>/2020/04/24/redis_dict/</url>
    <content><![CDATA[<blockquote>
<p>字典又称<code>符号表</code>, <code>关联数组</code>, <code>映射</code>, 是一种用于保存键值对的抽象数据结构</p>
<p>Redis构建了自己的字典实现, eg. set msg ‘test’会构建<code>key</code>为<code>msg</code>, <code>value</code>为<code>test</code>的键值对.</p>
<p>除了表示数据库之外, 字典还是hash键的底层实现之一(另外一种是ziplist)</p>
</blockquote>
<h4 id="字典实现"><a href="#字典实现" class="headerlink" title="字典实现"></a>字典实现</h4><h5 id="hash表"><a href="#hash表" class="headerlink" title="hash表"></a>hash表</h5><p>Redis字典所使用的哈希表由 dict.h&#x2F;dictht 结构定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">  dictEntry **table; <span class="comment">// hash表数组</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span> size; <span class="comment">// hash表大小</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span> sizemask; <span class="comment">// hash表大小掩码, 用于计算hash索引值, 总是=size-1</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span> used; <span class="comment">// 已有节点数量</span></span><br><span class="line">&#125;dictht;</span><br></pre></td></tr></table></figure>

<p><img src="/images/image-hash.png" alt="空hash表结构示意"></p>
<h5 id="hash表节点"><a href="#hash表节点" class="headerlink" title="hash表节点"></a>hash表节点</h5><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">  <span class="type">void</span> *key; <span class="comment">// 键</span></span><br><span class="line">  <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">    <span class="type">void</span> *val;</span><br><span class="line">    unit64_tu64;</span><br><span class="line">    int64_ts64;</span><br><span class="line">  &#125;v; <span class="comment">// 值</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span><span class="comment">// 指向下个hash节点、形成链表</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>key</code>属性保存着键值对中的键、而<code>v</code>属性则保存着键值对中的值, 它可以是一个<code>指针</code>, 或者是<code>uint64_t</code>类型的整数, 或者是 <code>int64_t</code>的整数</p>
<p><code>next</code>属性是指向另一个节点的指针, 这个指针可以将多个hash值相同的键值对连接在一起, 解决键冲突问题</p>
<h5 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h5><p>Redis中的字典由 <code>dict.h/dict</code> 结构定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span> &#123;</span></span><br><span class="line">  dictType *type; <span class="comment">// 类型特定函数</span></span><br><span class="line">  <span class="type">void</span> *privdata; <span class="comment">// 私有数据</span></span><br><span class="line">  dictht ht[<span class="number">2</span>]; <span class="comment">// hash表</span></span><br><span class="line">  in trehashidx; <span class="comment">// rehash索引, 当rehash不在进行时、值为-1</span></span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure>

<p><code>type</code>属性是一个指向 <code>dictType</code>结构的指针, 每个 dictType结构保存了一簇用于操作特定类型键值对的函数, Redis会为不同类型的字典设置不同类型的特定函数</p>
<p><code>privdata</code>属性则保存了需要传给那些特定类型函数的可选参数</p>
<p><code>type</code>和<code>privdata</code>是针对不同类型的键值对, 为创建多态字典设置的</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictType</span> &#123;</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="title function_">int</span> <span class="params">(*hashFunction)</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *key)</span>; <span class="comment">// 计算hash值的函数</span></span><br><span class="line">  <span class="type">void</span> *(*keyDup)(<span class="type">void</span> *privdata, <span class="type">const</span> <span class="type">void</span> *key); <span class="comment">// 复制键的函数</span></span><br><span class="line">  <span class="type">void</span> *(valDup)(<span class="type">void</span> *privdata, <span class="type">const</span> <span class="type">void</span> *obj); <span class="comment">// 复制值的函数</span></span><br><span class="line">  <span class="type">int</span> (*keyCompare)(<span class="type">void</span> *privdata, <span class="type">const</span> <span class="type">void</span> *key1, <span class="type">const</span> <span class="type">void</span> *key2); <span class="comment">// 对比键的函数</span></span><br><span class="line">  <span class="type">void</span> (*keyDestructor)(<span class="type">void</span> *privdata, <span class="type">void</span> *key); <span class="comment">// 销毁键的函数</span></span><br><span class="line">  <span class="type">void</span> (*valDestructor)(<span class="type">void</span> *privdata, <span class="type">void</span> *obj); <span class="comment">// 销毁值的函数</span></span><br><span class="line">&#125;dictType;</span><br></pre></td></tr></table></figure>

<p><code>ht</code>属性是一个包含两个项的数组, 数组中的每个项都是一个dictht哈希表, 一般只使用ht[0], ht[1]只会在对ht[0] 进行<code>rehash</code>时使用.</p>
<p><code>rehashidx</code>记录当前<code>rehash</code>的进度, 若没有在进行<code>rehash</code>, 则值为 <code>-1</code></p>
<h5 id="完整的dict结构"><a href="#完整的dict结构" class="headerlink" title="完整的dict结构"></a>完整的dict结构</h5><p><img src="/images/image-dict.png" alt="dict结构示意"></p>
<h4 id="hash算法"><a href="#hash算法" class="headerlink" title="hash算法"></a>hash算法</h4><p>Redis计算hash值的方式如下:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">hash = dict-&gt;type-&gt;hashFunction(key); <span class="comment">// 使用hash字典设置的hash函数、计算key的hash值</span></span><br><span class="line">index = hash &amp; dict-&gt;ht[x].sizemask; <span class="comment">// 根据sizemask和hash值、计算出hash索引</span></span><br></pre></td></tr></table></figure>

<h4 id="解决键冲突"><a href="#解决键冲突" class="headerlink" title="解决键冲突"></a>解决键冲突</h4><p>当有两个或以上数量的键被分配到hash表数组同一个索引上时, 称为<code>键冲突 collision</code>, Redis的hash表使用 <code>链地址法</code>(<code>separate chaining</code>)来解决冲突, 每个hash表节点上有一个next指针, 多个hash表节点使用next指针构成单链表</p>
<p><code>dictEntry</code>总是将新增节点添加到链表头部(时间复杂度为 O(1)), 因为没有tail指针.</p>
<h4 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h4><p>随着操作的不断进行、hash表维护的键值对会增加或减少, 为了让hash表的负载因子(load factor)维持在一个合理的额范围, 当hash表保存键值对数量太大或太小时, 程序需要对hash表扩容或缩容, 扩容或缩容通过<code>rehash</code>进行, <code>Rehash</code>步骤如下:</p>
<ol>
<li>为字典的ht[1]hash表分配空间, hash表的空间大小取决于要执行的操作, 及ht[0]当前包含的键值对的数量(即: ht[0].used 属性值), 若为扩容, ht[1] 为第一个大于等于 (ht[0].used<code>*</code>2)d的*2<sup>n</sup>; 若为缩容, ht[1] 为第一个大于等于 (ht[0].used) 的 2<sup>n</sup> </li>
<li>将ht[0]中的所有键值对rehash到ht[1]上, <code>rehash</code>是指: 重新计算键的hash值和索引值, 然后将键值对放到ht[1]hash表的对应位置</li>
<li>当ht[0]包含的所有键值对迁移到ht[1]之后(ht[0]变为空表), 释放ht[0], 将ht[1]设置为 ht[0], 并在 ht[1]新创建一个空白hash表, 为下一次rehash做准备</li>
</ol>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">eg. 扩容操作:</span><br><span class="line">ht<span class="selector-attr">[0]</span><span class="selector-class">.used</span> = <span class="number">4</span>, <span class="number">4</span>*<span class="number">2</span>=<span class="number">8</span>, 恰好是第一个大于等于<span class="number">4</span>的<span class="number">2</span>的n次方, 所以rehash后、ht<span class="selector-attr">[1]</span>size为<span class="number">8</span></span><br><span class="line"></span><br><span class="line">缩容操作:</span><br><span class="line">ht<span class="selector-attr">[0]</span><span class="selector-class">.used</span> = <span class="number">4</span>, <span class="number">4</span>=<span class="number">2</span>², 恰好是第一个大于等于<span class="number">4</span>的<span class="number">2</span>的n次方, rehash后 ht<span class="selector-attr">[1]</span><span class="selector-class">.size</span> = <span class="number">4</span></span><br></pre></td></tr></table></figure>



<h5 id="hash表的扩展与收缩"><a href="#hash表的扩展与收缩" class="headerlink" title="hash表的扩展与收缩"></a>hash表的扩展与收缩</h5><p>满足下述任意条件时, 会自动扩展:</p>
<ol>
<li><p>server 当前未执行<code>bgsave</code> 或者 <code>bgrewriteaof</code>, 且hash表的负载因子大于等于1</p>
</li>
<li><p>server 当前正在执行<code>bgsave</code> 或者 <code>bgrewriteaof</code>, 且 hash表的负载因子大于等于 5</p>
<p>(持久化时、优先持久化操作)</p>
</li>
</ol>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">load_factor = ht[<span class="number">0</span>].used / ht[<span class="number">0</span>].size; <span class="comment">// 负载因子 = hash表已保存节数量 / hash表大小</span></span><br></pre></td></tr></table></figure>

<p><strong>若<code>bgsave</code>或者<code>bgrewriteaof</code>执行时, Redis需要创建当前服务器进程的子进程, 大多数操作系统使用写时复制(<code>copy-on-write</code>)优化子进程使用效率, 所以子进程存在期间, Server会提高rehash操作的负载因子, 尽可能避免此时rehash, 避免不必要的内存写入操作, 最大限度的节省内存.</strong></p>
<p><strong>另外:</strong></p>
<p>hash表的负载因子小于<code>0.1</code>时, 程序会自动缩容</p>
<h4 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a>渐进式rehash</h4><blockquote>
<p>其实, hash表的rehash操作、不是一次集中完成的, 而是多次迭代进行的. 因为若 ht[0]里保存的key有百万计, 甚至更多, 一次rehash导ht[1], 庞大的计算量可能会导致Server一段时间的停止服务.</p>
</blockquote>
<p>渐进式rehash步骤如下:</p>
<ol>
<li>为ht[1]分配空间, 让字典同时持有ht[0] 和 ht[1]两个hash表</li>
<li>在字典中维护一个索引计数器变量 <code>rehashidx</code>, 设置为0, 表示<code>rehash</code>已经开始</li>
<li>在<code>rehash</code>期间, 每次对字典<code>add</code>, <code>del</code>, <code>find</code> or <code>update</code>操作, 程序除了执行指定操作外, 还会顺带将 ht[0] hash表在 <code>rehashidx</code>索引上的所有键值对 rehash 到 ht[1], rehash完成、将<code>rehashidx++</code>.</li>
<li>随字典操作的不断执行、某个时间点, ht[0]的所有键值对rehash到ht[1], rehash完成、将 <code>rehashidx</code>设为 <code>-1</code>.</li>
</ol>
<p>渐进式rehash过程中会维护 ht[0] 和 ht[1] 两个hash表, 字典的删除、查找、更新等操作都会在两个hash表上进行, eg. 查找: 会先在 ht[0] 上查找、若未找到则 到 ht[1] 上查找</p>
<p>但: 插入操作只会在 ht[1] 上操作</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">ht = dictIsRehashing(d) ? &amp;d-&gt;ht[<span class="number">1</span>] : &amp;d-&gt;ht[<span class="number">0</span>];</span><br></pre></td></tr></table></figure>



<h5 id="字典API"><a href="#字典API" class="headerlink" title="字典API"></a>字典API</h5><table>
<thead>
<tr>
<th>函数</th>
<th>作用</th>
<th>时间复杂度</th>
</tr>
</thead>
<tbody><tr>
<td>dictCreate</td>
<td>创建一个新的字典</td>
<td>O(1)</td>
</tr>
<tr>
<td>dictAdd</td>
<td>将给定键值对添加到字典</td>
<td>O(1)</td>
</tr>
<tr>
<td>dictReplace</td>
<td>添加or替换</td>
<td>O(1)</td>
</tr>
<tr>
<td>dictFetchValue</td>
<td>返回给定键的值</td>
<td>O(1)</td>
</tr>
<tr>
<td>dictGetRandomKey</td>
<td>随机返回一个键值对</td>
<td>O(1)</td>
</tr>
<tr>
<td>dictRelease</td>
<td>释放给定字典, 及字典中包含的所有键值对</td>
<td>O(N), N为值的数量</td>
</tr>
</tbody></table>
<h4 id="dict总结"><a href="#dict总结" class="headerlink" title="dict总结"></a>dict总结</h4><ul>
<li>广泛用于实现Redis的各种功能, 包括数据库和hash键</li>
<li>作为hash表的底层实现, 每个字典有两个hash表、一个平时使用, 一个 rehash 时使用</li>
<li>使用 <code>Murmurhash2</code> 计算key的hash值</li>
<li>使用链地址法解决键冲突、同一个索引上的多个键值对连接成一个单链表</li>
<li>rehash是渐进式完成、非一次性工作</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis数据结构-链表</title>
    <url>/2020/04/24/redis_list/</url>
    <content><![CDATA[<blockquote>
<p>链表提供了高效的节点重排能力, 及顺序性节点访问方式, Redis构建了自己的链表实现</p>
</blockquote>
<h4 id="链表和链表节点的实现"><a href="#链表和链表节点的实现" class="headerlink" title="链表和链表节点的实现"></a>链表和链表节点的实现</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span>&#123;</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">prev</span>;</span> <span class="comment">// 前置节点</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">next</span>;</span> <span class="comment">// 后置节点</span></span><br><span class="line">  <span class="type">void</span> *value; <span class="comment">// 节点值</span></span><br><span class="line">&#125;listNode;</span><br></pre></td></tr></table></figure>

<p>多个<code>listNode</code>节点通过 <code>prev</code> 和 <code>next</code>指针组成双端链表, 虽然仅使用多个listNode就可以组成链表, 使用 <code>adlist.h/list</code> 来持有链表会更方便操作.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span>&#123;</span></span><br><span class="line">  listNode *head; <span class="comment">// 表头节点</span></span><br><span class="line">  listNode *tail; <span class="comment">// 表尾结点</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span> len; <span class="comment">// 链表包含的节点数量</span></span><br><span class="line">  <span class="type">void</span> *(*dup)(<span class="type">void</span> *ptr); <span class="comment">// 节点值复制函数</span></span><br><span class="line">  <span class="type">void</span> (*<span class="built_in">free</span>)(<span class="type">void</span> *ptr); <span class="comment">// 节点值释放函数</span></span><br><span class="line">  <span class="type">int</span> (*match)(<span class="type">void</span> *ptr, <span class="type">void</span> *key); 节点值对比函数</span><br><span class="line">&#125; <span class="built_in">list</span>;</span><br></pre></td></tr></table></figure>

<p>list结构为链表提供了表头指针head、表尾指针tail, 及链表长度计数器len, 而udp, free, match成员则用于实现多态链表所需特定函数.</p>
<h5 id="Redis-链表实现特性总结"><a href="#Redis-链表实现特性总结" class="headerlink" title="Redis 链表实现特性总结"></a>Redis 链表实现特性总结</h5><ul>
<li>双端: 有<code>prev</code>和<code>next</code>指针, 获取前置和后置节点的复杂度都是O(1)</li>
<li>无环: 表头的<code>prev</code>和表尾的<code>next</code>都指向<code>NULL</code>, 对链表的访问以<code>NULL</code>为终点</li>
<li>带表头和表尾指针: 通过list结构的head和tail指针获取链表的头结点和尾结点复杂度为 O(1)</li>
<li>带长度计数器: 程序使用list结构的len属性对list节点计数, 获取节点数量的复杂度O(1)</li>
<li>多态: 链表节点使用 <code>void *</code>指针保存节点值, 可通过list结构的<code>dup</code>, <code>free</code>, <code>match</code>三个属性为节点值设置类型特定的函数, 所以链表可用来保存不同类型的节点值</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>读写分离有哪些坑</title>
    <url>/2020/03/20/mysql_%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E6%9C%89%E5%93%AA%E4%BA%9B%E5%9D%91-/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-9443eea1ca9ff032.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="读写分离基本架构.png"></p>
<blockquote>
<p>读写分离的主要目标是: 分摊主库的压力. 一般有两种架构. 客户端主动做负载 和 proxy做负载.</p>
</blockquote>
<p>两种负载方式的差异:</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="built_in">Client</span>负载、少了一层proxy转发、查询性能稍微好一些、且整体架构简单、排查问题方便、</span><br><span class="line">但与DB层耦合性高、若出现主备切换或者库迁移、<span class="built_in">Client</span>需要调整连接信息</span><br><span class="line"><span class="number">2.</span> proxy负载. 对<span class="built_in">Client</span>友好、但proxy本身也需要高可用架构、整体架构设计较复杂.</span><br></pre></td></tr></table></figure>
<p>不管采用哪种负载方式, 都会存在<code>从库读到系统过期状态</code>的现象, 称为<code>过期读</code>.<br>那么、如何解决过期读呢 ?<br>一、强制走主库<br>其实就是将查询分类、对于必须拿到最新结果的请求、强制转发到主库; 对于可以接受稍微延迟的请求、转发给从库. 但: 极端情况下、可能所有的请求都不能接受延迟、这样所有请求都打到主库、就失去了扩展性.</p>
<p>二、sleep一段时间<br>eg. 查询数据之前、先强制等待一段时间、但会失去用户体验度. 不过可以折中、用Ajax将客户端输入内容直接展示在页面上、而不去查询DB.<br>存在的问题是: </p>
<ol>
<li>若查询本可以0.5s就从从库拿到结果、也会等1s</li>
<li>若延迟超过1s、还是会出现过期读.</li>
</ol>
<p>三、判断主备无延迟</p>
<ol>
<li><p>每次从库查询前、先判断<code>seconds_behind_master</code>值、直到&#x3D;0、才执行查询请求.</p>
</li>
<li><p>对比位点、确保主备无延迟<br><code>master_log_file</code> 和 <code>read_master_log_pos</code>, 表示读到的主库的最新位点<br><code>relay_master_log_file</code> 和 <code>exec_master_log_pos</code>表示备库执行的最新位点<br>这两组值完全相同时、表示接收的日志已完成同步.</p>
</li>
<li><p>对比gtid<br><code>auto_position</code>&#x3D;1, 表示主备关系使用了gtid协议<br><code>retrieved_gtid_set</code>, 表示的是备库收到的所有日志gtid集合<br><code>executed_gtid_set</code>, 是备库已经执行完成的gtid集合<br>这两个集合相同、表示接收到的日志已同步完成.</p>
<p> 2、3两个方案都是基于<code>备库接收到的日志</code>执行完成了、但还有一部分日志是: Client已经收到提交确认、但备库还未收到日志的状态、所以, 比1要好些、但未达到精准的程度.</p>
</li>
</ol>
<p>四、配合semi-sync方案<br>对于上边的问题、可以解决不? 利用版同步复制、<code>semi-sync replication</code>可以.<br><code>semi-sync</code>设计:</p>
<ol>
<li>事务提交时、将binlog发给从库</li>
<li>从库收到binlog、给主库发送一个ack、代表收到了</li>
<li>主库收到ack以后、才返回给客户端<code>事务完成</code>的确认.<br>这样, 使用semi-sync配合前边的位点判断、就可以确定从库上执行的查询请求、避免过期读</li>
</ol>
<p>但: 一主多从的场景下、主库只要等到一个从库的ack、就开始对Client返回确认、这时可能会存在过期读(查询请求落到了非确认的从库上)</p>
<p>判断同步位点还有一个潜在问题: 若业务更新的高峰期、可能出现主库的位点或者GTID集合更新很快、导致位点等着判断一直不成立、从库迟迟无法响应的情况. 其实、我们并不需要完全同步、只希望要查询的数据已经同步即可.</p>
<p>五、等主库位点<br>可以解决上边两个问题:</p>
<ol>
<li>一主多从时、部分从库过期读</li>
<li>过度等待<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> master_pos_wait(file, pos[, timeout]);</span><br></pre></td></tr></table></figure>
执行逻辑:</li>
<li>从库上执行</li>
<li>file 和 pos 指主库上的文件名 和 位置</li>
<li>timeout 可选、设为正整数N表示这个函数最多等待N秒<br>正常返回一个正整数M、表示从命令开始执行、到应用完file和pos代表的binlog位置、执行了多少事务.<br>其它返回值:</li>
<li>null、表示执行期间、备库同步线程发生异常</li>
<li>-1、超过等待时间Ns</li>
<li>0、刚开始执行时、发现该位置已经执行过了.<br>则、查询逻辑变成了:<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> trx1更新完成后、马上执行 show master status 得到当前主库执行到的File 和 Pos</span><br><span class="line"><span class="bullet">2.</span> 选择一个从库执行查询语句</span><br><span class="line"><span class="bullet">3.</span> 在从库上执行 select master<span class="emphasis">_pos_</span>wait(File, Pos, 1);</span><br><span class="line"><span class="bullet">4.</span> 若返回值是&gt;=0的正整数、则在该从库查询、否则到主库查询</span><br><span class="line">同样存在的问题是: 若所有从库都延迟了、查询压力会打到主库</span><br></pre></td></tr></table></figure>
一般对于不允许过期读的要求、有两种方案: 超时放弃 和 转到主库, 要根据业务选择.</li>
</ol>
<p>六、等GTID<br>若开启GTID模式、同样有等待GTID的方案</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> wait_for_executed_gtid_set(gtid_set, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>执行逻辑:</p>
<ol>
<li>等待、直到该库执行的事务中包含传入的gtid_set、返回0</li>
<li>超时返回1<br>5.7.6版本开始、可以把事务的gtid返回给客户端<br>此时、等GTID的执行流程就变成:<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> trx1事务更新完后、从返回包之间获取事务的gtid、记为gtid1</span><br><span class="line"><span class="bullet">2.</span> 选定一个从库执行查询语句</span><br><span class="line"><span class="bullet">3.</span> 在从库上执行 select wait<span class="emphasis">_for_</span>Executed<span class="emphasis">_gtid_</span>set(gtid1, 1);</span><br><span class="line"><span class="bullet">4.</span> 若返回0、则在该从库执行查询、否则、到主库执行查询.</span><br></pre></td></tr></table></figure>
问题跟等位点的一样、选择超时放弃还是转到主库查询、要根据业务场景选择.</li>
</ol>
<p>思考:</p>
<blockquote>
<p>若系统采用的是等待GTID的方案、此时要对一个大表做DDL、可能会出现什么情况呢? 为避免这种情况、改怎么做呢 ?</p>
</blockquote>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">    这是一个典型的大事务的场景、若该DDL语句在主库执行了<span class="number">10</span><span class="built_in">min</span>、提交到备库、也需要执行<span class="number">10</span><span class="built_in">min</span>、</span><br><span class="line">那么在主库DDL之后再提交的事务的GTID、去备库查的时候、就会等待<span class="number">10</span><span class="built_in">min</span>才出现. 这样这个读写分离机制</span><br><span class="line">至少<span class="number">10</span><span class="built_in">min</span>内都会超时、既然是预期内的操作、应该在业务低峰期进行、确保主库可以支撑所有的业务查询、</span><br><span class="line">然后把请求都切到主库、再在主库上做DDL.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>redis功能梳理</title>
    <url>/2020/03/20/redis_redis%E5%8A%9F%E8%83%BD%E6%A2%B3%E7%90%86/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-36a967723586a0bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>redis基础命令</title>
    <url>/2020/03/20/redis_redis%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h4 id="redis基础命令"><a href="#redis基础命令" class="headerlink" title="redis基础命令"></a>redis基础命令</h4><figure class="highlight xquery"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 返回给定pattern的所<span class="built_in">有key</span></span><br><span class="line">   keys *</span><br><span class="line">   keys list*</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 确<span class="built_in">认key</span>是否存在</span><br><span class="line">  <span class="built_in"> exists</span><span class="built_in"> key</span></span><br><span class="line">   </span><br><span class="line"><span class="number">3</span>. 删<span class="built_in">除key</span></span><br><span class="line">   del<span class="built_in"> key</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span>. 设<span class="built_in">置key</span>过期</span><br><span class="line">   expire<span class="built_in"> key</span> expire</span><br><span class="line"></span><br><span class="line"><span class="number">5</span>. 将当期数据库的某<span class="built_in">个key</span>转移到另外一个db</span><br><span class="line">   move<span class="built_in"> key</span> dbindex</span><br><span class="line"></span><br><span class="line"><span class="number">6</span>. 移除给<span class="built_in">定key</span>的过期时间</span><br><span class="line">   persist<span class="built_in"> key</span></span><br><span class="line"></span><br><span class="line"><span class="number">7</span>. randomkey 随机返回一<span class="built_in">个key</span></span><br><span class="line"></span><br><span class="line"><span class="number">8</span>. <span class="keyword">rename</span><span class="built_in"> key</span> newname 重新命名一<span class="built_in">个key</span></span><br><span class="line"></span><br><span class="line"><span class="number">9</span>. type<span class="built_in"> key</span> 查<span class="built_in">看key</span>的数据类型</span><br><span class="line"></span><br><span class="line"><span class="number">10</span>. dump<span class="built_in"> key</span> 返回序列化后<span class="built_in">的key</span></span><br><span class="line"></span><br><span class="line"><span class="number">11</span>. restore<span class="built_in"> key</span> 反序列化为redis键</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>. expireat 和expire类型、接受的参数为 unix时间戳</span><br><span class="line"></span><br><span class="line"><span class="number">13</span>. migrate host port<span class="built_in"> key</span> destination-db timout [<span class="keyword">copy</span>] [repalce]</span><br><span class="line">    <span class="built_in">将key</span>原子性的从当前实例转移到目标实例的指定db上、一旦传送成功<span class="built_in">、key</span>会出现在目标实例、当前实例<span class="built_in">的key</span>会被删除</span><br><span class="line">    eg. redis-cli -h host migrate des_host <span class="number">6379</span> operateKey <span class="number">0</span> <span class="number">1000</span></span><br><span class="line">    </span><br><span class="line"><span class="number">14</span>. Object 从内部观察redis对象</span><br><span class="line">    Object encoding<span class="built_in"> key</span> </span><br><span class="line">    (str: raw &amp; int(为了节省内存) list: ziplist &amp; linkedlist set: intset &amp; hashtable</span><br><span class="line">     hash: zipmap &amp; hashtable zset: ziplist &amp; skiplist)</span><br><span class="line">    Object refcount<span class="built_in"> key</span></span><br><span class="line">    object idletime<span class="built_in"> key</span></span><br><span class="line"></span><br><span class="line"><span class="number">15</span>. renamenx<span class="built_in"> key</span> 当且仅当newkey不存在时、改名为newkey</span><br><span class="line"></span><br><span class="line"><span class="number">16</span>.<span class="built_in"> sort</span> 对列表、集合、有序集合中<span class="built_in">的key</span>进行排序</span><br><span class="line">    alpha对字符串进行排序 <span class="built_in"> sort</span> list alpha</span><br><span class="line">    limit offset<span class="built_in"> count</span> 跳过offset个元素、返<span class="built_in">回count</span>个元素</span><br><span class="line">   <span class="built_in"> sort</span> list limit offset<span class="built_in"> count</span></span><br><span class="line">    </span><br><span class="line"><span class="number">17</span>. scan、sscan、hscan、zscan 迭代元素</span><br><span class="line">    scan cursor 迭代获取元素</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>redis运维命令</title>
    <url>/2020/03/20/redis_redis%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>平时觉得没什么用的命令、关键时候救命、😁~~~</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="number">1</span>. 查看db大小</span><br><span class="line">   redis-cli -h host -p port -a password dbsize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. cat a.txt | redis-cli 从文件读入redis</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>. redis-cli -a password --csv lrange mylist offset count</span><br><span class="line">    从redis中快速读取一些key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">4</span>. n command 重复执行n次command</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">5</span>. help @</span><br><span class="line">  @generic  @list  @hash  @set  @sorted_set @string  @hyperloglog、@server、@connection、@scripting、@pubsub、@transactions</span><br><span class="line"></span><br><span class="line">help &lt;command&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">6</span>. redis-cli --<span class="keyword">stat</span> 实时监控redis运行状况</span><br><span class="line">   redis-cli monitor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">7</span>. redis-cli --bigkeys 查看redis中比较大的key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">8</span>. redis-cli --scan --pattern <span class="string">&#x27;*my*&#x27;</span> 用scan来查找key、并过滤</span><br><span class="line">   redis-cli --scan --pattern <span class="string">&#x27;*my*&#x27;</span> |wc -l  直接使用管道作为下个命令的输入</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">9</span>.  redis-cli -h host --rdb /tmp/dump.rdb</span><br><span class="line">    备份远程redis数据到本地文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">10</span>. maxmemory size 设置redis使用的最大内存</span><br><span class="line">      超过最大内存时、key过期策略</span><br><span class="line"></span><br><span class="line">     <span class="comment"># volatile-lru -&gt; remove the key with an expire set using an LRU algorithm</span></span><br><span class="line">   <span class="comment"># allkeys-lru -&gt; remove any key accordingly to the LRU algorithm</span></span><br><span class="line">   <span class="comment"># volatile-random -&gt; remove a random key with an expire set</span></span><br><span class="line">   <span class="comment"># allkeys-random -&gt; remove a random key, any key</span></span><br><span class="line">   <span class="comment"># volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)</span></span><br><span class="line">   <span class="comment"># noeviction -&gt; don&#x27;t expire at all, just return an error on write operations</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">11</span>. 使用客户端查看redis配置</span><br><span class="line">     redis-cli -h host config get key</span><br><span class="line">     redis-cli -h host config get slowlog-<span class="keyword">log</span>-slower-than 单位 微秒</span><br><span class="line">     redis-cli -h host config get slowlog-<span class="keyword">log</span>-slower-than 慢操作日志队列大小</span><br><span class="line">     redis-cli -h host slowlog get <span class="number">10</span> 查看最近<span class="number">10</span>条慢日志</span><br><span class="line">     hash-max-ziplist-entries 配置使用hashmap编码的最大字节数</span><br><span class="line">     redis-cli -h host get client-output-buffer-limit 客户端buffer控制、在server与client的交互中、</span><br><span class="line"></span><br><span class="line">每个连接都会有一个buffer关联、此buffer用来队列化等待被client接受的响应信息、若client不及时响应、</span><br><span class="line">buffer中积压的数据达到阈值、将会导致连接失败、buffer被移除</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">12</span>. redis以指定配置文件启动</span><br><span class="line">      redis-server redis.conf &amp;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">13</span>. redis-cli --lru-test <span class="number">10000000</span> 模拟<span class="number">1000</span>w <span class="keyword">keys</span>的执行情况</span><br><span class="line">     在maxmemory无限制的情况下、测试时无意义的、因为内存无限制、命中率会是<span class="number">100</span>%、计算机的ram会被耗尽</span><br><span class="line">    记得配置key的过期策略</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis数据结构实现-SDS</title>
    <url>/2020/04/24/redis_sds/</url>
    <content><![CDATA[<h4 id="SDS-定义"><a href="#SDS-定义" class="headerlink" title="SDS 定义"></a>SDS 定义</h4><p>每个sds.h&#x2F;sdshdr 结构表示一个SDS值</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sdshdr</span> &#123;</span></span><br><span class="line">  <span class="type">int</span> len; <span class="comment">// 记录buf数组中已使用字节的数量 (=SDS所保存字符串的长度)</span></span><br><span class="line">  <span class="type">int</span> <span class="built_in">free</span>; <span class="comment">// 记录buf数组中未使用的字节的数量</span></span><br><span class="line">  <span class="type">char</span> buf[]; <span class="comment">// 字节数组, 保存字符串  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/images/image-SDS.png" alt="SDS结构示例"></p>
<ul>
<li>free属性值为0, 表示 SDS 未分配 <code>未使用空间</code></li>
<li>len 属性为5, 表示 SDS 保存了一个5字节长的字符串</li>
<li>buf 属性是一个char类型的数组, 数组的前5个字节保存了 <code>R</code>, <code>e</code>,<code>d</code>,<code>i</code>, <code>s</code>, 五个字符, 最后一个字节保存了空字符串<code>\0</code></li>
</ul>
<h4 id="为什么不使用C原生字符串呢"><a href="#为什么不使用C原生字符串呢" class="headerlink" title="为什么不使用C原生字符串呢 ?"></a>为什么不使用<code>C</code>原生字符串呢 ?</h4><ol>
<li><code>C</code>字符串获取长度需要遍历, <code>SDS</code>则记录了自身长度(<code>len</code>), 将获取字符串长度的时间复杂度从<code>O(N)</code>降低到了<code>O(1)</code>, 即使反复执行<code>strlen</code>, 也不会对系统造成任何影响</li>
<li><code>C</code>字符串不记录自身长度, 容易造成缓冲区溢出, eg. strcat可以将字符串拼接, 执行这一操作时, 系统假定用户已分配了足够长度的内存, 假设不成立时, 就会造成缓冲区溢出(覆盖后边的字符)</li>
<li><code>C</code>的实现是一个<code>N+1</code>字符长的数组, 每次增长或缩短一个C字符串, 都会重新分配内存<ul>
<li>若增长, eg. <code>append</code>、需要先扩容, 否则会产生内存溢出</li>
<li>若缩容, eg. <code>trim</code>、需要先缩容, 否则会造成内存泄露</li>
</ul>
</li>
<li>为避免C字符串的缺陷, <code>SDS</code>通过未使用空间分配, 实现了<code>空间预分配</code>和<code>惰性空间释放</code>来优化.<ul>
<li>空间预分配: 当字符串扩展时, 不仅分配必须空间, 还会分配额外空间(len&lt;1M时, free&#x3D;len, len&gt;&#x3D;1M时, free&#x3D;1M), 来减少连续执行字符串增长需要的内存分配次数, 将字符串连续增长N次需要的内存重分配次数从必定N次, 降低到最多N次</li>
<li>惰性释放: 用free来标记被释放的空间, 而不真正操作内存, 也提供了API, 在需要时释放free空间, 不必担心惰性释放造成的空间浪费</li>
</ul>
</li>
<li>C字符串用<code>\0</code>标记字符串结尾, 字符串本身不能包含空字符, 使得<code>C</code>字符串只能保存文本数据, 而不能保存图片、音频、视频、压缩文件等二进制数据. 而redis SDS字符靠len属性来判断字符串结尾, 是二进制安全的.</li>
<li>兼容部分C字符. <code>SDS</code>总在结尾多分配一个字符<code>\0</code> 是为了保证C函数可以正常使用, 避免不必要的代码重复</li>
</ol>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><table>
<thead>
<tr>
<th align="left">C字符串</th>
<th>SDS字符串</th>
</tr>
</thead>
<tbody><tr>
<td align="left">获取字符串长度时间复杂度 O(N)</td>
<td>获取字符串长度时间复杂度 O(1)</td>
</tr>
<tr>
<td align="left">API非安全, 可能造成缓冲区溢出</td>
<td>API安全, 不会操作缓冲区溢出</td>
</tr>
<tr>
<td align="left">修改字符串会造成NN次内存分配</td>
<td>修改字符串最多N次内存分配</td>
</tr>
<tr>
<td align="left">只保存文本数据</td>
<td>可以保存文本及二进制数据</td>
</tr>
<tr>
<td align="left">可以使用 &lt;string.h&gt; 库中的函数</td>
<td>可以使用部分 &lt;string.h&gt; 库中的函数</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac安装mat独立工具报错</title>
    <url>/2020/03/20/tools_Mac%E5%AE%89%E8%A3%85mat%E7%8B%AC%E7%AB%8B%E5%B7%A5%E5%85%B7%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<p>####问题描述<br>官网下载、安装<br><img src="https://upload-images.jianshu.io/upload_images/14027542-0d8d68043d36538d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">An error has occurred. </span><br><span class="line">See the log <span class="keyword">file</span> </span><br><span class="line"><span class="regexp">/Users/</span>%username%<span class="regexp">/.eclipse/</span><span class="number">1899417313</span>_macosx_cocoa_x86_64<span class="regexp">/configuration/</span><span class="number">1507391541586</span>.log.</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/14027542-56ee81ed27935fe5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">!ENTRY org.eclipse.osgi <span class="number">4</span> <span class="number">0</span> <span class="number">2019</span><span class="number">-07</span><span class="number">-26</span> <span class="number">21</span>:<span class="number">12</span>:<span class="number">08.965</span></span><br><span class="line">!MESSAGE Application error</span><br><span class="line">!STACK <span class="number">1</span></span><br><span class="line">java.lang.IllegalStateException: The <span class="built_in">platform</span> metadata area could <span class="keyword">not</span> be written: /<span class="keyword">private</span>/var/<span class="built_in">folders</span>/kc/cc7tcgrx6_1d355s45t1q3nh0000gn/T/AppTranslocation/<span class="number">9361422</span>A<span class="number">-8</span>DF8<span class="number">-482</span>D<span class="number">-873</span>B<span class="number">-8</span>C030C46FB6E/d/mat.app/Contents/MacOS/workspace/.metadata.  By default <span class="keyword">the</span> <span class="built_in">platform</span> writes its content</span><br><span class="line">under <span class="keyword">the</span> current working <span class="built_in">directory</span> when <span class="keyword">the</span> <span class="built_in">platform</span> is launched.  Use <span class="keyword">the</span> -data parameter <span class="built_in">to</span></span><br><span class="line">specify <span class="keyword">a</span> different content area <span class="keyword">for</span> <span class="keyword">the</span> <span class="built_in">platform</span>.</span><br><span class="line">        <span class="keyword">at</span> org.eclipse.core.internal.runtime.DataArea.assertLocationInitialized(DataArea.java:<span class="number">70</span>)</span><br><span class="line">        <span class="keyword">at</span> org.eclipse.core.internal.runtime.DataArea.getStateLocation(DataArea.java:<span class="number">138</span>)</span><br><span class="line">        <span class="keyword">at</span> org.eclipse.core.internal.preferences.InstancePreferences.getBaseLocation(InstancePreferences.java:<span class="number">44</span>)</span><br><span class="line">        <span class="keyword">at</span> org.eclipse.core.internal.preferences.InstancePreferences.initializeChildren(InstancePreferences.java:<span class="number">209</span>)</span><br><span class="line">        <span class="keyword">at</span> org.eclipse.core.internal.preferences.InstancePreferences.&lt;init&gt;(InstancePreferences.java:<span class="number">59</span>)</span><br><span class="line">        <span class="keyword">at</span> org.eclipse.core.internal.preferences.InstancePreferences.internalCreate(InstancePreferences.java:<span class="number">220</span>)</span><br><span class="line">        <span class="keyword">at</span> org.eclipse.core.internal.preferences.EclipsePreferences.<span class="built_in">create</span>(EclipsePreferences.java:<span class="number">349</span>)</span><br><span class="line">@       </span><br></pre></td></tr></table></figure>

<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">使用命令行打开MemoryAnalyzer.ini，添加-data参数 </span><br><span class="line"><span class="regexp">/Users/</span>nj<span class="regexp">/package/m</span>at.app<span class="regexp">/Contents/</span>Eclipse/MemoryAnalyzer.ini</span><br><span class="line">如：</span><br><span class="line">-data</span><br><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/var/</span>log<span class="regexp">/mat/</span></span><br></pre></td></tr></table></figure>


<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><figure class="highlight haskell"><table><tr><td class="code"><pre><span class="line">-<span class="class"><span class="keyword">data</span> 放在 launcher前、</span></span><br><span class="line">-<span class="class"><span class="keyword">data</span> 和 value要放在两行</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-360b39a7c35efd15.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>git相关</title>
    <url>/2020/03/20/tools_git%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<ol>
<li><p>分支merge错了、需要撤回merge<br> git merge –abort</p>
</li>
<li><p>查看某段时间段内某个用户的提交<br>git log -p –author&#x3D;{name} –since&#x3D;{start-time} –until&#x3D;{end-time}<br>eg. git log -p –author&#x3D;nj –since&#x3D;2019-09-24 –until&#x3D;2019-09-24</p>
</li>
<li><p>查看某次提交属于哪个分支<br>  git br -r –contains commitId<br>  eg. git br -r –contains ca4efc1a</p>
</li>
<li><p>tag删除<br> git tag -d tag_name  删除本地tag<br> git push origin :refs&#x2F;tags&#x2F;tag_name 删除远程tag</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>google去掉新标签页缩略图</title>
    <url>/2020/03/20/tools_google%E5%8E%BB%E6%8E%89%E6%96%B0%E6%A0%87%E7%AD%BE%E9%A1%B5%E7%BC%A9%E7%95%A5%E5%9B%BE/</url>
    <content><![CDATA[<!-- MarkdownTOC -->

<ul>
<li>隐藏新标签页最近访问</li>
<li>mac下禁用 chrome 自动更新</li>
</ul>
<!-- /MarkdownTOC -->

<h4 id="隐藏新标签页最近访问"><a href="#隐藏新标签页最近访问" class="headerlink" title="隐藏新标签页最近访问"></a>隐藏新标签页最近访问</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 尝试过 <span class="keyword">new</span> tab direct.. &amp; 其它插件</span><br><span class="line">感觉不够爽、网络慢时、tab页有延时、可以看到明显的<span class="keyword">new</span> tab跳转过程...</span><br><span class="line">啊哈、心里还是不爽的~~~~</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 继续 google. 找到手动解决方式、~~</span><br><span class="line">    <span class="number">1</span>) 下载pak打包解压小工具  链接:https:<span class="comment">//pan.baidu.com/s/1TDp614rex0h0U5t2ShZE6g   密码:gtno</span></span><br><span class="line">    <span class="number">2</span>) 将pak文件小工具解压、备用</span><br><span class="line">       eg. 将pak文件解压</span><br><span class="line">           pak_tools -c=unpack -f=<span class="regexp">/Users/</span>aha<span class="regexp">/Package/</span>resources.pak </span><br><span class="line"></span><br><span class="line">           重新打包为pak文件 </span><br><span class="line">           pak_tools -c=repack -f=<span class="regexp">/Users/</span>aha<span class="regexp">/Package/</span>resources.json </span><br><span class="line"></span><br><span class="line">    <span class="number">3</span>) 找到google安装目录</span><br><span class="line">      Mac：</span><br><span class="line">      <span class="regexp">/Applications/G</span>oogle Chrome.app<span class="regexp">/Contents/</span>Versions/</span><br><span class="line">      -------------------------------------------------------------------------</span><br><span class="line">       (如果安装过多个版本的话、可以看到多个版本命名的文件夹、so... 接下来查看自己正在使用的版本</span><br><span class="line">      Chrome -&gt; 右上角... -&gt; 帮助 -&gt; 关于google chrome -&gt; 可以看到正在使用的版本)</span><br><span class="line">      -------------------------------------------------------------------------</span><br><span class="line">      进入对应版本目录下：</span><br><span class="line">      eg. 我的是：</span><br><span class="line">      <span class="regexp">/Applications/G</span>oogle Chrome.app<span class="regexp">/Contents/</span>Versions<span class="regexp">/&#123;&#123;69.0.3497.92&#125;&#125;/G</span>oogle Chrome Framework.framework<span class="regexp">/Versions/</span>A/Resources</span><br><span class="line">      然后可以看到有个文件叫：resource.pak </span><br><span class="line"></span><br><span class="line">    <span class="number">3</span>) 找到它之后、复制一份到自己方便找到的地方、把这里的重命名为 resource.pak-bak</span><br><span class="line">       eg. 我把它放到<span class="keyword">package</span>下、</span><br><span class="line">       然后、使用上边的命令解压、</span><br><span class="line">       pak_tools -c=unpack -f=<span class="regexp">/Users/</span>aha<span class="regexp">/Package/</span>resources.pak </span><br><span class="line">       解压后会生成 rasource.json 和 resource 文件夹</span><br><span class="line">       用sublime或者其它的文本编辑器在 resources文件夹中搜索 </span><br><span class="line">       &lt;<span class="keyword">div</span> id=<span class="string">&quot;most-visited&quot;</span>&gt;可以看到两处</span><br><span class="line">        enen、干脆点儿、都注释掉吧~~</span><br><span class="line"></span><br><span class="line">      然后、重新生成pak文件</span><br><span class="line">      pak_tools -c=repack -f=<span class="regexp">/Users/</span>aha<span class="regexp">/Package/</span>resources.json </span><br><span class="line"></span><br><span class="line">      将重新生成的 resources.pak 放回 ：</span><br><span class="line">      <span class="regexp">/Applications/G</span>oogle Chrome.app<span class="regexp">/Contents/</span>Versions<span class="regexp">/&#123;&#123;69.0.3497.92&#125;&#125;/G</span>oogle Chrome Framework.framework<span class="regexp">/Versions/</span>A/Resources</span><br><span class="line">      </span><br><span class="line">    <span class="number">4</span>) 退出google chrome、然后重新启动、可以看到 那八个缩略图从我们的世界中消失了、</span><br><span class="line">       enen / 干净的感觉真爽~~</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="mac下禁用-chrome-自动更新"><a href="#mac下禁用-chrome-自动更新" class="headerlink" title="mac下禁用 chrome 自动更新"></a>mac下禁用 chrome 自动更新</h4><figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 来个干脆的吧</span><br><span class="line">   找到update程序、直接删除或者重命名</span><br><span class="line">   我的是在 ~<span class="regexp">/Library/</span>Chrome/下</span><br><span class="line">   文件夹的名字叫： GoogleSoftwareUpdate</span><br><span class="line">   eg. 我的完整路径是 ~<span class="regexp">/Library/</span>Chrome/GoogleSoftwareUpdate 直接将它重命名、就不会自动更新了</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 hexo 框架搭建网站</title>
    <url>/2020/03/18/tools_hexo_use/</url>
    <content><![CDATA[<h4 id="使用-hexo-框架搭建网站"><a href="#使用-hexo-框架搭建网站" class="headerlink" title="使用 hexo 框架搭建网站"></a>使用 hexo 框架搭建网站</h4><h5 id="先搭建基础环境"><a href="#先搭建基础环境" class="headerlink" title="先搭建基础环境"></a>先搭建基础环境</h5>   <figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">brew install node <span class="regexp">//</span> 安装node</span><br><span class="line">node -v <span class="regexp">//</span> 检查npm是否安装成功</span><br><span class="line">npm -v <span class="regexp">//</span> 查看npm版本</span><br></pre></td></tr></table></figure>
<h5 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h5>   <figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">npm install hexo-cli-g <span class="regexp">//</span> 安装hexo</span><br><span class="line">hexo init xxx <span class="regexp">//</span> 初始化hexo站点目录</span><br><span class="line">cd xxx <span class="regexp">//</span> 进入目录</span><br><span class="line">hexo clean</span><br><span class="line">hexo g <span class="regexp">//</span> 生成站点, g -&gt; generate</span><br><span class="line">hexo s <span class="regexp">//</span> 运行网站, s -&gt; server</span><br></pre></td></tr></table></figure>
<p>   此时、本地网站已经搭建完成, 访问 <code>localhost:4000</code> 即可.</p>
<h5 id="配置文件-config-yml"><a href="#配置文件-config-yml" class="headerlink" title="配置文件 _config.yml"></a>配置文件 <code>_config.yml</code></h5>   <figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">title</span><span class="punctuation">: </span>牛牛的Blog</span><br><span class="line"><span class="attribute">subtitle</span><span class="punctuation">: </span>不奢望岁月静好 只希望点滴积累</span><br><span class="line"><span class="attribute">description</span><span class="punctuation">: </span>&#x27;多数是学习笔记、偶尔发发感慨、给生活添加些许乐趣&#x27;</span><br><span class="line"><span class="attribute">keywords</span><span class="punctuation">: </span>Java, Mysql, Linux</span><br><span class="line"><span class="attribute">author</span><span class="punctuation">: </span>niuniu</span><br><span class="line"><span class="attribute">language</span><span class="punctuation">: </span>zh</span><br><span class="line"><span class="attribute">timezone</span><span class="punctuation">: </span>&#x27;&#x27;</span><br><span class="line"><span class="attribute">theme</span><span class="punctuation">: </span>next // 定义主题</span><br></pre></td></tr></table></figure>
<h5 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h5>   <figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">下载: https:<span class="regexp">//</span>hexo.io<span class="regexp">/themes/</span> </span><br><span class="line">theme: <span class="keyword">next</span> <span class="regexp">//</span> 定义主题 _config.yml</span><br><span class="line">hexo g <span class="regexp">//</span> 重新生成站点</span><br><span class="line">hexo s <span class="regexp">//</span> 重新运行站点</span><br></pre></td></tr></table></figure>
<h5 id="分类和标签"><a href="#分类和标签" class="headerlink" title="分类和标签"></a>分类和标签</h5>   <figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> <span class="keyword">file</span>-name (<span class="keyword">file</span>-name是你的文章名, 也可以直接在 spurce/_post 文件夹下新建md文件)</span><br><span class="line">hexo <span class="keyword">new</span> page <span class="keyword">tags</span></span><br></pre></td></tr></table></figure>
<p>   打开 source&#x2F;tags&#x2F;index.md、修改为:<br>   <figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">type:</span> <span class="string">&quot;tags&quot;</span></span><br><span class="line"><span class="symbol">comments:</span> flase</span><br></pre></td></tr></table></figure></p>
   <figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> <span class="type">page</span> categories <span class="comment">// 打开分类功能</span></span><br></pre></td></tr></table></figure>
<p>   打开 <code>source/categories/index.md</code>、修改为:<br>   <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">type:</span> <span class="string">categories</span></span><br><span class="line"><span class="attr">comments:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></p>
<p>   使用:<br>   <figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"> <span class="attribute">在文章头部添加</span></span><br><span class="line"><span class="attribute"> tags</span><span class="punctuation">:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">tag1</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">tag2</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">tag3</span></span><br><span class="line"> <span class="attribute">categories</span><span class="punctuation">:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">cat1</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">cat2</span></span><br></pre></td></tr></table></figure></p>
<h5 id="修改hexo侧边栏标签"><a href="#修改hexo侧边栏标签" class="headerlink" title="修改hexo侧边栏标签"></a>修改hexo侧边栏标签</h5>  <figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">menu:</span></span><br><span class="line"><span class="symbol">home:</span> / || home</span><br><span class="line"><span class="symbol">about:</span> <span class="keyword">/about/</span> || user</span><br><span class="line"><span class="symbol">tags:</span> <span class="keyword">/tags/</span> || tags</span><br><span class="line"><span class="symbol">categories:</span> <span class="keyword">/categories/</span> || th</span><br><span class="line"><span class="symbol">archives:</span> <span class="keyword">/archives/</span> || archive</span><br><span class="line"><span class="symbol">MySQL:</span> <span class="keyword">/categories/</span>MySQL || database</span><br><span class="line"><span class="symbol">Redis:</span> <span class="keyword">/categories/</span>Redis || database</span><br><span class="line"><span class="meta">#schedule: /schedule/ || calendar</span></span><br><span class="line"><span class="meta">#sitemap: /sitemap.xml || sitemap</span></span><br><span class="line"><span class="meta">#commonweal: /404/ || heartbeat</span></span><br></pre></td></tr></table></figure>
<p>   注意: <code>:</code>前边展示的是侧边栏显示名称<br>         <code>/xxx/</code> 展示的是分类名称<br>         <code>||</code> 后边是图标<br>         图标从 <a href="https://fontawesome.com/icons?d=gallery&m=free">fontawesome.com</a> 获取</p>
<h5 id="将链接修改为蓝色"><a href="#将链接修改为蓝色" class="headerlink" title="将链接修改为蓝色"></a>将链接修改为蓝色</h5><p>打开<code>themes/next/source/css/_common/components/post/post.styl</code> 文件, 将下面的代码复制到文件最后</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.post-body</span> <span class="selector-tag">p</span> <span class="selector-tag">a</span>&#123;</span><br><span class="line">     <span class="attribute">color</span>: <span class="number">#0593d3</span>;</span><br><span class="line">     <span class="attribute">border-bottom</span>: none;</span><br><span class="line">     &amp;<span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">       <span class="attribute">color</span>: <span class="number">#0477ab</span>;</span><br><span class="line">       <span class="attribute">text-decoration</span>: underline;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h5 id="修改代码块样式"><a href="#修改代码块样式" class="headerlink" title="修改代码块样式"></a>修改代码块样式</h5><p>打开 <code>themes/next/_config.yml</code>, 搜索 <code>custom_file_path</code>, 去掉 <code>style</code> 前边的注释, 然后新建或者打开 <code>&#123;blog_root&#125;/source/_date/styles.styl</code> 文件 </p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">code</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#D1082D</span>;</span><br><span class="line">    <span class="attribute">background</span>: <span class="number">#E8E5E6</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">2px</span>;</span><br><span class="line">   // <span class="attribute">font-size</span>: <span class="number">14px</span>; // 设置你的字体大小</span><br><span class="line">   // <span class="attribute">font-family</span>: Source Corde Pro; // 设置你喜欢的字体</span><br><span class="line">&#125;</span><br><span class="line">// 大代码块的自定义样式</span><br><span class="line"><span class="selector-class">.highlight</span>, pre &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">5px</span> <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">5px</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">3px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.highlight</span>, <span class="selector-tag">code</span>, pre &#123;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#d6d6d6</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用valine评论系统"><a href="#使用valine评论系统" class="headerlink" title="使用valine评论系统"></a>使用valine评论系统</h4><p>新版本的 <a href="https://valine.js.org/">https://valine.js.org/</a> 支持npm安装</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install leancloud&#x27;s js-sdk</span></span><br><span class="line">npm install leancloud-storage <span class="comment">--save</span></span><br><span class="line"><span class="comment"># Install valine</span></span><br><span class="line">npm install valine <span class="comment">--save</span></span><br></pre></td></tr></table></figure>

<p>新的版本next主题已经默认支持, 需要注册leanCloud账号 <a href="https://leancloud.cn/">https://leancloud.cn/</a>， 获取<code>appId</code>和<code>appKey</code>, 然后修改配置文件 <code>**themes/hexo-theme-next/_config.yml**</code>, 搜索 <code>valine</code>, 修改配置项:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Valine.</span></span><br><span class="line"><span class="comment"># You can get your appid and appkey from https://leancloud.cn</span></span><br><span class="line"><span class="comment"># more info please open https://valine.js.org</span></span><br><span class="line"><span class="attr">valine:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">appid:</span>  <span class="comment"># your leancloud application appid</span></span><br><span class="line">  <span class="attr">appkey:</span>  <span class="comment"># your leancloud application appkey</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="literal">false</span> <span class="comment"># mail notifier , https://github.com/xCss/Valine/wiki</span></span><br><span class="line">  <span class="attr">verify:</span> <span class="literal">false</span> <span class="comment"># Verification code</span></span><br><span class="line">  <span class="attr">placeholder:</span> <span class="string">Just</span> <span class="string">go</span> <span class="string">go</span> <span class="comment"># comment box placeholder</span></span><br><span class="line">  <span class="attr">avatar:</span> <span class="string">mm</span> <span class="comment"># gravatar style</span></span><br><span class="line">  <span class="attr">guest_info:</span> <span class="string">nick,mail,link</span> <span class="comment"># custom comment header</span></span><br><span class="line">  <span class="attr">pageSize:</span> <span class="number">10</span> <span class="comment"># pagination size</span></span><br></pre></td></tr></table></figure>

<p>将 <code>enable</code> 改为 <code>true</code>, 将刚刚申请的 <code>appId</code> 和 <code>appKey</code> 填入,</p>
<p>leancloud appId申请请参考: <a href="https://valine.js.org/quickstart.html">https://valine.js.org/quickstart.html</a></p>
<h5 id="评论头像显示"><a href="#评论头像显示" class="headerlink" title="评论头像显示"></a>评论头像显示</h5><ol>
<li><p>注册 <a href="http://cn.gravatar.com/">gravatar</a>, valine 默认使用 gravatar的头像管理</p>
</li>
<li><p>进行评论, 注意要在评论时填写自己注册后绑定的邮箱、才会显示头像</p>
<p>如下图所示</p>
</li>
</ol>
<p><img src="/images/image-20200322112148688.png" alt="image-20200322112148688"></p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>google访问助手安装</title>
    <url>/2020/03/20/tools_google%E8%AE%BF%E9%97%AE%E5%8A%A9%E6%89%8B%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>悄悄的~~~😝</p>
<p>链接:<a href="https://pan.baidu.com/s/1BlNBd2xGUMJ7LYF1UYqvwg">https://pan.baidu.com/s/1BlNBd2xGUMJ7LYF1UYqvwg</a>  密码:4u3t</p>
<p>下载以上地址压缩包</p>
<p>chrome浏览器访问 chrome:&#x2F;&#x2F;extensions&#x2F;<br>把解压后的文件夹拖进去、如下图</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-761560184bd3cab4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>idea安装离线插件</title>
    <url>/2020/03/20/tools_idea%E5%AE%89%E8%A3%85%E7%A6%BB%E7%BA%BF%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<ol>
<li><p>查看idea版本<br> <img src="https://upload-images.jianshu.io/upload_images/14027542-5ead294f44819a44.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-44591f7bab73a3a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
</li>
<li><p>查找对应插件<br>以 lombok 为例：<br><a href="https://github.com/mplushnikov/lombok-intellij-plugin/releases/">https://github.com/mplushnikov/lombok-intellij-plugin/releases/</a></p>
</li>
<li><p>下载对应版本</p>
</li>
<li><p>不用解压、直接安装<br> <img src="https://upload-images.jianshu.io/upload_images/14027542-62469994e086f308.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
</li>
<li><p>重新启动idea、离线插件安装即可生效</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>idea快捷键记录</title>
    <url>/2020/03/20/tools_idea%E5%BF%AB%E6%8D%B7%E9%94%AE%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>command + 左右键 跳转到行首、行位<br>option + 左右键 跳转到单词的首、尾<br>command + enter 在下边插入一行、光标不变</p>
<p>debug相关:<br><code>Show Execution Point(Alt + F10)</code> 将光标从其它页面或者代码行、跳转到当前正在执行的行<br><code>Step Over(F8)</code>: 步过, 一步步往下走<br><code>Step into(F7)</code>: 步入，可以进入方法内部<br><code>Force Step into(Alt + Shift + F7)</code>: 强制步入, 可以进入官方类库<br><code>Step out(Shift + F8)</code>: 步出、跳回到方法调用处<br><code>Run to Cursor(Alt + F9)</code>: 运行到光标处<br><code>Evaluate Expression(Alt + F8)</code>: 计算表达式</p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>linux性能监控---top</title>
    <url>/2020/03/20/linux%E4%BD%BF%E7%94%A8_linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7---top/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-15663f2f66d4722a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>可以看到<code>top</code>的前半部分是系统统计信息、后半部分是进程信息<br>第<code>1</code>行：任务队列信息，等同于<code>uptime</code>、从左到右依次为：<br><code>系统当前时间</code>，<code>系统运行时间</code>、<code>登录用户数</code><br><code>load avg</code> 是系统平均负载、代表最近<code>1min</code>、<code>5min</code>、<code>15min</code> 的平均值<br>第<code>2</code>行：进程统计信息<code>总进程数</code>、 <code>正在运行进程数</code>、<code>休眠进程数</code>、<code>停止的进程数</code>、<code>僵死进程数</code><br>第<code>3</code>行：cpu统计信息 <code>us:用户空间cpu占用率</code>、<code>sy:内核空间cpu占用率</code>、<code>ni用户进程空间改变过优先级的进程cpu占用率</code>、<code>id空闲cpu占用率</code>、<code>wa等待输入输出的cpu时间百分比</code>、<code>hi硬中断请求</code>、<code>si软中断请求</code><br>第<code>4</code>行：内存统计信息 <code>total:物理内存总量</code> <code>free:空闲内存总量</code> <code>used:已使用内存总量</code> <code>内核缓冲使用量</code><br>第<code>5</code>行：交换区使用情况</p>
<p>进程区字段含义：<br><code>pid</code>: 进程id<br><code>user</code>: 进程所有者的用户名<br><code>pr</code>: 优先级<br><code>ni</code>: nice值、负值表示高优先级<br><code>virt</code>: 进程使用的虚拟内存总量<br><code>res</code>: 进程使用的、未被换出的物理内存大小<br><code>shr</code>: 共享内存大小<br><code>s</code>: 进程状态<br><code>%cpu</code>: 上次更新到现在的cpu时间占用百分比<br><code>%mem</code>: 进程使用的物理内存百分比<br><code>time+</code>: 进程使用的cpu时间总计，单位：<code>1/100s</code><br><code>command</code>: 命令名</p>
]]></content>
      <categories>
        <category>Linux使用</category>
      </categories>
      <tags>
        <tag>Linux使用</tag>
      </tags>
  </entry>
  <entry>
    <title>idea无法打开</title>
    <url>/2020/03/20/tools_idea%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80/</url>
    <content><![CDATA[<p>无意中发现idea的版本更新到2019.2了、我上次更新的时候是2019.1<br>闲来无事想玩儿下新版本、就升级了下、</p>
<h4 id="官网下载"><a href="#官网下载" class="headerlink" title="官网下载"></a>官网下载</h4><p><a href="https://www.jetbrains.com/idea/download/#section=mac">https://www.jetbrains.com/idea/download/#section=mac</a></p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>Mac安装很简单、dmg双击 -&gt; 导入原配置文件 -&gt; 破解(<a href="https://www.jianshu.com/p/1f2596084784">https://www.jianshu.com/p/1f2596084784</a>)</p>
<p>很麻溜的操作完、点击运行、傻了 … 居然跑不起来</p>
<h4 id="搜索、可以借鉴"><a href="#搜索、可以借鉴" class="headerlink" title="搜索、可以借鉴"></a>搜索、可以借鉴</h4><p><a href="https://www.jianshu.com/p/1f2596084784">https://www.jianshu.com/p/1f2596084784</a><br><a href="https://blog.csdn.net/weixin_40866404/article/details/80192780">https://blog.csdn.net/weixin_40866404&#x2F;article&#x2F;details&#x2F;80192780</a><br>… 类似文章很多、发现都不好使😔</p>
<h4 id="胡思乱想"><a href="#胡思乱想" class="headerlink" title="胡思乱想"></a>胡思乱想</h4><p>突然想到之前有篇idea破解的文章、可以让 idea 从命令行启动、查看错误提示</p>
<p>惊喜~</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-6054554eeebf794a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="idea启动.png"></p>
<p><code>1处</code>是 idea 启动的jvm参数<br><code>2、3</code>是启动过程中发生的错误</p>
<blockquote>
<p>可以看到、一共是两个错误: 1.gc文件找不到、2.jvm启动参数给的有问题</p>
</blockquote>
<p>正常情况下是不会发生这种问题的、纯属自作孽🤷‍♀️、<br>1.之前调过idea的jvm启动参数、都给成1300了、不知道为什么xms的值变成了-Xmx1024m、可能是多版本混合装了、某一个版本修改了默认值<br>2.为了看idea运行过程中gc的情况、将gc写入文件、删垃圾文件的时候又手残删掉了😭</p>
<p>借以给小伙伴儿们一点儿提示、万一遇到idea无法启动的问题、可以试试从命令行启动、看下错误日志</p>
<h4 id="任何从命令行启动idea"><a href="#任何从命令行启动idea" class="headerlink" title="任何从命令行启动idea"></a>任何从命令行启动idea</h4><p>应用程序 -&gt; idea -&gt; 右键 -&gt; 显示包内容 -&gt; Contents -&gt; MacOS -&gt; 双击  idea </p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>iptables学习</title>
    <url>/2020/03/30/tools_iptables/</url>
    <content><![CDATA[<h4 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h4><h5 id="基础说明"><a href="#基础说明" class="headerlink" title="基础说明"></a>基础说明</h5><figure class="highlight"><table><tr><td class="code"><pre><span class="line">iptables并不是真正的防火墙、它只是位于用户空间的一个命令行工具, netfilter 才是真正的安全框架、iptables只是将我们定义的规则转交给netfilter. </span><br><span class="line">netfilter 是Linux操作系统核心层的一个数据包处理模块</span><br></pre></td></tr></table></figure>



<h5 id="规则链名称"><a href="#规则链名称" class="headerlink" title="规则链名称"></a>规则链名称</h5><p>规则链名称包括以下5个、也被称为5个钩子函数:</p>
<p><code>INPUT链</code>: 处理输入数据包</p>
<p><code>OUTPUT链</code>: 处理输出数据包</p>
<p><code>FORWARD链</code>: 处理转发数据</p>
<p><code>PREROUTING链</code>: 用于目的地址转换(DNAT)</p>
<p><code>POSTROUTING链</code>: 用于源地址转换(SNAT)</p>
<h5 id="报文流向"><a href="#报文流向" class="headerlink" title="报文流向"></a>报文流向</h5><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">本机到某进程: <span class="function"><span class="title">prerouting</span> -&gt;</span> input</span><br><span class="line">本机转发: <span class="function"><span class="title">prerouting</span> -&gt;</span> <span class="function"><span class="title">forward</span> -&gt;</span> postrouting (直接在内核空间转发)</span><br><span class="line">本机进程发出(通常为响应报文): <span class="function"><span class="title">output</span> -&gt;</span> postrouting</span><br><span class="line">即: 当启用你过来防火墙功能时、报文需要经过不同的关卡(链)、但根据情况的不同、会经过不同的链</span><br></pre></td></tr></table></figure>



<h5 id="为什么称为链"><a href="#为什么称为链" class="headerlink" title="为什么称为链"></a>为什么称为链</h5><figure class="highlight"><table><tr><td class="code"><pre><span class="line">防火墙的作用就在于对经过的报文进行规则匹配、然后执行对应的动作、但是每个关卡上可能有很多规则、这些规则按照配置顺序从上到下执行、看起来就像是一个链</span><br></pre></td></tr></table></figure>



<h5 id="表"><a href="#表" class="headerlink" title="表"></a>表</h5><figure class="highlight llvm"><table><tr><td class="code"><pre><span class="line">这么多的链都放了一系列的规则、但是有些很类似、比如A类规则是对ip或者短裤过滤<span class="comment">; B类规则是修改报文... , 那么这些类似功能的规则能不能放在一起呢 ?</span></span><br><span class="line">答案是可以的、iptables提供了如下规则的分类(表):</span><br><span class="line"><span class="keyword">filter</span>表: 负责过滤功能 <span class="punctuation">,</span> 防火墙<span class="comment">; 内核模块 iptable_filter</span></span><br><span class="line">nat表: 网络地址转换<span class="comment">; 内核模块: iptable_nat</span></span><br><span class="line">mangle表: 解析报文、修改报文、并重新封装 内核模块: iptable_mangle</span><br><span class="line">raw表: 关闭nat表上启用的连接追踪机制<span class="comment">; 内核模块: iptable_raw</span></span><br><span class="line"></span><br><span class="line">当这些表处于同一条链时优先级如下:</span><br><span class="line">raw -&gt; mangle -&gt; nat -&gt; <span class="keyword">filter</span></span><br></pre></td></tr></table></figure>



<h5 id="防火墙的策略"><a href="#防火墙的策略" class="headerlink" title="防火墙的策略"></a>防火墙的策略</h5><p><code>通</code>: 默认不允许、需要定义谁可以进入</p>
<p><code>堵</code>: 默认允许、但需要证明自己的身份</p>
<p>filter功能: 定义允许或者不允许的策略, 工作在 input &#x2F; output &#x2F; forward 链</p>
<p>nat选项: 定义地址转换功能, 工作在 prerouting &#x2F; output &#x2F; postrouting 链</p>
<p>为了让这些功能都工作、制定了<code>表</code>的定义, 来区分不同的工作功能和处理方式</p>
<h5 id="常用功能"><a href="#常用功能" class="headerlink" title="常用功能"></a>常用功能</h5><p><code>filter</code> 定义允许或者不允许、工作在 <code>input</code>, <code>output</code>, <code>forward</code> 链上</p>
<p><code>nat</code> 定义地址转换, 工作在 <code>prerouting</code>, <code>output</code>, <code>postrouting</code> 链上</p>
<p><code>mangle</code> 修改报文原数据, 5个链都可以工作</p>
<p>注意: 设置多个规则链时、要把规则严格的放在前边、因为它是从上到下检查的~</p>
<h5 id="规则动作"><a href="#规则动作" class="headerlink" title="规则动作"></a>规则动作</h5><p><code>accept</code>: 接收数据包</p>
<p><code>drop</code>: 丢弃数据包</p>
<p><code>redirect</code>: 重定向、映射、透明代理</p>
<p><code>snat</code>: 源地址转换</p>
<p><code>dnat</code>: 目标地址转换</p>
<p><code>masquerade</code>: ip伪装(nat), 用于ADSL</p>
<p><code>log</code>: 日志记录</p>
<h5 id="思考"><a href="#思考" class="headerlink" title="思考:"></a>思考:</h5><p>其实iptables就是帮我们实现了网络包选择、地址转换、报文修改这些功能、为了实现这些功能、它划分了很多链、包括 prerouting、input、forward、output、postrouting, 定义了规则动作 accept、drop、redirect、snat、dnat、log、masquerade来实现这些功能.</p>
<h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><h5 id="清空当前所有规则和计数"><a href="#清空当前所有规则和计数" class="headerlink" title="清空当前所有规则和计数"></a>清空当前所有规则和计数</h5><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">iptables</span> -F <span class="comment"># 清空所有防火墙规则</span></span><br><span class="line">iptables -X <span class="comment"># 删除用户自定义的空链</span></span><br><span class="line">iptables -Z <span class="comment"># 清空计数</span></span><br></pre></td></tr></table></figure>

<h5 id="配置允许ssh端口连接"><a href="#配置允许ssh端口连接" class="headerlink" title="配置允许ssh端口连接"></a>配置允许ssh端口连接</h5><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">iptables</span> -A INPUT -s <span class="number">192.168.1.0</span>/<span class="number">24</span> -p tcp --dport <span class="number">22</span> -j ACCEPT</span><br><span class="line"><span class="comment"># 22: ssh端口 -s 192.168.1.0/24 被允许的网段、 -j accept 接受这种类型的请求</span></span><br></pre></td></tr></table></figure>



<h5 id="允许本地回环地址可以正常使用"><a href="#允许本地回环地址可以正常使用" class="headerlink" title="允许本地回环地址可以正常使用"></a>允许本地回环地址可以正常使用</h5><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -<span class="selector-tag">i</span> lo -j accept</span><br><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -o lo -j accept</span><br></pre></td></tr></table></figure>



<h5 id="设置默认规则"><a href="#设置默认规则" class="headerlink" title="设置默认规则"></a>设置默认规则</h5><figure class="highlight gauss"><table><tr><td class="code"><pre><span class="line">iptables -P INPUT <span class="built_in">DROP</span> <span class="meta"># 配置默认的不让进</span></span><br><span class="line">iptables -P FORWARD <span class="built_in">DROP</span> <span class="meta"># 默认的不允许转发</span></span><br><span class="line">iptables -P <span class="keyword">OUTPUT</span> ACCEPT <span class="meta"># 默认的可以出去</span></span><br></pre></td></tr></table></figure>



<h5 id="配置白名单"><a href="#配置白名单" class="headerlink" title="配置白名单"></a>配置白名单</h5><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -<span class="selector-tag">p</span> <span class="attribute">all</span> -s <span class="number">192.168</span>.<span class="number">1.0</span>/<span class="number">24</span> -j ACCEPT  # 允许机房内网机器可以访问</span><br><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -<span class="selector-tag">p</span> <span class="attribute">all</span> -s <span class="number">192.168</span>.<span class="number">140.0</span>/<span class="number">24</span> -j ACCEPT  # 允许机房内网机器可以访问</span><br><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -<span class="selector-tag">p</span> tcp -s <span class="number">183.121</span>.<span class="number">3.7</span> <span class="attr">--dport</span> <span class="number">3380</span> -j ACCEPT </span><br><span class="line"># 允许<span class="number">183.121</span>.<span class="number">3.7</span>访问本机的<span class="number">3380</span>端口</span><br></pre></td></tr></table></figure>



<h5 id="开启相应的服务端口"><a href="#开启相应的服务端口" class="headerlink" title="开启相应的服务端口"></a>开启相应的服务端口</h5><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -<span class="selector-tag">p</span> tcp <span class="attr">--dport</span> <span class="number">80</span> -j ACCEPT # 开启<span class="number">80</span>端口，因为web对外都是这个端口</span><br><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -<span class="selector-tag">p</span> icmp <span class="attr">--icmp-type</span> <span class="number">8</span> -j ACCEPT # 允许被ping</span><br><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -m state <span class="attr">--state</span> ESTABLISHED,RELATED -j ACCEPT # 已经建立的连接得让它进来</span><br></pre></td></tr></table></figure>



<h5 id="保存规则到配置文件"><a href="#保存规则到配置文件" class="headerlink" title="保存规则到配置文件"></a>保存规则到配置文件</h5><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">cp <span class="regexp">/etc/</span>sysconfig<span class="regexp">/iptables /</span>etc<span class="regexp">/sysconfig/i</span>ptables.bak <span class="comment"># 任何改动之前先备份，请保持这一优秀的习惯</span></span><br><span class="line">iptables-save &gt; <span class="regexp">/etc/</span>sysconfig/iptables</span><br><span class="line">cat <span class="regexp">/etc/</span>sysconfig/iptables</span><br></pre></td></tr></table></figure>



<h5 id="列出已设置规则"><a href="#列出已设置规则" class="headerlink" title="列出已设置规则"></a>列出已设置规则</h5><figure class="highlight hsp"><table><tr><td class="code"><pre><span class="line">iptables -L [-t 表名] [链名]</span><br><span class="line"></span><br><span class="line">iptables -L -t nat                  <span class="meta"># 列出 nat 上面的所有规则</span></span><br><span class="line"><span class="meta">#            ^ -t 参数指定，必须是 raw， nat，filter，mangle 中的一个</span></span><br><span class="line">iptables -L -t nat  --<span class="keyword">line</span>-numbers  <span class="meta"># 规则带编号</span></span><br><span class="line">iptables -L <span class="keyword">INPUT</span></span><br><span class="line"></span><br><span class="line">iptables -L -nv  <span class="meta"># 查看，这个列表看起来更详细</span></span><br></pre></td></tr></table></figure>



<h5 id="端口映射"><a href="#端口映射" class="headerlink" title="端口映射"></a>端口映射</h5><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">iptables</span> -t nat -A PREROUTING -d <span class="number">210.14.67.127</span> -p tcp --dport <span class="number">2222</span>  -j DNAT --to-dest <span class="number">192.168.188.115:22</span></span><br><span class="line"><span class="comment"># 将本机的 2222端口 映射到虚拟机的 22端口</span></span><br></pre></td></tr></table></figure>



<h5 id="防止SYN洪水攻击"><a href="#防止SYN洪水攻击" class="headerlink" title="防止SYN洪水攻击"></a>防止SYN洪水攻击</h5><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">iptables -<span class="selector-tag">A</span> <span class="selector-tag">INPUT</span> -<span class="selector-tag">p</span> tcp <span class="attr">--syn</span> -m limit <span class="attr">--limit</span> <span class="number">5</span>/second -j ACCEPT</span><br></pre></td></tr></table></figure>



<h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><blockquote>
<p>iptables –help 可以看到更多的选项、可以看到每一个选项的解释、本文列出了一些简单使用、欢迎指正、交流~</p>
</blockquote>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>idea破解安装</title>
    <url>/2020/03/20/tools_idea%E7%A0%B4%E8%A7%A3%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>有钱的小伙伴请支持原装正版。。。</p>
<ol>
<li><p>下载idea<br><a href="https://www.jetbrains.com/idea/download/">https://www.jetbrains.com/idea/download/</a></p>
</li>
<li><p>下载破解jar包<br><a href="https://pan.baidu.com/s/18Guu4-X5RwGifELcHkOyiA">https://pan.baidu.com/s/18Guu4-X5RwGifELcHkOyiA</a><br>2019.3版本使用  【仔细查看readme有惊喜^.^】<br>链接: <a href="https://pan.baidu.com/s/17Sk2w3kJ6KdFs3S9pNPCAw">https://pan.baidu.com/s/17Sk2w3kJ6KdFs3S9pNPCAw</a> 提取码: ivv3</p>
</li>
</ol>
<p>3.启动idea -&gt; 试用模式<br><code>configuration | help</code> -&gt; <code>edit customer vm options</code><br>添加 <code>-javaagent</code> 参数</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">-javaagent:<span class="regexp">/Users/</span>nj<span class="regexp">/package/</span>jetbrains-agent.jar</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p>重启idea</p>
</li>
<li><p><code>help</code> -&gt; <code>register</code></p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="number">3</span>AGXEJXFK9-eyJsaWNlbnNlSWQiOiIzQUdYRUpYRks5IiwibGljZW5zZWVOYW1lIjoiaHR0cHM6Ly96aGlsZS5pbyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkFDIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJHTyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJETSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSUzAiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkQiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUEMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUk0iLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREIiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9XSwiaGFzaCI6IjEyNzk2ODc3LzAiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-WGTHs6XpDhr+uumvbwQPOdlxWnQwgnGaL4eRnlpGKApEEkJyYvNEuPWBSrQkPmVpim<span class="regexp">/8Sab6HV04Dw3IzkJT0yTc29sPEXBf69+7y6Jv718FaJu4MWfsAk/</span>ZGtNIUOczUQ0iGKKnSSsfQ<span class="regexp">/3UoMv0q/y</span>Jcfvj+me5Zd<span class="regexp">/gfaisCCMUaGjB/</span>lWIPpEPzblDtVJbRexB1MALrLCEoDv3ujcPAZ7xWb54DiZwjYhQvQ+CvpNNF2jeTku7lbm5v+BoDsdeRq7YBt9ANLUKPr2DahcaZ4gctpHZXhG96IyKx232jYq9jQrFDbQMtVr3E+GsCekMEWSD<span class="regexp">//</span>dLT+HuZdc1sAIYrw==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG<span class="regexp">/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/</span>nYV31HLF7fJUAplI<span class="regexp">/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/</span>GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4<span class="regexp">/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/</span>GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt<span class="regexp">/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/</span>THOT7NJQhr6AyLkhhJCdkzE2cob<span class="regexp">/KouVp4ivV7Q3Fc6HX7eepHAAF/</span>DpxwgOrg9smX6coXLgfp0b1RU2u<span class="regexp">/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/</span><span class="number">40</span>BjpMUrDRCeKuiBahC0DCoU<span class="regexp">/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g</span>==</span><br></pre></td></tr></table></figure>
</li>
<li><p>注意：</p>
</li>
</ol>
<ol>
<li>破解文件的权限需要给到777</li>
<li>移除hosts里边关于jetbrains的信息</li>
</ol>
<p>如果上述方法不行、试试：<br><a href="https://www.cnblogs.com/dfsu/p/11362594.html">https://www.cnblogs.com/dfsu/p/11362594.html</a></p>
<p>19.3版本<br><a href="https://zhile.io/2018/08/17/jetbrains-license-server-crack.html">https://zhile.io/2018/08/17/jetbrains-license-server-crack.html</a></p>
<p>还烦请小伙伴儿们在经济允许的条件下多多支持正版 ~~</p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>item使用</title>
    <url>/2020/03/20/tools_item%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p><code>command + D</code> 垂直拆分面板<br><code>command  + shift + D</code> 水平拆分面板<br><code>command + w</code> 关闭当前面板<br><code>command + ]</code> 多个面板间切换<br><code>command + shift + enter</code> 最大化当前面板 | 还原</p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>简书文章迁移hexo</title>
    <url>/2020/03/20/tools_jianshu_migrate/</url>
    <content><![CDATA[<h4 id="导出markdown文件"><a href="#导出markdown文件" class="headerlink" title="导出markdown文件"></a>导出markdown文件</h4><p>首先登陆简书后台, 下载所有源文件</p>
<figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">我 -&gt; 设置 -&gt; 账号管理 -&gt; 下载所有文章</span><br></pre></td></tr></table></figure>



<h4 id="将源文件替换成我们需要的格式"><a href="#将源文件替换成我们需要的格式" class="headerlink" title="将源文件替换成我们需要的格式"></a>将源文件替换成我们需要的格式</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">简书文件存放路径</span></span><br><span class="line">src=/Users/xx/Downloads/jianshu</span><br><span class="line">dsc=/Users/xx/Downloads/jianshu-m</span><br><span class="line">date=$(date &quot;+%Y-%m-%d&quot;)</span><br><span class="line"></span><br><span class="line">for f in $src/*/*; do</span><br><span class="line">   base=$(basename $f .md)</span><br><span class="line">   catgories=$(basename $(dirname $f) $PWD)</span><br><span class="line">   insert=&quot;---\ntitle: $&#123;base&#125;\ndate: $date\ncategories:\n  - $&#123;catgories&#125;\ntags:\n  - $&#123;catgories&#125;\n---\n&quot;</span><br><span class="line">   echo &quot;$&#123;insert&#125;$(cat $f)&quot; &gt; $f  # 将hexo需要的头部内容插入</span><br><span class="line">   lower=$(echo $catgories|tr &#x27;[A-Z]&#x27; &#x27;[a-z]&#x27;) # 可根据个人需要、这里是为了生成指定分类开头的文件名</span><br><span class="line">   srcFile=$dsc&quot;/&quot;$lower&quot;_&quot;$base&quot;.md&quot;</span><br><span class="line">   mv $f $srcFile # 将源文件放到一个文件夹下、统一copy到 _post 文件夹下即可</span><br><span class="line">done</span><br></pre></td></tr></table></figure>



<h4 id="临时解决简书图片链接无法加载"><a href="#临时解决简书图片链接无法加载" class="headerlink" title="临时解决简书图片链接无法加载"></a>临时解决简书图片链接无法加载</h4><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">找到主题文件夹下 -&gt; <span class="function"><span class="title">layout</span>文件夹下 -&gt;</span> 有 &lt;head&gt; 标记的文件、</span><br><span class="line">eg. hexo-<span class="built_in">theme</span>-next主题为:</span><br><span class="line">themes/hexo-<span class="built_in">theme</span>-next/layout/_layout.swig</span><br><span class="line"></span><br><span class="line">添加meta:</span><br><span class="line">&lt;meta <span class="keyword">name</span>=<span class="string">&quot;referrer&quot;</span> content=<span class="string">&quot;no-referrer&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line">^.^仅为权宜之计、不想盗链...., 有好的替换方式后更新....</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="本地新增文件图片链接"><a href="#本地新增文件图片链接" class="headerlink" title="本地新增文件图片链接"></a>本地新增文件图片链接</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">利用电脑上的各种工具、剪切的图片直接粘贴到 Typora上、会有 <span class="keyword">copy</span>至 选项, 直接<span class="keyword">copy</span>到我们的资源目录(你存放image的地方)即可</span><br><span class="line">eg. 如果使用默认配置、应该是 <span class="keyword">source</span><span class="regexp">/images/</span></span><br><span class="line">若开启 post_asset_folder: <span class="keyword">true</span> 则每篇文章的图片会单独存放在一个与文件同名的文件夹内</span><br><span class="line">![<span class="number">1</span>.jpg](<span class="regexp">/images/im</span>age-<span class="number">20200320205834941</span>.png)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>markdown常用语法</title>
    <url>/2020/03/20/tools_markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<p><code>上标</code>: <code>2&lt;sup&gt;m-1&lt;/sup&gt;</code> 2<sup>m-1</sup><br><code>下标</code>: <code>H&lt;sub&gt;2&lt;/sub&gt;O</code> H<sub>2</sub>O<br><code>颜色</code>: <font color="green">red</color><br><code>目录</code>:[toc] 简书不支持<br><code>表格</code>:</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">|<span class="string">星期</span>|<span class="string">1</span>|<span class="string">2</span>|<span class="string">3</span>|<span class="string">4</span>|<span class="string">5</span>|<span class="string">6</span>|<span class="string">7</span>|</span><br><span class="line">|<span class="string">---</span>|<span class="string">---</span>|<span class="string">---</span>|<span class="string">---</span>|<span class="string">---</span>|<span class="string">---</span>|<span class="string">---</span>|<span class="string">---</span>|</span><br><span class="line">|<span class="string">早餐</span>|<span class="string">香蕉牛奶燕麦粥</span>|<span class="string">皮蛋瘦肉粥</span>|<span class="string">蜂蜜小蛋糕</span>|<span class="string">灌汤包</span>|<span class="string">南瓜饼</span>|<span class="string">肉末蛋羹</span>|<span class="string">豆浆油条</span>|</span><br><span class="line">|<span class="string">中餐</span>|<span class="string">爆炒鸡肝</span>|<span class="string">笋干炒肉</span>|<span class="string">箩卜炒肉</span>|<span class="string">剁椒鱼头</span>|<span class="string">葱油蛏子</span>|<span class="string">风味蹄筋</span>|<span class="string">珍珠丸子</span>|</span><br><span class="line">|<span class="string">晚餐</span>|<span class="string">牛肉砂锅</span>|<span class="string">虾皮炒海带</span>|<span class="string">牛肉炒西芹</span>|<span class="string">芝麻豆腐</span>|<span class="string">香菇炒肉</span>|<span class="string">土豆丝饼</span>|<span class="string">叉烧肉</span>|</span><br></pre></td></tr></table></figure>
<p>效果</p>
<table>
<thead>
<tr>
<th>星期</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
</tr>
</thead>
<tbody><tr>
<td>早餐</td>
<td>香蕉牛奶燕麦粥</td>
<td>皮蛋瘦肉粥</td>
<td>蜂蜜小蛋糕</td>
<td>灌汤包</td>
<td>南瓜饼</td>
<td>肉末蛋羹</td>
<td>豆浆油条</td>
</tr>
<tr>
<td>中餐</td>
<td>爆炒鸡肝</td>
<td>笋干炒肉</td>
<td>箩卜炒肉</td>
<td>剁椒鱼头</td>
<td>葱油蛏子</td>
<td>风味蹄筋</td>
<td>珍珠丸子</td>
</tr>
<tr>
<td>晚餐</td>
<td>牛肉砂锅</td>
<td>虾皮炒海带</td>
<td>牛肉炒西芹</td>
<td>芝麻豆腐</td>
<td>香菇炒肉</td>
<td>土豆丝饼</td>
<td>叉烧肉</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>如何同时登陆两个github账号</title>
    <url>/2020/03/18/tools_multi_terminal/</url>
    <content><![CDATA[<h4 id="生成一个新的ssh-key"><a href="#生成一个新的ssh-key" class="headerlink" title="生成一个新的ssh key"></a>生成一个新的ssh key</h4><figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">nj:~ nj$ cd ~/.ssh</span><br><span class="line">nj:.ssh nj$ ls</span><br><span class="line">id_rsa        id_rsa.pub  known_hosts</span><br><span class="line">nj:.ssh nj$ ssh-keygen -t rsa -C <span class="string">&quot;iMac_personnal_publicKey&quot;</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/Users/nj/.ssh/id_rsa):               </span><br><span class="line">/Users/nj/.ssh/id_rsa_personal</span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /Users/nj/.ssh/id_rsa_personal.</span><br><span class="line">Your public key has been saved in /Users/nj/.ssh/id_rsa_personal.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:1gepuxDHwJRnFbKvc0Zq/NGrFGE9kEXS06jxatPPrSQ iMac_personnal_publicKey</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|<span class="string">      ....=*oo   </span>|</span><br><span class="line">|<span class="string">     o. ooo=+ .  </span>|</span><br><span class="line">|<span class="string">      oo. =+o.   </span>|</span><br><span class="line">|<span class="string">       o =.o..   </span>|</span><br><span class="line">|<span class="string">      . S =o.    </span>|</span><br><span class="line">|<span class="string">       = =++.    </span>|</span><br><span class="line">|<span class="string">      . B.=.Eo.. </span>|</span><br><span class="line">|<span class="string">       o B . +o .</span>|</span><br><span class="line">|<span class="string">          . o.. .. </span>|</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line">njdeiMac:.ssh nj$ ls</span><br><span class="line">id_rsa            id_rsa_personal     known_hosts</span><br><span class="line">id_rsa.pub        id_rsa_personal.pub`</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>打开新生村的 <code>~/.ssh/id_rsa_personal.pub</code> 文件、将内容添加到 github 后台</li>
<li>打开 <code>~/.ssh/config</code> 文件<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">Host xxx <span class="regexp">//</span>你的host别名</span><br><span class="line">  HostName github.com</span><br><span class="line">  User yyy <span class="regexp">//gi</span>thub的注册用户名</span><br><span class="line">  IdentityFile ~<span class="regexp">/.ssh/i</span>d_rsa_personal</span><br></pre></td></tr></table></figure></li>
<li>将github ssh仓库中的 <a href="mailto:&#103;&#105;&#116;&#x40;&#x67;&#x69;&#116;&#x68;&#x75;&#98;&#46;&#x63;&#x6f;&#x6d;">&#103;&#105;&#116;&#x40;&#x67;&#x69;&#116;&#x68;&#x75;&#98;&#46;&#x63;&#x6f;&#x6d;</a> 替换成新建的Host别名<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">eg. git<span class="variable">@github</span>.<span class="symbol">com:</span>hbxn740150254/<span class="title class_">BestoneGitHub</span>.git</span><br><span class="line"> -&gt; git<span class="variable">@xxx</span><span class="symbol">:hbxn740150254/BestoneGitHub</span>.git</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>postman功能支持记录</title>
    <url>/2020/03/20/tools_postman%E5%8A%9F%E8%83%BD%E6%94%AF%E6%8C%81%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<figure class="highlight smali"><table><tr><td class="code"><pre><span class="line">1.<span class="built_in"> add </span>collection 可以理解为一个project</span><br><span class="line">2.<span class="built_in"> add </span>floders 添加目录、可以添加多级、可以理解为多个功能模块</span><br><span class="line">3.<span class="built_in"> add </span>requests 添加请求</span><br><span class="line">4. mock server 作为mock数据的接口、有调用上限</span><br><span class="line">5. runner 可以支持简单压测</span><br><span class="line">6. environment 支持分组(dev/test/prod 环境区分、每个分组下支持多个变量)</span><br><span class="line">7. globals 全局变量、会在每个请求中添加</span><br><span class="line">8. view in web / publish 支持发布、共享</span><br><span class="line">9. history 支持浏览记录查看</span><br><span class="line">10. 文档说明支持markdown格式</span><br><span class="line">11.<span class="built_in"> monitor </span>服务性能监控</span><br></pre></td></tr></table></figure>

<h4 id="文件参考"><a href="#文件参考" class="headerlink" title="文件参考"></a>文件参考</h4><p><a href="https://crifan.github.io/api_tool_postman/website/">https://crifan.github.io/api_tool_postman&#x2F;website&#x2F;</a></p>
<p><a href="https://blog.csdn.net/water_0815/article/details/53326990">https://blog.csdn.net/water_0815&#x2F;article&#x2F;details&#x2F;53326990</a></p>
<p><a href="https://blog.csdn.net/ruanhao1203/article/details/79096279">https://blog.csdn.net/ruanhao1203/article/details/79096279</a></p>
<p><a href="https://www.cnblogs.com/qiaoyeye/p/5524750.html">https://www.cnblogs.com/qiaoyeye/p/5524750.html</a></p>
<p><a href="https://blog.csdn.net/cloud_huan/article/details/78326159">https://blog.csdn.net/cloud_huan&#x2F;article&#x2F;details&#x2F;78326159</a></p>
<p><a href="https://www.jianshu.com/p/12185c5dc120">https://www.jianshu.com/p/12185c5dc120</a></p>
<p><a href="https://juejin.im/entry/5a32a7e86fb9a0452a3c5b97">https://juejin.im/entry/5a32a7e86fb9a0452a3c5b97</a></p>
<p><a href="https://blog.csdn.net/testdeveloper/article/details/80679988">https://blog.csdn.net/testdeveloper/article/details/80679988</a></p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>postman添加sign签名</title>
    <url>/2020/03/20/tools_postman%E6%B7%BB%E5%8A%A0sign%E7%AD%BE%E5%90%8D/</url>
    <content><![CDATA[<h4 id="安装postman插件"><a href="#安装postman插件" class="headerlink" title="安装postman插件"></a>安装postman插件</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">https:<span class="regexp">//</span>www.jianshu.com<span class="regexp">/p/</span><span class="number">451</span>e0d009304</span><br></pre></td></tr></table></figure>


<h4 id="常用功能使用"><a href="#常用功能使用" class="headerlink" title="常用功能使用"></a>常用功能使用</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">https:<span class="regexp">//</span>www.jianshu.com<span class="regexp">/p/</span><span class="number">15</span>f8dfaaecef</span><br></pre></td></tr></table></figure>


<h4 id="生成sign签名"><a href="#生成sign签名" class="headerlink" title="生成sign签名"></a>生成sign签名</h4><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 编写脚本 </span><br><span class="line">   以order项目为例(下边<span class="built_in">sign</span>.js)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 在请求中添加脚本</span><br><span class="line">   <span class="function"><span class="title">managerEnvirenment</span> -&gt;</span> <span class="function"><span class="title">add</span> -&gt;</span> <span class="built_in">sign</span> (值可以随便给、这个是用来给postman使用的、在发送请求时会替换为计算出来的<span class="built_in">sign</span>值)</span><br><span class="line">   如下图所示</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>. 发送请求、可以发现签名是ok的</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">4</span>. 如果发现签名不对、可以调试脚本</span><br><span class="line">   在chrome地址栏中输入：chrome:<span class="comment">//flags/#debug-packed-apps ，开启Debugging for packed app</span></span><br><span class="line">   输入chrome:<span class="comment">//inspect/#apps，选择postman的inspect  会弹出调试框</span></span><br><span class="line">   </span><br><span class="line">   在弹出的调试框里、选择elements在下边可以看到console</span><br><span class="line">   可以查看签名的方式是否正确(配合idea调试、对比签名方式和签名结果)</span><br><span class="line">   idea调试：以debug模式运行、</span><br><span class="line">   在指定合适的位置打断点、代码逻辑运行到断点处即会被中断掉、可以进行单步调试~~</span><br><span class="line">   查找问题出现的原因</span><br><span class="line">   </span><br></pre></td></tr></table></figure>




<h4 id="sign-js"><a href="#sign-js" class="headerlink" title="sign.js"></a>sign.js</h4><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> appkey = <span class="string">&#x27;6615be7b44ca4ab9ac03060088202792&#x27;</span>; <span class="comment">// 自动化测试的key</span></span><br><span class="line"> <span class="comment">//获取当前时间</span></span><br><span class="line"> <span class="keyword">function</span> <span class="title function_">createTime</span>(<span class="params"></span>) &#123;</span><br><span class="line">     <span class="keyword">return</span> (<span class="keyword">new</span> <span class="title class_">Date</span>()).<span class="title function_">valueOf</span>();</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">var</span> time = <span class="title function_">createTime</span>();</span><br><span class="line"> <span class="keyword">var</span> method = request.<span class="property">method</span>;</span><br><span class="line"> <span class="keyword">delete</span> request.<span class="property">data</span>[<span class="string">&quot;sign&quot;</span>];</span><br><span class="line"> <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;request data is : &quot;</span> + request.<span class="property">data</span>);</span><br><span class="line"> <span class="keyword">var</span> keys = <span class="title class_">Object</span>.<span class="title function_">keys</span>(request.<span class="property">data</span>), i, len = keys.<span class="property">length</span>;</span><br><span class="line"> keys.<span class="title function_">sort</span>();</span><br><span class="line"> <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;sortedKeys is : &quot;</span> + keys)</span><br><span class="line"> <span class="comment">// Build the request body string from the Postman request.data object</span></span><br><span class="line"> <span class="keyword">var</span> requestBody = <span class="string">&quot;&quot;</span>;</span><br><span class="line"> <span class="keyword">var</span> firstpass = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 构造数据为 key=param&amp;key=param....字符串</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="keyword">var</span> index <span class="keyword">in</span> keys)&#123;</span><br><span class="line"> <span class="keyword">if</span> (keys[index] == <span class="string">&quot;sign&quot;</span>) &#123;</span><br><span class="line"> 	<span class="keyword">continue</span>;</span><br><span class="line"> &#125;</span><br><span class="line"><span class="keyword">if</span>(!firstpass)&#123;</span><br><span class="line">    requestBody += <span class="string">&quot;&amp;&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span>(keys[index]==<span class="string">&quot;create_time&quot;</span>)&#123;</span><br><span class="line">    request.<span class="property">data</span>[keys[index]]=time;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(request.<span class="property">data</span>[keys[index]]);</span><br><span class="line">    &#125;</span><br><span class="line">    requestBody += keys[index] + <span class="string">&quot;=&quot;</span> + request.<span class="property">data</span>[keys[index]];</span><br><span class="line">    firstpass = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">requestBody += <span class="string">&#x27;&amp;key=&#x27;</span> + appkey;   </span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;request body is : &quot;</span> + requestBody);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> md5=<span class="title class_">CryptoJS</span>.<span class="title class_">MD5</span>(requestBody, appkey);</span><br><span class="line"><span class="keyword">var</span> base64md5 = <span class="title class_">CryptoJS</span>.<span class="property">enc</span>.<span class="property">Base64</span>.<span class="title function_">stringify</span>(md5);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(base64md5);</span><br><span class="line">postman.<span class="title function_">setEnvironmentVariable</span>(<span class="string">&#x27;sign&#x27;</span>, base64md5); <span class="comment">// 将变量放入postman 变量中;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>图一、添加postman环境变量<br><img src="https://upload-images.jianshu.io/upload_images/14027542-5337c8380fbe226e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-323bcf356a646c1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-2cf8d68e2ad29999.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>图二、postman脚本调试<br><img src="https://upload-images.jianshu.io/upload_images/14027542-6f2ffb4315989907.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-066f5d87bcf85312.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-5e0888d32e2590c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>vim</title>
    <url>/2020/03/20/tools_vim/</url>
    <content><![CDATA[<ul>
<li>vim中文乱码 <code> set fileencodings=utf-8</code></li>
<li>十六进制显示 <code>:!xxd</code></li>
<li>十六进制显示, n个字节为一组 <code>:!xxd -g n</code></li>
<li>n,m 行复制到x行之后 <code>:n,m co x</code></li>
<li>n,m 行移动到x行之后 <code>:n,m m x</code></li>
<li>一批id、组装成SQL<br><code>:%s/^/select field from table where id=/g</code></li>
<li>vim匹配指定模式删除 <code>:g/pattern/d</code></li>
<li>vim删除非指定模式的行 <code>:v/pattern/d</code> or <code>:g!/pattern/d</code></li>
<li>包含指定字符的个数 <code>:%s/pattern//gn</code></li>
<li>忽略大小写查找 &#96;&#x2F;</li>
</ul>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>xmind常用快捷键</title>
    <url>/2020/03/20/tools_xmind%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<p><code>tab</code> 插入子主题<br><code>shift + enter</code> 当前主题之前插入主题<br><code>enter</code> 当前主题之后插入主题<br><code>command + B</code> 插入外框<br><code>option + enter</code> 插入标注<br><code>command + ]</code> 插入概要<br><code>command + L</code> 插入联系<br><code>command + i</code> 插入图片</p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>常用shell</title>
    <url>/2020/03/20/tools_%E5%B8%B8%E7%94%A8shell/</url>
    <content><![CDATA[<p>AWK 多个分隔符</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">awk</span> -F <span class="string">&#x27;[sep1|sep2]&#x27;</span> <span class="string">&#x27;&#123;print <span class="variable">$0</span>&#125;&#x27;</span></span><br></pre></td></tr></table></figure>



<p>删除文件中包含指定字符串的行</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">&#x27;/abc/d&#x27;</span>  <span class="selector-tag">a</span><span class="selector-class">.txt</span>  &gt; <span class="selector-tag">a</span><span class="selector-class">.log</span>   <span class="comment">// 删除a.txt中含&quot;abc&quot;的行，将操作之后的结果保存到a.log</span></span><br><span class="line"></span><br><span class="line">sed <span class="string">&#x27;/abc/d;/efg/d&#x27;</span> <span class="selector-tag">a</span><span class="selector-class">.txt</span> &gt; <span class="selector-tag">a</span><span class="selector-class">.log</span>    <span class="comment">// 删除含字符串&quot;abc&quot;或“efg&quot;的行，将结果保存到a.log</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>替换指定字符串</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s/reg/replace/g&#x27;</span> 将reg替换为replcace</span><br><span class="line">eg. sed -i <span class="string">&quot;s/aaa/bbb/g&quot;</span> <span class="regexp">/tmp/</span><span class="number">1</span> 将<span class="regexp">/tmp/</span><span class="number">1</span> 文件中的a替换为b</span><br></pre></td></tr></table></figure>


<p>截取n到m列</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">head -<span class="number">3</span> /tmp/<span class="number">3</span> | cut -d<span class="symbol">&#x27;sep</span>&#x27; -f <span class="number">2</span>,<span class="number">7</span></span><br><span class="line">-d 指定分隔符</span><br><span class="line">-f 指定截取列</span><br><span class="line"></span><br><span class="line">cut 常用参数</span><br><span class="line">-d :分隔符 （ <span class="comment">--delimiter 按照指定分隔符分割列 ）</span></span><br><span class="line">-b : 表示字节</span><br><span class="line">-c : 表示字符</span><br><span class="line">-f : 表示字段(列号) （ <span class="comment">--field 提取第几列 ）</span></span><br><span class="line">N- : 从第<span class="type">N</span>个字节、字符、字段到结尾</span><br><span class="line">N-M : 从第<span class="type">N</span>个字节、字符、字段到第M个</span><br><span class="line">-M : 从第一个字节、字符、字段到第<span class="type">M</span>个</span><br><span class="line">eg. head -<span class="number">3</span> /tmp/<span class="number">3</span> | cut -c1-<span class="number">3</span> 截取字符串第<span class="number">1</span>到<span class="number">3</span>列</span><br></pre></td></tr></table></figure>

<p>diff 文件差异</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1. <span class="built_in">comm</span> 命令(需要先进行文件排序 <span class="built_in">sort</span> file1 )</span><br><span class="line">    <span class="built_in">comm</span> -23 file1 file2 &gt; /tmp/1 得到只在file1、不在file2中的数据</span><br><span class="line">      -1   不显示只在第1个文件里出现过的列。</span><br><span class="line">      -2   不显示只在第2个文件里出现过的列。</span><br><span class="line">      -3   不显示只在第1和第2个文件里出现过的列。</span><br><span class="line">2. diff 命令</span><br><span class="line">3. <span class="built_in">sort</span> 命令</span><br><span class="line">    <span class="built_in">sort</span> file2 file1 file1 | <span class="built_in">uniq</span> -u  &gt; /tmp/1</span><br></pre></td></tr></table></figure>

<p>字符串截取</p>
<blockquote>
<p><code>$&#123;string: start :length&#125;</code> 左边开始计数<br><code>$&#123;string: start :length&#125;</code> 右边开始计数</p>
</blockquote>
<p>二进制文件查看</p>
<blockquote>
<p>xxd -b file</p>
</blockquote>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>常用sql</title>
    <url>/2020/03/20/tools_%E5%B8%B8%E7%94%A8sql/</url>
    <content><![CDATA[<ol>
<li><p>insert.. select<br>eg. insert into tb1 select * from tb2 ; </p>
</li>
<li><p>create … like<br>eg. create tb1 like tb2;</p>
</li>
<li><p>查看所有库中包含指定字段的所有表</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> information_schema <span class="keyword">where</span> <span class="built_in">column_name</span>=<span class="string">&#x27;xxx&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 指定db</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> information_schema <span class="keyword">where</span> <span class="built_in">column_name</span>=<span class="string">&#x27;xxx&#x27;</span> <span class="keyword">and</span> table_schema=<span class="string">&#x27;xxdb&#x27;</span>; </span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>批量修改表字段类型</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> CONCAT(<span class="string">&#x27;alter table  &#x27;</span>,TABLE_SCHEMA,<span class="string">&#x27;.&#x27;</span>,TABLE_NAME,<span class="string">&#x27;  </span></span><br><span class="line"><span class="string">modify `&#x27;</span>, COLUMN_NAME, <span class="string">&#x27;` bigint(20) &#x27;</span>,  </span><br><span class="line"><span class="string">&#x27; default &#x27;</span>, COLUMN_DEFAULT, <span class="string">&#x27; COMMENT  &#x27;&#x27; , COLUMN_COMMENT, &#x27;&#x27;;&#x27;</span>) </span><br><span class="line"><span class="keyword">from</span> information_schema.COLUMNS </span><br><span class="line"><span class="keyword">where</span>  COLUMN_NAME <span class="operator">=</span> <span class="string">&#x27;first_order_id&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>彻底卸载idea</title>
    <url>/2020/03/20/tools_%E5%BD%BB%E5%BA%95%E5%8D%B8%E8%BD%BDidea/</url>
    <content><![CDATA[<p>完全卸载idea</p>
<p>首先在应用里面右键移动到垃圾桶[先卸载应用]</p>
<p>cd Users&#x2F;xxx&#x2F;Library&#x2F;</p>
<p>上面的xxx对应你的用户名，然后输入</p>
<p>rm -rf Logs&#x2F;IntelliJIdeaxxx&#x2F;</p>
<p>rm -rf Preferences&#x2F;IntelliJIdeaxxx&#x2F;</p>
<p>rm -rf Application\ Support&#x2F;IntelliJIdeaxxx&#x2F;</p>
<p>rm -rf Caches&#x2F;IntelliJIdeaxxx<br>上面的对应xxx对应不同的版本号，注意开头是 IntelliJIdea就行</p>
<p>把～&#x2F;下的.idea&#x2F;也删掉</p>
<p>Idea 的缓存文件在</p>
<p>&#x2F;Users&#x2F;xxxx&#x2F;Library&#x2F;Preferences<br>注意：以上方式会直接删除缓存文件，所以你重新安装的idea，没有任何插件【卸载前可导出配置setting.jar】</p>
<p> <br>原文链接：<a href="https://blog.csdn.net/qq_17213067/article/details/88226062">https://blog.csdn.net/qq_17213067/article/details/88226062</a></p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>表数据删了一半、表大小不变</title>
    <url>/2020/03/20/mysql_%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%88%A0%E4%BA%86%E4%B8%80%E5%8D%8A%E3%80%81%E8%A1%A8%E5%A4%A7%E5%B0%8F%E4%B8%8D%E5%8F%98/</url>
    <content><![CDATA[<blockquote>
<p>innodb表包含两部分: 表定义和表数据、在mysql8.0之前、表定义单独存放、.frm 文件、8.0之后允许把表结构定义放在系统数据表中了(表结构定义占用的空间很小)</p>
</blockquote>
<h4 id="innodb-file-per-table"><a href="#innodb-file-per-table" class="headerlink" title="innodb_file_per_table"></a>innodb_file_per_table</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">off</span>: 表数据放在系统共享表空间、跟数据字典放在一起</span><br><span class="line"><span class="keyword">on</span>: 每个innodb表数据存储在一个.ibd结尾的文件中(<span class="keyword">drop</span> <span class="keyword">table</span>时直接删除文件)</span><br></pre></td></tr></table></figure>

<h4 id="数据删除流程"><a href="#数据删除流程" class="headerlink" title="数据删除流程"></a>数据删除流程</h4><p><img src="https://upload-images.jianshu.io/upload_images/14027542-9ef7fd91e2dcd722.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="索引树示意图"></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 假设删掉R4这个记录、innodb引擎只会把这个记录标记为已删除、之后再插入一个300-600之间的记录时、可能会复用这个位置、但是空间不会释放</span><br><span class="line"><span class="bullet">2.</span> innodb的数据是按页存放的、如果删掉了一个数据页上的所有内容呢 ？</span><br><span class="line"><span class="code">    整个页可以复用</span></span><br><span class="line"><span class="code">3. 数据页的复用: 可以复用到任意位置</span></span><br><span class="line"><span class="code">    记录复用: 插入数据若不在400-600之间、无法复用</span></span><br><span class="line"><span class="code">4. 若相邻两个数据页的利用率都很小、系统会把数据合并到一个页】另一个标记为可复用</span></span><br><span class="line"><span class="code">5. delete删除整个表数据呢？所有数据页都被标记为可复用</span></span><br><span class="line"><span class="code">所以delete操作只是标记页面可复用、这些可复用但未被复用的空间、就像是空洞、空间不会回收</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">6.</span> 插入数据也会造成空洞</span><br><span class="line"><span class="code">    数据若不是顺序插入、如果需要在某个页的末尾插入一条记录、就会申请新的页、把要插入位置之后的数据转移到新的页去: 如下图</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-dede264180fcc1f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<h4 id="如何去除空洞"><a href="#如何去除空洞" class="headerlink" title="如何去除空洞"></a>如何去除空洞</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 重建表 alter table A engine=Innodb</span><br><span class="line"><span class="bullet">2.</span> 5.6之后的版本、引入Online DDL、重建流程变为: </span><br><span class="line"><span class="bullet">    1.</span> 建立一个临时文件、扫描表A主键的所有数据页、</span><br><span class="line"><span class="bullet">    2.</span> 用数据页中表A的记录生成B+树、存储到临时文件中、</span><br><span class="line"><span class="bullet">    3.</span> 生成临时文件过程中、所有表A的操作记录在日志文件(row log) 中、</span><br><span class="line"><span class="bullet">    4.</span> 临时文件生成后、将日志文件应用于临时文件、得到与表A逻辑相同的文件</span><br><span class="line"><span class="bullet">    5.</span> 用临时文件替换表A的数据文件</span><br><span class="line"><span class="code">    与以前不同之处在于: 在重建表的过程中允许对表A的操作</span></span><br><span class="line"><span class="code"></span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-92ae8e30bfdb3194.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="重建表流程.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-79acd12bb61357d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Online DDL.png"></p>
<h4 id="完全Online-？"><a href="#完全Online-？" class="headerlink" title="完全Online ？"></a>完全Online ？</h4><figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">不是, DDL之前是要拿MDL锁的、但这个写锁会在<span class="keyword">copy</span>数据之前退化成读锁、就不会阻塞CURD操作了</span><br><span class="line">可以直接解锁？不行、为了保证自己在<span class="keyword">copy</span>的过程中表结构不会再次被修改、为了保护自己</span><br><span class="line">对大表来说、最耗时的是<span class="keyword">copy</span>文件、可以认为MDL读锁的时间可以忽略、但操作会比较消耗IO和CPU、安全操作可以使用 gh-ost来做</span><br></pre></td></tr></table></figure>

<h4 id="online和inplace"><a href="#online和inplace" class="headerlink" title="online和inplace"></a>online和inplace</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">图三中、表A导出数据存放位置叫tmp_table、是一个临时表、在<span class="keyword">server</span>层创建</span><br><span class="line">图四种、表A重建的数据放在tmp_file、是innodb内部创建出来的、整个DDL过程在innodb内部完成、对<span class="keyword">server</span>来说、没有挪到数据到临时表、是原地操作、inplace</span><br><span class="line"></span><br><span class="line">假如磁盘空间是<span class="number">1.2</span>T、现有一个<span class="number">1</span>T的表、可否完成一个inpalce的DDL？</span><br><span class="line">不能、inplace也是需要临时空间的、<span class="keyword">alter</span> <span class="keyword">table</span> t engine=innodb,ALGORITHM=inplace;</span><br><span class="line"><span class="keyword">copy</span>表其实是: <span class="keyword">alter</span> <span class="keyword">table</span> t engine=innodb,ALGORITHM=<span class="keyword">copy</span>; 对应图三</span><br><span class="line"></span><br><span class="line">inplace和online并无直接关系</span><br><span class="line">eg. 添加索引、是inplace操作、但不是online的</span><br></pre></td></tr></table></figure>

<h4 id="alter-table、analyze-table-、-optimize-table"><a href="#alter-table、analyze-table-、-optimize-table" class="headerlink" title="alter table、analyze table 、 optimize table"></a>alter table、analyze table 、 optimize table</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 5.6之后、默认上图四操作、就是recreate</span><br><span class="line"><span class="bullet">2.</span> analyze table不是重建表、是重新统计索引信息、过程会加MDL读锁</span><br><span class="line"><span class="bullet">3.</span> optimize = recreate+analyze</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/2020/03/20/web-design_README/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Web-design</category>
      </categories>
      <tags>
        <tag>Web-design</tag>
      </tags>
  </entry>
  <entry>
    <title>再忆陈情</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E5%86%8D%E5%BF%86%E9%99%88%E6%83%85/</url>
    <content><![CDATA[<blockquote>
<p>年关、慵懒极了、想看看电视剧、读读小说、结束一年的忙忙碌碌.<br>看了庆余年、看评论提到了 <a href="https://v.qq.com/detail/v/vbb35hm6m6da1wc.html"><strong>陈情令</strong></a>、初播便得到很多好评的一部电视剧, 彼时未得闲暇、未曾顾及, 此时看到、不免心生欢喜. </p>
</blockquote>
<pre><code>回忆开头、未懂, 不明所以, 剧情渐入回忆, 我渐渐沉迷...
想以人物为主线、理理自己的思绪、乱七八糟、若不慎入眼、看看且过即可...

绵绵: 善良正直真性情的小女孩、也算是剧中最幸福的一个, 地位不高、
      首次出现在与金子轩一起去云深不知处听学时、那时结识魏无羡. 
      后在被温氏要挟、去不夜天听训时、被魏婴救过(挡下烙铁). 
      射日之征后, 魏婴被诬陷、绵绵挺身而出、直言 魏婴不是这样的人, 遂脱离金家氏族. 
      最后一场戏是魏婴、蓝忘机再次去乱葬岗时路过山野小屋、竟是绵绵与丈夫、还有一个乖巧的女儿、
      也叫绵绵, 只怕是绵绵无尽的思念也未可知~
      结局也算美好、在告别金家氏族、告别蓝忘机之后、远离了`正义`, 活成了自己喜欢的样子.
      戏份不多、确是活的最洒脱的女子.

薛洋: 作恶多端、却无法相恨, 他坏、但坏的明明白白, 恨不起来大概是因为他受过的那许多的苦.
      从小遭受了太多世界的冰冷、从未感受过暖、世界不曾教过他、又缘何怪他不懂 ？晓星尘给他点滴的爱、
      他就把晓星尘放在心头, 若他成长的道路上有阳光、他何尝不会是一个好孩子 ？ 
      或许有很多朋友愿意说、魏婴也遭受了很多打击与诬陷, 区别就在于所有的遭遇处于人生哪个阶段罢了.
      三观构建完成、就有了判断力、忍耐力、有了思考. 偏偏薛洋在人生最关键的时候遭受的都是冰冷, 
      从未有一米阳光, 对这个很坏的孩子更多的是同情吧、愿下一世、有阳光普照、有温暖与美好、
      带着你的聪慧、做个阳光明媚的孩子、一如你喜欢的晓星尘...
 
晓星尘、宋岚: 明月清风晓星尘，傲雪凌霜宋子琛, 开场被他们深深吸引、可惜戏份不多, 再出现已难回首...
     愿悲情的你们、下一世真正的活成明月清风. 也愿彼此间多一些信任， 就如 蓝湛和魏婴 ~

魏婴: 魏无羡 (夷陵老祖)、年少时经过几年流离生活、后被江枫眠带回江家、收为弟子、初始、
      江澄不喜欢他、但孩童总是天真、很快就成为好友、又有阿姐的悉心照料, 生活也算幸福、自身天赋极高、
      很快成为同辈里的佼佼者、排名仅在姑苏双壁之下, 修为极高、性格跳脱、善良随性、师姐的话就是
      `阿羡大事从不胡闹`, 佩剑取名`随意`、可见一般、活脱脱已调皮任性的小公子、但为人极善良、
      很多细节、他应该是将师姐看作母亲一般、在她面前任性、一副小孩子的模样、惹得江澄嫉妒, 
      后在云深不知处结识蓝二公子、调侃他`披麻戴孝`、偏生又爱挑逗他、此后接下不解之缘, 后在玄武洞
      救下绵绵、还惹得蓝二公子一身醋意, 身受重伤的他、挑逗忘玑、他要听歌、忘玑创作 `忘羡`, 
      随后温氏不满、欲灭江氏一族、为救江澄、舍弃自身金丹, 后被丢入乱葬岗、创造阴虎符. 
      射日后、力保温情族人、与众人为敌; 后与温氏族人一起在乱葬岗生活了一段时间, 也就是在此时、
      温宁开始对他不离不弃. 后金子轩惨死、温宁温情姐弟不忍拖累他、然后去自首、被挫骨扬灰(后证实宁未死)、
      接近崩溃的魏婴孤身来到不夜天与众人对峙, 师姐又为挡剑而死、当场崩溃、心如死灰
      十六年后、魏婴重生、亦是蓝湛的重生, 那个问灵十三载的少年郎...
      后师姐问及笛子叫何名字、遂取`陈情`, 且不乱猜、各人心想吧; 从`随意`到`陈情`, 承载了多少苦难？
      还好本心善良的魏婴和蓝湛一起重生、蓝湛将内心疮痍的`夷陵老祖`又养成了一个`小可爱`, 
      会撒娇、会调侃、会躲在身后~~~. 他知道蓝湛哥哥一定会护他周全...
      愿来生、还是那个偏偏白衣少年郎~~~

江澄: 江晚吟, 背负太多家族使命, 性格里有很多怯懦、也有许多坚强、从小被魏婴的光环笼罩、
       内心好强、想要胜过魏婴、却处处比不过、但也是从心底里心疼魏婴, 在乱葬岗为了家族、
      一剑刺在乱石上、这一剑、又何尝不是救了魏婴 ？ 若不是他、必是别人、那时候怕刺的不再是石头...
      莲花坞被侵占时、身心俱碎、发现外出为姐姐买药的魏婴将要被温氏发现时、挺身而出、
      让自己成为目标, 后被化丹手化去金丹, 一心好强的他、痛不欲生 ...
      这些何尝不是坚强？何尝不是关爱？有时对魏婴的挑剔怕是来源于亲昵的任性、心底的依赖...
      在穷奇道、魏婴就走温清族人、在乱葬岗下、魏婴带着温情族人一起生活、他气愤, 又怎么不是
      来自于想要被魏婴保护的渴望 ？ 姐姐虽对他们万般宠爱、终究帮不了太多、一个十几岁的孩子
      突然成为偌大的江氏家主、心中不免惶恐, 重建莲花坞、保护家族的重任就落在了他的肩上、
      注定不能成为魏婴一般潇潇洒洒的人....
      十六年后、与魏婴重聚、他生气、为何不先来找他、也是源自心底那份情吧？ 有些话说得不合适、
      但难掩心中的善、不是如同魏婴那般孤注一掷的善、彻彻底底的善、因为背负了太多的使命吧.....
      愿你来生、只做个任性的小公子、哎、你又这么好强、该如何是好？

江厌离: 暖情小姐姐、若得此姐、此生足矣. 在虞紫鸢强势的性格下居然能长出如此温婉的性格、着实不易、
       从小就保护阿羡、阿澄, 给他们煲汤、调节他们的不愉快. 无论是师姐的身份还是姐姐的身份, 
       他都是合格的、江澄和魏婴对她也都是依赖的, 在去往云深不知处时、偶遇未来夫婿金子轩, 
       开始喜欢他, 但此时子轩并不喜欢厌离、一番波折、总算是相互欢喜, 不料、在孩子满月酒宴时, 
       由于金光瑶捣乱、苏涉乱吹笛、导致温宁失控、误杀金子轩. 暖心的姐姐并没有恨魏婴、她相信他
       是发自心底的信任, 一刻也不曾动摇. 在她心里、羡羡和阿澄是最好的弟弟. 有次夜猎、
       魏婴被金家人侮辱`家仆之子`, 厌离挺身而出、一改柔弱、说`他是我弟弟、不是外人`, 要求对方道歉. 
       愿来生, 所爱之人携手白头、疼爱的弟弟膝下承欢, 愿小小心愿都能称心如意...
    
蓝湛: 蓝忘机, 含光君, 也是剧中称呼最多的一个(都是羡羡给的~~~), 有很多坎坷、也有很多甜美、
      雅正端方、严于律己、逢乱必出...
      遇到魏婴之前、清冷如冰, 遇见之后慢慢的因为知己、后深不可离...
      从最初的高傲冰冷变得调皮、玄武洞内调侃魏婴的情节、大概暖到了很多人. 魏婴帮他包扎伤口、
      上凝血草时、他突然抓住魏婴的手、将凝血草敷在了救绵绵时留下的烫伤上、顺便来了一句: 不用谢、哈哈~
      羡羡救绵绵、恐怕含光君还吃了一潭子醋、正经答道 `你要是没那个意思、不要随便撩拨别人`
      没忍住笑喷了, 含光君居然会这么可爱~, 一本正经的可爱这么好玩儿~~~
      他们也经历了很多的磨难、玄武洞、不夜城、穷奇道、乱葬岗...
      心一点点的被揪着, 不敢放松. 
      魏婴出事后、第一次违反家规、被罚3年禁闭、出来之后、无时不在寻找. 问灵十三载、等一不归人
      大部分剧友都觉得刻骨难忘吧 ？待到被问时、只轻轻一句、我有悔, 不夜天没有和你站在一起. 
      十六年里、受过魏无羡受的伤, 喝过魏无羡喝过的酒, 种魏无羡种过的思追, 气魏无羡气过的蓝启仁, 
      违反过魏无羡违反的家规, 将阿苑带回云深不知处、取字思追(思君不可追), 将思追养成了魏无羡、
      一样善良肆意洒脱、敢于做自己, 一样的善良热血、将破魔咒珍藏了16年.
      十六年后、魏婴复生、成为魏婴最真切的守护神、凭借`忘羡` 立即认出魏婴、此后对魏婴可谓无微不至的
      关怀、不允许别人对他丝毫的伤害、魏婴怕狗、躲在忘玑身后的情节也是温暖了很多剧友~~~, 
      醉酒抓鸡的情节也是深入人心. 魏婴被欺负时、他对哥哥说、我想带一人回云深不知处、藏起来..., 
     被人戏称`护妻狂魔`,^.^~
      愿来生, 温润如玉、有母爱陪伴、多些笑容、早遇知己, 愿给你所有的美好


蓝涣: 蓝曦臣, 泽芜君. 与弟弟含光君一起并称`姑苏双壁`, 清煦温雅、永远都是那么善良、那么温柔、理智
      修为极高、从不欺负弱小、若他称谦谦公子第二、怕是没人敢居第一吧？整部剧除了两个情节失态、
      一直是温润如玉、长者之风、十分疼爱弟弟忘玑、初见魏婴、觉得适合做弟弟的朋友、便各种暗示
      可以猜透忘玑心中所想, 魏婴身死魂消后、一直陪伴在侧. 道出忘玑身上戒鞭痕来历、
      又在云梦观音庙吐露忘玑对魏婴的13年苦守、促使二人心意相通
      一直拿金光瑶当成最好的朋友、聂明玦和金光瑶关系不和、他居中调节、魏婴回归后、发现金光瑶
      所做的事情、他不愿相信、对忘玑说: 你相信魏婴、我相信阿瑶、他是你的知己、阿瑶也是我的知己(非原话). 
      又将随意出入云深不知处的令牌给金光瑶, 可见信任非同一般. 可惜、金光瑶却真实的死在了他手上、
      恐怕心中的痛无人能晓吧 ？愿有人将你温暖、替你扛下一些使命...
      之前温氏毁掉云深不知处、打伤他最疼爱的弟弟、害他狼狈出逃、在清缴温氏时、
      他依然冷静的将温情与温家分开、仗义执言、不迁怒于人、难能可贵.
      借言百度百科:
      1. 蓝曦臣沉吟道：&quot;这位温情的大名我知晓几分，似乎没听说她参与过射日之征中任何一场凶案的。&quot;
      聂明玦道：&quot;可她也没有阻拦过. &quot;
      蓝曦臣道：&quot;温情是温若寒的亲信之一，如何能阻拦？&quot;
      2. 聂明玦道：&quot;英魂长存&quot; 蓝曦臣道：&quot;愿安息. &quot;
      他的心底相信魏婴做的不算冤枉吧？只是敌人、仇人死了、他依然愿意安静的道一声&quot;愿安息&quot;.
      来生、愿你仍为翩翩君子、温润如玉、愿你有属于自己的幸福、有人疼、有人爱、不用一人担尽天下心.

蓝思追: 阿苑, 从小漂泊、经历不夜城被毁、同族人一起经历不幸、后被魏婴救出、带领他们生活在乱葬岗下.
    还好、余生皆是暖情. 小小年纪、还不知凄苦悲凉、有族人陪伴、魏婴逗玩、在乱葬岗依然生活的快乐、
    被魏婴当成萝卜种在地里的情节好暖心, 后被蓝二哥哥效仿羡羡当成小兔子种、哈哈哈、好温暖~~~
    小时候称蓝二哥哥有钱哥哥、喜欢抱大腿儿(~.~), 魏婴出事后、被蓝二哥哥悄悄收养、改名 蓝苑、字思追. 
    在蓝湛的培养下、变成一个谦谦君子、又糅合了魏婴的灵动、善良、恣意洒脱、挺招人喜欢的, 初见鬼将军很怕、
    但不让人伤害他, 初见十六年后的魏婴、不让别人欺负他、善良的孩子~~~
    愿来生、满满的岁月静好 ....

温晁: 温若寒小公子, 嚣张跋扈、高傲自大、行径恶劣. 喜欢显摆、因为不满江家不服从温家的指令，
      所以找了个借口把江家灭门。魏无羡和江澄虽然有幸逃过一命，但是江澄的金丹被温逐流炼化，
      彻底丢失了灵力。而魏无羡在把金丹给了江澄后，被温晁丢进乱葬岗里
      剧中、我真心找不到他的一点儿善良...
      就算在最后、都还在斥责温逐流、彻彻底底很可恶的一个人, 愿来生、学会善良、读懂温暖...

温情: 岐山温氏人、一个旁支、高傲能干的妙手神医, 内心善良. 倾尽全力的保护族人、保护弟弟, 
     不夜天听训时、被温若寒恐吓、为了弟弟安危、告诉弟弟不要乱跑、不要和魏婴混在一起,  自己却逮着机会就帮助魏婴,
     后莲花坞被温氏侵占、江枫眠和虞紫鸢被害、收留江家姐弟并为他们疗伤, 又帮助魏婴实现换丹. 
     最悲情的角色、天性善良、不作恶、却是剧中唯一被挫骨扬灰的一个...
     来生、愿安好、与自己的族人过着静美的小日子 ~~~

温宁: 暖心的小天使、从小被抽去一部分灵识、显得呆呆傻傻, 因魏婴在云深不知处赏识、
      内心孤僻的温宁从此感恩、在不夜城救过魏婴、在莲花坞被毁时帮过魏婴, 射日后、魏婴在穷奇道救下
      温宁及其族人、后成为`鬼将军`(傀儡)但保留了意识、功力大增、听魏婴吹笛杀人、后被金光瑶控制
      十六年后重逢与魏婴重逢、拔出他头部的铁钉、更加只听魏婴一个人的、称他为`公子`. 
      整部剧一直感觉他是一个温暖的小天使, 呆萌可爱 ...
      愿来生, 他可以生的美好、做一个暖情的小公子, 弥补此生的孤独.
      愿来生只做白衣少年温琼林...

金子轩: 金家公子、为人高傲、但心底善良、敢于追求内心的爱、人物着墨不多. 来生, 愿幸福~~~

金光瑶: 人物性格比较复杂、表面温和、内心阴暗、但真心帮助蓝曦臣. 剧里做了很多坏事、最终也只是
        为他人做嫁衣、母亲虽为艺伎、不多的着笔、却让人难忘、是一个温和、知书识礼的好母亲
       后来利用蓝曦臣(清心音)设计杀害聂明玦、并做成凶尸. 为了得到秦仓业支持、娶同父异母
       妹妹秦愫、又为免受非议、杀死亲生子金如松. 为了夺取金家地位、杀死父亲金光善. 与薛洋一般、
       是一个缺少温暖的孩子、内心有太多的恨与恶、千般不该、设计杀死聂明玦、那个曾经给他支持、
       拿他当亲兄弟对待的人. 就算知道他放走薛洋、也只是把他赶出去、并未伤害他、这样的人都伤害、
       心中有个无法原谅的坎儿....
       来生、愿其母觅得良人、给他一个温暖的家, 愿多些温暖、少些心中阴霾. 

聂怀桑: 初时、同魏婴一般、算是志趣相投. 修为不高、成为家主之后被称为: 三不知、然而看似柔弱无害
       的他, 确是藏的最深的一个、剧中有很多伏笔, 比如: 十六年后说书人说到夷陵老祖时的回头一看
       大梵山假的舞天女重生
       温家墓前的扫墓老丈其实是聂怀桑...
       从魏婴十六年后重生到后续的情节、由他一人策划、只为复兄仇, 算不
       得坏、不是大奸大恶之人、亦无泽芜君的容人之量、终究是被内心的情感左右、算不得对、算不得错、
       好在、此后任逍遥~~~, 也没什么野心、亦真心喜欢和魏婴做朋友.
       来生、愿有哥哥一生庇佑、只做恣意山水的快活少年.
</code></pre>
<p>好多情节、令人禁不住落泪、或是真情流露、或是温暖荡漾、或者是悲情感慨, 人物是复杂的、性格是综合的、确也更符合现实的人性吧. 世上人心终是横看成火、侧看成冰. 本着不讨论的原则写文、可能还是注入了不少自己的感情、魏婴和蓝湛的爱情也实在太感人了耶、^*^ 、闲来无事可以看看~~~</p>
<p>附图册:<br><img src="https://upload-images.jianshu.io/upload_images/14027542-820ea7d77fee68d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="绵绵.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-a8df6e357a7eed1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="温情.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-4c78adb0ad0aa9b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="江厌离..png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-9e2a3cd49e1d6dec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="羡羡和忘玑.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-4a13722b0f5c8922.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="羡羡和忘玑.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-27e948953c0e8834.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="羡羡和忘玑.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-9f673870dbd02b47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="蓝曦臣.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-805db79586c26cc4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="魏婴和聂怀桑.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-04623bbab6fc3eda.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="晓星尘.png"></p>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>收藏</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E6%94%B6%E8%97%8F/</url>
    <content><![CDATA[<p>文档：MySQL技术内幕 InnoDB存储引擎<br>链接：<a href="http://note.youdao.com/noteshare?id=825861cad04ce2d9420b7c6949320dee">http://note.youdao.com/noteshare?id=825861cad04ce2d9420b7c6949320dee</a></p>
<p>文档：从Paxos到zookeeper<br>链接：<a href="http://note.youdao.com/noteshare?id=5c62699d4db431b25d73ff05bf500fbf">http://note.youdao.com/noteshare?id=5c62699d4db431b25d73ff05bf500fbf</a></p>
<p>文档：深入理解Java虚拟机<br>链接：<a href="http://note.youdao.com/noteshare?id=bca9a23c7db0031bc7a67010ffbab1bd">http://note.youdao.com/noteshare?id=bca9a23c7db0031bc7a67010ffbab1bd</a></p>
<p>jvm工具收藏<br><a href="https://www.cnblogs.com/noKing/p/9457541.html">https://www.cnblogs.com/noKing/p/9457541.html</a></p>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>早安、世界</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E6%97%A9%E5%AE%89%E3%80%81%E4%B8%96%E7%95%8C/</url>
    <content><![CDATA[<p>啊哈</p>
<!-- MarkdownTOC -->

<ul>
<li>缘起</li>
<li>过往、感恩</li>
<li>现在、enjoying~~</li>
<li>未来、waiting~~</li>
<li>接下来的日子</li>
<li>Why</li>
</ul>
<!-- /MarkdownTOC -->

<h4 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h4><figure class="highlight parser3"><table><tr><td class="code"><pre><span class="line"><span class="language-xml">起床、读书、做在窗边、抬头的那一刻、竟是万分温暖、初阳淡淡、轻洒墙角、沉睡了一晚的楼脚飘过</span></span><br><span class="line"><span class="language-xml">一抹明丽的淡红、不由自主想起那些游离于心间的美好、禁不住自我感动了一把</span><span class="keyword">^.</span><span class="language-xml">^</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">又想起最近种种、嗯嗯、新开的简书还是空白的、那么、让我开始一个新的篇章吧~~</span></span><br></pre></td></tr></table></figure>

<h4 id="过往、感恩"><a href="#过往、感恩" class="headerlink" title="过往、感恩"></a>过往、感恩</h4><figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line">普通的不能在普通的大学、好不经意流散的时光、无所事事面对将要毕业的我、无疑是失败的~~</span><br><span class="line"></span><br><span class="line">幸运、偶然的机会走近 <span class="keyword">IT</span> 的世界、从此打开一扇门、感谢曾经一路走来的小伙伴、给过我太多帮助</span><br><span class="line"></span><br><span class="line">幸运、<span class="number">16</span>年年初发现自己的世界如此之小、别离、来到北京、或许那时候只是觉得自己的世界太小了、想要一个更大的天地</span><br><span class="line"></span><br><span class="line">幸运、来到北京没有遇到太多别人描述里的坎坷与压力、有的是我想要的世界、有的是同事的热心帮助、</span><br><span class="line">差不多从没基础开始吧、从此我进入了一个喜欢而又迷茫着的世界、发现它的周边是如此的绚丽多彩、</span><br><span class="line">从此、匆匆忙忙、想要知道的多一点、再多一点、那时候不懂的东西太多、感觉是新鲜好奇的、于是尽自己最大努力去学、沉浸于这种成长的幸福</span><br><span class="line"></span><br><span class="line">要感谢的人很多、你们陪我成长、给我鼓励、~~心里默默一一谢过、而有些、我相信、我不说、你们也懂、</span><br><span class="line">懂我深深的感恩、亦懂我害怕让你们失望的忐忑、让我们一起加油、为我们喜欢的未来~.~</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="现在、enjoying"><a href="#现在、enjoying" class="headerlink" title="现在、enjoying~~"></a>现在、enjoying~~</h4><figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line">   过往、就在那里、不管你喜不喜欢、都不会再变、我的过去不管是无知的苍白还是迷茫后的成长、</span><br><span class="line">   我都喜欢、它的身上流动着我的气息、无知的四年大学、我亦不后悔、一种经历、一种人生。</span><br><span class="line"></span><br><span class="line">   笃信、不喜欢的过去、就认真的作为借鉴、迷茫之后、世界是清晰的、却也更大更广、</span><br><span class="line">   很长一段时间的迷茫之后、不久前、选择了一条、在很多人眼里向下走的路、我却坚定不移、</span><br><span class="line">我相信自己的选择、我知道自己想要什么</span><br><span class="line">   en/就酱紫、自己决定了的、就认真的走下去、失败总比苍白更美好</span><br><span class="line"></span><br><span class="line">   换句话、既然一无所有、又何惧失败、~~</span><br><span class="line"></span><br><span class="line">   诚然、幸运之神再次眷顾了我、很顺利、下个月中旬可以转过去、开始java之旅、为了得到这次机会、</span><br><span class="line">   我同意php 和 java的项目一起做、精力稍有分散、会有<span class="number">2</span>份压力、但我愿意用这段时光见证自己的成长</span><br><span class="line">   enen~.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="未来、waiting"><a href="#未来、waiting" class="headerlink" title="未来、waiting~~"></a>未来、waiting~~</h4><figure class="highlight parser3"><table><tr><td class="code"><pre><span class="line"><span class="language-xml">生如逆旅单行道、哪有岁月可回头、既然如此、何不用心谱写未来、干嘛不让未来的自己感谢现在的自己</span><span class="keyword">^.</span><span class="language-xml">^</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="keyword">^.</span><span class="language-xml">^ enen、我还是那个小小小小的小女孩儿</span></span><br><span class="line"><span class="language-xml">那个每次有好事发生都把你们拿出来感谢一遍的小女生、你们告诉我那叫越努力越幸运、</span></span><br><span class="line"><span class="language-xml">我心底却始终认为该归功于你们、是你们不遗余力的帮助、so、不管是怎样的吧、愿我们的未来都是我们期待的模样</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">勇气不是不害怕、而是尽管害怕依然可以迎难而上～</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">愿我们都能带着一颗留白的心上路、在光阴里扮演一个最从容的角色～</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">愿我们都能带着最微薄的行李和最丰厚的自己、在时间里流浪、流梦为马、随处可栖～</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">Thanks、我的朋友们、你们才是我最宝贵的财富、愿我们永远是最幸福的模样~~</span></span><br></pre></td></tr></table></figure>

<h4 id="接下来的日子"><a href="#接下来的日子" class="headerlink" title="接下来的日子"></a>接下来的日子</h4><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">还会喜欢看阳光飘落</span><br><span class="line">还会喜欢拿着洒水壶给我的小花儿们来一场甘霖</span><br><span class="line">还会喜欢晚上躺在床上什么都不思考、安静的放空自我</span><br><span class="line">还会喜欢抬眼的那一刻发现的诸多美好、一溜烟儿的跑出去浪上一会儿</span><br><span class="line">还会喜欢风轻轻吹过的日子、和朋友们做在一起聊聊天</span><br><span class="line">还会喜欢做在书桌前发发呆、思念我的朋友们</span><br><span class="line">还好喜欢周末去逛逛街、晚上跑跑步</span><br><span class="line">还会喜欢就算不论何时、都想要搞明白想要搞明白的东西、</span><br><span class="line"><span class="keyword">en</span>/我还是我、所有的都一如既往~~</span><br></pre></td></tr></table></figure>

<h4 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h4><figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">是的、我... 小神经有犯抽了、aha~、总是喜欢这种细碎的小美好、怀念下朋友们、然后发发神经、</span><br><span class="line"></span><br><span class="line">正经的、未来不可欺、让我们一起加油吧~~</span><br><span class="line"></span><br><span class="line">==<span class="keyword">end</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>时光说</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E6%97%B6%E5%85%89%E8%AF%B4/</url>
    <content><![CDATA[<pre><code>    愿我们心生玲珑、细品丝丝温情～
    
    愿我们心坚如铁、足御刺骨寒冷～
    
    不委屈每一份善意、亦不惧怕每一分寒意～
    
    愿我们有人吐槽、亦善聆听～
    
    愿我们有人宠爱、亦不骄横～
    
    不满亦不积怨、任性但不失理性～
    
    愿我们有机会倾听故事的全部～
    
    愿我们就算是被人认识万分之一亦不悲伤～
    
    不愤世嫉俗、也不过分张扬～
    
    愿我们的朋友不止是正向的、能有机会完整的成长～
    
    愿我们见惯所有的恶、亦能有发自内心的善～
    
    懂得拿起、又善于放下～
    
    但愿我们能把平凡乃至糟糕的日子过的精彩、也能在顺风顺水的日子保持谦和～
    
    但愿我们能耐得住所有成长的寂寞、也能在最得意的时候谦卑温和～
    
    ……
    
    嗯、不是在最好的日子里遇到了你们、
    
    而是遇到你们才有了这段最美好的时光～
    
    不愿时光不老、不求相伴永远、但愿我们相顾不言早已知其冷暖～
    
    ------
    
    人生就是一场修行. 成长毫无违和～
</code></pre>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>未知的小惊喜</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E6%9C%AA%E7%9F%A5%E7%9A%84%E5%B0%8F%E6%83%8A%E5%96%9C/</url>
    <content><![CDATA[<p>时光跳动、晴雨霾风哀愁喜, 无需计较、无需叹息、无需着急….</p>
<p>属于你的、终归是属于你、想要的、只需努力、静静等待</p>
<p>有人说, 机遇很重要、是的、很重要、前提是、当机遇到来的时候有足够的能力来把握<br>机遇才叫机遇、否则只能叫别人的机遇….</p>
<p>有人说、背景很重要、是的、很重要、前提是、你只是芸芸众生中特别一般的一个<br>背景才能带来优越感、跳出一般人的圈子、背景可能只是润色….</p>
<p>有人说、家境很重要、是的、很重要、有些人一出生就在你人生的终点线附近、<br>能说这话的、一定没有一个特别优秀的家庭背景、<br>为何不努力让自己的下一代出生就站在较好的起点线上?</p>
<p>有人说、子孙自有子孙福、他们怎么样看自己的努力和造化、这话我不去反驳</p>
<p>我只想能给自己想要的东西、输在了起跑线不可怕<br>就算是奋斗了10年才能和别人坐在一起聊天又如何？如果不奋斗、连一起聊天的机会都没有<br>世界是不公平的、也是公平的</p>
<p>所有的努力不一定都能得到回报、不努力也不一定得不到回报<br>不管你选不选择、相不相信、事实就在这里</p>
<p>路还是要自己走的~~~</p>
<p>遇见小惊喜、迷惑了很久的东西、豁然开朗、感觉所有的努力都是值得的<br>有感而发</p>
<p>愿每个人都能按自己最喜欢的方式去生活、感谢不曾放弃努力的自己~</p>
<p>.^.^.</p>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>Sun Sep 08 2019 00:00:00 GMT+0800 (中国标准时间)</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E6%9D%82%E8%B0%88/</url>
    <content><![CDATA[<p>   突然想说、喜欢安姐、😝、优秀的那么自然、还有那么许多一直优秀的人、读读你们的故事、思考下自己的人生、是啊、对错并不重要、关键是成长和思考</p>
<p>希望所有人都能按照自己的意愿过一生</p>
<p>——- 杂谈 ——-</p>
<p>最近在看了些电视剧、射雕英雄传、很多自己喜欢的角色、可能每个人都不完美、但刻画的是那么的真实</p>
<p>黄蓉 机敏、博学、善良、调皮、黄小邪 哈哈哈~、总是特别的机智</p>
<p>郭靖 老实、有点儿木讷、小事听蓉儿的、大事却会坚守自己的内心、机警不足、有些迂腐、哈哈哈、不过瑕不掩瑜、善良而又有责任心的他应该赢得了不少人的好感</p>
<p>华筝 善良、专一、任性、顾大局、对她没有蓉儿喜欢的深、却想不到有什么不好的地方</p>
<p>穆念慈 善良、希望过平凡的生活可生活却给了她一个不甘心平凡的相公</p>
<p>杨康 好的一点是 对自己在乎的人是很真心的、比如父王、母亲、念慈、师傅、不能忍受的是 做事情太残忍、不善良、喜欢他的规划性、年纪不大、做事情缺能充分考虑、前后关联、这种思维很重要, 如果方向不偏、应该是有一番成就的、抢夺丐帮帮主那事儿、我觉得不是一般20岁的孩子就能达到的思维水平、可以认可的是能力、但不证明他做的事情是正确的</p>
<p>丘处机 我觉得最不好的一点是 每次不给人说话的机会、太过于按照自己的想法去判定<br>至少 在开篇和江南奇怪打起来、导致主持过世他是有一部分责任的、如果先搞清楚是非黑白、就不至于这样、孙x来着的、同样的问题</p>
<p>老顽童  哈哈哈、很深入人心的一个角色、任性、贪玩儿、武功很好、对朋友也很好、有时候责任心不够</p>
<p>洪七公 武功好、人好、不古板、耐心好、我最欣赏的角色之一、不像大多数的角色一样、不给人说话解释的机会</p>
<p>黄老邪  挺喜欢的、热情、不古板、博学、有责任心、若说做错了什么、大概就是对他那几个徒儿吧、角色整体来说很喜欢、喜欢那份儿潇洒、喜欢那份儿真诚、或许也是经过世事历练的成长吧、从很多回忆来看、年轻时应该比较狂傲、大抵也不怎么听得进去劝~</p>
<p>共性: 大侠们不喜欢搞清楚事实、过于江湖义气、过于在乎名誉</p>
<p>可能最喜欢的角色是一灯大师、一直的善良、对瑛姑的钟爱、人生鼎盛时的峰转、归于自身的身心修养、喜欢这种淡淡的人生态度~~~~</p>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>那段时光、恰恰好~</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E9%82%A3%E6%AE%B5%E6%97%B6%E5%85%89%E3%80%81%E6%81%B0%E6%81%B0%E5%A5%BD~/</url>
    <content><![CDATA[<pre><code>                --  致心灵相依的朋友们
</code></pre>
<p>愿我们不浓不淡、不执着不言弃<br>清淡如水、落花无痕<br>如一缕清风、做着暖情的自己～ </p>
<p>温柔淡雅、在凡尘世事的人间烟火里做一个馨香的自己～<br>如一汪清泉、细润绵长</p>
<p>找寻内心深处最炙烈的自己、又学会不着痕迹～</p>
<p>愿我们温润如玉、凡世无双、用平凡造就灵魂的精灵～</p>
<p>一切恰到好处、只一句、你也在、刚刚好～</p>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>且走且回首</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E4%B8%94%E8%B5%B0%E4%B8%94%E5%9B%9E%E9%A6%96/</url>
    <content><![CDATA[<blockquote>
<p>不管是磕磕绊绊也好、惊喜无限也罢、我们总是用力的走完了这一年、犹如东逝之水、不管有没有激起一朵浪花、时光仍是悄然的划过、不留痕迹、或者交界钟声想起的那一刻、我们才蓦然明白、19年已从指间划过, 永远的变成回忆、沉淀在心底….</p>
</blockquote>
<p>2019年, 成长的一年、亦是堕落的一年, 经历了激情澎湃、我辈自有凌云志的兴奋期, 也挨过了 凄清惨淡的身心俱疲; 尝试过落叶无声, 默然关怀的佛系思维、也有过人我无犯的不甘怯懦, 时光滴滴哒哒的向前走、一切依然成了回忆、永远定格, 再去思考、凡此种种、或觉得可笑, 或觉得落寞</p>
<p>2020年、愿自己是阳光的、积极的、把更多的精力凝聚在自己身上, 给自己尽可能的成长, 感受日出日落的美好、品味云淡风轻的生活, 好好的锻炼身体, 努力的追求新知, 静待一切的一切、终将美好~~~</p>
<p>古今多少事、都付笑谈中, 愿我们都能惯看秋月春风, 遇见最美好的人、经历最美好的时光, 一起感受生活的滴滴点点、愿我们都如朝阳, 温暖而柔和….</p>
<p>未来的每一天都值得期待…..</p>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>零零碎的小美好</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E9%9B%B6%E9%9B%B6%E7%A2%8E%E7%9A%84%E5%B0%8F%E7%BE%8E%E5%A5%BD/</url>
    <content><![CDATA[<p>有些句子、简简单单、曼妙无比、收藏谨记~</p>
<ol>
<li><p>时光不老、青春不散、繁华落幕、漫看似水流年~</p>
</li>
<li><p>星光不问赶路人、时光不负有心人</p>
</li>
<li><p>生活从来不会给我们从容思考的机会</p>
</li>
<li><p>勿以流沙造高台</p>
</li>
<li><p>人生如逆旅，我亦是行人<br>ps: 生如逆旅单行道、从无岁月可回头</p>
</li>
<li><p>时光是种极好的东西、<br> 原谅了不可原谅的、过去了曾经过不去的、也许偶尔想回到之前的时光、但我知道 人 始终要学会向前看…</p>
</li>
<li><p>我也愿学习蝴蝶、一再的蜕变、一再的祝愿 既不思虑、也不彷徨；既不回顾、也不忧伤～</p>
</li>
<li><p>不雨花犹落、无风絮自飞</p>
</li>
<li><p>终于明白、有些路只能一个人走、<br>那些约好同行的人、一起相伴、走过雨季、走过年华、但总有一天会在某个渡口离散</p>
</li>
<li><p>真正的宁静、不是避开车马喧嚣、而是在心中修篱种菊、尽管如流往事、每一天都有涛声依旧、只要消除执念、便可寂静安然～</p>
</li>
<li><p>愿你此生清澈明朗、流年无殇; 也愿你时光静好、安暖如初</p>
</li>
</ol>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>陈情令经典对白</title>
    <url>/2020/03/20/%E5%B0%8F%E7%A1%AE%E5%B9%B8_%E9%99%88%E6%83%85%E4%BB%A4%E7%BB%8F%E5%85%B8%E5%AF%B9%E7%99%BD/</url>
    <content><![CDATA[<p>1、忘羡一曲远，曲终人不散。</p>
<p>2、我想带一人回云深不知处。带回去，藏起来。</p>
<p>3、我<a href="http://www.kuyv.cn/tv/modaozushizhichenqingling/castlist/11/"><strong>薛洋</strong></a>，晓天地，晓人心，但终究不<a href="http://www.kuyv.cn/tv/modaozushizhichenqingling/castlist/9/"><strong>晓星尘</strong></a>。</p>
<p>4、是<a href="http://www.kuyv.cn/tv/modaozushizhichenqingling/castlist/5/"><strong>蓝曦臣</strong></a>，我这一生，杀父杀兄杀妻杀子杀师杀友，什么坏事没做过!”他倒吸了一口气，仿佛肺部被刺穿，“可我独独没有想过要害你。</p>
<p>5、他并不怕摔，这些年来，也摔过很多次。但摔到地上，毕竟还是会疼。如果有个人能接住他，那就再好不过了。</p>
<p>6、其实从头到尾，被挫骨扬灰，灰飞烟灭的，只有<a href="http://www.kuyv.cn/tv/modaozushizhichenqingling/castlist/2/"><strong>温情</strong></a>一人。</p>
<p>7、要救一个人往往束手无策，可要害一个人，又何止有千百种办法。</p>
<p>8、为遇一人而入红尘，人去我亦去，此身不留尘。</p>
<p>9、全世界只为你一人唱的曲，今生成为我认出你最好的证明。</p>
<p>10、只是自以为心若顽石，却终究人非草木。</p>
<p>11、他是真真实实的人，他是见不得光的鬼，他们之间，仿佛永远都隔着这样一道生死鸿沟。</p>
<p>12、天真无忌的童言，最是能致命。小孩子什么都不懂，而正是因为他们不懂，所以伤人心才往往最直接。</p>
<p>13、我独自徘徊在孤苦世间、耗尽元神精气，宁可魂飞魄散，也想再见你一面。但这一见，就是最后永诀。</p>
<p>14、他哽咽着道：“你说过，将来我做家主，你做我的下属，一辈子扶持我，永远不会背叛云梦江氏……这是你自己说的。”沉默片刻，<a href="http://www.kuyv.cn/tv/modaozushizhichenqingling/castlist/0/"><strong>魏无羡</strong></a>道：“对不起。我食言了。”</p>
<p>15、喝他喝过的酒，受他受过的伤，种他种过的思追。</p>
<p>16、因为并不存在任何误会。误会这种东西，推心置腹畅谈一番，摊开了说，便能清楚明白、你好我好。可这世上，更多的是无解的难题。</p>
<p>17、现在才去堵伤口，什么用都没有。晓星尘已经死了，彻彻底底地死了。连魂魄都碎了。</p>
<p>18、人间欠我一颗糖，我却只有砒霜付以人间。</p>
<p>19、原以为殊途同归，却不想同道殊途。</p>
<p>20、薛洋，他们若不要你，我要你，你看，我也有糖…我知道，我不是晓星尘。</p>
<p>21、酒很香，很醇，也很辣，大概能明白那个人为什么会喜欢。喝他喝过的酒，受他受过的伤。</p>
<p>22、人这一辈子，有两句肉麻的话是非说不可的。――“谢谢你”和“对不起”。</p>
<p>23、晓星尘笑道：“那可不行，你一开口我就笑。我一笑，剑就不稳了。”</p>
<p>24、君不见陌上花开落几度，燕影疏斜去又还。君不闻无名之曲歌长夜，歪坐榻上醉复醒。君不知山有木兮木有枝，枇杷尚青酸伴苦。君不复黑衣横笛且徐行，执杯瑶酹对空席。</p>
<p>25、霜华敛去君珍重 在无明月送清风。</p>
]]></content>
      <categories>
        <category>小确幸</category>
      </categories>
      <tags>
        <tag>小确幸</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux基本认知-常用命令&amp;系统调用</title>
    <url>/2020/03/20/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F_Linux%E5%9F%BA%E6%9C%AC%E8%AE%A4%E7%9F%A5-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4&amp;%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</url>
    <content><![CDATA[<ol>
<li><p><code>rpm -qa</code> 查看安装的软件列表<br><code>-q</code> <code>--query</code> 查看  <code>-a</code> <code>--all</code> 所有<br>后可用管道输出 eg. <code>rpm -qa | less</code> <code>rpm -qa | grep mysql</code><br><code>-i</code> <code>--install</code> 从软件包安装<br><code>-e</code> <code>--erase</code> 删除软件包</p>
</li>
<li><p><code>man rpm</code> 查看rpm帮助文档</p>
</li>
<li><p>yum配置文件 <code>/etc/yum.repos.d/CentOS-Base.repo</code></p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">[base]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Base - <span class="number">163</span>.com</span><br><span class="line">baseurl=http:<span class="regexp">//mi</span>rrors.<span class="number">163</span>.com<span class="regexp">/centos/</span><span class="variable">$releasever</span><span class="regexp">/os/</span><span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=<span class="number">1</span></span><br><span class="line">gpgkey=http:<span class="regexp">//mi</span>rrors.<span class="number">163</span>.com<span class="regexp">/centos/</span>RPM-GPG-KEY-CentOS-<span class="number">7</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>nohup</code> <code>no hang up</code> 程序不挂起、退出命令行、程序依然执行</p>
</li>
<li><p><code>&amp;</code> 表示后台运行</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">nohup</span> command &gt; out.file <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br><span class="line"><span class="attribute">1</span>表示文件描述符<span class="number">1</span>, 代表标准输出</span><br><span class="line"><span class="attribute">2</span>表示文件描述符<span class="number">2</span>, 代表标准错误输出</span><br><span class="line"><span class="attribute">2</span>&gt;&amp;<span class="number">1</span> 合并标准错误输出和标准输出 输出到out.file</span><br></pre></td></tr></table></figure>

<blockquote>
<p>ps -ef | grep command | awk ‘{print $2}’ | xargs kill -9 </p>
<p>关闭进程</p>
</blockquote>
</li>
<li><p>创建新的进程 <code>fork</code></p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line">父进程返回<span class="number">0</span>、子进程返回进程号、调用execve来执行另外的程序(先copy再修改)</span><br><span class="line">每个进程有独立的内存空间、相互不干扰</span><br><span class="line">代码段: <span class="meta">Code</span> Segment 存放程序代码</span><br><span class="line">数据段: <span class="meta">Data</span> Segment 存放运行中数据</span><br><span class="line">       局部变量、当前函数执行时分配、运行结束释放</span><br><span class="line">       动态分配、长时间保存、指明才销毁 堆heap</span><br><span class="line">一个进程的内存空<span class="number">32</span>位是 <span class="number">4</span>G、<span class="number">64</span>位</span><br><span class="line"></span><br><span class="line">进程内存的分配是在使用时、进程需要使用内存的时候调用内存管理系统登记、但此时不会真正分配、真正写入数据的时候发现无对应物理内存、才会触发中断、分配物理内存</span><br><span class="line"></span><br><span class="line">需要内存小的时候、使用brk分配和原来的数据堆连在一起、</span><br><span class="line">需要内存大的时候、使用mmap、重新划分一整块区域</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>等待子进程 <code>waitpid</code></p>
</li>
<li><p>文件管理</p>
<ul>
<li>已有文件, 使用 <code>open</code> 打开文件, <code>close</code> 关闭文件</li>
<li>不存在的文件, 使用 <code>create</code> 创建文件</li>
<li>打开后的文件, 使用 <code>lseek</code> 跳转到指定位置</li>
<li>文件读取 <code>read</code> 文件写入 <code>write</code></li>
</ul>
<blockquote>
<p>linux 的核心思想: 一切皆文件</p>
</blockquote>
<ul>
<li><p>启动一个进程、需要一个程序文件、这是 二进制文件</p>
</li>
<li><p>启动时的配置文件, 如 <code>*.yml</code>, <code>*.properties</code> 等、是文本文件、日志也是文本文件</p>
</li>
<li><p>命令交互控制台输出、是标准输出 <code>stdout文件</code></p>
</li>
<li><p>A进程的输出可以作为另外一个进程的输入、这个方式成为 <code>管道</code> 也是一种文件</p>
</li>
<li><p>不同进程间的通信、通过<code>socket</code> 也是文件</p>
</li>
<li><p>进程需要访问外部设备、<code>设备</code>也是文件</p>
</li>
<li><p><code>文件夹</code>也是文件</p>
</li>
<li><p>进程运行时、<code>/proc</code> 下对应的<code>进程号</code> 也是文件</p>
</li>
</ul>
</li>
<li><p>进程间通信</p>
<ul>
<li><code>消息队列</code>: <code>Message Queue</code> 在内核实现, <code>msgget</code> 创建、<code>msgsnd</code> 发送、<code>msgrcv</code> 接收, 消息内容不大时使用</li>
<li><code>共享内存</code>: 交互消息比较大的时候, <code>shmget</code>创建 <code>shmat</code> 将共享内存映射到自己的内存空间, 通过信号量<code>  semaphore</code> 来处理<code>竞争</code><ul>
<li>对于只允许一个人访问的资源、将信号量设为1、第二个访问请求进入会调用 <code>sem_wait</code> 进行等待、访问结束调用 <code>ssem_post</code> 释放资源、结束等待</li>
</ul>
</li>
</ul>
</li>
<li><p><code>Glibc</code> 提供<code>字符串处理</code>, <code>数学运算</code>等用户态服务, 提供系统调用封装</p>
<ul>
<li><p>每个特定的系统调用至少对应一个<code>Glibc</code> 封装的库函数、</p>
<p>eg. 打开文件的系统调用 <code>sys_open</code> 对应的是 <code>Glibc</code> 中的 <code>open</code> 函数</p>
</li>
<li><p><code>Glibc</code> 中一个单独的API可能对应多个系统调用、</p>
<p>eg. <code>Glibc</code> 对应的<code>printf</code> 就会调用 <code>sys_open</code>, <code>sys_mmap</code>, <code>sys_write</code>, <code>sys_close</code> 等系统调用</p>
</li>
<li><p>也可能多个api对应同一个系统调用、</p>
<p>eg. <code>Glibc</code> 下实现的 <code>malloc</code>, <code>calloc</code>, <code>free</code> 等函数用来分配和释放内存、都利用了内核的 <code>sys_brk</code> 的系统调用</p>
</li>
</ul>
</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-beca9374617ce5cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Linux系统调用.png"></p>
<p>参考:<br><a href="https://time.geekbang.org/column/article/89251">https://time.geekbang.org/column/article/89251</a></p>
<p>【感谢极客时间、有很多优秀的专栏】</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统架构简析</title>
    <url>/2020/03/20/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p><code>CPU</code> 最核心的组件, 中央处理器 <code>Central Processing Unit</code></p>
<p><code>Bus</code> 总线, CPU 和 其它设备连接的桥梁、其实就是主板上密密麻麻的集成电路</p>
<p><code>内存</code> 最重要的设备、与CPU一样、是完成计算任务的核心组件</p>
<blockquote>
<p>cpu 包含 运算单元、数据单元 和 控制单元</p>
<p>运算单元: 负责计算, eg. 加法、移位等. 但不知道结果存放在哪里 </p>
<p>​                  若每次通过总线到内存去拿、速率很低、所以有了数据单元</p>
<p>数据单元: 包括CPU内部的缓存和寄存器组、空间小、速度高、可暂时存放数据和运算结果</p>
<p>控制单元: 同一指挥中心、获取指令 &amp; 执行指令, 会指导运算单元取出数据单元中的某几个数据、计算出结果、然后存放在数据单元的某个地方</p>
</blockquote>
<p>CPU这么执行程序, 操作数据, 并将结果写回内存的呢 ？</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">CPU的控制单元里, 有一个指令指针寄存器、存放的是下一条指针的地址, 控制单元会不断将代码段的指令拿进来、写入指令寄存器</span><br><span class="line"></span><br><span class="line">当前指令分为: 做什么操作 ？ 操作哪些数据？</span><br><span class="line">数据单元根据数据地址、从数据段读到数据寄存器、然后参与运算、运算结果会暂存在数据单元的数据寄存器、最终会有指令将数据写回内存中的数据段</span><br><span class="line"></span><br><span class="line">CPU有两个寄存器, 专门保存当前处理的代码段的起始地址和数据段的起始地址.</span><br><span class="line">里边是哪个进程就执行哪个进程的指令、等切换成另一进程就会执行另一进程的额指令、这个过程叫 进程切换 <span class="keyword">Process</span> <span class="keyword">Switch</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>CPU 和 内存进行数据交换、靠的是总线 <code>Bus</code>, 分为 <code>地址总线</code> 和 <code>数据总线</code></p>
<p><code>地址总线</code>的位数、决定可寻址范围, eg 只有两位、那CPU只认 <code>00</code> <code>01</code> <code>10</code> <code>11</code> 四个位置</p>
<p><code>数据总线</code> 的位数、决定一次可以拿多少个数据进来、</p>
<p>eg. 只有两位、CPU一次只能拿2位数、要想拿8位就需要4次、位数越多、一次拿的数据就越多、访问速度也越快</p>
</blockquote>
<p><strong>8086 系统架构</strong></p>
<p>8个16位通用寄存器 <code>AX</code> <code>BX</code> <code>CX</code> <code>DX</code> <code>SP</code> <code>BP</code> <code>SI</code> <code>DI</code>主要用于计算过程中暂存数据 (数据单元)</p>
<p><code>IP</code> 指令指针寄存器<code>Instruction Pointer Register</code> 指向代码段下一条指令的位置, CPU根据它从内存的代码段加载指令到CPU的指令队列中、交给运算单元去执行</p>
<p><code>段寄存器</code>：</p>
<p> <code>CS</code> 代码段寄存器, 保存代码在内存中的位置 <code>Code Segment Registeer</code></p>
<p><code>DS</code> 数据段寄存器, 保存数据在内存中的位置 <code>Data Segment Register</code></p>
<p><code>SS</code> 桟寄存器 <code>Stack Register</code> 程序运行中的一个特殊结构、存取只能从一端进行 </p>
<p><code>ES</code> </p>
<blockquote>
<p>若运算中需要加载内存中的数据、需要通过<code>DS</code>找到内存中的数据, 加载到通用寄存器中该如何加载？</p>
<p>对于一个段、有一个起始的地址、而段内的具体位置、称为偏移量 Offset</p>
</blockquote>
<p>在<code>CS</code>和 <code>DS</code>中都存放着一个段的起始地址、代码段的偏移量在<code>IP寄存器</code>中、数据段的偏移量通常在 <code>通用寄存器</code>中</p>
<p>那么问题来了:</p>
<p><code>CS</code>和<code>DS</code>都是16位的、即: 起始地址都是16位的、</p>
<p>IP寄存器和通用寄存器都是16位的、即: 偏移量也是16位的</p>
<p>但: 8086 的地址总线是20位、怎么做? </p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">起始地址*16 + 偏移量, 即: 把<span class="keyword">CS</span>和<span class="keyword">DS</span>中的值、左移4位 + 16位的偏移量 得到20位的数据地址</span><br></pre></td></tr></table></figure>

<blockquote>
<p> so. 无论真正的内存是多大、对于只有20位地址总线的8086来说、能识别出的地址只有 2^20 &#x3D; 1M</p>
<p>偏移量是16位、段大小最大为 2^16 &#x3D; 64k</p>
</blockquote>
<h4 id="32位处理器"><a href="#32位处理器" class="headerlink" title="32位处理器"></a>32位处理器</h4><p>在32位处理器中、有32根地址总线、可以访问 2^32&#x3D;4G 的内存</p>
<p>那如何去兼容原有8086架构呢？</p>
<ol>
<li>通用寄存器扩展、将8个16位的扩展到8个32位的、保留8位和16位的使用方式</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-6275d5210fda1f81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>改动较大的是 段寄存器(Segment Register)</p>
<p><code>CS</code>、<code>DS</code>、<code>SS</code>、<code>ES</code> 还是16位, 但不再是段的起始地址、段的起始地址放在内存、该内存是一个保存了段描述符的表格、段寄存器中保存的是在表格中的哪一项、称为<code>选择子(Selector)</code></p>
<p>这种模式灵活度比较高、将来也可以一直兼容、前边的设计就不够灵活</p>
<p>前一种模式、称为 <code>实模式</code> <code>Real Pattern</code>, 后一种模式称为<code>保护模式</code> <code>Protected Pattern</code></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-5599d15b659b6c48.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>参考:</p>
<p><a href="https://time.geekbang.org/column/article/89417">https://time.geekbang.org/column/article/89417</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>复杂度分析</title>
    <url>/2020/03/20/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95_%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>#####为什么需要复杂度分析?</p>
<figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">通过监控得到的时间和内存占用是正确的、有些地方称为</span><span class="punctuation">:</span> <span class="string">事后统计法</span></span><br><span class="line"><span class="attribute">但事后统计有很大的局限性</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">1. 测试结果严重依赖测试环境</span></span><br><span class="line"><span class="attribute">   机器配置和设置都会导致测试结果的差异</span></span><br><span class="line"><span class="attribute">2. 受数据规模的影响较大</span></span><br><span class="line"><span class="attribute">   eg. 对于同一排序算法、待排序数据的有序度不同、排序得到的时间差别会比较大、也会受数据本征的影响. 若原数据有序、对有些算法来说 可能不需要任何操作、会特别快</span></span><br><span class="line"><span class="attribute">   另</span><span class="punctuation">:</span> <span class="string">数据规模较小时、可能无法反馈出排序算法的性能</span></span><br><span class="line">   </span><br><span class="line">所以、需要一个不受测试数据和测试环境影响、可以用来粗略计算算法执行效率的方法。</span><br></pre></td></tr></table></figure>



<h5 id="大O复杂度表示法"><a href="#大O复杂度表示法" class="headerlink" title="大O复杂度表示法"></a>大O复杂度表示法</h5><figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">算法的执行效率简单来说、就是算法代码执行的时间</span><br><span class="line"></span><br><span class="line">eg. 下边代码</span><br><span class="line"> <span class="built_in">int</span> cal(<span class="built_in">int</span> <span class="built_in">n</span>) &#123;</span><br><span class="line">   <span class="built_in">int</span> <span class="built_in">sum</span> = <span class="number">0</span>;</span><br><span class="line">   <span class="built_in">int</span> i = <span class="number">1</span>;</span><br><span class="line">   for (; i &lt;= <span class="built_in">n</span>; ++i) &#123;</span><br><span class="line">     <span class="built_in">sum</span> = <span class="built_in">sum</span> + i;</span><br><span class="line">   &#125;</span><br><span class="line">   return <span class="built_in">sum</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> 从CPU的角度来看、每一行都有类似的操作<span class="symbol">:</span> 读数据-运算-写数据</span><br><span class="line"> 尽管每行代码对应的CPU执行的个数、执行的时间都不同、但对于粗略估计、可以认为是相同的, 假设为<span class="symbol">:</span> unit_time</span><br><span class="line"> 第<span class="number">4</span>、<span class="number">5</span>行运行了<span class="built_in">n</span>遍、需要<span class="number">2</span><span class="built_in">n</span>*unit_time, so. 总共需要 (<span class="number">2</span><span class="built_in">n</span>+<span class="number">2</span>)*unit_time</span><br><span class="line"> 所有代码的执行时间 <span class="built_in">T</span>(<span class="built_in">n</span>) 与执行次数成正比</span><br><span class="line"> </span><br><span class="line"> 将改规律记为<span class="symbol">:</span></span><br><span class="line"> <span class="built_in">T</span>(<span class="built_in">n</span>) = O(f(<span class="built_in">n</span>)) </span><br><span class="line"> <span class="built_in">T</span>(<span class="built_in">n</span>)<span class="symbol">:</span>执行时间 <span class="symbol">n:</span>数据规模 f(<span class="built_in">n</span>)<span class="symbol">:</span>每行代码的执行次数总和、就是大O时间复杂度表示法</span><br><span class="line"> </span><br><span class="line"> 大O时间复杂度只是代表执行时间随数据规模增长的变化趋势、而不是真正的代码执行时间、也叫 渐进时间复杂度</span><br><span class="line"> </span><br></pre></td></tr></table></figure>



<h5 id="时间复杂度分析"><a href="#时间复杂度分析" class="headerlink" title="时间复杂度分析"></a>时间复杂度分析</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 只关注执行次数最多的代码</span><br><span class="line"><span class="bullet">2.</span> 加法法则: 总复杂度等于量级最大的代码的复杂度</span><br><span class="line"><span class="bullet">3.</span> 乘法法则: 嵌套代码的复杂度=嵌套内外代码复杂度的乘积</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="常见复杂度量级"><a href="#常见复杂度量级" class="headerlink" title="常见复杂度量级"></a>常见复杂度量级</h5><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">常量阶 <span class="constructor">O(1)</span></span><br><span class="line">对数阶 <span class="constructor">O(<span class="params">log</span> <span class="params">n</span>)</span></span><br><span class="line">线性阶 <span class="constructor">O(<span class="params">n</span>)</span></span><br><span class="line">线性对数阶 <span class="constructor">O(<span class="params">nlog</span> <span class="params">n</span>)</span></span><br><span class="line">平方阶 <span class="constructor">O(<span class="params">n</span>&lt;<span class="params">sup</span>&gt;2&lt;<span class="operator">/</span><span class="params">sup</span>&gt;)</span>、立方阶  <span class="constructor">O(<span class="params">n</span>&lt;<span class="params">sup</span>&gt;3&lt;<span class="operator">/</span><span class="params">sup</span>&gt;)</span>、... K次方阶  <span class="constructor">O(<span class="params">n</span>&lt;<span class="params">sup</span>&gt;<span class="params">k</span>&lt;<span class="operator">/</span><span class="params">sup</span>&gt;)</span></span><br><span class="line">指数阶 <span class="constructor">O(2&lt;<span class="params">sup</span>&gt;2&lt;<span class="operator">/</span><span class="params">sup</span>&gt;)</span></span><br><span class="line">阶乘阶<span class="constructor">O(<span class="params">n</span>!)</span></span><br><span class="line"></span><br><span class="line">可以粗略的分为 多项式量级和非多项式量级(指数阶 和 阶乘阶)、把时间复杂度为非多项式量级的算法问题叫 NP问题、当n的规模增大时、非多项式量级算法很低效</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="复杂度量级简单说明"><a href="#复杂度量级简单说明" class="headerlink" title="复杂度量级简单说明"></a>复杂度量级简单说明</h5><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> <span class="constructor">O(1)</span></span><br><span class="line">   常量级复杂度、一般只要算法中不存在循环、递归语句、代码行再多、时间复杂度也是 <span class="constructor">O(1)</span></span><br><span class="line"> </span><br><span class="line"><span class="number">2.</span> <span class="constructor">O(<span class="params">logn</span>)</span>、<span class="constructor">O(<span class="params">nlogn</span>)</span></span><br><span class="line">   对数阶复杂度(归并排序、快速排序的时间复杂度都是<span class="constructor">O(<span class="params">nlogn</span>)</span></span><br><span class="line">   eg. i=<span class="number">1</span>;<span class="keyword">while</span>(i&lt;n)&#123;i = i*<span class="number">3</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> <span class="constructor">O(<span class="params">m</span>+<span class="params">n</span>)</span>、<span class="constructor">O(<span class="params">m</span><span class="operator">*</span><span class="params">n</span>)</span></span><br><span class="line">   明显有m和n两个数据规模的示例</span><br><span class="line">   </span><br></pre></td></tr></table></figure>



<h5 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h5><blockquote>
<p>时间复杂度的全称是: 渐进时间复杂度、表示算法的执行时间与数据规模之间的增长关系</p>
<p>类比: 空间复杂度 –&gt; 空间渐进复杂度、表示算法的存储空间与数据规模之间的增长关系</p>
</blockquote>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">常用的空间复杂度只有: <span class="constructor">O(1)</span>、<span class="constructor">O(<span class="params">n</span>)</span>、<span class="constructor">O(<span class="params">n</span>&lt;<span class="params">sup</span>&gt;2&lt;<span class="operator">/</span><span class="params">sup</span>&gt;)</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>数据结构和算法</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构概况</title>
    <url>/2020/03/20/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95_%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%A6%82%E5%86%B5/</url>
    <content><![CDATA[<p>课程链接：<br><a href="https://time.geekbang.org/column/article/40011">https://time.geekbang.org/column/article/40011</a></p>
<p>【强烈推荐极客时间原版课程、这里仅仅是个人笔记、方便自己学习回顾】</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-6dc246178f53676e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="数据结构和算法概况.jpg"></p>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>数据结构和算法</tag>
      </tags>
  </entry>
  <entry>
    <title>数组</title>
    <url>/2020/03/20/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95_%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<blockquote>
<p>数组: 用一组连续的内存空间、存储一组具有相同数据类型的线性表数据结构</p>
</blockquote>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">1.线性表: 数据只有前、后两个方向. 链表、队列、桟也是线性结构</span></span><br><span class="line"><span class="section">2.连续空间、数据类型相同: 使得数组可以随机访问、但: 插入、删除数据的效率就低很多、需要数据重排</span></span><br></pre></td></tr></table></figure>



<h5 id="插入和删除"><a href="#插入和删除" class="headerlink" title="插入和删除"></a>插入和删除</h5><figure class="highlight isbl"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>.插入</span><br><span class="line">  <span class="number">1</span>) 末尾插入、无需移动元素、复杂度 <span class="function"><span class="title">O</span>(<span class="number">1</span>)</span></span><br><span class="line">  <span class="number">2</span>) 头部插入、搬移全部元素、复杂度 <span class="function"><span class="title">O</span>(<span class="variable">n</span>)</span></span><br><span class="line">  每个位置插入的概率相同、平均复杂度为 (<span class="number">1</span>+<span class="number">2</span>+<span class="number">3</span>+...n)/<span class="variable">n</span> = <span class="function"><span class="title">O</span>(<span class="variable">n</span>)</span></span><br><span class="line"> </span><br><span class="line">  若数组有序、只需要搬移<span class="variable">k</span>之后的数据</span><br><span class="line">  若数组无序、且不要求有序、将<span class="variable">k</span>位置的元素直接搬移到最后、只需要一次搬移 <span class="function"><span class="title">O</span>(<span class="number">1</span>)</span></span><br><span class="line">  </span><br><span class="line"><span class="number">2</span>.删除</span><br><span class="line">  <span class="number">1</span>) 与插入类似、最好<span class="function"><span class="title">O</span>(<span class="number">1</span>) 最坏<span class="title">O</span>(<span class="variable">n</span>) 平均<span class="title">O</span>(<span class="variable">n</span>)</span></span><br><span class="line">  <span class="number">2</span>) 删除多(<span class="variable">m</span>)个元素时、可先标记删除(只标记)、后一次性删除、节省<span class="variable">m</span>*<span class="function"><span class="title">O</span>(<span class="variable">n</span>)次操作</span></span><br><span class="line"><span class="function">     <span class="variable">JVM</span>的标记清除算法的核心</span></span><br></pre></td></tr></table></figure>



<p>容器能否代替数组 ?</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> arrayList 将数组操作的细节封装. eg. 数据搬移</span><br><span class="line"><span class="bullet">2.</span> arrayList 支持动态扩容、默认扩容是1.5 </span><br><span class="line">   扩容涉及到内存申请和数据搬移、比较耗时、若知道数据存储大小时、最好指定大小</span><br><span class="line">   </span><br><span class="line"><span class="bullet"> 1.</span> 容器无法存储基础类型、eg. int, long, 需要封装为 Integer、Long 而自动装箱则有部分性能损耗</span><br><span class="line"><span class="bullet"> 2.</span> 若数据大小已知、且操作特别简单、可直接使用数组</span><br><span class="line"> 所以、对业务开发基本上直接使用容器就好、省力、不易出错、丢失的性能可以不太关注、不影响整体性能</span><br><span class="line"> 对底层开发、性能要做到极致、数组就优于容器成为首选</span><br><span class="line"> </span><br></pre></td></tr></table></figure>



<h5 id="为什么大部分编程语言中、数组从0开始编号"><a href="#为什么大部分编程语言中、数组从0开始编号" class="headerlink" title="为什么大部分编程语言中、数组从0开始编号"></a>为什么大部分编程语言中、数组从0开始编号</h5><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">下标确切定义是: 偏移offset、</span><br><span class="line"><span class="number">1</span>.使用a表示首地址、<span class="selector-tag">a</span><span class="selector-attr">[0]</span>就是偏移为<span class="number">0</span>的位置、即首地址、<span class="selector-tag">a</span><span class="selector-attr">[k]</span>表示第k个type_size的地址</span><br><span class="line">  <span class="selector-tag">a</span><span class="selector-attr">[k]</span>_addr = base_addr + k*type_size</span><br><span class="line"><span class="number">2</span>.若使用<span class="number">1</span>开始计数、则</span><br><span class="line">  <span class="selector-tag">a</span><span class="selector-attr">[k]</span>_addr = base_addr + (k-<span class="number">1</span>)*type_size </span><br><span class="line"> 从<span class="number">1</span>开始编号、对于CPU来说、就是多了一次减法运算</span><br><span class="line"> </span><br><span class="line"> 		</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>数据结构和算法</tag>
      </tags>
  </entry>
  <entry>
    <title>链表</title>
    <url>/2020/03/20/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95_%E9%93%BE%E8%A1%A8/</url>
    <content><![CDATA[<h5 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h5><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">链表: 用指针将一组零散的内存块串联在一起、其中: 把内存块称为链表的节点</span></span><br><span class="line">为了将节点串联起来、每个链表的节点除了存储数据、还需要记录链上的下一个节点的地址(后继指针)</span><br><span class="line"></span><br><span class="line"><span class="section">分为:单链表、双链表和循环链表</span></span><br><span class="line"></span><br><span class="line"><span class="section">其中: 第一个节点称为头节点(用来记录链表的基地址)、最后一个节点称为尾节点、</span></span><br><span class="line"></span><br><span class="line">单链表的尾节点指向一个空地址NULL、</span><br><span class="line"><span class="section">循环链表: 一种特殊的单链表、与单链表的区别是: 尾节点指向链表的头节点</span></span><br><span class="line"><span class="section">双向链表: 每个节点有一个后继指针next和一个前驱指针prev</span></span><br><span class="line"></span><br><span class="line">存储相同的数据、双向链表要占据两个额外的空间来存储prev和next指针、需要更多的空间、但也带来了双向链表操作的灵活性</span><br><span class="line"></span><br><span class="line"><span class="section">一个重要思想:</span></span><br><span class="line"><span class="section">空间换时间: 在内存充足的时候、若追求代码的执行速度、可以利用空间换时间、选择空间复杂度高、但时间复杂度相对较低的算法</span></span><br><span class="line"><span class="section">相反: 若内存较少、eg. 代码跑在单片机或者手机上、就需要考虑时间换空间的思路</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="链表vs数组"><a href="#链表vs数组" class="headerlink" title="链表vs数组"></a>链表vs数组</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 链表可有效使用内存、插入和删除效率较高</span><br><span class="line"><span class="bullet">2.</span> 数组随机访问效率更高、插入删除效率较低</span><br><span class="line"><span class="bullet">3.</span> 数组的连续存储性、可借助CPU的缓存机制、预读数组中数据、访问效率更高</span><br><span class="line">   链表存储非连续、对CPU缓存支持不够友好</span><br><span class="line"><span class="bullet">4.</span> 数组大小固定、一旦声明就要占用整块的连续空间、若声明的数组过大、系统无足够连续内存、会导致OOM、链表本身无大小限制、可天然支持动态扩容</span><br><span class="line"><span class="bullet">5.</span> 若代码对内存要求很高、则数组更合适、且: 对链表频繁的增删会导致频繁的内存申请和释放、容易造成GC</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="几个写链表代码的技巧"><a href="#几个写链表代码的技巧" class="headerlink" title="几个写链表代码的技巧"></a>几个写链表代码的技巧</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">一、理解指针或者引用的含义</span><br><span class="line">   将某个变量赋值给指针、实际上就是将这个变量的地址赋值给指针、即: 指针中存储了这个变量的内存地址、指向了这个变量、通过指针就能找到这个变量</span><br><span class="line"></span><br><span class="line">二、警惕指针丢失和内存泄漏</span><br><span class="line">   插入节点时需要注意操作顺序、删除节点时也要手动释放内存</span><br><span class="line"></span><br><span class="line">三、利用哨兵简化实现难度</span><br><span class="line">   针对链表的增删操作、需要对头节点和尾节点进行特殊处理</span><br><span class="line"></span><br><span class="line">四、留意边界条件</span><br><span class="line"><span class="bullet">   1.</span> 空链表能否正常工作 ？</span><br><span class="line"><span class="bullet">   2.</span> 只有一个节点的链表能否正常工作 ？</span><br><span class="line"><span class="bullet">   3.</span> 只有两个节点能否正常工作 ？</span><br><span class="line"><span class="bullet">   4.</span> 处理头尾节点时能否正常工作 ？</span><br><span class="line"></span><br><span class="line">五、举例画图、辅助思考</span><br><span class="line"></span><br><span class="line">六、多写多练</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>数据结构和算法</tag>
      </tags>
  </entry>
  <entry>
    <title>http请求解析</title>
    <url>/2020/03/20/%E6%B5%8F%E8%A7%88%E5%99%A8_http%E8%AF%B7%E6%B1%82%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h4 id="如何把数据包送达目的主机"><a href="#如何把数据包送达目的主机" class="headerlink" title="如何把数据包送达目的主机"></a>如何把数据包送达目的主机</h4><blockquote>
<p>主机A -&gt; 网络层(添加IP头信息) -&gt; 底层 -&gt; 物理网络 -&gt; 主机B -&gt; 解析IP头信息 -&gt; 将数据部分交给应用</p>
</blockquote>
<h4 id="如何把数据包送达应用程序"><a href="#如何把数据包送达应用程序" class="headerlink" title="如何把数据包送达应用程序"></a>如何把数据包送达应用程序</h4><blockquote>
<p>UDP协议: User Datagram Protocol<br>网络层和上层之间添加一层(传输层)、封装UDP头信息</p>
</blockquote>
<p>UDP并不提供重传机制、只是丢弃当前数据包、且发送之后不知道是不是数据能到达目的地</p>
<h4 id="TCP将数据完整送达应用程序"><a href="#TCP将数据完整送达应用程序" class="headerlink" title="TCP将数据完整送达应用程序"></a>TCP将数据完整送达应用程序</h4><blockquote>
<p>对于数据包丢失的情况、TCP提供重传机制<br>引入数据包排序机制、保证将乱序的数据包组合成一个完整的文件</p>
</blockquote>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line">浏览器使用HTTP协议作为应用层协议、用来封装请求的文本信息</span><br><span class="line">使用TCP/<span class="built_in">IP</span>作为传输层协议 将它发在网络上</span><br><span class="line">即: HTTP请求的内容是通过TCP的传输数据阶段来实现的</span><br></pre></td></tr></table></figure>



<h4 id="HTTP请求流程"><a href="#HTTP请求流程" class="headerlink" title="HTTP请求流程"></a>HTTP请求流程</h4><ul>
<li>构建请求</li>
</ul>
<blockquote>
<p>GET &#x2F;index.html HTTP1.1</p>
</blockquote>
<ul>
<li>查找缓存</li>
</ul>
<blockquote>
<p>浏览器在网络请求之后会保存资源副本在本地</p>
<ol>
<li>缓解服务端压力、提升性能</li>
<li>对于网站来说、可以实现快速下载</li>
<li>若本地无资源副本、就会进入网络请求</li>
</ol>
</blockquote>
<ul>
<li>准备IP地址和端口</li>
</ul>
<blockquote>
<p>思考：</p>
<ol>
<li>http请求的第一步是什么呢 ？- 构建请求信息</li>
<li>建立连接的信息都包含什么? - ip和端口号</li>
<li>如果只有url可以拿到建立连接的信息么 ？- 通过DNS解析、http协议默认80端口</li>
</ol>
</blockquote>
<ul>
<li>等待TCP队列</li>
</ul>
<blockquote>
<p>准备好IP和端口、是不是就可以建立TCP连接？</p>
<p>不一定, Chrome 同一个域名最多建立6个TCP连接、若同时有10个请求、会有4个请求进入排队队列等待、直到进行中的请求完成</p>
</blockquote>
<ul>
<li>建立TCP连接</li>
</ul>
<blockquote>
<p>在http开始工作之前、需要先建立TCP连接</p>
</blockquote>
<ul>
<li>发送HTTP请求</li>
</ul>
<blockquote>
<ol>
<li>请求行(请求方法、路由、http版本)</li>
<li>请求头(cookie等信息)</li>
<li>请求体(请求参数等)</li>
</ol>
</blockquote>
<h4 id="服务端处理http请求流程"><a href="#服务端处理http请求流程" class="headerlink" title="服务端处理http请求流程"></a>服务端处理http请求流程</h4><ul>
<li>返回请求</li>
<li>断开连接(正常情况下、一单server返回响应数据、就会关闭TCP连接、若头信息加入 Connection:Keep-Alive则保持TCP连接不断开)</li>
<li>重定向</li>
</ul>
]]></content>
      <categories>
        <category>浏览器</category>
      </categories>
      <tags>
        <tag>浏览器</tag>
      </tags>
  </entry>
  <entry>
    <title>url解析流程</title>
    <url>/2020/03/20/%E6%B5%8F%E8%A7%88%E5%99%A8_url%E8%A7%A3%E6%9E%90%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<ul>
<li><p>浏览器进程主要负责用户交互、子进程管理和文件存储等功能</p>
</li>
<li><p>网络进程是面向渲染进程和浏览器进程等提供网络下载功能</p>
</li>
<li><p>渲染进程主要职责是把从网络下载的HTML、JS、CSS图片等资源解析为可显示赫尔交互的页面</p>
</li>
</ul>
<h4 id="请求解析流程"><a href="#请求解析流程" class="headerlink" title="请求解析流程"></a>请求解析流程</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">大致可以描述为：</span><br><span class="line"><span class="bullet">1.</span> 首先从浏览器进程输入请求URL</span><br><span class="line"><span class="bullet">2.</span> 网络进程发起URL请求</span><br><span class="line"><span class="bullet">3.</span> 服务器响应URL请求之后、浏览器进程开始准备渲染进程</span><br><span class="line"><span class="bullet">4.</span> 渲染进程准备好之后、向渲染进程提交网络进程响应的数据、称为提交文档阶段</span><br><span class="line"><span class="bullet">5.</span> 渲染进程接收完整文档信息之后、开始解析加载页面及子资源、完成页面渲染</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 用户输入</span><br><span class="line">   用户在地址栏输入查询关键字时、地址栏会判断输入的是关键字还是请求的<span class="built_in">URL</span></span><br><span class="line">   若是搜索内容、地址栏会使用浏览器默认的搜索引擎、合成包含搜索关键字的<span class="built_in">URL</span></span><br><span class="line">   若输入内容符合<span class="built_in">URL</span>规则、则解析为<span class="built_in">URL</span>、浏览器加载一个地址之后、导航栏图表就进入了加载状态、页面没变、需要等待提交文档阶段、页面内容才会替换</span><br><span class="line"><span class="number">2.</span> <span class="built_in">URL</span>请求过程</span><br><span class="line">   浏览器进程通过进程间通信IPC把url请求发送到网络进程、网络进程接收到<span class="built_in">URL</span>请求后才发起请求</span><br><span class="line">   </span><br><span class="line">   <span class="number">1</span>) 网络进程先查找本地缓存是否缓存了改资源、若有直接返回</span><br><span class="line">   <span class="number">2</span>) 没有、进入网络请求流程(DNS解析-&gt;ip、若<span class="keyword">https</span>协议先建立TLS连接)</span><br><span class="line">   <span class="number">3</span>) 利用IP地址和服务器建立TCP连接、建立连接后浏览器会构造请求信息(请求行/头)把相关cookie加入请求头、发送请求信息</span><br><span class="line">   <span class="number">4</span>) 服务器收到请求后、生产响应数据(响应行/头/体)、发给网络进程、网络进程接收到响应行和响应头之后解析响应头</span><br><span class="line">      <span class="keyword">a</span>. 重定向 - 响应码 <span class="number">301</span>|<span class="number">302</span> 从响应头提取Location、然后发起新的请求、从新开始</span><br><span class="line">      b. 响应数据类型处理</span><br><span class="line">         Content-Type标记浏览器响应类型 <span class="keyword">text</span>/html 代表返回数据是HTML格式、继续后续流程</span><br><span class="line">         application/octet-stream 返回数据是字节流类型、按照下载类型来处理、请求提交给浏览器的下载管理器</span><br><span class="line"><span class="number">3.</span> 准备渲染进程</span><br><span class="line">   默认情况下、Chrome会为每个页面分配一个渲染进程、但某些情况下会多个页面运行在同一渲染进程中</span><br><span class="line">   通常: </span><br><span class="line">   打开新的页面会使用单独的渲染进程、</span><br><span class="line">   若从A页面打开B页面、且AB属于同一站点、则B复用A页面的渲染进程、若是其它情况、会单独创建进程</span><br><span class="line">   </span><br><span class="line">   渲染进程准备好之后、不能立即进入文档解析阶段、因为此时文档还在网络进程中、并未提交给渲染进程、所以下一步是进入提交文档阶段</span><br><span class="line">   </span><br><span class="line"><span class="number">4.</span> 提交文档</span><br><span class="line">   提交文档(响应数据)的请求是浏览器进程发出的、渲染进程接收到消息后、会和网络进程建立传输数据的通道</span><br><span class="line">   文档数据传输完成后、渲染进程返回 确认提交 的消息给浏览器进程</span><br><span class="line">   浏览器进程在收到确认提交的消息后、更新浏览器界面状态、包含了安全状态、地址栏的url、前进后退的历史状态、并更新web界面</span><br><span class="line">   </span><br><span class="line">   一个完整的导航走完了、进入渲染阶段</span><br><span class="line">   </span><br><span class="line"><span class="number">5.</span> 渲染阶段</span><br><span class="line">   文档一旦被提交、渲染进程就开始页面解析和子资源加载了、一旦页面生成、渲染进程会给浏览器进程发送消息、浏览器进程收到消息停止标签页上的加载动画</span><br><span class="line">   </span><br></pre></td></tr></table></figure>


<p><img src="https://upload-images.jianshu.io/upload_images/14027542-26a86c6a9a0ae591.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="浏览器加载页面.png"></p>
]]></content>
      <categories>
        <category>浏览器</category>
      </categories>
      <tags>
        <tag>浏览器</tag>
      </tags>
  </entry>
  <entry>
    <title>浏览器渲染流程</title>
    <url>/2020/03/20/%E6%B5%8F%E8%A7%88%E5%99%A8_%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B8%B2%E6%9F%93%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<p>HTML的内容由标记和文本组成、也称标签</p>
<p>CSS又称 层叠样式表、由选择器和属性组成</p>
<p>JS 使页面内容动起来</p>
<p>渲染模块在执行过程中分为很多子阶段、输入的HTML经过这些子阶段、输出像素、这个处理过程称为 渲染流水线</p>
<ol>
<li><p>构建DOM树</p>
<blockquote>
<p>浏览器无法直接理解和使用html、需要先转化为其能理解的结构 - DOM树</p>
<p>构建dom树的输入是简单的html文件、经过html解析器解析、输出 树状结构的DOM</p>
<p>DOM和html的内容基本一致、但dom是保存在内存中的树状就结构、可以通过JS直接修改</p>
</blockquote>
</li>
<li><p>样式计算</p>
<blockquote>
<p>是为了计算出DOM节点中每个元素的具体样式</p>
<ol>
<li><p>将CSS转化为浏览器可理解的结构 stylesheets</p>
</li>
<li><p>转换样式表中的属性值、使其标准化 eg. 2em -&gt; 32px  blue -&gt; rgb(0,0,255)</p>
</li>
<li><p>计算出dom树中每个节点的具体样式</p>
</li>
</ol>
</blockquote>
</li>
<li><p>布局计算</p>
<blockquote>
<p>计算dom树中可见元素的几何位置</p>
<ol>
<li><p>创建布局树 遍历dom节点、将这些节点加载到布局中</p>
</li>
<li><p>布局计算 将布局运算的结果写回布局树</p>
</li>
</ol>
</blockquote>
</li>
<li><p>分层</p>
<blockquote>
<p>为了更方便的实现3D变换、页面滚动或者使用z-indexing做z轴排序等</p>
<p>渲染引擎还需要为特定的节点生成专用图层、并生成一棵对应的图层树LayerTree</p>
<p>浏览器的页面其实是很多图层、这些图层叠加后合成了最终的页面</p>
<p>并不是所有的布局树的每个节点都包含一个图层、若节点无对应图层、则从属于父节点的图层</p>
<ol>
<li><p>拥有层叠上下文属性的元素会被提升为单独的一层</p>
</li>
<li><p>需要裁剪的地方也会被创建为图层</p>
</li>
</ol>
</blockquote>
</li>
<li><p>绘制</p>
<blockquote>
<p>图层的绘制与画画的流程基本一致、会把一个图层的绘制拆分成很多小的绘制指令、然后将指令按照顺序组成一个待绘制列表</p>
</blockquote>
</li>
<li><p>栅格化</p>
<blockquote>
<p>绘制列表只是用来记录绘制顺序和绘制指令的列表、而实际上绘制操作是由渲染引擎中的合成线程来完成(图层绘制列表准备完成后、主线程会把绘制列表提交给合成线程)</p>
<p>通常、栅格化过程会使用GPU来加速生成、使用GPU生成位图的过程叫 快速栅格化、生成的位图保存在GPU内存中</p>
</blockquote>
</li>
<li><p>合成</p>
<blockquote>
<p>所有图块被光栅化之后、合成进程会生成一个绘制图块的命令、提交给浏览器进程</p>
<p>浏览器进程的viz组件、接收绘制命令绘制内容显示到浏览器</p>
</blockquote>
</li>
</ol>
<h4 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h4><p><code>重排</code>: 通过JS或者CS修改元素几何位置、eg. 改变元素的宽、高、等会触发重新布局、解析之后的一系列子阶段、这个过程就叫重排、需要更新完整的渲染流水线、开销很大</p>
<p><code>重绘</code>: eg. JS更改某些元素的背景色、布局阶段不会重新执行、直接进入绘制阶段、然后执行之后的子阶段、相对<code>重排</code> 少了<code>布局</code>和<code>分层</code>阶段、执行效率会高一些</p>
<p><code>直接合成阶段</code>: eg. 使用CSS的transform来实现动画、可以避开<code>重排</code>和<code>重绘</code>阶段、直接在非主线程上执行合成动画操作、大大提升绘制效率</p>
]]></content>
      <categories>
        <category>浏览器</category>
      </categories>
      <tags>
        <tag>浏览器</tag>
      </tags>
  </entry>
  <entry>
    <title>DHCP与PXE--ip是怎么来的、又是怎么没的--</title>
    <url>/2020/03/20/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE_DHCP%E4%B8%8EPXE--ip%E6%98%AF%E6%80%8E%E4%B9%88%E6%9D%A5%E7%9A%84%E3%80%81%E5%8F%88%E6%98%AF%E6%80%8E%E4%B9%88%E6%B2%A1%E7%9A%84--/</url>
    <content><![CDATA[<h4 id="如何配置ip地址"><a href="#如何配置ip地址" class="headerlink" title="如何配置ip地址"></a>如何配置ip地址</h4><ol>
<li>使用net-tools<figure class="highlight crystal"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sudo ifconfig eth1 <span class="number">10.0</span>.<span class="number">0.1</span>/<span class="number">24</span></span><br><span class="line"><span class="variable">$ </span>sudo ifconfig eth1 up</span><br></pre></td></tr></table></figure></li>
<li>使用iprote2<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo<span class="built_in"> ip </span>addr <span class="built_in">add</span> 10.0.0.1/24 dev eth1</span><br><span class="line">$ sudo<span class="built_in"> ip </span>link <span class="built_in">set</span> up eth1</span><br></pre></td></tr></table></figure>
但: 是可以随意配置的吗 ?<blockquote>
<p>显然不是. 只要在网络上的包、都是完整的、可以有下层无上层、不能反之.<br>若配置为不同网段, 发送请求包时、linux的默认逻辑是: 跨网段调用、不会直接将包发送到网络上、而是企图发送到网关.<br>若配置同网段呢? – 会配置失败</p>
</blockquote>
</li>
</ol>
<h4 id="动态主机配置协议-DHCP"><a href="#动态主机配置协议-DHCP" class="headerlink" title="动态主机配置协议(DHCP)"></a>动态主机配置协议(DHCP)</h4><p><code>DHCP</code>: 动态主机配置协议(Dynamic Host Configuration Protocol)<br>有了DHCP、网络管理员只需要配置一段共享的ip地址. 每一台新接入的机器会通过DHCP协议去共享的ip地址里申请、然后自动配置 </p>
<blockquote>
<p>若数据中心里的服务器、ip一旦配置好、基本不会改变、相当于自己买房、自己装修. DHCP的方式类似于租房、临时借用、用完归还即可.</p>
</blockquote>
<h4 id="解析DHCP的工作方式"><a href="#解析DHCP的工作方式" class="headerlink" title="解析DHCP的工作方式"></a>解析DHCP的工作方式</h4><p>刚加入网络的机器、暂无ip地址、处于<code>DHCP Discover</code>的状态.</p>
<p>它会使用ip地址 0.0.0.0 发送广播包、目的地址为: 255.255.255.255. 广播包封装了UDP、UDP封装了BOOTP. 若网络里配置了DHCP Server, Server会分配ip地址给该MAC地址、同时记录(不会分配给其它机器). 这个过程称为 <code>DHCP Offer</code>.</p>
<p>若收到多个DHCP Server回复、一般会选择接受第一个到达的、且向网络发送一个DHCP Request广播数据包, 包含Clineet的MAC地址、接受的ip地址、提供该ip的HDCP Server地址等, 告诉其它server它接受了哪一台server提供的ip、请求他们撤销提供的ip、以提供给下一个ip租用者.</p>
<p>DHCP Server 接收到Client的request后、会广播返回一个ACK消息.</p>
<p>client会在租期过去50%时、向为其提供ip地址的server发送request消息包, client 再根据接收到server回应的ack消息包中提供的新的租期及其他已更新的tcp&#x2F;ip参数更新自己的配置.</p>
<h4 id="预启动执行环境-PXE"><a href="#预启动执行环境-PXE" class="headerlink" title="预启动执行环境(PXE)"></a>预启动执行环境(PXE)</h4><p>预启动执行环境: </p>
]]></content>
      <categories>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title>ifconfig</title>
    <url>/2020/03/20/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE_ifconfig/</url>
    <content><![CDATA[<blockquote>
<p><code>ip地址</code>是一个网卡在网络世界的通信地址、类似<code>门牌号</code></p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-73bac7cc574fb7e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="32位ip地址分类.png"></p>
<h4 id="无类型域间选路-CIDR"><a href="#无类型域间选路-CIDR" class="headerlink" title="无类型域间选路(CIDR)"></a>无类型域间选路(CIDR)</h4><p>从上图可以看到、C类地址能包含的主机数只有 2<sup>8</sup> &#x3D; 254个, 数量过少; 而B类地址能包含的最大主机数量又太多了、一般企业规模达不到65534、剩余的地址就是浪费.</p>
<p>于是产生了一个折中方案: CIDR. 打破ip类别设计、将32位ip一分为二、前边是网络号、后边是主机号.<br>eg. 10.100.122.2&#x2F;24<br><code>/ </code> 表示前24位代表网络号、后8位是主机号</p>
<p>伴随CIDR存在的还有<code>广播地址</code> 和 <code>子网掩码</code>.<br>广播地址是: 10.100.122.255, 若发送这个地址、所有10.100.122 网络里的机器都可以收到<br>子网掩码: 255.255.255.0</p>
<p>将子网掩码 和 ip 进行 AND运算、可以得到网络号</p>
<h4 id="公有ip地址-和-私有ip地址"><a href="#公有ip地址-和-私有ip地址" class="headerlink" title="公有ip地址 和 私有ip地址"></a>公有ip地址 和 私有ip地址</h4><p><img src="https://upload-images.jianshu.io/upload_images/14027542-6f0cb3fd1a380ca4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="私有ip地址范围.png"></p>
<p><code>组播地址</code>: 属于某个组的机器都能收到消息.<br>eg. 邮件组</p>
<p>在ip地址的后边、有个scope, 对eth0这个网卡来讲、是global, 说明这个网卡是可以对外的、可以接收来自各个地方的包. 对于lo来讲、是host, 说明这张网卡仅可以供本机相互通信.</p>
<p>lo 全程 loopback, 又称<code>回环接口</code>, 往往被分配打平 127.0.0.1 这个地址、经过内核处理后直接返回、不会在任何网络中出现.</p>
<h4 id="MAC地址"><a href="#MAC地址" class="headerlink" title="MAC地址"></a>MAC地址</h4><p><code>MAC地址</code>是一个网卡的物理地址、十六进制表示、6个byte、全局唯一. 但不可替代ip地址.<br>类似: 身份证号全网唯一、但若在问路时、被人知道的概率确很小、ip具有定位功能、类似省市区街道小区的概念、</p>
<p>MAC地址本身更像是身份证、是唯一标识. 设计唯一性是为了不同网卡放在同一网络时、可以不用担心冲突. 从硬件角度、确保不同网卡有不同标识.</p>
<p>MAC具有一定定位功能、但范围有限. 局限在同一子网. 跨子网的情况、就需要ip地址来查找了.</p>
<h4 id="网络设备的状态标识"><a href="#网络设备的状态标识" class="headerlink" title="网络设备的状态标识"></a>网络设备的状态标识</h4><p>&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; 是干什么的？这个叫作 net_device flags，网络设备的状态标识</p>
<p>UP 代表网卡处于启动的状态<br>BROADCAST 表示网卡有广播地址、可以发送广播<br>MULTICAST 表示网卡可以发送多播包<br>LOWER_UP 表示L1是启动的, 即: 网线插着呢</p>
<p>mtu 1500 呢 ? 代表最大传输MTU为1500, 这个是以太网的默认值<br>网络是层层封装的, MTU是二层MAC概念. MAC层有MAC层的头、以太网规定连MAC头带正文合起来不能超过1500个字节、正文里有ip、tcp、http的头,<br>若放不下、就需要分片来传输.</p>
<p><code>qdisc pfifo_fast</code> 全称<code>queueing discipline</code>, 即<code>排队规则</code>. 内核若需要通过某个网络接口发送数据包、就需要按照为这个接口配置的qdisc将数据包加入队列.<br>最简单的qdisc是 pfifo, 它不对进入的数据包做任何处理、数据包采用先入先出的方式通过队列. pfifo_fast 稍微复杂些、它的队列包括3个波段(band)、在每个波段里使用先进先出的规则. band 0的优先级最高, band 2的最低, 若band 0里有数据包、系统就不会处理band 1里的数据包.</p>
<p>数据包是按照服务类型(<code>Type of Service, TOS</code>)被分配到三个波段的、TOS是 IP 头里边的一个字段、代表了当前包的优先级.</p>
]]></content>
      <categories>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title>CPU发回顾</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_CPU%E5%8F%91%E5%B1%95%E5%9B%9E%E9%A1%BE/</url>
    <content><![CDATA[<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line">指令周期: Fetch -&gt; Decode -&gt; Execute</span><br><span class="line"></span><br><span class="line">CPU周期: 从内存取出一条指令的最短时间(一个指令周期至少需要<span class="number">2</span>个CPU周期)</span><br><span class="line"></span><br><span class="line">通过D触发器实现存储功能</span><br><span class="line">通过时钟信号实现计数器</span><br><span class="line"></span><br><span class="line">一个时钟周期内确保完成一条最复杂的CPU指令 -&gt; 单指令周期处理器</span><br><span class="line">译码器 -&gt; 从输入的多个位的信号中、根据一定的开关和电路组合、选择出自己想要的信号</span><br><span class="line">优化<span class="number">1</span>: CPU流水线设计(保障一个最复杂的流水线级在一个时钟周期内完成即可)</span><br><span class="line">       不能优化单条指令执行延时、可以提高CPU的吞吐率(可同时并行多条指令)</span><br><span class="line">       </span><br><span class="line">       缺点: 流水线深度增加带来性能成本、每级流水线的输出需放到流水线寄存器、然后在下一个时钟周期、交给下一个流水线级处理、每增加一级就要多一次写入流水线寄存器的操作(<span class="number">20ps</span>)</span><br><span class="line">       为了保证指令的响应时间这个指标、只有提升时钟周期、电路数量和晶体管数量都会增加、功耗变大</span><br><span class="line">       </span><br><span class="line">       挑战: 冒险和分支预测</span><br><span class="line"> </span><br><span class="line">优化<span class="number">2</span>: 结构冒险 -&gt; 增加资源(eg. 数据内存和指令内存分开, 现代CPU只将CPU内部的缟素缓存分成指令缓存和数据缓存)</span><br><span class="line"></span><br><span class="line">优化<span class="number">3</span>: 数据冒险 -&gt; 流水线停顿(插入NOP操作), 最差会退化成单指令周期CPU</span><br><span class="line">优化<span class="number">4</span>: 数据冒险 -&gt; 操作数前推(操作数转发、节省了写入写入寄存器、从寄存器读出的时间)</span><br><span class="line">优化<span class="number">5</span>: 乱序执行 -&gt; 将指令发送到保留站 -&gt; 提交到不同的FU -&gt; 重排缓存区重排<span class="function"><span class="params">(cpu按照取指顺序、对指令结果重排, 只有排在前边的都完成、才提交指令、完成指令运算)</span> -&gt;</span> 指令提交</span><br><span class="line">       提高了CPU的吞吐量</span><br><span class="line">优化<span class="number">6</span>: 分支预测(缩短分支延迟、动态分支预测、静态分支预测)</span><br><span class="line">优化<span class="number">7</span>: 超标量(多发射, 让cpi&gt;<span class="number">1</span>, 并行取指、译码 -&gt; 需要增加电路元件)</span><br><span class="line">优化<span class="number">8</span>: 超线程: 在一个CPU内部、有双份PC寄存器、指令寄存器、条件码寄存器、同时维护两个并行指令的状态(指令译码器、ALU都只有单份)</span><br><span class="line">优化<span class="number">9</span>: SIMD(单指令多数据流):一次加载多个整数、然后使用多个FU并行计算(MMX)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>CPU性能极致</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_CPU%E6%80%A7%E8%83%BD%E6%9E%81%E8%87%B4/</url>
    <content><![CDATA[<h4 id="超线程"><a href="#超线程" class="headerlink" title="超线程"></a>超线程</h4><blockquote>
<p>在一个物理CPU核心内部、有双份的PC寄存器、指令寄存器和条件码寄存器、这样这个CPU核心就可以维护两条并行的指令的状态、在外部看起来似乎有两个逻辑层面的CPU在同时运行. so 又称为同时多线程(SMT: Simulataneous Multi-Threading)、但其它功能组件依然是一份、因为超线程不是真的同时运行两个指令、而是在一个线程A的指令在流水线里停顿的时候、让空闲的CPU译码器和ALU去执行线程B的指令</p>
</blockquote>
<h4 id="SIMD-单指令多数据流"><a href="#SIMD-单指令多数据流" class="headerlink" title="SIMD 单指令多数据流"></a>SIMD 单指令多数据流</h4><blockquote>
<p>一种指令级并行的加速方案、在处理向量计算的情况下、同一个向量的不同维度直接的计算是相互独立的、而CPU里的寄存器、又可以放得下多条数据、所以可以一次性取出多条数据、交给CPU并行执行</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>DMA--为什么Kafka这么快-(48讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_DMA--%E4%B8%BA%E4%BB%80%E4%B9%88Kafka%E8%BF%99%E4%B9%88%E5%BF%AB-(48%E8%AE%B2)/</url>
    <content><![CDATA[<blockquote>
<p>SSD的IOPS可以达到2w、4w, 可CPU主频在2GHZ以上、每秒可以有2亿次操作, 若对于IO操作、都是由CPU发出对应的指令、然后等待IO设备完成操作之后返回、那CPU有大部分的时间在等待IO. 其实对于IO设备的大量操作、都只是把内存数据传输到IO设备而已、CPU是无效等待, 于是, 就有了 <code>DMA</code>(Direct Memory Access)<code>直接内存访问</code> 技术</p>
</blockquote>
<h4 id="理解DMA、一个协处理器"><a href="#理解DMA、一个协处理器" class="headerlink" title="理解DMA、一个协处理器"></a>理解DMA、一个协处理器</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="title">本质上:</span> DMA技术就是在主板上放一块独立的芯片, 在进行内存与IO设备的数据传输时, 不在通过CPU来控制</span><br><span class="line">数据传输、而是通过`DMA控制器`(`DMAC`), 这块芯片可以认为就是一个`协处理器`</span><br><span class="line"></span><br><span class="line">DMAC最有价值的地方体现在, 当要传输的数据特别大、速度特别快, 或者传输的数据特别小、速度特别慢时.</span><br><span class="line">eg. <span class="number">1</span>. 用千兆网卡或者硬盘传输大量数据时、若都用CPU来搬运的话、肯定忙不过来、所以, 选择DMAC</span><br><span class="line">    <span class="number">2</span>. 数据传输很慢时, DMAC可以等数据到齐了、再发送信号给CPU处理、而不是让CPU在那里忙等待.</span><br><span class="line"></span><br><span class="line">DMAC在控制数据传输时、还是需要CPU的.</span><br><span class="line"></span><br><span class="line">总线上的设备包括`主设备`和`从设备`, 主动发起数据传输的、必须是主设备, eg.CPU<span class="comment">;从设备只能接收数据. </span></span><br><span class="line"><span class="title">所以:</span> 只能是 CPU从IO设备读数据、或者是CPU向IO设备写数据.</span><br><span class="line"></span><br><span class="line">IO设备不能向主设备发起请求吗？</span><br><span class="line">可以. 但发送的不是实际的数据内容, 而是控制信号. IO设备可以告诉CPU, 有数据要传输、实际数据由CPU</span><br><span class="line">拉取, 而不是IO设备主动推送给CPU.</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-c4145e8dae426f5f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="包含DMAC的数据传输.png"></p>
<figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line"><span class="symbol">DMAC</span>既是一个主设备、有是一个从设备. 对<span class="symbol">CPU</span>来说、它是从设备, 对<span class="symbol">IO</span>设备来说、它是主设备.</span><br><span class="line">使用<span class="symbol">DMAC</span>进行数据传输的过程如下:</span><br><span class="line"><span class="number">1.</span> <span class="symbol">CPU</span>作为一个主设备、向<span class="symbol">DMAC</span>设备发起请求(就是在<span class="symbol">DMAC</span>里修改配置寄存器).</span><br><span class="line"><span class="number">2.</span> <span class="symbol">CPU</span>修改<span class="symbol">DMAC</span>寄存器的时候, 会告诉<span class="symbol">DMAC</span>几个信息:</span><br><span class="line">   <span class="number">1</span>) 源地址的初始值及传输时的地址增减方式</span><br><span class="line">       源地址: 数据要从哪里传输过来. eg. 从内存写入硬盘时, 就是一个内存地址</span><br><span class="line">              从硬盘读取到内存时, 就是硬盘的<span class="symbol">IO</span>接口的地址.</span><br><span class="line">       地址的增减方式: 是说数据从大的地址向小的地址传输, 还是从晓得地址往大的地址传输.</span><br><span class="line">   <span class="number">2</span>) 目标地址初始值及传输时的地址增减方式</span><br><span class="line">   <span class="number">3</span>) 要传输的数据长度</span><br><span class="line"><span class="number">3.</span> 设置完这些信息<span class="symbol">DMAC</span>就变成一个空闲的状态idle</span><br><span class="line"><span class="number">4.</span> 若从硬盘 -&gt; 内存加载数据, 硬盘会向<span class="symbol">DMAC</span>发起一个数据传输请求,这个请求是通过额外的连线(不是总线)</span><br><span class="line"><span class="number">5.</span> <span class="symbol">DMAC</span>再通过一个额外的连线响应该请求.</span><br><span class="line"><span class="number">6.</span> 于是, <span class="symbol">DMAC</span>再向内存发起总线读的数据传输请求, 就从硬盘读到了<span class="symbol">DMAC</span>控制器里.</span><br><span class="line"><span class="number">7.</span> 然后、<span class="symbol">DMAC</span>再向我们的内存发起写的请求、把数据写入内存</span><br><span class="line"><span class="number">8.</span> <span class="symbol">DMAC</span>会反复进行<span class="number">6</span>、<span class="number">7</span> 的操作, 直到<span class="symbol">DMAC</span>的寄存器里边设置的数据长度传输完成.</span><br><span class="line"><span class="number">9.</span> 数据传输完成之后、<span class="symbol">DMAC</span>重新回到第三步的空闲状态.</span><br><span class="line"></span><br><span class="line">整个数据传输的过程中，我们不是通过 <span class="symbol">CPU</span> 来搬运数据，而是由 <span class="symbol">DMAC</span> 这个芯片来搬运数据.</span><br><span class="line">但是 <span class="symbol">CPU</span> 在这个过程中也是必不可少的. 因为传输什么数据，从哪里传输到哪里，其实还是 <span class="symbol">CPU</span> 来设置的.</span><br><span class="line">这也是为什么，<span class="symbol">DMAC</span> 被叫作<span class="string">`协处理器`</span></span><br><span class="line"></span><br><span class="line">早期的计算机里没有<span class="symbol">DMAC</span>、所有数据都是<span class="symbol">CPU</span>来搬运的、然后出现了主板上独立的<span class="symbol">DMAC</span>控制器.</span><br><span class="line">现在数据传输要求越来越复杂、加上显卡、网卡、硬盘等各个设备对数据传输的需求不同、各个设备</span><br><span class="line">都有自己的<span class="symbol">DMAC</span>芯片了</span><br></pre></td></tr></table></figure>

<h4 id="Kafka为什么这么快"><a href="#Kafka为什么这么快" class="headerlink" title="Kafka为什么这么快"></a>Kafka为什么这么快</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">kafka 是一个用来处理实时数据的管道, 常用来做消息队列、或者收集和落地海量的日志. </span><br><span class="line">作为一个实时数据和日志的管道、瓶颈自然也在IO层面</span><br><span class="line"></span><br><span class="line">kafka常见的两种海量数据传输: 1.从网络接收上游数据,落地到本地磁盘 2.从本地磁盘读取、发送到网络上.</span><br><span class="line"></span><br><span class="line">先看场景2, 最直观的是用一个文件读操作, 从磁盘把数据读到内存、再通过一个socket、把数据发到网络上.</span><br><span class="line"></span><br><span class="line">File.read(fileDesc, buf, len);</span><br><span class="line">Socket.send(socket, buf, len);</span><br><span class="line"></span><br><span class="line">这样会有四次数据传输:(两次DMA、两次通过CPU控制的传输)</span><br><span class="line"><span class="bullet">1.</span> 从硬盘上、读到操作系统内核缓冲区(通过DMA搬运).</span><br><span class="line"><span class="bullet">2.</span> 将内核缓冲区的数据、复制到应用分配的内存里(通过CPU搬运)</span><br><span class="line"><span class="bullet">3.</span> 从应用的内存、写到操作系统Socket的缓冲区里(CPU搬运)</span><br><span class="line"><span class="bullet">4.</span> 从Socket的缓冲区、写到网卡的缓冲区(DMA)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-1827f1506ed4ab8f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="本次磁盘到网络的数据传输过程.png"></p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">其实只需要搬运一份数据、却搬运了<span class="number">4</span>次、且: 从内核的缓冲区传输到应用的内存里、再从应用的内存里</span><br><span class="line">传输到<span class="built_in">socket</span>的缓冲区里、其实是把一份数据在内存里搬来搬去, 所以kafka就调用Java NIO库、</span><br><span class="line">FileCahnnel-&gt;transfer <span class="built_in">to</span> 方法, 将数据直接通过Channel写入到对应网络设备, 且对于<span class="built_in">socket</span>的操作、</span><br><span class="line">也不是写到<span class="built_in">socket</span>的buffer里、而是直接根据描述符写入到网卡的缓冲区, 省去了<span class="number">2</span>、<span class="number">3</span>, 只有两次数据传输.</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-b190e4dc04bd2a64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="kafka的数据传输模型.png"></p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">这样、同一份数据的传输次数从<span class="number">4</span>次变成了<span class="number">2</span>次、且没有通过CPU传输、都是DMA传输, 在这个方法里、</span><br><span class="line">没有在内存层面copy数据, 也称为`零拷贝`(Zero-Copy)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>FPGA和ASIC(32讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_FPGA%E5%92%8CASIC(32%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="FPG"><a href="#FPG" class="headerlink" title="FPG"></a>FPG</h4><blockquote>
<p>CPU其实是一些简单的门电路搭建而成、从最简单的门电路、搭建成半加器、全加器, 然后再搭建完整功能的ALU. 这些功能有完成各种实际计算功能的组合逻辑电路、也有用来控制数据访问、创建出寄存器和内存的时序逻辑电路, 一个<code>4核</code> <code>i7</code>的CPU、大约有20亿个晶体管.</p>
</blockquote>
<p>思考:</p>
<blockquote>
<p>如何保证连接20亿晶体管时不出错 ？若每验证一次bug就重新生成一块芯片、代价过高.</p>
</blockquote>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">现场可编程门阵列(Filed-Programmable Gate <span class="built_in">array</span>)解决了这个问题.</span><br><span class="line">P: Programmable, 可通过编程来控制的硬件</span><br><span class="line">G: Gate, 代码芯片里的门电路, 各种编程功能的实现、依赖的就是一个个的门电路</span><br><span class="line">A: <span class="built_in">Array</span>, 阵列, 是说在一块<span class="string">`FPGA`</span>上、布满了大量的门电路</span><br><span class="line">F: 一块<span class="string">`FPGA`</span>的板子、可以多次进行编程、不像<span class="string">`PAL`</span>(Programming <span class="built_in">Array</span> Logic, 可编程阵列逻辑)这样古老的硬件设备、只能编程一次.</span><br></pre></td></tr></table></figure>

<p>思考:</p>
<blockquote>
<p>如何对硬件进行编程呢 ?</p>
</blockquote>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">CPU其实是通过晶体管、来实现各种组合逻辑或者时序逻辑、如何去`编程`这些线路呢 ?</span><br><span class="line">一、用存储功能实现组合逻辑</span><br><span class="line">在实现CPU时、需要完成各种各样的电路逻辑、在FPGA里、这些基本的电路逻辑、不是采用布线连接的方式进行的、</span><br><span class="line">而是预先根据软件里设计的逻辑电路、算出对应的真值表、然后直接存到`LUT(Look-Up Table, 查找表)`的电路中</span><br><span class="line">(其实就是一块存储空间、存储了输入特定信号时、对应输出是<span class="number">0</span>还是<span class="number">1</span>)</span><br><span class="line"><span class="title">如图(Look-Up Table)示:</span></span><br><span class="line">这个查表的方法、其实就是FPGA通过LUT来实现各种组合逻辑的方法</span><br><span class="line"></span><br><span class="line">二、对于需要实现的时序逻辑电路、可以在FPGA里直接放上`D触发器`、作为`寄存器`. </span><br><span class="line">和CPU里的触发器本质相同、会把多个LUT的电路和寄存器组合在一起(称为`逻辑簇`). </span><br><span class="line">在FPGA里、组合了多个LUT和寄存器的设备叫 `CLB`(Configurable Logic Block, 可配置逻辑块)</span><br><span class="line">通过配置CLB实现的功能类似全加器、是基础电路上的组合、可提供更复杂的功能、更复杂的芯片可以从CLB组合搭建、不用从基本门电路</span><br><span class="line"></span><br><span class="line">三、FPGA是通过可编程逻辑布线来连接各个不同的CLB、最终实现我们想要的功能芯片. </span><br><span class="line">可类比为铁路网、整个铁路系统已经铺好、单设计了很多岔道、通过控制岔道来确定不同列车的线路. </span><br><span class="line">在可编程逻辑布线里、编程做的、就是拨动像岔道一样的各个电路开关、最终实现CLB之间的连接、完成我们想要的功能</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-71a87f3241540b00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Look-Up Table.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-7a1ee5e4e7844f2e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="ASIC"><a href="#ASIC" class="headerlink" title="ASIC"></a>ASIC</h4><blockquote>
<p>虽然在手机或者录音笔上塞上一个Intel的CPU可以实现拍照、录音等功能、但, 显然比较浪费、于是: 考虑为专门用途的场景、设计单独芯片, 称为:<br><code>ASIC(Application-Specifed Integrated Circuit)</code> -&gt; 专用集成电路, 电路比较精简、制造成本也比CPU低、功耗也较小</p>
</blockquote>
<p>思考:</p>
<blockquote>
<p>可以FPGA实现ASIC的事情吗?</p>
</blockquote>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">可以、而且成本和功耗上要优于做通用计算的CPU和GPU、</span><br><span class="line"></span><br><span class="line"><span class="title">那:</span> 为什么不直接使用FPGA替代ASIC呢 ?</span><br><span class="line">硬件上的浪费. 每一个门电路都是一个小小浪费、一个LUT电路设计出来、既可以实现`与`门、</span><br><span class="line">又可以实现`或`门、用到的晶体管是比单一功能要多的、单品FPGA的生成制造成本也较高</span><br><span class="line"><span class="title">FPGA的优点是:</span> 无硬件研发成本、ASIC的电路设计、需要仿真、验证、还要经过六篇、变成一个印刷的电路板、最终变成芯片、</span><br><span class="line">从研发到上式、最低花费也要几万美元、高的话、可能在几千万到数亿美元、还要失败的可能,</span><br><span class="line">若设计的芯片最终只制造几千片、那还是FPGA的成本较低</span><br><span class="line"></span><br><span class="line"><span class="title">实际上:</span> 到底采用FPGA这样的可编程通用硬件、还是ASIC这样的专用芯片, 核心决定因素还是成本(不止是单个芯片的制造成本、还包括总体拥有成本)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>FPGA</code> 本质上是一个可以通过编程来控制硬件电路的芯片、通过<code>LUT</code>这样的存储设备来代替硬连线的电路、有了可编程逻辑门、然后把LUT和寄存器放在一起、变成一个更复杂的电路<code>CLB</code>, 单号通过可编程布线中的开关、设计成芯片、<code>FPGA</code>常用来进行芯片的设计和验证、也可直接当成专用芯片、替代CPU或者GPU<br>相比<code>FPGA</code>, <code>ASIC</code>设计出来的芯片针对特殊场景、研发成本高、制造成本和能耗较低、针对大量需求、适合<code>ASIC</code></p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>GPU的产生和发展(第30、31讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_GPU%E7%9A%84%E4%BA%A7%E7%94%9F%E5%92%8C%E5%8F%91%E5%B1%95(%E7%AC%AC30%E3%80%8131%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="GPU的历史进程"><a href="#GPU的历史进程" class="headerlink" title="GPU的历史进程"></a>GPU的历史进程</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">GPU是随着需要在计算机里渲染三维图形、而发展起来的设备</span><br><span class="line"></span><br><span class="line">到<span class="number">90</span>年代中期、随个人电脑的性能越来越好、开始有了<span class="number">3D</span>显卡的需求、那个时代之前的<span class="number">3D</span>游戏、都是伪<span class="number">3D</span></span><br><span class="line">从不同视角看到的是<span class="number">8</span>副不同的贴图、并不是通过图形学渲染出来的多边形</span><br><span class="line"></span><br><span class="line">为什么<span class="meta">CPU</span>的性能已经大幅度提升、还需要单独的GPU呢 ？</span><br></pre></td></tr></table></figure>



<h4 id="图形渲染的流程"><a href="#图形渲染的流程" class="headerlink" title="图形渲染的流程"></a>图形渲染的流程</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">现在电脑显示的3D画面、其实是通过多边形组合出来的. 现在各种游戏人物的脸、不是相机或者摄像头拍出来的、而是通过多边形建模创建出来的</span><br><span class="line"></span><br><span class="line">实际这些人物在画面里的移动、动作、乃至根据光线发生的变化、都是通过计算机根据图形学的各种计算、实时渲染出来的</span><br><span class="line"></span><br><span class="line">图像实时渲染、可拆解为:</span><br><span class="line"><span class="bullet">1.</span> 定点处理 (Vertex Processing)</span><br><span class="line"><span class="bullet">2.</span> 图元处理 (Primitive Processing)</span><br><span class="line"><span class="bullet">3.</span> 栅格化 (Rasteerization)</span><br><span class="line"><span class="bullet">4.</span> 片段处理 (Fragement Processing)</span><br><span class="line"><span class="bullet">5.</span> 像素操作 (Pixel Operations)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="解放图像渲染的GPU"><a href="#解放图像渲染的GPU" class="headerlink" title="解放图像渲染的GPU"></a>解放图像渲染的GPU</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">若使用<span class="meta">CPU</span>渲染、需要多少资源来处理 ?</span><br><span class="line">上世纪<span class="number">90</span>年代、屏幕分辨率大概: <span class="number">640</span>*<span class="number">480</span>, 约30w, 为了眼睛看到的画面不眩晕、希望画面有<span class="number">60</span>帧、即:</span><br><span class="line">每秒重新渲染<span class="number">60</span>次(<span class="number">1800</span>万次单个像素的渲染), 从栅格化开始、每个像素有<span class="number">3</span>个流水线步骤、假设每个步骤只有<span class="number">1</span>个指令、也需要5400w条指令</span><br><span class="line"></span><br><span class="line"><span class="number">90</span>年代的<span class="meta">CPU</span>性能是多少呢 ? <span class="number">93</span>年第一代Pentium处理器、主频60MHZ、后续逐步推出了 66MHZ、75MHZ、100MHZ的处理器、以这个性能来看、用<span class="meta">CPU</span>来渲染<span class="number">3D</span>图形、就基本上把<span class="meta">CPU</span>的性能耗光了、因为实际的每一个渲染步骤不可能只包含一个指令、所以、<span class="meta">CPU</span>跑不动<span class="number">3D</span>图形渲染</span><br><span class="line"></span><br><span class="line">既然图形渲染的流程是固定的、直接使用硬件来处理、不用<span class="meta">CPU</span>计算是不是可以呢 ? Voodoo FX这样的图形加速器出现了、显然、硬件会比制造通用计算性能的<span class="meta">cpu</span>要便宜的多、因为整个计算过程是固定的、不需要流水线停顿、乱序执行等各类导致<span class="meta">CPU</span>计算变的复杂的问题、也不需要可编程能力、只让硬件按照谢浩的逻辑进行运算即可</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="现代GPU的三个核心创意"><a href="#现代GPU的三个核心创意" class="headerlink" title="现代GPU的三个核心创意"></a>现代GPU的三个核心创意</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">现代CPU里的晶体管越来越多、越来越复杂、其实已经不是用来实现`计算`这个核心功能、而是拿来实现乱序执行、分支预测及存储器高速缓存</span><br><span class="line"></span><br><span class="line">而 对于GPU、这些电路就很多余了、GPU的整个处理过程是一个流式处理的过程(Stream Processing), </span><br><span class="line"><span class="title">因为没有太多分支条件或者复杂的依赖关系、可以把GPU的对应电路都省掉、只保留取指令、指令译码、ALU以及执行这些计算需要的寄存器和缓存、一般会抽象为如下图三部分:</span> 取指令、指令译码、ALU和执行上下文(乱序执行、分支预测、高速缓存... 都被省掉)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-f713259807500f3e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="SIMT和多核并行"><a href="#SIMT和多核并行" class="headerlink" title="SIMT和多核并行"></a>SIMT和多核并行</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">这样一来、GPU的电路就比<span class="meta">CPU</span>简化很多了、于是可以在一个GPU里、塞很多并行的GPU来实现计算、好像<span class="meta">CPU</span>里的多核<span class="meta">CPU</span>一样、和<span class="meta">CPU</span>不同的是、不需要单独实现多线程的计算、GPU的计算是天然并行的</span><br><span class="line"></span><br><span class="line">上节提到:</span><br><span class="line">无论是对多边形里的顶点进行处理还是对屏幕里的每一个像素、每个点的计算都是独立的、所以:</span><br><span class="line">简单的添加多核的GGPU、就能做到并行加速、</span><br><span class="line">另外: <span class="meta">CPU</span>的SIMD技术: 在向量计算的时候、要执行的指令是一样的、只是同一个指令的数据有所不同、在GPU的渲染管里、无论是顶点线性变换还是屏幕上临近像素点的光照和上色、都是在用相同指令流程进行计算、GPU就借鉴了SIMD、用来一种叫SIMT的技术,</span><br><span class="line"></span><br><span class="line">SIMT比SIMD更加灵活、在SIMD里、<span class="meta">CPU</span>一次性取出了多个固定长度的数据、放在寄存器里、用同一个指令去执行、而SIMT可以将多条数据、交给不同的线程来处理</span><br><span class="line"></span><br><span class="line">各个线程里执行的指令流程是相同的、但可能根据数据的不同、走到不同的条件分支、这样相同的代码和相同的流程、可能执行不同的具体的指令、于是GPU可以进一步简化、取指的时候可以交给后面多个不同的ALU并行计算、这样一个GPU的核里就可以放下更多的ALU、同时进行更多的并行运算了</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-c61ffb172e910ccf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="多核并行.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-4a8944f4e16eae26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="SIMT并行-多个ALU.png"></p>
<h4 id="GPU里的超线程"><a href="#GPU里的超线程" class="headerlink" title="GPU里的超线程"></a>GPU里的超线程</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">GPU里的指令、可能会遇到和CPU类似的流水线停顿问题、是不是可以想到优化方案`超线程` ?</span><br><span class="line"><span class="title">在GPU里一样可以有类似的优化. 即:</span> 遇到流水线停顿时、调度一些别的计算任务给当前的ALU</span><br><span class="line"></span><br><span class="line">和超线程一样、既然要调度一个不同的任务执行、就需要针对这个任务、提供更多的执行上下文、so. 一个Core里的执行上下文的数量、需要比 ALU 多</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-a8845384202d495f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="GPU在深度学习上的性能差异"><a href="#GPU在深度学习上的性能差异" class="headerlink" title="GPU在深度学习上的性能差异"></a>GPU在深度学习上的性能差异</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">通过芯片瘦身、SIMT和更多的执行上下文、GPU更擅长并行进行暴力运算、恰好适合深度学习的应用场景</span><br><span class="line"></span><br><span class="line"><span class="section">一方面: GPU是一个可以进行通用计算的框架、可以通过编程、在GPU上实现不同的算法、</span></span><br><span class="line"><span class="section">另一方面: 现在的深度学习计算、都是超大的向量和矩阵、海量的训练样本的计算、整个过程没有复杂的逻辑和分支、非常适合GPU这样并行、计算能力强的架构</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>IO设备(43讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_IO%E8%AE%BE%E5%A4%87(43%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="接口和设备-经典的适配器模式"><a href="#接口和设备-经典的适配器模式" class="headerlink" title="接口和设备: 经典的适配器模式"></a>接口和设备: 经典的适配器模式</h4><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">实际上, 输出输入设备、并不只是一个设备、大部分的输入输出设备、都有两个组成部分.</span><br><span class="line">接口和实际的IO设备. 硬件设备不是直接接入到总线上和CPU通信的、而是通过接口、用接口连接到总线上</span><br><span class="line">再通过总线和CPU通信的. 平时听说的并行接口<span class="comment">(Parallel Interface)</span>, 串行接口<span class="comment">(Serial Inteerface)</span>、</span><br><span class="line">USB接口都是计算机主板上内置的各个接口, 实际的硬件设备 eg. 使用并口的打印机、使用串口的老式鼠标</span><br><span class="line">或者使用USB接口的U盘、都要插入到这些接口上、才能和CPU工作及通信的.</span><br><span class="line"></span><br><span class="line">接口本身就是一块电路板、CPU其实不是和实际的硬件设备打交道、而是和这个接口电路板打交道.</span><br><span class="line">常说的设备里有三类寄存器、都在设备的接口电路上、而不是实际的设备上.</span><br><span class="line"></span><br><span class="line">三类寄存器: 状态寄存器<span class="comment">(Status Register)</span>、命令寄存器<span class="comment">(Command Register)</span>和数据寄存器<span class="comment">(Data Register)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="CPU是如何控制IO设备的"><a href="#CPU是如何控制IO设备的" class="headerlink" title="CPU是如何控制IO设备的"></a>CPU是如何控制IO设备的</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">无论是内置在主板上的接口、还是集成在设备上的接口、除了<span class="number">3</span>类寄存器之外、还有对应的控制电路,</span><br><span class="line">正是通过这个控制电路、<span class="meta">CPU</span>才能向这个接口电路板传输信号、来控制实际的硬件</span><br><span class="line"></span><br><span class="line">设备上的寄存器有什么用呢 ？</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-1349e7dbc149f62a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640" alt="打印机.png"></p>
<figure class="highlight smali"><table><tr><td class="code"><pre><span class="line">1. 数据寄存器. CPU向IO设备写入需要传输的数据、eg. 要打印`GeekTime`, 会先发送一个G给对应IO设备</span><br><span class="line">2. 命令寄存器. CPU发送一个命令、告诉打印机、要打印. 此时打印机里的控制电路会做两个动作.</span><br><span class="line">1) 设置状态寄存器里的状态为<span class="built_in"> not-ready</span></span><br><span class="line"><span class="built_in"></span>2) 实际操作打印机进行打印</span><br><span class="line">3. 状态寄存器. 告诉CPU、设备已经在工作了、此时再发送数据或者命令都是无效的</span><br><span class="line">直到前边的动作已完成、状态寄存器重新变成ready状态、CPU才发送下一个字符和命令</span><br><span class="line"></span><br><span class="line">在实际情况中、打印机通常不止有数据寄存器还有数据缓冲区、CPU也不是真的一个字符一个字符交给打印机处理的</span><br><span class="line">而是一次性将整个文档传输至打印机的内存或者数据缓冲区一起打印的</span><br></pre></td></tr></table></figure>

<h4 id="信号和地址-发挥总线的价值"><a href="#信号和地址-发挥总线的价值" class="headerlink" title="信号和地址: 发挥总线的价值"></a>信号和地址: 发挥总线的价值</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="meta">CPU</span>到底要往总线上发送一个什么样的命令、才能和IO接口上的设备通信呢 ？</span><br><span class="line"></span><br><span class="line"><span class="meta">CPU</span>和IO设备的通信、一样是通过<span class="meta">CPU</span>支持的机器指令来执行的.</span><br><span class="line">和访问主内存一样、使用内存地址来和IO设备通信. 为了让已经足够复杂的<span class="meta">CPU</span>尽可能简单、</span><br><span class="line">计算机会把IO设备的各个寄存器及IO设备内部的内存地址、都映射到主内存地址空间来、</span><br><span class="line">主内存的地址空间里、会给不同的IO设备预留一段一段的内存地址. <span class="meta">CPU</span>想和IO设备通信的时候、</span><br><span class="line">就往这些地址发送数据、这些地址信息就是通过地址总线老来发送的、对应的数据信息就是通过数据总线发送的</span><br><span class="line"></span><br><span class="line">而IO设备、会监控地址线、且在<span class="meta">CPU</span>往自己的地址发送数据的时候、把对应的数据线里边传输过来的数据、</span><br><span class="line">接入到对应的设备里边的寄存器和内存里. <span class="meta">CPU</span>无论是向IO设备发送命令、查询状态还是传输数据都可以</span><br><span class="line">通过这种方式. 称为内存映射IO(Memory-Mapped IO, MMIO)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-6ca26f4063f664e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<blockquote>
<p>那么、MMIO是不是唯一一种CPU和设备通信的方式呢 ?</p>
</blockquote>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">不是的. 精简指令集MIPS的<span class="meta">CPU</span>特别简单、所以这里只有MMIO. 而有<span class="number">2000</span>多个指令的Intel</span><br><span class="line">而我们有<span class="number">2000</span>多个指令的Intel X86架构的计算机、有专门的和IO设备通信的指令, 即: <span class="keyword">in</span> 和 <span class="keyword">out</span> 指令.</span><br><span class="line">Intel <span class="meta">CPU</span>虽然也支持MMIO、不过还可以通过特定的指令、来支持端口映射IO(Port-Mapped IO, 简称PMIO)</span><br><span class="line">也可以叫独立输入输出(Isolated IO)</span><br><span class="line"></span><br><span class="line">其实PMIO的通信方式和MMIO差不多、核心区别在于: PMIO里访问的设备地址、不再是在内存地址空间里、</span><br><span class="line">而是一个专门的端口, 这个端口不是硬件杀昂的插口、而是和<span class="meta">CPU</span>通信的一个抽象概念</span><br><span class="line"></span><br><span class="line">无论是PMIO还是MMIO、<span class="meta">CPU</span>都会传送一条二进制的数据、给到IO设备的对应地址. 设备自己本身的接口电路、</span><br><span class="line">再去解码这个数据、解码之后的数据会变成设备支持的一条指令、再去通过控制电路操作实际的硬件设备</span><br><span class="line">对<span class="meta">CPU</span>来说、它不关心设备本身可以支持哪些操作、只是在总线上传输一条条数据就好了.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>RISC和CISC</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_RISC%E5%92%8CCISC/</url>
    <content><![CDATA[<blockquote>
<p><code>CISC</code>: <code>Complex Insturction Set Computing </code>, 即: 复杂指令集</p>
<p><code>RISC</code>: <code>Reduced Instruction Set Computing</code>, 即: 精简指令集</p>
</blockquote>
<figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">早期、所有的CPU都是 CISC、并无 CISC 和 RISC 之分 </span><br><span class="line">CPU指令集的设计、需要考虑硬件限制、为了性能考虑、很多功能直接通过硬件电路完成、为了减少内存、指令的长度也是可变的, 常用指令的长度短一些、不常用指令长度可以长一些</span><br><span class="line"></span><br><span class="line">随历史发展、计算机性能和存储都在发展、当时 大卫*帕特森教授发现: 实际在CPU运行的程序里、<span class="number">80</span>%都是在使用 <span class="number">20</span>% 的简单指令、提出 RISC的理念</span><br><span class="line"></span><br><span class="line">RISC的CPU想法其实很直观、既然<span class="number">80</span>%的时间都在使用<span class="number">20</span>%的简单指令、那只使用<span class="number">20</span>%的简单指令呢？ - 因为指令数量很多、计算机科学家在软硬件两方面都受到了很大的挑战</span><br><span class="line"></span><br><span class="line">在硬件层面、想支持更多的复杂指令、CPU里的电路就要越复杂、在散热和功耗上也就会带来更大的挑战、</span><br><span class="line">在软件层面、支持更多的复杂指令、编译器的优化就更难</span><br><span class="line"></span><br><span class="line">于是在RISC架构里、CPU选择将指令精简到<span class="number">20</span>%的简单指令、而原先的复杂指令 则用简单指令组合起来实现、让软件实现硬件的功能、这样CPU的硬件设计就更简单了、性能提升也会变的容易</span><br><span class="line"></span><br><span class="line">RISC的CPU里完成指令的电路变简单了、就腾出了更多空间、这个空间、常被拿来放通用寄存器、因为RISC完成同样的功能、执行的指令数要比CISC多、所以、若需要反复从内存读取指令或者数据到寄存器、很多时间就会花在访问内存上、于是, RISC架构的CPU往往有更多的通用寄存器、</span><br><span class="line"></span><br><span class="line">除了寄存器这样的存储空间、RISC的CPU也可以把更多的晶体管、用来实现更好的分支预测等相关功能、进一步提升CPU的实际利用率</span><br><span class="line"></span><br><span class="line"><span class="string">`CPU执行时间`</span> = <span class="string">`指令数`</span> * <span class="string">`CPI`</span> * <span class="string">`Clock Cycle Time`</span></span><br><span class="line"></span><br><span class="line">CISC的架构其实就是通过优化指令数、来减少CPU的执行时间、而RISC的架构、其实是在优化CPI</span><br><span class="line">指令比较简单、需要的时钟周期就很少</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="微指令架构"><a href="#微指令架构" class="headerlink" title="微指令架构"></a>微指令架构</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">在微指令架构的<span class="meta">CPU</span>里、编译器编译出来的机器码和汇编代码没发生变化、但: 在指令译码阶段、指令译码器翻译出来的、不再是某一条<span class="meta">CPU</span>指令、译码器会把一条机器码、翻译成好几条微指令、这一条条的微指令就变成了固定长度的RISC风格的了</span><br><span class="line"></span><br><span class="line">这些RISC风格的微指令、会被放在一个微指令缓冲区里、然后再从缓冲区里边、分发给后边的超标量、且乱序执行的流水线架构里(精简指令)、在这个架构里、指令译码器相当于变成了<span class="string">`适配器`</span>, 填平； CISC和RISC之间的指令差异</span><br><span class="line"></span><br><span class="line">但: 这样一个可以把CISC的指令译码成RISC指令的指令译码器、比原来的译码器要复杂、就意味着更复杂的电路和更长的译码时间, 本来以为可以通过RISC提升的性能、又有一部分浪费在了指令译码上、怎么解决呢?</span><br><span class="line"></span><br><span class="line">由于<span class="number">80</span>%运行的代码、只包含<span class="number">20</span>%的常用指令、这个很强的局部性、可以使用缓存来解决.</span><br><span class="line">Intel在<span class="meta">CPU</span>里加了一层 L0 Cache、这个Cache保存的就是指令译码器把CISC的指令翻译RISC的微指令的结果、于是大部分情况、<span class="meta">CPU</span>可以从Cache拿到译码结果、而不用实际译码, 不仅优化了性能、因为译码器的开关动作变少了、还减少了功耗</span><br><span class="line"></span><br><span class="line">由于Intel本身在<span class="meta">CPU</span>层上做过大量优化: 分支预测、乱序执行等、X86的<span class="meta">CPU</span>始终在功耗上还是要超过RISC架构的ARM、所以最终在智能手机崛起替代PC的时代、落在了ARM后面</span><br></pre></td></tr></table></figure>



<h4 id="CPU的现在和未来"><a href="#CPU的现在和未来" class="headerlink" title="CPU的现在和未来"></a>CPU的现在和未来</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">现在、CISC和RISC架构的分界已经不明显了、Intel和AMD的<span class="meta">CPU</span>也都是采用译码成RISC风格的微指令来运行、而ARM的芯片、一条指令通用需要多个时钟周期、有乱序执行和多发射</span><br><span class="line"></span><br><span class="line">未来的<span class="meta">CPU</span>、多半会像Linux一样、逐渐成为一个业界的主流选择、若想打造一个属于自己的<span class="meta">CPU</span>、可以关注下 RISC-V开源项目的发展</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD-(46、47讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_SSD-(46%E3%80%8147%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="SSD的读写原理"><a href="#SSD的读写原理" class="headerlink" title="SSD的读写原理"></a>SSD的读写原理</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="title">下边性能对比图显示:</span> SSD的耐用性很差、若需要频繁的写入/删除数据、则机械硬盘比SSD性价比要高很多.</span><br><span class="line"></span><br><span class="line">之前我们知道、CPU Cahe 是SRAM 用一个电容来存放一个比特的数据、对于SSD、也可先简单认为, </span><br><span class="line">是一个电容+一个电压计、记录一个或多个比特</span><br><span class="line"></span><br><span class="line">`SLC`、`MLC`、`TLC`、`QLC`</span><br><span class="line">给电容充电时、电压就是<span class="number">1</span><span class="comment">; 放电后,里边没电、就是0. 采用这种方式存储的SSD硬盘、称`使用了SLC的颗粒`,</span></span><br><span class="line"><span class="title">全称`Single-Level Cell`, 即:</span> 一个存储单元只有一位数据.</span><br><span class="line"><span class="title">但: 这样就会遇到与CPU Cache相同的问题:</span> 相同面积下、由于存放的元器件有限、存储容量上不去.</span><br><span class="line">于是, 有了`MLC`(Multi-Level Cell)、`TLC`(Triple-Level Cell)及`QLC`(Quad-Level Cell), </span><br><span class="line"><span class="title">即:</span> 一个电容可存<span class="number">2</span>、<span class="number">3</span>乃至<span class="number">4</span>个bit</span><br><span class="line">同时, 由于对精度的要求更高、QLC的读写速度比SLC要慢好几倍</span><br><span class="line"></span><br><span class="line">P/E擦写问题</span><br><span class="line">SSD同其它IO设备、有对应接口和控制电路、控制电路中一个很重要的模块叫`TFL`(Flush Transaction Layer)</span><br><span class="line">闪存转换层. SSD磁盘性能的好坏、很大程度上取决于FTL算法的好坏.</span><br><span class="line"></span><br><span class="line">实际的IO设备和机械硬盘很像、有很多裸片叠在一起<span class="comment">;</span></span><br><span class="line">一张裸片上可放多个平面(Plane), 一个平面的存储容量大概在GB级别<span class="comment">; </span></span><br><span class="line">一个平面上会划分成很多块(Block), 一般一个块的存储大小在几百KB到几MB<span class="comment">;</span></span><br><span class="line">一个块、还会分为很多页(Page), 大小通常是<span class="number">4</span>KB.</span><br><span class="line"></span><br><span class="line">SSD读取和写入的基本单位是`页`， 擦除单位是`块`.</span><br><span class="line">SSD的使用寿命、其实就是每一个块的擦除次数.</span><br><span class="line">`SLC`的擦除次数大概在<span class="number">10</span>w次、`MLC`就<span class="number">1</span>w次左右、`TLC`和`QLC`只有几千次.</span><br><span class="line"></span><br><span class="line">SSD特别适合读多、写少的应用、在日常应用里、系统盘适合使用SSD.</span><br><span class="line">但若使用SSD做下载盘、一直下载各种影音数据、就不好了、特别是现在QLC的SSD, 只有几千次的擦写寿命.</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-277084bb88844b36.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="SSD和HDD性能对比.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-dbd383714531b895.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="SSD物理结构.png"></p>
<h4 id="如何最大化利用SSD"><a href="#如何最大化利用SSD" class="headerlink" title="如何最大化利用SSD"></a>如何最大化利用SSD</h4><figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line"><span class="string">`磨损均衡`</span>: 实现的核心办法、类似虚拟内存、添加一个间接层<span class="string">`FTL`</span>， 像通过一个页表映射虚拟内存和物理页</span><br><span class="line">一样、在<span class="symbol">FLT</span>里存放了逻辑块地址(<span class="symbol">Logic</span> <span class="symbol">Block</span> <span class="symbol">Address</span>, <span class="symbol">LBA</span>)到物理块地址(<span class="symbol">Physical</span> <span class="symbol">Block</span> <span class="symbol">Address</span>, </span><br><span class="line"><span class="symbol">PBA</span>)的映射.</span><br><span class="line"></span><br><span class="line">操作系统所有对<span class="symbol">SSD</span>的读写请求、都要经过<span class="symbol">FLT</span>、<span class="symbol">FTL</span>里又有逻辑块对应的物理块、这样<span class="symbol">FTL</span>可以记录每个物理块</span><br><span class="line">被擦写的次数. 若一个物理块被擦写较多、<span class="symbol">FTL</span>就将它挪到一个擦写少的物理块上,逻辑块不动、操作系统无感.</span><br><span class="line"></span><br><span class="line"><span class="string">`TRIM`</span>指令支持</span><br><span class="line">操作系统不关心底层硬件是什么、在<span class="symbol">SSD</span>的使用上也会带来一个问题:</span><br><span class="line">操作系统的逻辑层和<span class="symbol">SSD</span>的逻辑层里的块状态是不匹配的.</span><br><span class="line"></span><br><span class="line">在操作系统里删除一个文件、其实并没有真正在物理层操作删除、只在文件系统里把对应的inode元信息清理掉, </span><br><span class="line">这个inode还可以继续使用, 写入新的数据, 在物理层面对应的存储空间、在操作系统里被标示可写入.</span><br><span class="line">所以: 日常文件删除、只是操作系统层面的逻辑删除、不小心误删文件时、还可以通过恢复软件、恢复出来,</span><br><span class="line">想彻底删除数据、需要使用文件粉碎功能.</span><br><span class="line"></span><br><span class="line">这个删除的逻辑在机械硬盘上可行、后续的写入可直接覆写该位置. 但在<span class="symbol">SSD</span>上不行. </span><br><span class="line"></span><br><span class="line">eg. 在操作系统里删除一个刚下载的文件 a.txt, 在操作系统里、对应的inode里、就没有文件的元信息,</span><br><span class="line">但 <span class="symbol">SSD</span>的逻辑块层面、并不知道这个事情, a.txt 依然占用了空间、对应的物理页、也是被占用的.</span><br><span class="line">此时: 若要对<span class="symbol">SSD</span>进行垃圾回收、a.txt 对应的物理页、让要被搬运到其它<span class="symbol">Block</span>中去、只有当操作系统再</span><br><span class="line">在刚才的inode写入数据时、才会知道原来的数据已无用, 才会标记删除这种现象导致, 为了磨损均衡、</span><br><span class="line">可能搬运了很多已删除的数据、导致很多不必要的数据读写和擦除, 损耗<span class="symbol">SSD</span>性能.</span><br><span class="line"></span><br><span class="line">为了解决这个问题、现在的操作系统和<span class="symbol">SSD</span>的主控芯片都支持<span class="string">`TRIM`</span>命令、可在文件删除时、让操作系统通知</span><br><span class="line"><span class="symbol">SSD</span>, 标记对应逻辑块为已删除.</span><br><span class="line"></span><br><span class="line"><span class="string">`写入放大`</span>:</span><br><span class="line"><span class="symbol">TRIM</span> 命令的发明，也反应了一个使用 <span class="symbol">SSD</span> 硬盘的问题，那就是，<span class="symbol">SSD</span> 硬盘容易越用越慢.</span><br><span class="line"><span class="symbol">SSD</span>存储空间被越占越多时、每次数据写入可能都没有足够空间, 不得不进行垃圾回收、合并块里的页、</span><br><span class="line">然后擦除一些页. 此时, 从操作系统层看、可能只是写入<span class="number">4</span>k或者<span class="number">4</span><span class="symbol">M</span>的数据、通过<span class="symbol">FTL</span>后、可能要搬运<span class="number">8</span><span class="symbol">MB</span>、<span class="number">16</span><span class="symbol">MB</span>甚至更多的数据</span><br><span class="line"></span><br><span class="line"><span class="string">`实际的闪存写入的数据量 / 系统通过 FTL 写入的数据量 = 写入放大`</span></span><br><span class="line">写入放大越多、<span class="symbol">SSD</span>的性能也就越差.</span><br><span class="line">解决写入放大、需要在后台定时进行垃圾回收.在磁盘较闲时、把搬运数据、擦除数据、留出空白的工作做完.</span><br><span class="line">实际数据写入时、就不会有这么多的性能损耗了.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-25a82b2bc13b5e1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="AeroSpike-如何最大化SSD的使用效率"><a href="#AeroSpike-如何最大化SSD的使用效率" class="headerlink" title="AeroSpike: 如何最大化SSD的使用效率"></a>AeroSpike: 如何最大化SSD的使用效率</h4><figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>.AeroSpike 操作SSD硬盘、未通过操作系统的文件系统、而是直接操作SSD里的块和页.</span><br><span class="line"><span class="number">2</span>.AeroSpike 在读写数据时有<span class="number">2</span>个优化.</span><br><span class="line">  <span class="number">1</span>) 写数据时、尽可能写一个较大的块, 而不是频繁的写很多小的数据块, 这样磁盘就不太容易出现磁盘碎片.</span><br><span class="line">     也更好的理由磁盘的顺序写入优势.</span><br><span class="line">  <span class="number">2</span>) 读取时、可以读取小数据, 因为SSD的随机读取性能很好、也不像写入数据一样有擦除寿命问题. </span><br><span class="line">     且一次性读较大数据、需要在网络间传输时、可能导致带宽不够.</span><br><span class="line"></span><br><span class="line">另: 由于AeroSpike是一个对响应时间要求很高的实时KV数据库、若出现严重的写放大效应、会导致数据写入</span><br><span class="line">响应时长大幅度变长. 所以做了下边的优化:</span><br><span class="line"><span class="number">1</span>. 持续进行磁盘碎片整理. 使用高水位算法, 其实就是: 一旦一个物理块的数据碎片超过<span class="number">50</span><span class="comment">%, 就将其搬运</span></span><br><span class="line">压缩、然后进行数据擦除、确保始终有足够空间写入.</span><br><span class="line"><span class="number">2</span>.为保障数据库性能,建议只用SSD硬盘容量一半, 即: 人为预留SSD50<span class="comment">%空间、确保SSD的写放大效应尽可能小.</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>TPU--设计和拆解ASIC芯片</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_TPU--%E8%AE%BE%E8%AE%A1%E5%92%8C%E6%8B%86%E8%A7%A3ASIC%E8%8A%AF%E7%89%87/</url>
    <content><![CDATA[<blockquote>
<p>GPU天生适合海量、并行的矩阵运算、于是大量用在深度学习的模型训练上<br>深度学习中计算量最大的是什么呢 ? 深度学习的推断部分</p>
</blockquote>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">`推断部分`: 在完成深度学习训练之后、把训练完成的模型存储下来. 这个存储下来的模型、是许多个向量组成的参数、然后根据这些参数、计算输入的数据、得到结果. eg. 推测用户是否点击广告<span class="comment">; 扫身份证进行人脸识别</span></span><br></pre></td></tr></table></figure>

<p>思考: 模型的训练和推断有什么区别 ?</p>
<figure class="highlight erlang-repl"><table><tr><td class="code"><pre><span class="line">一、深度学习的推断、灵活性要求更低. 只需要计算一些矩阵的乘法、加法、调用一些sigmoid这样的激活函数、可能计算很多层、但也只是这些计算的简单组合</span><br><span class="line"></span><br><span class="line">二、深度学习推断的性能、首先要保证响应时间的指标</span><br><span class="line">模型训练的时候、只需要考虑吞吐率就可以、但推断不行. eg. 我们不希望人脸识别会超过几秒钟</span><br><span class="line"></span><br><span class="line">三、深度学习的推断工作、希望功耗尽可能的小一些</span><br><span class="line">因为深度学习的推断要<span class="number">7</span>*<span class="number">24</span>小时的跑在数据中心、且对应芯片要大规模的部署在数据中心、一块芯片减少<span class="number">5</span><span class="comment">%的功耗、就可以节省大量的电力</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>于是: 第一代TPU的设计目标:<br>在保障响应时间的情况下、尽可能的提高<code>能效比</code>这个指标、也就是进行相同数量的推断工作、花费的整体能源要低于CPU和GPU</p>
</blockquote>
<h4 id="TPU的几点设计"><a href="#TPU的几点设计" class="headerlink" title="TPU的几点设计"></a>TPU的几点设计</h4><blockquote>
<ol>
<li>向前兼容  2. TPU未设计成包含取指电路的GPU、而是通过CPU发送需要执行的指令</li>
<li>使用<code>SRAM</code> 作为统一缓冲区, <code>SRAM</code>一般用来作为CPU的寄存器或者高速缓存、<code>SRAM</code>比<code>DRAM</code>快, 但因为电路密度小、占用空间大、价格也较贵、之所以选择<code>SRAM</code>是因为整个推断过程、它会高频反复地被矩阵乘法单元读写、来完成计算</li>
<li>细节优化, 使用8Bits数据</li>
</ol>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-9db6fb03181e5443.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>冒险和预测(21~26讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%86%92%E9%99%A9%E5%92%8C%E9%A2%84%E6%B5%8B(21~26%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="CPU流水线设计"><a href="#CPU流水线设计" class="headerlink" title="CPU流水线设计"></a>CPU流水线设计</h4><p><code>指令流水线</code>: 若把指令执行拆分成<code>取指令</code> -&gt; <code>指令译码</code> -&gt; <code>指令执行</code> 三个部分、这就是一个三级的流水线、若把指令执行进一步拆分成 <code>ALU 计算(指令执行)</code> -&gt; <code>内存访问</code> -&gt; <code>数据写回</code> 就变成了5级流水线、</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">五级流水线:</span></span><br><span class="line">表示在同一个时钟周期里、同时运行5条指令的不同阶段, 虽然执行一条指令的时钟周期变成5、但可以提高CPU的主频, 只需要保证最复杂的一个流水线级的操作在一个时钟周期内完成、无需确保最复杂的那条指令在时钟周期里执行完成</span><br></pre></td></tr></table></figure>

<h4 id="超长流水线性能瓶颈"><a href="#超长流水线性能瓶颈" class="headerlink" title="超长流水线性能瓶颈"></a>超长流水线性能瓶颈</h4><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">增加流水线的深度是有性能成本的</span><br><span class="line">用来同步时钟周期的、不再是指令级别, 而是流水线级别、每一个流水线对应的输出、都要放到流水线寄存器(Pipeline Register) 然后在下一个时钟周期交给下一个流水线级处理、<span class="keyword">so</span>. 增加流水线级、就要多出一级写入流水线寄存器的操作、虽然很快、假设<span class="number">20</span><span class="keyword">ps</span>、但不断增加流水线深度、这些操作占整个指令的执行时间的比例就会不断增加</span><br><span class="line"></span><br><span class="line">eg. 指令执行<span class="number">3</span>ns(<span class="number">3000</span><span class="keyword">ps</span>)、设计<span class="number">20</span>级的流水线、流水线的操作就需要 <span class="number">20</span><span class="keyword">ps</span> * <span class="number">20</span> = <span class="number">400</span><span class="keyword">ps</span> 占比 <span class="number">400</span>/<span class="number">3000</span>超过<span class="number">10</span>% 、也就是但从的增加流水线级数、会带来更多的额外开销、</span><br><span class="line"></span><br><span class="line">所以要合理的设计流水线级数</span><br></pre></td></tr></table></figure>

<h4 id="流水线设计的冒险"><a href="#流水线设计的冒险" class="headerlink" title="流水线设计的冒险"></a>流水线设计的冒险</h4><p>流水线设计需要解决的三大冒险: <code>结构冒险</code>, <code>数据冒险</code> 和 <code>控制冒险</code><br><code>结构冒险</code>: 本质上是硬件层面的资源竞争问题、CPU在同一个时钟周期、同时在运行两条计算机指令的不同阶段、但可能会用到同样的硬件了</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-878133ae5032eb4b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="同一时钟周期、两个指令访问同一资源.png"></p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">如上所示: 在第一条指令执行到访存(MEM)阶段的时候、流水线里的第4条指令、在执行指令Fetch的操作、访存和取指令、都要进行内存数据的读取, 内存只有一个地址译码器的作为地址输入、就只能在一个时钟周期里读取一条数据、无法同时执行第一条指令的读取内存数据和第4条指令的读取指令的操作</span></span><br><span class="line"></span><br><span class="line"><span class="section">类似的资源冲突: </span></span><br><span class="line">常用的键盘、不是每个键的背后都有一根独立的线路、而是多个键公用一个线路、如果在同一时间、按下两个共用一个线路的按键、这两个按键的信号都没办法传输出去、就出现了按下键却不生效的情况</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在CPU的结构冒险里、对于内存访问和取指令的冲突、直观的解决方案是把内存拆成2部分、让他们有各自的地址译码器、分别是存放指令的程序内存和存放数据的数据内存(对应体系结构叫 哈佛架构(Harvard Architecture)), 但这样拆对于指令和数据需要的内存空间、就无法根据实际的应用动态分配了、解决了资源冲突问题、也失去了灵活性<br>现代CPU架构借鉴了哈佛架构的思路、采用了普林斯顿架构、在高速缓存方面拆分成指令缓存和数据缓存<br>内存的访问速度远比CPU慢、所以现代的CPU不会直接读取主内存、会从主内存把指令和数据加载到高速缓存中、这样后续访问都是访问高速缓存、而指令缓存和数据缓存的拆分使得CPU在进行数据访问和取指令的时候、不会发生资源冲突了</p>
</blockquote>
<p><code>数据冒险</code>: 三种不同的依赖关系</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">数据冒险就是多个指令间有数据依赖的情况、可以分为 先读后写、先写后读和写后再写、如果满足不了依赖关系、最终结果就会出错</span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过流水线停顿(Pipeline Stall):插入nop操作 来解决数据冒险</p>
</blockquote>
<h4 id="操作数前推"><a href="#操作数前推" class="headerlink" title="操作数前推"></a>操作数前推</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add </span>$<span class="built_in">t0</span>, $<span class="built_in">s2</span>,$<span class="built_in">s1</span></span><br><span class="line"><span class="keyword">add </span>$<span class="built_in">s2</span>, $<span class="built_in">s1</span>,$<span class="built_in">t0</span></span><br><span class="line"><span class="number">1</span>. 第一条指令 将<span class="built_in">s1</span> 和 <span class="built_in">s2</span> 寄存器里的数据相加、写入 <span class="built_in">t0</span> 寄存器</span><br><span class="line"><span class="number">2</span>. 第二条指令 将 <span class="built_in">s1</span> 和 <span class="built_in">t0</span> 的数据相加、写入 <span class="built_in">s2</span> 寄存器</span><br><span class="line">指令<span class="number">2</span> 的执行、依赖<span class="built_in">t0</span>的值、而<span class="built_in">t0</span>的值来自于前一条指令的计算结果、所以指令<span class="number">2</span>需要等前一指令的数据写回之后才能执行、就遇到了数据依赖冒险、</span><br><span class="line">使用插入<span class="keyword">nop来解决、可以解决、但是会浪费两个时钟周期</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">其实、如果第一条指令的执行结果可以直接传给第二条指令的执行输入、在第一条指令的执行阶段完成之后、直接将数据传输给下一条指令的ALU、下一指令就不需要插入两个<span class="keyword">nop阶段、就可以继续执行阶段, </span>如下图所示、这种方案就叫操作数前推</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-54ea7826a6b70dad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="乱序执行"><a href="#乱序执行" class="headerlink" title="乱序执行"></a>乱序执行</h4><figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line">即使综合运用流水线停顿、操作数前推、增加资源等解决结构冒险和数据冒险的问题、仍然会遇到不得不停下整个流水线等待前一指令完成的情况、但是: 如果后边有指令不需要依赖前边指令的执行结果就可以不必等待前边指令完成、直接占用<span class="keyword">nop</span>即可、这样的解决方案、在计算机里叫 乱序执行</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-4d24af97f6f2a623.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="不得不nop填充.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-7b98287e4db1bca0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="nop占用.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-2b24ee6d961e9f88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="乱序执行的CPU.png"></p>
<h4 id="乱序执行的步骤"><a href="#乱序执行的步骤" class="headerlink" title="乱序执行的步骤"></a>乱序执行的步骤</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 取指令和指令译码阶段、同其它CPU、会一级一级顺序进行Fetch和Decode</span><br><span class="line"><span class="bullet">2.</span> 指令译码完成后、CPU不会直接进行指令执行、而是进行指令分发、把指令发到保留站(Reservation Stations)、类似火车站、指令类似列车</span><br><span class="line"><span class="bullet">3.</span> 指令不会立即执行、而是等待依赖数据完成才执行. 类似火车要等乘客到齐才出发</span><br><span class="line"><span class="bullet">4.</span> 依赖数据到齐之后、指令可以交给后边的功能单元(Function Unit, FU)、就是ALU来执行、很多功能单元可以并行运行、但不同功能单元可以执行的指令不同、类似铁轨可以从上海北上、到北京或者哈尔滨;有些是南下、到广州或者深圳</span><br><span class="line"><span class="bullet">5.</span> 指令执行的阶段完成后、不能立即把结果写回寄存器、而是把结果写入指令重排区(Re-Order buffer, ROB).</span><br><span class="line"><span class="bullet">6.</span> 在重排缓冲区、CPU会按照取指令的顺序、对指令的计算结果重新排序、 只有排在前边的指令都完成才会提交指令、完成整改指令的运算结果</span><br><span class="line"><span class="bullet">7.</span> 实际的指令计算结果不直接写入内存或者高速缓存、而是先写入存储缓冲区(Store Buffer)，最终才写入高速缓存和内存</span><br><span class="line">so. 在乱序执行的情况下、只有CPU内部指令的执行层面、可能乱序、只要在指令的译码阶段正确的分析出指令之间的数据依赖关系、乱序就只会在无相互影响的指令间发生</span><br></pre></td></tr></table></figure>

<h4 id="分支预测"><a href="#分支预测" class="headerlink" title="分支预测"></a>分支预测</h4><blockquote>
<p>缩短分支延迟: 将调解判断、地址调整 提前到指令译码阶段进行、无需放到指令执行阶段. 这种方式本质上和数据冒险的操作数前推方案类似、就是在硬件电路层面讲一些计算结果更早的反馈到流水线中、反馈更快、后边指令的等待时间就变短了</p>
</blockquote>
<blockquote>
<p>分支预测: 1) 静态预测、假装分支不发生. 分支预测失败的代价是: 丢弃已取出的指令&amp;清空已使用的寄存器的操作<br>2) 动态分支预测:<br>a. 一级分支预测: 用1比特、记录当前分支的比较清空、来预测下一次分支时候的比较情况<br>b. 双模态预测器: 从2byte记录对应状态、提高预测的准确度</p>
</blockquote>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="meta">CPU</span>的流水线设计里、会遇到eg. 指令依赖等的情况、使得下一条指令不能正确执行. 但是通过抢跑的方式、可以得到提升指令 吞吐率 的机会、流水线架构的<span class="meta">CPU</span>、是主动的冒险选择</span><br></pre></td></tr></table></figure>

<h4 id="流水线设计总结"><a href="#流水线设计总结" class="headerlink" title="流水线设计总结"></a>流水线设计总结</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">为了不浪费<span class="meta">CPU</span>的性能、把指令执行的过程切分成一个个的流水线、来提升<span class="meta">CPU</span>的吞吐率, 而每增加一级的流水线、也会增加overhead、同样因为指令不是顺序执行</span><br><span class="line"></span><br><span class="line">数据冒险和分支冒险: 通过插入<span class="keyword">nop</span>来解决</span><br><span class="line"></span><br><span class="line"><span class="keyword">nop</span>空转: 通过乱序执行来解决</span><br><span class="line"></span><br><span class="line">乱序执行: 是在指令执行阶段通过一个类似线程池的保留站、让系统之家动态调度先执行哪些指令、前提是不破坏数据依赖性. <span class="meta">CPU</span>只要等到在指令结果的最终提交阶段、再通过重排序的方式、确保指令是顺序执行的</span><br><span class="line"></span><br><span class="line">超标量: (Superscalar) 和 多发射(Multi issue) 在同一时间把多条指令发射到不同的译码器</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>函数调用为何会发生栈溢出(第7讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E4%B8%BA%E4%BD%95%E4%BC%9A%E5%8F%91%E7%94%9F%E6%A0%88%E6%BA%A2%E5%87%BA(%E7%AC%AC7%E8%AE%B2)/</url>
    <content><![CDATA[<p>一、为什么需要程序栈<br>示例代码:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// function_Example.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="type">static</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> a+b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="type">int</span> x = <span class="number">5</span>;</span><br><span class="line">   <span class="type">int</span> y = <span class="number">10</span>;</span><br><span class="line">   <span class="type">int</span> u = add(x, y);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>编译代码、使用objdump打印出来</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> static <span class="keyword">add</span>(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span><br><span class="line">&#123;</span><br><span class="line">   <span class="number">0</span>:   <span class="number">55</span>                      <span class="keyword">push</span>   <span class="built_in">rbp</span>   # <span class="built_in">bp</span>是基址指针寄存器、处理函数调用、 <span class="keyword">push</span> <span class="built_in">rbp</span> 就是先将<span class="built_in">rbp</span>的内存保存入栈</span><br><span class="line">   <span class="number">1</span>:   <span class="number">48</span> <span class="number">89</span> e5                <span class="keyword">mov</span>    <span class="built_in">rbp</span>,<span class="built_in">rsp</span> #将<span class="built_in">rsp</span>的值赋给<span class="built_in">rbp</span>(<span class="built_in">rbp</span>始终执行栈帧底部、<span class="built_in">rsp</span>始终指向栈帧顶部)</span><br><span class="line">   <span class="number">4</span>:   <span class="number">89</span> <span class="number">7d</span> fc                <span class="keyword">mov</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x4</span>],<span class="built_in">edi</span></span><br><span class="line">   <span class="number">7</span>:   <span class="number">89</span> <span class="number">75</span> f8                <span class="keyword">mov</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x8</span>],<span class="built_in">esi</span></span><br><span class="line">    return a+b<span class="comment">;</span></span><br><span class="line"><span class="symbol">   a:</span>   8b <span class="number">55</span> fc                <span class="keyword">mov</span>    <span class="built_in">edx</span>,<span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x4</span>]</span><br><span class="line"><span class="symbol">   d:</span>   8b <span class="number">45</span> f8                <span class="keyword">mov</span>    <span class="built_in">eax</span>,<span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x8</span>]</span><br><span class="line">  <span class="number">10</span>:   <span class="number">01</span> d0                   <span class="keyword">add</span>    <span class="built_in">eax</span>,<span class="built_in">edx</span></span><br><span class="line">&#125;</span><br><span class="line">  <span class="number">12</span>:   <span class="number">5d</span>                      <span class="keyword">pop</span>    <span class="built_in">rbp</span></span><br><span class="line">  <span class="number">13</span>:   c3                      <span class="keyword">ret</span>    </span><br><span class="line"><span class="number">0000000000000014</span> &lt;main&gt;:</span><br><span class="line"><span class="keyword">int</span> main()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="number">14</span>:   <span class="number">55</span>                      <span class="keyword">push</span>   <span class="built_in">rbp</span></span><br><span class="line">  <span class="number">15</span>:   <span class="number">48</span> <span class="number">89</span> e5                <span class="keyword">mov</span>    <span class="built_in">rbp</span>,<span class="built_in">rsp</span></span><br><span class="line">  <span class="number">18</span>:   <span class="number">48</span> <span class="number">83</span> ec <span class="number">10</span>             <span class="keyword">sub</span>    <span class="built_in">rsp</span>,<span class="number">0x10</span></span><br><span class="line">    <span class="keyword">int</span> x = <span class="number">5</span><span class="comment">;</span></span><br><span class="line">  1c:   c7 <span class="number">45</span> fc <span class="number">05</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>    <span class="keyword">mov</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x4</span>],<span class="number">0x5</span></span><br><span class="line">    <span class="keyword">int</span> y = <span class="number">10</span><span class="comment">;</span></span><br><span class="line">  <span class="number">23</span>:   c7 <span class="number">45</span> f8 0a <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>    <span class="keyword">mov</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x8</span>],<span class="number">0xa</span></span><br><span class="line">    <span class="keyword">int</span> u = <span class="keyword">add</span>(x, y)<span class="comment">;</span></span><br><span class="line">  2a:   8b <span class="number">55</span> f8                <span class="keyword">mov</span>    <span class="built_in">edx</span>,<span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x8</span>]</span><br><span class="line">  <span class="number">2d</span>:   8b <span class="number">45</span> fc                <span class="keyword">mov</span>    <span class="built_in">eax</span>,<span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0x4</span>]</span><br><span class="line">  <span class="number">30</span>:   <span class="number">89</span> d6                   <span class="keyword">mov</span>    <span class="built_in">esi</span>,<span class="built_in">edx</span></span><br><span class="line">  <span class="number">32</span>:   <span class="number">89</span> c7                   <span class="keyword">mov</span>    <span class="built_in">edi</span>,<span class="built_in">eax</span></span><br><span class="line">  <span class="number">34</span>:   e8 c7 ff ff ff          <span class="keyword">call</span>   <span class="number">0</span> &lt;<span class="keyword">add</span>&gt;</span><br><span class="line">  <span class="number">39</span>:   <span class="number">89</span> <span class="number">45</span> f4                <span class="keyword">mov</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rbp</span>-<span class="number">0xc</span>],<span class="built_in">eax</span></span><br><span class="line">  3c:   b8 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>          <span class="keyword">mov</span>    <span class="built_in">eax</span>,<span class="number">0x0</span></span><br><span class="line">&#125;</span><br><span class="line">  <span class="number">41</span>:   c9                      <span class="keyword">leave</span>  </span><br><span class="line">  <span class="number">42</span>:   c3                      <span class="keyword">ret</span>    </span><br></pre></td></tr></table></figure>

<p>二、如何使用函数内联进行优化<br>-O 指令 或者 加上 inline关键字、来提示编译器进行函数内联</p>
<p>内联带来的优化是、CPU需要执行的指令数变少了、根据地址跳转的过程不需要了、压栈和出栈的过程也不需要了</p>
<p>但是内联意味着、把可复用的程序指令在调用它的地方完全展开了、若一个函数在很多地方都被调用了、就会被展开多次、整个程序占用的空间就会变大</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">readelf -s link_example.o <span class="regexp">//</span>查看符号表</span><br><span class="line">objdump -r link_example.o <span class="regexp">//</span>查看重定位表</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>多发射和VLIW</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%A4%9A%E5%8F%91%E5%B0%84%E5%92%8CVLIW/</url>
    <content><![CDATA[<blockquote>
<p><code>程序的CPU执行时间</code>&#x3D;<code>指令数</code> * <code>CPI</code> * <code>Clock Cycle Time</code>(时钟周期)</p>
</blockquote>
<p><code>CPI</code>: 倒数是<code>IPC</code>,即: 一个时钟周期内能够执行的指令数、代表了CPU的吞吐率</p>
<p>那么: CPU的吞吐率能达到多少呢 ? </p>
<blockquote>
<p>最佳情况下、也只能达到1, 即使达到了指令层面的乱序执行、CPU一个周期、仍然只能取一条指令、说明指令优化做的多好、一个时钟周期也只能完成一条指令、而现在的CPU一般能达到2、为什么呢 ?</p>
</blockquote>
<h4 id="多发射与超标量-同一时间执行的两条命令"><a href="#多发射与超标量-同一时间执行的两条命令" class="headerlink" title="多发射与超标量: 同一时间执行的两条命令"></a>多发射与超标量: 同一时间执行的两条命令</h4><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">在指令乱序执行的过程中、取值<span class="keyword">IF</span> 和 指令译码ID 部分并不是并行的、那么 可不可以呢 ?</span><br><span class="line"><span class="number">1.</span> 将取指令和指令译码、也通过增加硬件的方式、一次从内存里取出多条指令、然后并行的分发给多个并行的指令译码器、进行译码、然后交给不同的FU<span class="comment">(功能单元)</span>去处理、这样一个时钟周期可完成的指令就大于<span class="number">1</span> 、即: IPC大于<span class="number">1</span></span><br><span class="line"></span><br><span class="line">这种CPU设计叫 多发射<span class="comment">(Mulitple issue)</span> 和 超标量<span class="comment">(Superscalar)</span></span><br><span class="line"></span><br><span class="line">在超标量的CPU里边、有很多条并行的流水线、而不是只有一条流水线、</span><br><span class="line">`超标量`这个词是说, 本来我们在一个时钟周期里、只能执行一个标量Scalar运算、在多发射的情况下、可以超过这个限制、同时进行多次运算</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="Intel的失败之作-安腾的超长指令设计"><a href="#Intel的失败之作-安腾的超长指令设计" class="headerlink" title="Intel的失败之作: 安腾的超长指令设计"></a>Intel的失败之作: 安腾的超长指令设计</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">无论是乱序执行、还是超标量技术、在实际的硬件层面、都需要解决依赖冲突(冒险)问题、所以、实施会比较复杂</span><br><span class="line"><span class="meta">CPU</span>需要在指令执行之前、判断指令是否有依赖关系、若有, 则不能分发到不同的执行阶段、</span><br><span class="line">所以: 超标量<span class="meta">CPU</span>发射、又被称为动态多发射处理器</span><br><span class="line">对于 依赖关系的检测、会使得<span class="meta">CPU</span>电路变的更加复杂</span><br><span class="line"></span><br><span class="line">于是: 科学家有一个大胆的想法: 将分析和解决依赖关系的事情、放到软件里</span><br><span class="line"><span class="string">`超长指令设计`</span>: VLIW(Very Long Insturction <span class="built_in">Word</span>)、想通过编译器来优化CPI</span><br><span class="line">编译器在汇编完成之后、也可以知道前后数据的依赖、可以让编译器把没有依赖关系的代码位置进行交换、然后把多条连续的指令打成一个指令包、安腾的<span class="meta">CPU</span>就是把<span class="number">3</span>条指令打成一个指令包, 如下图所示:</span><br><span class="line"><span class="meta">CPU</span>在运行的时候、就不再是取一条指令、而是取一个指令包、然后译码解析整个指令包、解析出<span class="number">3</span>条指令并行运行</span><br><span class="line"><span class="number">2</span>.流水线停顿、也是编译器来做了、除了停下整个处理器流水线、<span class="meta">CPU</span>不能在某个周期停顿一下、等待前边依赖的操作完成、编译器需要在适当的位置插入<span class="keyword">NOP</span>操作、直接在编译出来的机器码里、把流水线停顿设计完成</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-f665e77afa662d94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h5 id="为什么失败呢"><a href="#为什么失败呢" class="headerlink" title="为什么失败呢"></a>为什么失败呢</h5><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. 最重要的原因是<span class="string">&#x27;向前兼容&#x27;</span></span><br><span class="line">   安腾处理器的指令集和X86不同、无法兼容、需要重新编译才可以</span><br><span class="line"><span class="number">2</span>. VLIW架构决定了、若安腾需要提升并行度、就需要增加一个指令包的指令数量、<span class="function"><span class="title">eg</span>. 3个 -&gt;</span> <span class="number">6</span>个、</span><br><span class="line">   而一旦这么做了、同样是VLIW架构、同样指令集的安腾CPU也需要重新编译、甚至需要重写编译器、才能在原来的CPU上继续运行程序</span><br><span class="line">   </span><br><span class="line">   所以、它既不向前兼容、又很难向后兼容、就比较容易失败</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>如何提高性能(第4讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD(%E7%AC%AC4%E8%AE%B2)/</url>
    <content><![CDATA[<p>基本概念:<br><code>响应时间</code>:  执行程序需要花费的时间<br><code>吞吐率</code>: 一定时间内、可以执行的指令</p>
<p>性能一般定义为: <code>1/响应时间</code></p>
<p>计算机的计时单位: <code>cpu时钟</code></p>
<p>虽然时间是衡量性能的标准、但是也有很大的差异</p>
<ol>
<li><code>时间不准</code> 应该参与比较的是刨除了io和cpu切换之外的实际CPU时间(user + sys)</li>
<li>就算拿到cpu时间也不一定可以比较  CPU满载运行时、可能会降频<br>此外、还会受到主板、内存等的硬件影响</li>
</ol>
<p><code>程序的cpu执行时间</code> &#x3D; <code>cpu时钟周期数</code> x <code>时钟周期时间</code><br>cpu 时钟周期时间越小、散热的压力也就越大<br><code>cpu时钟周期数</code> &#x3D; <code>指令数</code> x <code>cpi</code> x <code>Clock Circle Time</code><br><code>cpi</code> : 每条指令的平均时钟周期数 Cycles Per Instruction</p>
<p>时钟周期时间: 取决于硬件<br>CPI: 取决于一条指令需要多少CPU周期、<br>指令数: 代表程序执行需要多少指令、用哪些指令</p>
<p><code>功耗</code> ~&#x3D; <code>1/2</code> x <code>负载电容</code> x <code>电压的平方</code> x <code>开关频率</code> x <code>晶体管数量</code></p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"><span class="title">所以:</span> </span><br><span class="line"><span class="number">1</span>.为了提升性能、需要增加晶体管数量, 同样面积、就要把体积造的小、  就是提升`制程`</span><br><span class="line"><span class="number">2</span>.但是 功耗增加太多、会导致CPU散热跟不上、就需要降低电压、</span><br><span class="line">   而功耗是和电压的平方成正比的、意味着电压下降到原来的 <span class="number">1</span>/<span class="number">5</span> 、功耗就会变成原来的 <span class="number">1</span>/<span class="number">25</span>.</span><br></pre></td></tr></table></figure>

<p>提升计算机性能的方式</p>
<figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">1. 摩尔定律</span><span class="punctuation">:</span> <span class="string">增加晶体管数量(主频)</span></span><br><span class="line"><span class="attribute">2. 并行原理</span><span class="punctuation">:</span> <span class="string">多CPU</span></span><br><span class="line"><span class="attribute">3. 加速大概率事件</span><span class="punctuation">:</span> <span class="string">gpu替代cpu</span></span><br><span class="line"><span class="attribute">4. 通过流水线提升性能</span><span class="punctuation">:</span> <span class="string">把cpu执行指令的过程细分</span></span><br><span class="line"><span class="attribute">5. 通过预测提高性能</span><span class="punctuation">:</span> <span class="string">分支和冒险, 局部性原理</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">应用：</span></span><br><span class="line"><span class="attribute">加速大概率事件</span><span class="punctuation">:</span> <span class="string">缓存(内存、CDN缓存)</span></span><br><span class="line"><span class="attribute">流水线</span><span class="punctuation">:</span> <span class="string">并发编程、异步编程、音频播放器边放边缓冲</span></span><br><span class="line"><span class="attribute">预测</span><span class="punctuation">:</span> <span class="string">下一页预加载、cdn预热、指令预加载</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>存储器层次结构</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<blockquote>
<p>存储器系统是一个通过各种不同的方法和设备、一层层组合起来的系统.</p>
</blockquote>
<h4 id="SRAM"><a href="#SRAM" class="headerlink" title="SRAM"></a>SRAM</h4><figure class="highlight verilog"><table><tr><td class="code"><pre><span class="line">静态存储器, 只要通电、保存的数据就一直存在、断电则丢失, <span class="number">1</span><span class="keyword">bit</span> 数据、大概需要<span class="number">6</span>~<span class="number">8</span>个晶体管, </span><br><span class="line">密度不高、同样物理空间下、存储的数据有限、不过, 由于电路简单、访问速度特别快</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-bffe7a74d40dae20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6个晶体管组成SRAM的一个bit.png"></p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">在<span class="meta">CPU</span>中、通常有L1、L2、L3三层高速缓存</span><br><span class="line">每个<span class="meta">CPU</span>有一块属于自己的L1缓存(<span class="string">`指令缓存`</span>和<span class="string">`数据缓存`</span> )</span><br><span class="line">L2缓存也是每个<span class="meta">CPU</span>有一块、但不在<span class="meta">CPU</span>内部、访问速度比L1稍慢</span><br><span class="line">L3 Cache通常是多个<span class="meta">CPU</span>核心共用的、尺寸更大、访问更慢一些</span><br></pre></td></tr></table></figure>

<h4 id="DRAM"><a href="#DRAM" class="headerlink" title="DRAM"></a>DRAM</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">比<span class="keyword">SRAM来说、DRAM的密度更高、容量更大、价格也便宜、CPU一般使用的是SRAM、内存一般使用的是DRAM</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">DRAM被称为动态存储器、是因为DRAM需要不断刷新、才能保持数据被存储起来</span><br><span class="line">DRAM的一个<span class="keyword">bit、只需要一个晶体管和一个电容就可以、同样物理空间、存储数据更多、即: </span>存储密度更大</span><br><span class="line">但: 数据是存储在电容里的、电容会不断漏电、需要定时刷新充电、才能保持数据不丢失</span><br><span class="line">DRAM的数据访问电路和刷新电路都比<span class="keyword">SRAM更复杂、so. </span>访问延时更长</span><br></pre></td></tr></table></figure>

<h4 id="存储器的层次结构"><a href="#存储器的层次结构" class="headerlink" title="存储器的层次结构"></a>存储器的层次结构</h4><figure class="highlight"><table><tr><td class="code"><pre><span class="line">整个存储器的层次结构、都类似于SRAM和DRAM在性能和价格上的差异、SRAM更贵、速度更快</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-d9ca803938888292.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="存储器的层次关系图.png"></p>
<figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line"> 从<span class="keyword">Cache</span>、内存、到SSD和HDD硬盘、计算机用到了所有存储设备、其中, 容量越小的设备速度越快、且: CPU不是直接合每一种存储设备打交道、而是只与相邻设备打交道.</span><br><span class="line">eg. CPU <span class="keyword">Cache</span>是从内存加载而来、数据需要写回内存、并不会直接写回数据到硬盘、也不会直接从硬盘加载数据到CPU <span class="keyword">Cache</span>、而是先加载到内存、再从内存加载到<span class="keyword">Cache</span>中</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这样、每个存储器只喝相邻的一层存储器打交道、且随着一层层向下、存储器的容量逐渐增大、访问速度逐层变慢、且单位存储成本也在逐层下降、就构成了存储器的层次结构</p>
</blockquote>
<h4 id="如何权衡价格和性能"><a href="#如何权衡价格和性能" class="headerlink" title="如何权衡价格和性能"></a>如何权衡价格和性能</h4><figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">存储器在不同层级之间的性能和价格差异、都至少在一个数量级以上、</span><br><span class="line">eg. L1 <span class="keyword">Cache</span>的访问延时是<span class="number">1</span>ns、内存是<span class="number">100</span>ns、在价格上也差出了<span class="number">400</span>倍</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-04e233a82ad956b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="存储器性能和价格对比图.png"></p>
<blockquote>
<p>一台惠普战66的笔记本配置如下:</p>
</blockquote>
<ol>
<li>Intel i5-8265U 的CPU (4核)</li>
</ol>
<ul>
<li>每个核有有32K、共128KB的L1指令Cache 和 128KB 的数据Cache、采用8路组相连的放置策略</li>
<li>每个核有256KB、共1M的L2 Cache、采用的是4路组相连的放置策略</li>
<li>多个核心共用的12MB 的L3 Cache、采用的是12路组相连的放置策略</li>
</ul>
<ol start="2">
<li>8G的内存</li>
<li>128GB 的SSD硬盘</li>
<li>1T的HDD硬盘<blockquote>
<p>可以看到，在一台实际的计算机里面，越是速度快的设备，容量就越小。这里一共十多兆的 Cache，成本只是几十美元。而 8GB 的内存、128G 的 SSD 以及 1T 的 HDD，大概零售价格加在一起，也就和我们的高速缓存的价格差不多</p>
</blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>局部性原理(36讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%B1%80%E9%83%A8%E6%80%A7%E5%8E%9F%E7%90%86(36%E8%AE%B2)/</url>
    <content><![CDATA[<blockquote>
<p>平时服务端访问db遇到瓶颈的时候、大部分工程师会选择添加缓存、来缓解DB压力、提升程序性能、但一定是有效的吗 ?</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-a6decbd56530e742.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="添加缓存层.png"></p>
<h4 id="理解局部性原理"><a href="#理解局部性原理" class="headerlink" title="理解局部性原理"></a>理解局部性原理</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">时间局部性: 若一个数据被访问了、短时间内再次被访问的概率就增加. </span></span><br><span class="line">eg. 今天读一本小说、还未读完、明天接着读的概率就很大</span><br><span class="line">电商系统中、用户打开一个APP、看到首屏、推断会访问其它页面、将用户的个人信息、从存储在硬盘的数据库读取到内存的缓存中来</span><br><span class="line">利用的就是时间局部性</span><br><span class="line"></span><br><span class="line"><span class="section">空间局部性: eg. 存储数据时、数组内的多项数据会存储在相邻位置、</span></span><br><span class="line">好比图书馆会将同一系列的书放到一个书架上、摆在一起、加载的时候一并加载、</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-99bf7bdef7b5865d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="同一数据在短时间内会反复访问.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-95a6a3adbe0eaed6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="相邻的数据被连续访问.png"></p>
<blockquote>
<p>有了时间和空间局部性、可以不用将数据都放在内场车、也不用都放在HDD上、而是将访问次数多的数据、放在贵但是快一些的存储器、访问次数少、价格便宜的放在慢但容量大的容器里、组合使用各种存储设备</p>
</blockquote>
<h4 id="如何花最少的钱满足存储需求？"><a href="#如何花最少的钱满足存储需求？" class="headerlink" title="如何花最少的钱满足存储需求？"></a>如何花最少的钱满足存储需求？</h4><figure class="highlight tp"><table><tr><td class="code"><pre><span class="line">假设: 需要提供一个亚马逊这样的电商网站、有<span class="number">6</span>亿件商品、每件商品需要<span class="number">4</span>MB 存储空间(共<span class="number">6</span>亿 * <span class="number">4</span>MB = <span class="number">2400</span><span class="keyword">TB</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>.数据都放在内存、需要<span class="number">3600</span>w美元(<span class="number">2400</span><span class="keyword">TB</span>/<span class="number">1</span>MB * <span class="number">0</span><span class="number">.015</span>美元)</span><br><span class="line"><span class="number">2</span>.假设内存只存放<span class="number">1</span>%的热门商品<span class="number">600</span>w件、剩下存储到HDD硬盘上、存储成本就下降到 <span class="number">45</span><span class="number">.6</span>w美元、原来的<span class="number">1</span><span class="number">.3</span>%</span><br><span class="line"><span class="number">3600</span>w美元*<span class="number">1</span>% + <span class="number">2400</span>T/<span class="number">1</span>M * <span class="number">0</span><span class="number">.00004</span>美元 = <span class="number">45</span><span class="number">.6</span>w美元</span><br><span class="line"></span><br><span class="line">利用的就是时间局部性、将用户访问过的数据、加载到内存中、一旦内存放不下、就把长时间未访问的数据从内存移走、</span><br><span class="line">其实就是LRU缓存算法、商品访问越频繁、越容易在内存找到、很好的利用了内存的随机访问性</span><br><span class="line"></span><br><span class="line">另外还要关注一个指标: 缓存命中率 (Hit Rate / Hit Ratio)</span><br><span class="line"></span><br><span class="line">内存的随机访问需要<span class="number">100</span>ns、即: 极限情况下、可以支持<span class="number">1000</span>w次随机访问</span><br><span class="line">假设: 用了<span class="number">24</span>T(<span class="number">8</span>G一条)内存、意味着<span class="number">3000</span>条内存、可以支持每秒<span class="number">300</span>亿次访问</span><br><span class="line"><span class="number">24</span><span class="keyword">TB</span> / <span class="number">8</span>GB * <span class="number">1</span>s/<span class="number">100</span>ns = <span class="number">300</span>亿</span><br><span class="line">以<span class="number">2017</span>年<span class="number">3</span>亿的用户来看、每天的活跃用户<span class="number">1</span>亿、平均访问<span class="number">100</span>个商品、平均每秒访问的商品数量<span class="number">12</span>w次 </span><br><span class="line">假设数据没有命中缓存、对应的数据请求访问HDD磁盘、一块硬盘每秒只能支撑<span class="number">100</span>次随机访问、</span><br><span class="line"><span class="number">2400</span><span class="keyword">TB</span>的数据、<span class="number">4</span><span class="keyword">TB</span>一块磁盘的话、有<span class="number">600</span>块、每秒支撑 <span class="number">6</span>w次请求</span><br><span class="line"><span class="number">2400</span><span class="keyword">TB</span>/<span class="number">4</span><span class="keyword">TB</span> * <span class="number">1</span>s/<span class="number">10</span>ms </span><br><span class="line">这意味着: 所有的商品都直接到了HDD硬盘、HDD支撑不了这样的压力</span><br><span class="line">至少需要<span class="number">50</span>%的缓存命中率、HDD磁盘才可以支撑对应的访问次数</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>常用术语</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%B8%B8%E7%94%A8%E6%9C%AF%E8%AF%AD/</url>
    <content><![CDATA[<p><code>IPL</code> 指令级并行 <code>Instruction-level parallelism</code><br><code>SMT</code> 同时多线程 Simultaneous Multi-Threading<br><code>SIMD</code>  单指令多数据流 Single Instruction Multiple Data<br><code>MIMD</code> 多指令多数据流 Multiple Instruction Multiple Data<br><code>SIMT</code> 单指令多线程 Single Instruction, Multiple Threads<br><code>ASIC</code> 专用集成电路 Application-Specified Integrated Circuit<br><code>FPGA</code> 现场可编程门阵列 Filed-Programmable Gate Array</p>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>建立数据通路(17-19讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%BB%BA%E7%AB%8B%E6%95%B0%E6%8D%AE%E9%80%9A%E8%B7%AF(17-19%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="指令周期"><a href="#指令周期" class="headerlink" title="指令周期"></a>指令周期</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">计算机每执行一条指令的过程、可以分解为:</span><br><span class="line"><span class="bullet">1.</span> Fetch(取得指令), 也就是从PC寄存器找到对应的指令地址、根据指令地址从内存找到具体指令、加载到指令寄存器、然后将PC寄存器自增、好在未来执行下一条指令</span><br><span class="line"><span class="bullet">2.</span> Decode(指令译码): 根据指令寄存器里的指令、解析成将要进行什么样的操作、是R、I、J中的哪一种指令、具体要操作哪些寄存器、数据或者内存地址</span><br><span class="line"><span class="bullet">3.</span> Execute(执行指令), 也就是实际运行对应的R、I、J这些特定的指令、进行算术逻辑操作、数据传输或者直接的地址跳转</span><br><span class="line"><span class="bullet">4.</span> 重复1~3的步骤</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>Machine Cycle</code>: 又称为<code>机器周期</code>或者<code>CPU周期</code>, CPU的内部操作速度很快、但是访问内存的速度却慢很多、每一条指令都从内存中加载而来、所以一般把从内存中读取一条指令的最短时间称为<code>CPU周期</code></p>
<p><code>Clock Cycle</code>: 也就是时钟周期及机器的主频、一个CPU周期通常是几个时钟周期的积累、一个CPU周期的时间、就是这几个时钟周期的总和</p>
<blockquote>
<p> 对于一个指令周期来说、取出一条指令、然后执行、至少需要两个CPU周期、取出指令至少需要一个CPU周期、执行也至少需要一个CPU周期、复杂的指令需要更多的CPU周期</p>
<p>so. 一个指令周期包含多个CPU周期、而一个CPU周期又包含多个时钟周期</p>
</blockquote>
<h4 id="建立数据通路"><a href="#建立数据通路" class="headerlink" title="建立数据通路"></a>建立数据通路</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">一般来说、数据通路就是处理器单元、通常有两类元件组成</span><br><span class="line"></span><br><span class="line"><span class="bullet">1.</span> 操作元件: 也叫组合逻辑单元、就是ALU、功能就是在特定的输入下、根据下面的组合电路的逻辑、生成特定的输出</span><br><span class="line"><span class="bullet">2.</span> 存储元件: 也叫状态原件, eg. 计算过程中需要用到的寄存器、无论是通用寄存器还是状态寄存器、其实都是存储原件</span><br><span class="line"></span><br><span class="line">通过数据总线的方式、将操作元件和存储元件连接起来、就可以完成数据的存储、处理和传输了、这就是所谓的建立数据通路</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<blockquote>
<p>控制器: 可以看成只是机械的重复 Fetch -&gt; Decode -&gt; Execute 循环中的前两个步骤、然后将最后一个步骤通过控制器产生的信号、交给ALU去处理</p>
</blockquote>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">控制器电路听起来很简单、其实特别复杂,</span><br><span class="line"><span class="number">1</span>. 所有<span class="meta">CPU</span>支持的指令、都会在控制器里边被解析成不同的输出信号、eg. Intel <span class="meta">CPU</span>支持<span class="number">2000</span>个以上的指令、意味着: 控制器输出的控制信号、至少有<span class="number">2000</span>种不同的组合</span><br><span class="line">控制器里的ALU和各种组合逻辑电路、可以认为是一个固定功能的电路、控制器翻译出来的、就是不同的控制信号、这些控制信号、告诉ALU去做不同的计算</span><br></pre></td></tr></table></figure>



<h4 id="CPU所需要的硬件电路"><a href="#CPU所需要的硬件电路" class="headerlink" title="CPU所需要的硬件电路"></a>CPU所需要的硬件电路</h4><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">要想搭建CPU、需要再数字电路层面、实现一些功能.</span><br><span class="line">一、ALU: 实际就是一个没有状态的、根据输入计算输出结果的一个电路</span><br><span class="line">二、需要一个寄存器<span class="comment">(可进行状态读写的电路元件)</span></span><br><span class="line">   需要一个电路<span class="comment">(可存储上次计算的结果)</span>、这个计算结果不一定立刻能拿到电路的下游使用、但可在需要的时候拿出来使用、常见能够进行状态读写的电路有: 锁存器<span class="comment">(Latch)</span> 和 D触发器<span class="comment">(Data / Delay Flip-flop)</span></span><br><span class="line">三、需要有一个`自动`的电路: 可按照固定的周期、不停地实现呢PC寄存器自增、自动的执行 Fetch-Decode-Execute的步骤</span><br><span class="line">四、需要一个译码电路: 无论是decode还是对于拿到的内存地址去获对应的数据或者指令、都需要通过一个电路找到对应的数据、这个就是译码器电路</span><br><span class="line"></span><br><span class="line">虽然CPU已经是有几十亿个晶体管组成的及其复杂的电路、但 仍然是由一个个的基本功能的电路组成的</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="时序逻辑电路"><a href="#时序逻辑电路" class="headerlink" title="时序逻辑电路"></a>时序逻辑电路</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">解决了以下问题:</span><br><span class="line"><span class="bullet">1.</span> 自动运行, 时序电路接通后可以不停的开启和关闭开关、进入下一个自动运行的状态、使得控制器不停的让PC寄存器自增读取下一条指令成为可能</span><br><span class="line"><span class="bullet">2.</span> 存储问题, 通过时序电路实现的触发器、可以把计算结果存储在特定的电路里、而不是像组合逻辑电路、一旦输入变化、对应的输出也会变化</span><br><span class="line"><span class="bullet">3.</span> 时序协调问题, 无论是程序实现的软件指令还是硬件层面、各种指令的操作都有先后的顺序要求、时序电路使得不同的事件按照时间顺序发生</span><br></pre></td></tr></table></figure>



<h4 id="时钟信号的硬件实现"><a href="#时钟信号的硬件实现" class="headerlink" title="时钟信号的硬件实现"></a>时钟信号的硬件实现</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">时钟: CPU的祝您是又一个晶体振荡器实现的、而这个晶体振荡器生成的电路信号、就是时钟信号</span></span><br><span class="line"><span class="section">反馈电路: 将电路的输出信号作为输入信号的电路构造方式、叫做反馈电路</span></span><br></pre></td></tr></table></figure>



<h4 id="通过D触发器实现存储功能"><a href="#通过D触发器实现存储功能" class="headerlink" title="通过D触发器实现存储功能"></a>通过D触发器实现存储功能</h4><figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line">将<span class="variable">R</span>和<span class="variable">S</span>两个信号通过一个反相器合并、可以通过一个数据信号<span class="built_in">D</span>进行<span class="variable">Q</span>的写入操作</span><br><span class="line"></span><br><span class="line">只要<span class="variable">CLK</span>信号是<span class="number">1</span>、<span class="variable">R</span>和<span class="variable">S</span>就可以设置输出<span class="variable">Q</span>、而当<span class="variable">CLK</span>信号是<span class="number">0</span>的时候、无论<span class="variable">R</span>和<span class="variable">S</span>怎么设置、输出信号<span class="variable">Q</span>是不变的、这样、整个电路就成了我们最常用的<span class="built_in">D</span>型触发器、用来控制<span class="variable">R</span>和<span class="variable">S</span>这两个开关的信号、可以视为一个输入的数据信号<span class="built_in">D</span>、也就是<span class="variable">Data</span>、这就是<span class="built_in">D</span>型触发器的由来</span><br><span class="line"></span><br><span class="line">一个<span class="built_in">D</span>型触发器、只能控制<span class="number">1</span><span class="variable">bit</span>的读写、若同时拿出多个<span class="built_in">D</span>型触发器并列在一起、并且把用同一个<span class="variable">CLK</span>信号控制作为所有<span class="built_in">D</span>型触发器的开关、就变成了一个<span class="built_in">N</span>位的<span class="built_in">D</span>型触发器、可以同时控制<span class="built_in">N</span>位的读写</span><br><span class="line"></span><br><span class="line"><span class="variable">CPU</span>中的寄存器可以直接通过<span class="built_in">D</span>型触发器来构造、可以在<span class="built_in">D</span>触发器的基础上、加上更多的开关、来实现清<span class="number">0</span>或者全置位这样的操作</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="PC寄存器所需要的计数器"><a href="#PC寄存器所需要的计数器" class="headerlink" title="PC寄存器所需要的计数器"></a>PC寄存器所需要的计数器</h4><figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="variable">PC</span>寄存器还有个名字叫程序计数器、为什么呢 <span class="operator">?</span></span><br><span class="line">有了时钟信号、可以提供定时的输入、有了<span class="built_in">D</span>型触发器、可以在时钟信号控制的时间点写入数据、将这两个功能组合起来、就可以实现一个自动的计数器了</span><br><span class="line"></span><br><span class="line">加法器的两个输入、一个始终设置为<span class="number">1</span>、另外一个个来自于一个<span class="built_in">D</span>型触发器<span class="variable">A</span>、将加法器的输出结果、写到这个<span class="built_in">D</span>触发器的<span class="variable">A</span>里边、于是 <span class="built_in">D</span>型触发器里边的数据就会在固定的时钟信号为<span class="number">1</span>的时候更新一次</span><br><span class="line"></span><br><span class="line">加法计数、内存取值、乃至后边的命令执行、最终其实都是由时钟信号来控制执行时间点和先后顺序的、这也是需要时序电路最核心的原因</span><br><span class="line"></span><br><span class="line">在最简单的情况下、需要让每一条指令、从程序计数器、到获取指令、执行指令、都在一个时钟周期内完成、若<span class="variable">PC</span>计数器增长太快、程序就会出错<span class="operator">,</span> 因为此时前一次运算的结果还没写回对应的寄存器</span><br><span class="line">在这种情况下、需要在一个时钟周期里、确保执行完成一条最复杂的<span class="variable">CPU</span>指令、即<span class="operator">:</span> 耗时最长的一条<span class="variable">CPU</span>指令、这样的<span class="variable">CPU</span>设计、称为 单指令周期处理器</span><br></pre></td></tr></table></figure>



<h4 id="读写数据所需要的译码器"><a href="#读写数据所需要的译码器" class="headerlink" title="读写数据所需要的译码器"></a>读写数据所需要的译码器</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">现在数据可以存储在D触发器里了、若将多个D触发器放在一起、就可以形成很大的一块存储空间、甚至可以当成一块内存来使用、</span><br><span class="line">eg. 现在的电脑内存可能有8G、16G、那么怎么才能知道写入和读取的数据是这块大的内存里、哪几个bit呢 ?</span><br><span class="line"><span class="section">于是: 我们需要一个电路来完成寻址的工作、就是 译码器</span></span><br><span class="line">将寻址退化到最简单的模型、就是两个地址中选择一个、称为 2-1选择器、</span><br><span class="line">若输入的信号有三个不同的开关、就可以从 2³=8中选择一个地址了、即3-8译码器</span><br><span class="line">现代计算机是64位的、寻址空间是2的64次方、需要一个有64个开关的译码器</span><br><span class="line"></span><br><span class="line"><span class="section">所以: 译码器的本质、就是从输出的多个位的信号中、根据一定的开关和电路组合、选择自己想要的信号、除了可以寻址、还可以将对应的需要运行的指令码同样通过译码器、找出我们期望执行的指令、也就是opcode及后边对应的操作数或者寄存器地址</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<blockquote>
<p>因为从内存取指令的时间很长、若使用单指令周期处理器、意味着我们的指令都要去等待一些慢速操作、这些不同指令执行速度的差异、也正是计算机指令有指令周期、CPU周期和时钟周期之分的原因、因此, 优化现代CPU性能时、用的CPU都不是单指令周期处理器、而是通过流水线、分支预测等技术、来实现在一个周期里同时执行多个指令</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>异常处理(28讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86(28%E8%AE%B2)/</url>
    <content><![CDATA[<p>之前都是程序正常运行的、不需要网络交互、无IO交互、执行过程无错误、</p>
<p>但: 实际的软件、程序不仅执行简单指令、还会和IO打交道、执行过程中也会遇到各种异常情况</p>
<p>此时计算机如何工作呢?</p>
<h4 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h4><blockquote>
<p>关于异常、其实是一个硬件和软件结合到一起的处理过程、异常的发生和捕获、是在硬件层面完成的; 异常的处理、是软件完成的</p>
</blockquote>
<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">计算机会为每一种可能发生的异常、分配异常代码<span class="comment">(Exception Number)</span>, 或者叫中断向量<span class="comment">(Interrupt Vector)</span>, 异常发生的时候、通常是CPU检测到了一个特殊的信号、eg. 按下键盘上个的按键、输入设备就会给CPU发送信号、或者 正在执行的指令发生了加法溢出、会有一个进位溢出的信号、</span><br><span class="line">这些信号在组成原理里, 一般叫 发生了一个事件<span class="comment">(event)</span></span><br><span class="line">CPU在检测到事件的时候、就拿到了对应的异常代码</span><br><span class="line"></span><br><span class="line">这些异常代码里、</span><br><span class="line"><span class="number">1.</span>IO发出的信号的异常代码是操作系统分配的、即: 软件来设定的、</span><br><span class="line"><span class="number">2.</span>像加法溢出这样的异常代码、则是CPU预先分配好的、也就是硬件来分配的</span><br><span class="line"></span><br><span class="line">拿到异常代码之后、CPU会触发异常处理的流程, 在计算机的内存里、会保留一个异常表 <span class="comment">(Exception Table)</span>, 又叫中断向量表、存放了不同异常代码对应的异常处理程序<span class="comment">(Exception Handler)</span>的地址</span><br><span class="line"></span><br><span class="line">CPU拿到异常码 -&gt; 保存当前程序执行现场<span class="comment">(到程序桟)</span> -&gt; 根据异常码找到对应处理程序 -&gt; 把后续指令执行的指挥权、交给异常处理程序来处理</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="异常的分类-中断、陷阱、故障和终止"><a href="#异常的分类-中断、陷阱、故障和终止" class="headerlink" title="异常的分类: 中断、陷阱、故障和终止"></a>异常的分类: 中断、陷阱、故障和终止</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">中断(Interrupt): 在程序执行的过程中被打断、这个打断执行的信号、来自于CPU外部的IO设备、eg. 按下键盘按键</span></span><br><span class="line"></span><br><span class="line"><span class="section">陷阱(Trap): 主动触发的异常, </span></span><br><span class="line">            eg. 1. 程序调试时、设定断点 </span><br><span class="line">            2.应用程序产生系统调用的时候、从用户态切换到内核态、</span><br><span class="line">            3. 应用程序通过系统调用去读取文件、创建进程、其实也是通过触发陷阱完成的</span><br><span class="line">            </span><br><span class="line"><span class="section">故障(Fault): 和陷阱的区别在于: 陷阱是开发者主动触发的、故障是意料之外的、会导致系统异常</span></span><br><span class="line"><span class="section">和前两者的区别在于: 故障在异常处理完成后、仍然回来处理当前指令、而不是执行下一条指令、因为当前指令由于故障没有执行完成</span></span><br><span class="line"></span><br><span class="line"><span class="section">中止(Abort): 与其说是一种异常、不如说是故障的特殊情况、当CPU遇到故障、但无法恢复时、就不得不终止</span></span><br></pre></td></tr></table></figure>



<h4 id="异常的处理-上下文切换"><a href="#异常的处理-上下文切换" class="headerlink" title="异常的处理: 上下文切换"></a>异常的处理: 上下文切换</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">在实际异常处理程序之前、CPU需要一次保存现场的操作、过程与函数调用类似</span><br><span class="line">实际更复杂一些:</span><br><span class="line"></span><br><span class="line"><span class="bullet">1.</span> 异常情况往往发生在正常执行的预期之外、eg. 中断、故障发生时、除了本来程序压桟要做的事情、还要把CPU内当前运行程序用到的所有寄存器、放到桟中、最典型的是 条件码寄存器</span><br><span class="line"><span class="bullet">2.</span> 像陷阱这种异常、涉及程序指令在用户态和内核态之间的切换、对应压桟的时候、对应数据要压到内核栈、而不是程序桟</span><br><span class="line"><span class="bullet">3.</span> 像故障这样的异常、在异常处理程序执行完成之后、从桟里返回、继续执行的是引起故障的当前指令、而不是顺序的下一条指令</span><br><span class="line"></span><br><span class="line">对于异常这样的处理流程、不像是顺序执行的指令间的函数调用关系、更像是两个不同的独立进程在CPU层面的切换、这个过程称为 上下文切换(Context Switch)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>异常处理</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<blockquote>
<p>异常的发生和捕获是在硬件层面完成的、异常的处理是软件完成的</p>
</blockquote>
<h4 id="异常分类"><a href="#异常分类" class="headerlink" title="异常分类"></a>异常分类</h4><p><code>中断Interrupt</code> 触发CPU内部开关值发生变化的信号<br><code>陷阱 Trap</code> 主动触发的异常、比如调试断点<br><code>故障 Fault</code> 非主动的错误、处理完异常之后回来处理当前指令、而不是去执行程序中的下一条指令<br><code>终止 Abort</code> 故障的一直特殊情况、当CPU遇到故障、但无法恢复时、程序就必须终止了<br><img src="https://upload-images.jianshu.io/upload_images/14027542-9e29e130eb12f784.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="异常.png"></p>
<h4 id="异常处理、上下文切换"><a href="#异常处理、上下文切换" class="headerlink" title="异常处理、上下文切换"></a>异常处理、上下文切换</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">类似异常处理函数调用、指令的控制权被切换到另外一个<span class="code">`函数`</span>里、但比函数调用更复杂一些</span><br><span class="line"><span class="bullet">1.</span> 因为异常情况往往发生在正常执行的预期之外、eg. 中断、故障发生的时候、所以、除了本来程序压桟要做的事情之外、还需要把CPU内当前运行程序用到的所有寄存器都放在桟里边. eg. 条件码寄存器的内容</span><br><span class="line"></span><br><span class="line"><span class="bullet">2.</span> 类似陷阱这种异常、涉及程序指令在用户态和内核态之间的切换、对应压桟的时候、对应数据是压到内核栈、而不是程序桟</span><br><span class="line"></span><br><span class="line"><span class="bullet">3.</span> 类似故障这样的异常、在异常处理执行完成之后、从桟里返回出来、继续执行的不是顺序的下一条指令、而是故障发生的当前指令、因为当前指令因为故障没有正常执行成功、必须重新执行一次</span><br><span class="line"></span><br><span class="line">对于异常这样的处理流程、不像是顺序执行的指令间的函数调用关系、更像是两个不同的独立进程之间在CPU层面的切换、称为 <span class="code">`上下文切换`</span> </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>总线--计算机内部的高速公路(42讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E6%80%BB%E7%BA%BF--%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%86%85%E9%83%A8%E7%9A%84%E9%AB%98%E9%80%9F%E5%85%AC%E8%B7%AF(42%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="降低复杂性-总线的设计思路来源"><a href="#降低复杂性-总线的设计思路来源" class="headerlink" title="降低复杂性: 总线的设计思路来源"></a>降低复杂性: 总线的设计思路来源</h4><figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">计算机有很多不同的硬件设备、除了CPU和内存之外、还有大量的输入/出设备.</span><br><span class="line">键盘、鼠标、显示器、硬盘或者通过USB接口连接的各种外部设备、都对应了一个设备</span><br><span class="line">若各个设备间的通信、都是独立的. 假设有<span class="built_in">N</span>个不同的设备、之间独立连接、复杂度为<span class="built_in">N</span>², </span><br><span class="line">为了简化系统复杂度、引入总线、将<span class="built_in">N</span>²的复杂度变成<span class="built_in">N</span>的复杂度</span><br><span class="line"></span><br><span class="line">如何降低呢 ？</span><br><span class="line"></span><br><span class="line">设计一个公用的线路、CPU和设备的通信指令、对应数据或者设备和CPU的通信指令和数据都</span><br><span class="line">发送到该线路上、设备间无需单独建立连接、只建立与总线的连接就好</span><br><span class="line"> 这个设计思路就是`总线`</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-5f05820ee8d9e708.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line">总线其实就是一组线路、各个设备通过这组线路相互通信.</span><br><span class="line">对应的设计思路就是<span class="string">`事件总线`</span>设计模式</span><br><span class="line">在这个设计模式里、系统中的各个组件间也需要相互通信、各个模块触发对应的事件、并把事件对象发送到总线上.</span><br><span class="line">即: 每个模块都是发布者<span class="symbol">Publisher</span>, 同时把自己注册到总线上、监听总线上的事件、并根据事件的对象类型</span><br><span class="line">或是对象内容来决定自己是否进行特定的处理或者响应</span><br><span class="line">这样各个模块就是松耦合的、模块间无依赖关系、无论是代码的维护还是未来的扩展、都很方便</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-ac56318353560e27.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="理解总线-三种线路和多总线架构"><a href="#理解总线-三种线路和多总线架构" class="headerlink" title="理解总线: 三种线路和多总线架构"></a>理解总线: 三种线路和多总线架构</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">现代Intel CPU的体系结构里、通常有好几条总线</span><br><span class="line"><span class="title">首先, CPU和内存及高速缓存通信的总线、通常有两种, 称为`双独立总线`(DIB:</span> Dual Independent Bus)</span><br><span class="line">CPU里、有一个快速的`本地总线`(Local Bus)及一个相对较慢的`前端总线`(front-side Bus)</span><br><span class="line">本地总线和高速缓存通信、前端总线用来和主内存及IO设备通信</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-4a8892f00a079bc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">在物理层面、可以将总线看做一组电线、不过这些电线之间也是有分工的、通常有3类:</span><br><span class="line"><span class="bullet">1.</span> 数据线(Data Bus): 用来传输实际的数据信息</span><br><span class="line"><span class="bullet">2.</span> 地址线(Address Bus): 用来确定将数据传输到哪里、是内存的额某个位置还是某个Io设备、</span><br><span class="line"><span class="bullet">3.</span> 控制线(Control Bus): 用来控制对总线的访问. 若将总线比喻为公交车、有人要坐车时需要通知司机、这个就是控制信号</span><br><span class="line"></span><br><span class="line">总线减少了设备耦合、降低了系统设计的复杂度、但不能同时给多个设备提供通信功能</span><br><span class="line">那多个设备都想使用总线、给谁用呢? 就需要一个机制来决定、这个机制叫<span class="code">`总线裁决`</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>理解IO_WAIT--IO性能到底怎么回事儿</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E7%90%86%E8%A7%A3IO_WAIT--IO%E6%80%A7%E8%83%BD%E5%88%B0%E5%BA%95%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B%E5%84%BF/</url>
    <content><![CDATA[<blockquote>
<p>应用系统的大部分瓶颈在IO上、不是所有的问题都可以利用内存或者CPU Cache做缓存解决、Mysql单表几千万的数据、早已不是罕见现象了、意味着, 使用内存当缓存、存储空间是不够用的. 大部分请求还是会打到硬盘上.</p>
</blockquote>
<h4 id="IO性能、顺序和随机访问"><a href="#IO性能、顺序和随机访问" class="headerlink" title="IO性能、顺序和随机访问"></a>IO性能、顺序和随机访问</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">从硬盘厂商的性能报告上、通常可以看到两个指标: 响应时间(Response Time)和数据传输率(Data Transfer Rate)</span><br><span class="line"></span><br><span class="line">现在常用的硬盘有两种: HDD硬盘(机械硬盘) 和 SSD硬盘(固态硬盘). 现在的HDD硬盘使用的是 SATA 3.0 的接口.</span><br><span class="line">SSD硬盘有两种接口: SATA 3.0 和 PCI Express 接口</span><br><span class="line"></span><br><span class="line">SATA 3.0 接口、带宽是6Gb/s, b是bit、相当于每秒传输 768M 数据; 日常使用的HDD硬盘的数据传输率差不多200MB/s</span><br><span class="line">SSD的硬盘、数据传输率差不多500MB/s, 实际SSD的硬盘可以更快. 可以换用PCI Experss的三星SSD硬盘、</span><br><span class="line">它的数据传输率、在读取的时候可以达到2GB/s 左右、差不多是HDD硬盘的10倍、写入时也有1.2GB/s.</span><br><span class="line"></span><br><span class="line">除了数据传输率、我们还关心响应时间. SSD硬盘大概在几十微秒、HDD大概在几ms到十几ms、差异在几十倍甚至上百倍.</span><br><span class="line"></span><br><span class="line">单看响应时间和吞吐率、硬盘性能还可以、基本上在ms时间内可以返回, 1s内可传输的数据也有200MB左右、</span><br><span class="line">db一条记录、一般也就1kb大小、差不多每秒可写入 200M*1024 / 1 约20w条数据、似乎和平时经验不符 ？</span><br><span class="line"></span><br><span class="line">因为硬盘顺序读写和随机读写的性能差异很大.</span><br><span class="line">SSD随机读写的时候、数据传输率只有40MB/s、只有顺序读写情况的几十分之一、按照每次读取4KB计算、</span><br><span class="line">40MB/s / 4kb = 10000次、即: 每秒随机读取1万次、写入会多一些、1s大概90MB、即: 2w多次</span><br><span class="line">这个每秒读写的次数、称为IOPS、即: 每秒输入输出操作的次数</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>HDD的IOPS通常只有100左右、而不是20w次、这个100怎么得到的呢 ？如何优化 ？</p>
</blockquote>
<figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">一块机械硬盘由盘面、磁头和悬臂三个部件组成.</span></span><br><span class="line"><span class="attribute">盘面</span><span class="punctuation">:</span> <span class="string">就是实际存储数据的盘片、通常是使用铝、玻璃或者陶瓷制成的光滑盘片, 盘面有一层磁性涂层</span></span><br><span class="line"><span class="attribute">数据就存储在磁性的涂层上、中间有一个受电机控制的转轴, 用来控制盘面旋转.</span></span><br><span class="line"><span class="attribute"></span></span><br><span class="line"><span class="attribute">硬盘一个很重要的指标是转速, 通常有5400转、7200转、10000转的、这个转速指的就是转轴的旋转速度、</span></span><br><span class="line"><span class="attribute">英文单位 RPM, 即</span><span class="punctuation">:</span> <span class="string">每分钟的旋转圈数、7200转为例, 折算到s、就是120圈</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">磁头</span><span class="punctuation">:</span> <span class="string">数据是通过磁头从盘面读取、然后通过电力信号传输给控制电路、接口、再到总线的</span></span><br><span class="line"><span class="attribute">通常一个盘面在正反两面有连你刚刚磁头、且</span><span class="punctuation">:</span> <span class="string">一块硬盘也不是只有一个盘面、而是上下堆叠了很多个盘面、</span></span><br><span class="line"><span class="attribute">各个盘面是平行的、每个盘的正反两面都有磁头.</span></span><br><span class="line"><span class="attribute"></span></span><br><span class="line"><span class="attribute">悬臂</span><span class="punctuation">:</span> <span class="string">连接在磁头上、在一定范围内把磁头定位到某个特定的磁道上.</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">盘面通常是圆形的、多个同心圆组成、每个磁道有自己的编号, 悬臂用来控制读哪个磁道的数据</span></span><br><span class="line"><span class="attribute">磁道会分成一个个扇区、上下平响的一个个盘面的相同扇区叫一个柱面、</span></span><br><span class="line"><span class="attribute"></span></span><br><span class="line"><span class="attribute">读取数据分两步</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">1. 将盘面旋转到某一个位置、在这个位置上、悬臂可以定位到整个盘面的任意子区间、这个区间称为`几何扇区`</span></span><br><span class="line"><span class="attribute">2. 将悬臂移动到特定磁道的特定扇区、找到之后磁头落下、读取数据</span></span><br><span class="line"><span class="attribute">所以, 需要的时间也由两个部分构成</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">1. 平均延时, 就是将几何扇区对准悬臂的时间</span></span><br><span class="line"><span class="attribute">7200转为例, 1s可以旋转240个半圈、即</span><span class="punctuation">:</span> <span class="string">1s/240 = 4/71ms</span></span><br><span class="line">2. 平均询道时间, 即 悬臂定位到扇区的时间</span><br><span class="line">HDD硬盘一般在4-10ms、</span><br><span class="line">这样随机数据访问延时一般在8-14ms, 那么</span><br><span class="line">1s/8ms = 125 IOPS 或者 1s/14ms = 70 IOPS</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-f70d1bb6ea65e300.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="硬盘物理结构.png"></p>
<h4 id="如何定位-IO-WAIT"><a href="#如何定位-IO-WAIT" class="headerlink" title="如何定位 IO_WAIT"></a>如何定位 IO_WAIT</h4><figure class="highlight xquery"><table><tr><td class="code"><pre><span class="line">由上边可以看到、即使是PCI Express接口的SSD硬盘、IOPS也只有<span class="number">2</span>w左右, CPU 的主频通常在<span class="number">2</span>GHZ以上、</span><br><span class="line">也就是每秒可以做<span class="number">20</span>亿次操作. 即使一条指令需要多个时钟周期、一秒内CPU可执行的指令数和硬盘能进行的操作次数</span><br><span class="line">也有好几个数量级的差异, 所以常听到性能瓶颈在IO上的说法、因为CPU发出指令之后、需要等待IO操作完成.</span><br><span class="line"></span><br><span class="line">如何判断程序性能问题是否真的来源于IO瓶颈呢 ？</span><br><span class="line"><span class="number">1</span>. top指令</span><br><span class="line">top指令的输出结果中、有一行 <span class="meta">%CPU</span> 开头、有一个 wa 的指标、就代表iowait, 即: CPU等待io操作完成花费的时间占CPU的百分比</span><br><span class="line"></span><br><span class="line">iostat可以看到实际的情况</span><br><span class="line"><span class="built_in"></span></span><br><span class="line"><span class="built_in">avg</span>-cpu:  <span class="meta">%user</span>   <span class="meta">%nice</span> <span class="meta">%system</span> <span class="meta">%iowait</span>  <span class="meta">%steal</span>   <span class="meta">%idle</span></span><br><span class="line">          <span class="number">17.02</span>    <span class="number">0</span>.<span class="number">01</span>    <span class="number">2.18</span>    <span class="number">0</span>.<span class="number">04</span>    <span class="number">0</span>.<span class="number">00</span>   <span class="number">80.76</span></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">sda               <span class="number">1.81</span>         <span class="number">2.02</span>        <span class="number">30.87</span>     <span class="number">706768</span>   <span class="number">10777408</span></span><br><span class="line"></span><br><span class="line">tps: 对应的就是硬盘的 IOPS 指标</span><br><span class="line">KB_read/s 和 kb_write/s 对应的就是 数据传输指标</span><br><span class="line">iotop 可以看到具体哪一个进程占用了大量的io</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>程序装载(第9、10、11讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E7%A8%8B%E5%BA%8F%E8%A3%85%E8%BD%BD(%E7%AC%AC9%E3%80%8110%E3%80%8111%E8%AE%B2)/</url>
    <content><![CDATA[<p>一、程序装载的挑战<br>在运行可执行文件的时候、装载器会把对应的指令和数据加载到内存中、让CPU执行、装载器需要满足两个条件:</p>
<ol>
<li>可执行程序加载后占用的空间是连续的、</li>
<li>需要同时加载多个程序、并且不能让程序自己规定在内存中加载的位置<br>因为想要的地址可能已经被其它程序给占了</li>
</ol>
<p>解决:</p>
<blockquote>
<p>在内存里找到连续内存空间分配给装载的程序、然后把这段连续的内存地址和整个程序指令里的指定内存地址做映射</p>
</blockquote>
<p><code>虚拟内存地址</code> <code>Virtual Memory Address</code>指令里用到的地址<br><code>物理内存地址</code> <code>Physical Memory Address</code>在内存硬件里的地址</p>
<p>程序中有指令和各种内存地址、我们只需要关心虚拟内存地址就行了、对于任何一个程序来说、它看到的都是同样的内存地址、我们维护一个虚拟内存到物理内存的映射表、这样实际程序指令执行时、会通过虚拟内存地址、找到对应的物理内存地址、然后执行.<br>因为地址是连续的、只需要维护映射关系的起始地址和对应的空间大小就可以了</p>
<p>二、内存分段<br><code>分段</code> 找出一段连续的物理内存和虚拟内存地址进行映射的方法<br><img src="https://upload-images.jianshu.io/upload_images/14027542-0603efd72056da7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>分段解决了程序本身不需要关心具体内存地址的问题、也有一些不足之处、<code>内存碎片</code></p>
<p><code>内存交换</code> <code>Memory Swapping</code> 将程序写回硬盘、再从硬盘读回、读回时放到连续空间位置上、这样剩余空间就是连续的了、解决了<code>内存碎片</code> 的问题<br>但: 若内存交换的时候交互的是一个内存占用很大的程序、机器会十分卡顿</p>
<p>三、内存分页</p>
<blockquote>
<p>既然问题出在内存碎片和交换空间太大上、那么解决办法就是: 少程序内存碎片、另外 当进行内存交换的时候、让需要交换的数据更少、那么问题就可以解决<br>这个办法在计算机的内存管理里边叫<code>内存分页</code></p>
</blockquote>
<p><code>内存分页</code> 是把整个物理内存空间切成一段固定尺寸的大小、这样一个连续并且尺寸固定的内存空间叫页(Page)</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">getconf</span> PAGE_SIZE <span class="comment"># 查看页大小、默认4k</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>由于内存是预先划分好的、就没有了不能使用的碎片、只有被释放出来的很多4kb的页、即使内存空间不够、需要让现有的正在运行的程序通过内存交互、释放出来一些内存空间、一次写入磁盘的也只有少数一个或者几个页、不会花很多时间、不会卡顿</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-5ace5504fb471b31.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<blockquote>
<p>进一步、程序加载的时候不是一次性全部加载、二手在运行时、需要用到对应虚拟内存页里的指令和数据时才加载、读取特定页时、发现数据未加载到物理内存时会触发一个来自CPU的缺页错误(Page Fault) 系统捕获这个错误、将对应页从虚拟内存读取加载到物理内存</p>
</blockquote>
<p>四、链接: 动态链接和静态链接<br><code>动态链接</code> <code>Dynamic Link</code> 链接的不是存储在硬盘上的目标文件代码、二手加载到内存的<code>共享库</code>(<code>shared Libiaries</code>)<br><code>静态链接</code> 之前说到的合并代码段的方式</p>
<p>在win下、共享库文件是<code>.dll</code> 文件、也就是 <code>Dynamic-Link Library</code>(DLL, 动态链接库).<br>在Linux下、就是<code>.so</code> 文件、(<code>Shared Object</code>)</p>
<p>五、电信号&amp;门电路</p>
<blockquote>
<p>远古传信: 人工、速度慢<br>   -&gt; 金、鼓: 距离有限<br>   -&gt; 烽火台: 光信号、不能传递复杂信息<br>   -&gt; 电报: 传输距离增加、输入信号速度加快<br>   -&gt; 继电器: 解决更远距离传输</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存一致性(39讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7(39%E8%AE%B2)/</url>
    <content><![CDATA[<blockquote>
<p>多核CPU里的每一个CPU核、都有独立属于自己的L1 Cache 和 L2 Cache、多个CPU之间、只是共用L3 Cache 和 主内存、CPU的每个核之间都有各自的缓存、相互之间的操作又是独立的、就会带来<code>缓存一致性</code>问题</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-466c7123a41eebba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640" alt="image.png"></p>
<figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">示例: 如上图有两个CPU核心、CPU1、CPU2</span><br><span class="line">假设<span class="number">1</span>号核心要将降价信息写入到内存、但使用的是写回策略、先写入到L2 <span class="keyword">Cache</span></span><br><span class="line">但并未同步到L3 <span class="keyword">Cache</span>或者主内存、只有在这个<span class="keyword">Cache</span> Block被交换出去的时候、才会写到主内存</span><br><span class="line">此时L2 <span class="keyword">Cache</span>得到的依然是原始价格、CPU1 和 CPU2 <span class="keyword">Cache</span>里的数据都是读的自身<span class="keyword">Cache</span>、是不一致的</span><br><span class="line">这就是缓存不一致性</span><br></pre></td></tr></table></figure>

<p>思考:<br>缓存要保证一致性、需要满足什么条件呢 ？</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 写传播(<span class="keyword">Write</span> Propagation). 在一个CPU核心里、<span class="keyword">Cache</span>数据更新、必须能传播到其它节点对应的<span class="keyword">Cache</span> Line里</span><br><span class="line"><span class="number">2.</span> 事务的串行化(<span class="keyword">Transaction</span> Serialization): 在一个CPU核心里的读取和写入、在其它的节点看起来、顺序是一样的</span><br><span class="line">(eg. L1 核心先操作了降价为<span class="number">6000</span>、L2核心又操作了降价为<span class="number">5000</span>、若不能保证事务的串行化, 可能L3核心</span><br><span class="line">得到的顺序是L1 -&gt; L2 最终为<span class="number">5000</span>, 而L4得到的顺序为 L2 -&gt; L1 最终为<span class="number">6000</span>、j出现不一致)</span><br></pre></td></tr></table></figure>

<h4 id="总线嗅探机制和MESI协议"><a href="#总线嗅探机制和MESI协议" class="headerlink" title="总线嗅探机制和MESI协议"></a>总线嗅探机制和MESI协议</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">要解决缓存一致性问题、首先要解决的是多个CPU核心之间的数据传播问题、最常见的解决方案叫 `总线嗅探`</span><br><span class="line">其实是把所有的读写请求都通过总线Bus广播给所有的CPU核心、然后让各个核心去嗅探这些请求、再根据本地情况进行响应</span><br><span class="line"></span><br><span class="line">由于总线本身就是一个特别适合广播进行数据传输的机制、所以、也是日常使用的Intel CPU采用的方案</span><br><span class="line"></span><br><span class="line">基于总线嗅探机制、可以分成很多种不同的缓存一致性协议、最常用的就是`MESI`协议</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="MESI协议-写失效协议"><a href="#MESI协议-写失效协议" class="headerlink" title="MESI协议(写失效协议)"></a><code>MESI</code>协议(写失效协议)</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">`MESI`协议、是一种叫`写失效`(`Write Invalidate`)的协议、在写失效协议里、只有一个CPU核心负责写入数据、</span><br><span class="line">其它的核心、只是同步读取到这个写入、在这个CPU核心写入Cache之后、它会广播一个`失效`请求告诉其它核心</span><br><span class="line">其它核心只是判断自己是否也有一个`失效`版本的Cache Block、然后相应标记为`失效`</span><br><span class="line"></span><br><span class="line">MESI 协议由来是对应于 Cache Line的四个不同的标记</span><br><span class="line"><span class="title">M:</span> 已修改 Modified</span><br><span class="line"><span class="title">E:</span> 代表独占 Exclusive</span><br><span class="line"><span class="title">S:</span> 代表共享 Shard</span><br><span class="line"><span class="title">I:</span> 代表已失效 Invalidated</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>独占和共享的差别在哪里呢 ？</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">独占状态下的数据、对应的CPULine只加载到了当前CPU所拥有的<span class="keyword">Cache里、其它的CPU核、</span></span><br><span class="line"><span class="keyword"></span>并没有加载对应的数据到自己的<span class="keyword">Cache里、此时若向独占的Cache </span><span class="keyword">Block写入数据、可自由操作、无需通知其它CPU</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">独占状态下的数据、若收到来自总线的读取缓存的请求、就变成共享状态、因为另一个CPU也把对应的<span class="keyword">Cache </span><span class="keyword">Block加载到了自己的Cache</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">共享状态下、同样的数据多个CPU核心的<span class="keyword">Cache里都有、更新Cache时不可直接修改、</span></span><br><span class="line"><span class="keyword"></span>而是要先向其它的CPU广播一个请求、要求先把其它CPU <span class="keyword">Cache变成无效状态、再更新当前Cache里的数据</span></span><br><span class="line"><span class="keyword"></span>这个广播操作叫`RFO`(Request For Ownership)获取当前对应<span class="keyword">Cache </span><span class="keyword">Block </span>数据的所有权</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-a4378b7c57f51202.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="MESI状态流转.png"></p>
<h4 id="写广播协议"><a href="#写广播协议" class="headerlink" title="写广播协议"></a>写广播协议</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">写广播协议会将一个写入请求广播到所有的<span class="meta">CPU</span>核心、同时更新各个核心里的Cache</span><br><span class="line">在实现上比较简单、但要占用更多的总线带宽、写失效只是告诉其它<span class="meta">CPU</span>核心、哪个地址的缓存失效了、</span><br><span class="line">但是写广播协议把对应的数据传播给其它的<span class="meta">CPU</span>核心</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>虚拟内存和内存保护(40讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%92%8C%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4(40%E8%AE%B2)/</url>
    <content><![CDATA[<blockquote>
<p>内存需要被分成固定大小的页(Page),通过虚拟地址到物理地址的转换、才能找到实际物理地址、程序看到的地址都是虚拟地址</p>
</blockquote>
<h4 id="简单页表"><a href="#简单页表" class="headerlink" title="简单页表"></a>简单页表</h4><figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line">虚拟内存和物理内存映射、最直观的方法就是建立一张映射表、实现虚拟内存到物理内存的一一映射</span><br><span class="line">其实就是页表<span class="punctuation">(</span><span class="variable">Page</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">这种转换会把一个内存地址分成页号<span class="built_in">Directory</span>和偏移量<span class="built_in">Offset</span>两个部分</span><br><span class="line">前边的高位、就是内存地址的页号<span class="operator">;</span> 后边的地位就是内存地址里的偏移量<span class="operator">.</span></span><br><span class="line">地址转换的页表、只保留页号之间的映射关系即可<span class="operator">.</span></span><br><span class="line"></span><br><span class="line">同一个页面的内存、在物理层面是连续的、<span class="variable">eg</span><span class="operator">.</span> 一个页大小为<span class="number">4</span><span class="built_in">K</span></span><br><span class="line">需要<span class="number">20</span>位的高位和<span class="number">12</span>位的地位</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-19cb2185b036b931.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/340" alt="image.png"></p>
<blockquote>
<p>内存地址转换:</p>
</blockquote>
<ol>
<li>将虚拟内存地址、切分成页号和偏移量的组合</li>
<li>从页表里边、查询出虚拟页号对应的物理页号</li>
<li>拿物理页号 + 偏移量 -&gt; 物理内存地址</li>
</ol>
<p>思考: 这样一个页表需要多大空间 ？</p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line"><span class="number">32</span>位的内存地址空间、需要记录<span class="number">2</span>^<span class="number">20</span>大小的数组、一个页号是完整的<span class="number">32</span>位的<span class="number">4</span>字节、这样一个页表就需要<span class="number">4</span>M的空间</span><br><span class="line">并且: 每个进程都有属于自己的虚拟地址空间、也就是、每个进程都需要这样一个页表.</span><br><span class="line">不管进程本身是只有几KB大小的程序、还是需要几GB这样的内存空间、都需要这样一个页表</span><br><span class="line">现在的内存大多超过了<span class="number">4</span>G、若使用上边的数据结构来保存页面、内存占用会更大、如何处理呢 ？</span><br></pre></td></tr></table></figure>

<h4 id="多级页表"><a href="#多级页表" class="headerlink" title="多级页表"></a>多级页表</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">大部分进程占用的内存是有限的、需要的页自然也是有限的、只保存 `用到的页`</span><br><span class="line">之间的映射关系即可</span><br><span class="line"></span><br><span class="line">那、是不是可以选择hash表呢 ？其实采用的是多级页表. 为什么呢 ？</span><br><span class="line"></span><br><span class="line">在整个进程的内存地址空间、通常是 `两头实、中间空`. 在程序运行的时候、内存地址从顶部往下、</span><br><span class="line">不断分配占用的桟的空间. 而堆的空间、则是从底部往上、不断分配占用的</span><br><span class="line"></span><br><span class="line">所以、在一个世纪的程序进程里、虚拟内存占用的地址空间、通常是两段连续的空间、而不是完全散落的随机的内存地址. </span><br><span class="line">而多级页表、就很适合这样的内存地址分布</span><br></pre></td></tr></table></figure>

<blockquote>
<p>以一个4级的多级页表为例: 同一个虚拟内存地址、偏移量的部分和简单页表一样不变、但原有的页号部分、拆成4段、从低到高、分成4级到1级这样4个页表索引</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-2446e7a120d4d843.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line">对应的、一个进程会有一个<span class="number">4</span>级页表、先通过<span class="number">4</span>级页表索引、找到<span class="number">4</span>级页表里对应的条目<span class="symbol">Entry</span>. 存放的是一张<span class="number">3</span>级页表所在的位置</span><br><span class="line"><span class="number">4</span>级页表的每一个条目、都对应这一张<span class="number">3</span>级页表、所以可能有多张<span class="number">3</span>级页表</span><br><span class="line"></span><br><span class="line">找到对应的<span class="number">3</span>级页表之后、用<span class="number">3</span>级页表找对应<span class="number">3</span>级索引的条目.</span><br><span class="line"><span class="number">3</span>级页表的索引会指向一个<span class="number">2</span>级页表、同样、二级页表使用索引指向<span class="number">1</span>级页表</span><br><span class="line"><span class="number">1</span>级页表的条目对应的数据内容是物理页号.</span><br><span class="line">拿到物理页号之后、使用 <span class="string">`页号 + 偏移量 `</span> 得到最终的物理内存地址</span><br><span class="line"></span><br><span class="line">可能有很多张<span class="number">1</span>级页表、<span class="number">2</span>级页表甚至<span class="number">3</span>级页表、但: 因为实际的虚拟内存地址通常是连续的、可能只需要很少的<span class="number">2</span>级页表、甚至只需要一张<span class="number">3</span>级页表就可以了</span><br><span class="line">事实上、多级页表就像一个多叉树、常称为页表树(<span class="symbol">Page</span> <span class="symbol">Table</span> <span class="symbol">Tree</span>)</span><br><span class="line"></span><br><span class="line">因为虚拟地址分布的连续性、树的第一层节点的指针、很多是空的、无需对应子树、找最终物理页号</span><br><span class="line">就类似通过一个特定的访问路径、走到树最底层的叶子节点.</span><br><span class="line"></span><br><span class="line">这样分成<span class="number">4</span>级的多级页表来看、若每一级都用<span class="number">5</span>个bit表示、每一张某一级的页表、只需要<span class="number">2</span>^<span class="number">5</span>=<span class="number">32</span>个条目</span><br><span class="line">若每个条目还是<span class="number">4</span>个字节、共需要<span class="number">128</span>字节、而一个一级索引表、对应<span class="number">32</span>个<span class="number">4</span><span class="symbol">KB</span>的、即共<span class="number">128</span><span class="symbol">KB</span>的大小</span><br><span class="line">一个填满的<span class="number">2</span>级索引、对应<span class="number">32</span>个<span class="number">1</span>级索引、即<span class="number">4</span><span class="symbol">MB</span>的大小</span><br><span class="line"></span><br><span class="line">若一个进程占用<span class="number">8</span><span class="symbol">MB</span>的内存空间、分成<span class="number">2</span>个<span class="number">4</span><span class="symbol">MB</span>的连续空间、则它需要<span class="number">2</span>个独立的、填满的<span class="number">2</span>级索引表、</span><br><span class="line"><span class="number">64</span>个<span class="number">1</span>级索引表、<span class="number">2</span>个独立的<span class="number">3</span>级索引表、<span class="number">1</span>个<span class="number">4</span>级索引表、共需要<span class="number">64</span>+<span class="number">2</span>+<span class="number">2</span>+<span class="number">1</span>=<span class="number">69</span>个索引表、每个<span class="number">128</span>字节(<span class="number">9</span><span class="symbol">KB</span>)</span><br><span class="line">差不多只有简单页表的<span class="number">1</span>/<span class="number">500</span>、不过也带来了时间上的开销</span><br><span class="line"></span><br><span class="line">原本只需要一次内存访问就可以找到物理页号、算出物理内存地址、使用<span class="number">4</span>级页表的话、就需要<span class="number">4</span>次内存访问、才能找到物理页号</span><br></pre></td></tr></table></figure>

<p>思考:</p>
<blockquote>
<p>内存访问比Cache的性能要差很多、原本只是要做一个简单地址转换、反而要访问好几次内存、时间性能的损耗如何优化呢 ？</p>
</blockquote>
<p>— 下文分析</p>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>解析TLB和内存包含(41讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%A7%A3%E6%9E%90TLB%E5%92%8C%E5%86%85%E5%AD%98%E5%8C%85%E5%90%AB(41%E8%AE%B2)/</url>
    <content><![CDATA[<blockquote>
<p>机器指令里的地址都是虚拟内存地址、程序里的每一个进程、都有属于自己的内存地址空间<br>可通过地址转换得到最终的实际物理地址. 指令都放在内存里、数据页都在内存、<code>地址转换</code>是一个高频动作、必须保证性能问题</p>
</blockquote>
<h4 id="加速地址转换TLB"><a href="#加速地址转换TLB" class="headerlink" title="加速地址转换TLB"></a>加速地址转换TLB</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">从虚拟地址到物理地址的转换、可通过页表来处理、为节约存储空间、使用多级页表</span><br><span class="line">内存访问比Cache慢很多、简单的地址转换按照多级页表的设计会有很性能损失、怎么办呢? -- 加个缓存试试呢 ?</span><br><span class="line"></span><br><span class="line">程序需要的指令、都顺序放在虚拟内存里、执行的指令也是一条条顺序执行的</span><br><span class="line"><span class="title">即:</span>对于指令地址的访问、存在局部性(空间局部性和时间局部性)、需要的数据也是一样的</span><br><span class="line">连续执行<span class="number">5</span>条指令、因为地址都是连续的、所以这<span class="number">5</span>条指令通常在同一个虚拟页里</span><br><span class="line">因此、连续<span class="number">5</span>次的内存地址转换、其实都来自于同一个虚拟页号、转换的结果自然是同一个物理页号、</span><br><span class="line">就可以将之前的内存地址转换缓存下来、不需要反复访问内存来进行内存地址的转换</span><br><span class="line"></span><br><span class="line">于是、专门在CPU里放了一块缓存芯片、称为`TLB`(Translation-Lookaside Buffer)地址变换高速缓存</span><br><span class="line">存放已进行转换过的结果、同样的虚拟地址需进行地址转换的时候、可直接在TLB里查询结果、无需多次访问内存来完成转换</span><br><span class="line"></span><br><span class="line"><span class="title">TLB和CPU的高速缓存类似、可分为指令的TLB和数据的TLB、即:</span> ITLB</span><br><span class="line"> 和 DTLB、也可分级、变成L1、L2这样多层的TLB</span><br><span class="line"></span><br><span class="line">需要脏标记这样的标记位来实现`写回`这样缓存管理策略、也和高速缓存很类似</span><br><span class="line"></span><br><span class="line">为了性能、整个内存转换过程也由硬件来执行、CPU芯片里、封装了内存管理单元MMU(Memory Management Unit)来完成地址转换</span><br></pre></td></tr></table></figure>

<h4 id="安全性和内存保护"><a href="#安全性和内存保护" class="headerlink" title="安全性和内存保护"></a>安全性和内存保护</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">虽然现代操作系统和CPU、有各种权限管控、通过虚拟内存和物理内存的区分、隔离了各个进程</span><br><span class="line"><span class="title">但:</span> 无论CPU这样的硬件还是操作系统这样的软件、都很复杂、难免会被黑客找到各种漏洞</span><br><span class="line"></span><br><span class="line">计算机最底层的安全保护机制称为内存保护、如`可执行空间保护`和`地址空间布局随机化`等</span><br></pre></td></tr></table></figure>

<h4 id="可执行空间保护"><a href="#可执行空间保护" class="headerlink" title="可执行空间保护"></a>可执行空间保护</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">对一个进程使用的内存、只把指令部分设置成<span class="string">`可执行`</span>的、其它、如数据部分、不给予执行权限</span><br><span class="line">因为无论指令还是数据、在<span class="meta">CPU</span>看来、都是二进制的数据、直接将数据部分拿给<span class="meta">CPU</span>、数据解码后、也是合理的指令、即可执行的</span><br><span class="line"></span><br><span class="line">此时黑客们就想到了在程序的数据区、放入一些要执行的指令编码后的数据、让<span class="meta">CPU</span>当成指令去加载、</span><br><span class="line"><span class="meta">CPU</span>就能执行想执行的指令了、对内存空间的执行权限进行控制、就使得<span class="meta">CPU</span>只能执行指令区的代码、</span><br><span class="line">对数据区的内容、即时找到了其它漏洞想装成指令被执行也会因为没权限而被阻挡掉</span><br><span class="line">eg. php进行web开发时、通常会禁用php执行eval函数的执行权限</span><br><span class="line">sql注入攻击</span><br></pre></td></tr></table></figure>

<h4 id="地址空间布局随机化"><a href="#地址空间布局随机化" class="headerlink" title="地址空间布局随机化"></a>地址空间布局随机化</h4><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">内存层面的安全保护核心策略、是在可能有漏洞的情况下进行安全预防、可执行空间保护就是很好的例子、</span><br><span class="line"><span class="title">但内存层面的漏洞还存在其它的可能性:</span></span><br><span class="line">eg. 其它的人、进程和程序修改调特定进程的指令、数据、让当前进程执行特定的指令和数据、造成破坏</span><br><span class="line"></span><br><span class="line">原先、进程的内存布局空间是固定的、任何第三方很容易知道指令在哪里、程序桟、堆、数据又在哪里</span><br><span class="line">为人文破坏创造了很大的便利、`地址空间布局随机化`就是让位置不固定、让内存空间随机分配这些进程里</span><br><span class="line">不同部分所在的额内存空间地址、让破坏者猜不出来、减小破坏性</span><br><span class="line">eg. 密码登录</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p><a href="https://time.geekbang.org/column/article/91427">https://time.geekbang.org/column/article/91427</a></p>
<p><img src="http://upload-images.jianshu.io/upload_images/14027542-eb2558be654ee6b2.jpg" alt="图片发自简书App"></p>
<p>极课时间上的课程是我觉得质量最高的课程、很多课程忍不住想要记下笔记、如果觉得好、还希望大家多支持作者、到极课时间购买课程</p>
<p>推荐书籍汇总：</p>
<p>入门书籍：</p>
<ol>
<li>程序是怎样跑起来的</li>
<li>计算机是怎样跑起来的</li>
</ol>
<p>深入学习书籍:</p>
<ol>
<li>计算机设计与组成: 硬件&#x2F;软件接口</li>
<li>深入理解计算机系统</li>
<li>计算机体系结构: 量化研究方法</li>
</ol>
<p>课外阅读:</p>
<ol>
<li>What Every Programmer Should Kown About Memory</li>
<li>编码: 隐匿在计算机软硬件背后的语言</li>
<li>程序员的自我修养: 链接、装载和库</li>
<li><a href="https://www.bilibili.com/video/av24540152/">https://www.bilibili.com/video/av24540152/</a></li>
</ol>
<p>阅读推荐</p>
<p><a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">https://people.freebsd.org/~lstewart&#x2F;articles&#x2F;cpumemory.pdf</a></p>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机指令(第5、6讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8C%87%E4%BB%A4(%E7%AC%AC5%E3%80%816%E8%AE%B2)/</url>
    <content><![CDATA[<p>一、在软硬件接口中、CPU帮我们做了什么事？<br><code>硬件角度</code> CPU就是一个超大规模集成电路、通过电路实现加法、乘法及各种各样的处理逻辑</p>
<p><code>软件角度</code> CPU就是执行各种计算机指令(机器语言: Machine Language)的逻辑机器</p>
<p>不同CPU有不同的指令集、所以 电脑上的程序简单的复制下装载到手机上是不能正常运行的、而复制到另外一台计算器上就可以正常运行</p>
<p><code>存储程序型计算机</code> 程序是由成千上万条指令组成的、但是CPU里不能一直放着所有指令、平时是存储在存储器的、这种指令存储在存储器的计算机叫<code>存储程序型计算机</code></p>
<p>二、从编译到汇编、代码怎么变成机器码？<br>高级语言 -&gt; 编译 -&gt; 得到汇编代码<br>汇编代码 -&gt; 汇编 -&gt; 机器码(计算机可识别的指令)</p>
<p>三、解析指令和机器码<br>常见指令:<br><code>算术指令</code> 加减乘除等、在CPU层面、都会变成一条算术指令<br><code>数据传输指令</code> 给变量赋值、在内存里读写数据等、用的都是数据传输类指令<br><code>逻辑类指令</code> 逻辑上的与或非、都是这类指令<br><code>条件分支指令</code> if&#x2F;else 等都是分支类指令<br><code>无条件跳转指令</code> 函数调用</p>
<p>四、CPU是如何执行指令的？<br>拿Intel CPU来说、里边包含几百亿个晶体管、实际上指令执行起来非常复杂、对软件程序员来说、只需要知道指令是顺序执行就可以了</p>
<p>CPU其实是一堆寄存器组成的、而寄存器就是CPU内部由多个触发器(Flip-Flop)或者锁存器(Latches) 组成的简单电路</p>
<p>N个寄存器或者锁存器可以组成一个N位(bit) 的寄存器、能够保持N位的数据、eg. 我们使用64位Intel的服务器、寄存器就是64位的</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-e91a7da79b52f77c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>CPU中不同功能的寄存器会有很多、有三种比较特殊的:<br><code>PC寄存器</code> <code>Program Counter Register</code>， 也叫<code>地址寄存器</code> <code>Instruction Address Register</code> 用来存放<code>下一条</code>需要执行的计算机指令的内存地址</p>
<p><code>指令寄存器</code> <code>Instruction Register</code> 用来存放<code>当前</code>正在执行的指令</p>
<p><code>条件码寄存器</code> <code>Status Register</code> 用里边的标记位<code>Flag</code>, 存放CPU进行算术或者逻辑运算的结果</p>
<p>除了这些特殊的寄存器、CPU还有更多用来存储数据和内存地址的寄存器. 这样的寄存器每类通常有很多、会根据它们的存放内容取名字、eg. <code>整数寄存器</code>, <code>浮点数寄存器</code>, <code>向量寄存器</code>和<code>地址寄存器</code> 等，有些既可以存放数据、也可以存放地址, 我们称为 <code>通用寄存器</code></p>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-36b4838173fa42aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>实际上、程序运行的时候、CPU会根据PC寄存器里边的地址、从内存把需要执行的指令读取到寄存器里边执行、然后根据指令长度自增、读取下一条指令, 可以看到指令在内存中是连续保存的、也会顺序加载<br>而有些特殊指令、eg. <code>J指令</code>， 也就是<code>跳转指令</code> 会修改<code>PC</code>寄存器里边的地址值、这样下一条要执行的指令就不是才能够内存顺序加载的了、因此才能使用 <code>if...else</code> &#x2F; <code>while</code> &#x2F; <code>for</code> 等语句</p>
<p>五、周期概念<br><code>指令周期</code> <code>Fetch</code>-&gt;<code>Decode</code> -&gt; <code>Execute</code> (获取指令 -&gt; 指令译码 -&gt; 执行指令 ) 的循环称为一个指令周期(<code>Instruction Cycle</code>)</p>
<p><code>CPU周期</code> <code>Machine Cycle</code> CPU的内部操作很快、但是内存访问速度很慢、每一条指令都需要从内存里加载而来、把从内存中读取一条指令的最短时间称为一个<code>CPU周期</code></p>
<p>一个<code>指令周期</code> 包含多个 <code>cpu周期</code>,<br>一个<code>cpu周期</code> 包含多个 <code>时钟周期</code></p>
<p>六、建立数据通路</p>
<blockquote>
<p>数据通路就是我们的处理器单元、通常由两类元件组成：<br>1.操作元件(组合逻辑元件) 其实就是ALU、在特定输入下、根据组合电路的逻辑生成特定输出<br>2.存储元件: 状态元件 eg. 计算过程中用到的寄存器、无论是通用寄存器还是状态寄存器、都是存储元件<br>通过数据总线将操作元件和存储元件连接、就可以完成数据的存储和传输、就是所谓的建立数据通路</p>
</blockquote>
<p>  七、CPU所需要的硬件电路</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> ALU: 无状态的、根据输入得到输出结果的电路</span><br><span class="line"><span class="bullet">2.</span> 寄存器：能够进行状态读写的电路元件. 常见的有 锁存器(Latch)， D触发器(Data/Delay Flip-flop) 电路</span><br><span class="line"><span class="bullet">3.</span> 自动实现pc寄存器自增的电路</span><br><span class="line"><span class="bullet">4.</span> 译码电路: 实现对指令进行decode、对拿到的地址去获取对应的数据或者指令等</span><br></pre></td></tr></table></figure>

<p><code>组合逻辑电路</code> 给定输入、得到固定输出. 无法完成复杂工作<br><code>时序逻辑电路</code> 解决了<code>自动运行</code>和<code>存储</code>问题</p>
<blockquote>
<p>时钟信号: 通过一个电磁电路实现、不断切换信号</p>
</blockquote>
<blockquote>
<p>反馈电路: 把当前电路的输出信号作为输入信号、再返回到当前电路</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>课后问题汇总</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%AF%BE%E5%90%8E%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<p>一、图灵机和冯.诺依曼机是不同的计算机吗？</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">简单来说: 图灵机更侧重于计算抽象、后者更侧重于硬件抽象</span></span><br></pre></td></tr></table></figure>

<p>二、time指令的返回分表代表什么?</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="type">real</span> <span class="type">time</span>: 时钟时间(Wall clock <span class="type">time</span>), 进从开始到结束所用的实际时间、包括其它进程使用的时间片和等待io完成的时间</span><br><span class="line"></span><br><span class="line"><span class="keyword">user</span> <span class="type">time</span>: 指进程执行用户态代码(核心之外)使用的时间、执行此进程实际消耗的CPU时间、其它进程和此进程阻塞时间不包含在内</span><br><span class="line"></span><br><span class="line">sys <span class="type">time</span>: 指进程在内核态消耗的cpu时间</span><br><span class="line"></span><br><span class="line">为什么<span class="keyword">user</span>+sys &gt; <span class="type">real</span> ?</span><br><span class="line"><span class="number">1.</span> <span class="keyword">user</span> + sys 为实际的CPU时间、若有多个线程、则可能出现、<span class="keyword">user</span>+sys包含子进程的时间</span><br><span class="line"><span class="number">2.</span> 在多处理器系统上、可能出现、因为多进程或者线程可并行处理</span><br><span class="line"><span class="number">3.</span> <span class="type">time</span>的输出是由几个不同的系统调用得到的</span><br><span class="line"><span class="keyword">user</span> <span class="type">time</span>和sys <span class="type">time</span>是从wait(<span class="number">2</span>) 或 <span class="type">time</span>(<span class="number">2</span>) 得到的(根据系统不同决定)</span><br><span class="line"><span class="type">real</span> <span class="type">time</span>是从 g<span class="string">e&#x27;t&#x27;</span>timeofday中结束时间和起始时间相减得到</span><br></pre></td></tr></table></figure>

<p>三、时钟周期是什么</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>四、为什么程序无法在linux和win下同时运行？</p>
<blockquote>
<p>因为两个系统下的可执行文件的格式不同</p>
</blockquote>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">-g 得到的是目标文件</span><br><span class="line">-o 得到的是可执行文件</span><br><span class="line"></span><br><span class="line">c -&gt; 汇编 -&gt; 机器码</span><br><span class="line">c-&gt;汇编: 编译、汇编、链接 <span class="number">3</span>部分组成</span><br><span class="line">汇编-&gt; 机器码: 通过装载器Loader把可执行文件<span class="keyword">Load</span>到内存中、CPU从内存读取指令和数据、开始真正的执行程序</span><br><span class="line"></span><br><span class="line">目标文件和可执行文件dump得到的内容差不多、因为linux下、都是使用elf(executable and linkable file format)的格式</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-f3fd1f4b38b519c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="https://upload-images.jianshu.io/upload_images/14027542-39279b8724e3dacf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">ELF 文件格式信息:</span><br><span class="line"><span class="number">1.</span> text <span class="keyword">Section</span>: 代码段 用来保存程序的代码和指令</span><br><span class="line"><span class="number">2.</span> .data <span class="keyword">Section</span>: 数据段 用来保存程序里边设置好的初始化数据信息</span><br><span class="line"><span class="number">3.</span> .rel.text <span class="keyword">Section</span>: 重定向表Relocation <span class="keyword">Table</span> 保留的是当前文件里、哪些跳转地址是未知的</span><br><span class="line"><span class="number">4.</span> .symtab <span class="keyword">Section</span>: 符号表 保留了当前文件里定义的函数和对应的地址信息</span><br><span class="line">连接器会扫描所有的输入目标文件、把所有符号表里的信息收集起来、构成一个全局的符号表、把所有不确定要跳转地址的代码、根据符号表里存储的地址、进行一次修正, 最后 把所有的目标文件的对应段进行一次合并、变成了最终的可执行代码</span><br></pre></td></tr></table></figure>

<p>五、java这样使用虚拟机的编程语言里、程序是如何装载到内存的 ？</p>
<figure class="highlight haskell"><table><tr><td class="code"><pre><span class="line"><span class="title">jvm</span>是上层应用、无需考虑物理分页、一般是直接考虑对象本身的空间大小、物理硬件统一管理由承载<span class="keyword">jvm</span>的操作系统来解决</span><br></pre></td></tr></table></figure>

<p>六、CPU一直在取下一条指令、为什么还有满载和idle空闲状态呢？</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机信息存储</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BF%A1%E6%81%AF%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<blockquote>
<p>大多数计算机使用8位的块、或者字节byte 作为最小的可寻址的内存单位、而不是访问内存中独立的位、机器级的程序将内存视为一个很大的字节数组、称为 虚拟内存(<code>virtual memory</code>), 内存的每个字节由一个唯一的数字来标识、所有可能地址的集合称为 虚拟地址空间(<code>virtual address space</code>)</p>
</blockquote>
<blockquote>
<p>每个计算机都有一个字长 word size, 表明指针数据的标称大小, 对于宇哥w位的机器而言、虚拟地址的范围是 0~2<sup>m-1</sup></p>
<p>32位字长限制虚拟地址空间为4GB、64位为16EB(1.84*10<sup>19</sup>)字节</p>
<p>大多数64位机器可以运行32位的程序、</p>
<p>eg. gcc -m32 prog.c 编译出来的程序可在32位机器上运行、</p>
<p>​     gcc -m64 prog.c 编译出来只可在64位机器上运行</p>
<p>so. 将程序称为32位或者64位程序时、区别在于程序是如何编译的、而不是运行时机器的类型</p>
</blockquote>
<p><strong>为了避免依赖大小和不同编译器设置带来的差异、ISO C99标准引入了 int32_t 和 int64_t 两种固定长度的数据类型</strong></p>
<blockquote>
<p>大端法: 高地址存储高位数</p>
<p>小端法则反之</p>
<p>对大多数程序来说、字节顺序完全不可见、但:</p>
<p>A机器产生的数据通过网络发送到B机器时、B机器会按照字节的内部表示来进行转换、可能会出问题、eg. add %eax, 0x2000b43(%rip) 、字节顺序就会导致数据解析错误</p>
<p>so. 网络应用程序的代码必须遵守已建立的关于字节顺序的规则</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机概念漫谈</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A6%82%E5%BF%B5%E6%BC%AB%E8%B0%88/</url>
    <content><![CDATA[<p><code>总线</code>: 一组电子管道, 携带信息字节、并负责在各个组件间传递</p>
<blockquote>
<p>每个IO设备通过一个控制器或者适配器与IO总线相连</p>
<p>控制器和适配器的区别是: 封装方式的不同、但功能都是在IO总线和IO设备之间传递信息</p>
<p>控制器: IO设备本身或者系统的主板上的芯片组</p>
<p>适配器: 是一块插在主板槽上的卡</p>
</blockquote>
<blockquote>
<p>主存: 是一个临时性的存储设备、在处理器执行程序时、用来存放程序和程序处理的数据</p>
<p>从物理上来说、主存是由一组<code>动态随机存取存储器</code>芯片组成的</p>
<p>从逻辑上来说、存储器是一个线性的字节数组、每个字节有唯一地址(数组索引)、地址从0开始、</p>
</blockquote>
<blockquote>
<p>处理器: 中央处理单元CPU、简称处理器、是解释(或执行)存储在主存中指令的引擎、</p>
<p>处理器的核心是<code>一个大小为1个字的存储设备(或寄存器)</code>、即: <code>程序计数器PC</code></p>
<p>在任何时刻、PC都指向主存中的某条机器语言指令(即: 含有该指令的地址)</p>
<p>处理器从程序计数器指向的内存处读取指令、解释指令中的位、执行该指令的简单操作、然后更新PC, 使其指向下一条指令(不一定和内存中刚刚执行的指令相邻、比如 jump)</p>
<p>这样的简单操作不多、围绕 主存、寄存器文件 和 算术&#x2F;逻辑单元 ALU 进行. eg. 如下操作</p>
<p><code>加载</code>: 从<code>主存</code>复制一个字节或者一个字到<code>寄存器</code>、以覆盖寄存器原来的内容</p>
<p><code>存储</code>: 从<code>寄存器</code>复制一个字节或者一个字到<code>主存</code>的某个位置、以覆盖这个位置上原来的内容</p>
<p><code>操作</code>: 把两个寄存器的内容复制到<code>ALU</code>, ALU对这两个寄存器的字进行算术运算、并将结果存放到一个寄存器中、覆盖该寄存器原来的内容</p>
<p><code>跳转</code>: 从指令本身抽取一个字、并将这个字复制到程序计数器PC中、以覆盖PC中原来的值</p>
</blockquote>
<blockquote>
<p>处理器的指令架构集描述的是每条机器代码指令的效果</p>
<p>微体系结构描述的是处理器实际上如何实现的</p>
</blockquote>
<p>处理器从寄存器文件中读数据比从主存中读取几乎要快100倍、所以系统设计者采用了更小更快的存储设备 高速缓存存储器 cache 来存放近期需要的数据</p>
<blockquote>
<p>位于处理器芯片上的L1高速缓存 容量可以达到数万字节、访问速度几乎和访问寄存器问你件一样快</p>
<p>一个容量为数十万到数百万字节的L2高速缓存 通过一条特殊的总线连接到处理器、进程访问L2高速缓存的时间要比访问L1高速缓存的时间长5倍、但仍比访问主存快5~10倍</p>
<p>L1和L2高速缓存是使用 静态随机访问存储器SRAM的硬件技术实现的</p>
<p>新的系统出现了L3缓存、系统可以获得一个更大的存储器、同时访问素的也更快、是利用了高速缓存的局部性原理、使程序具有访问局部区域里的数据和代码的趋势、通过让高速缓存里存放可能经常性访问的数据、</p>
</blockquote>
<blockquote>
<p>程序不会直接操作硬件、而是依靠操作系统提供的服务</p>
<p>可以将操作系统看成应用程序和硬件之间插入的一层软件</p>
<p>操作系统: 1.防止硬件被失控的应用程序滥用 2.向应用程序提供简单一致的机制来控制硬件设备(通过 进程、虚拟内存、文件来实现)</p>
</blockquote>
<p>进程:</p>
<blockquote>
<p>并发运行: 一个进程的指令和另一个进程指令是交错执行的、大多数系统中可以运行的进程数多于CPU个数、传统系统 一个时刻只能执行一个程序、多核处理器可以同时执行多个程序</p>
<p>无论是单核还是多核处理器、一个CPU看上去都像是在并发执行多个进程、是通过进程间切换实现的。这种交错执行的机制称为 上下文(包括PC、寄存器文件当前值及主存内容等)切换</p>
<p>从一个进程到另一个进程的切换是操作系统内核管理的, 内核是操作系统代码常驻主存部分</p>
<p>注意: 内核不是一个独立的奖金池、而是系统管理全部进程所用代码和数据结构的集合</p>
</blockquote>
<p>线程:</p>
<blockquote>
<p>进程实际上由多个线程执行单元组成、每个线程运行在进程上下文中、并共享同样的代码和全局数据</p>
</blockquote>
<p>虚拟内存;</p>
<blockquote>
<p>虚拟内存是一个抽象概念、为每个进程提供了独占使用主存的假象、每个进程看到的内存是一致的、称为虚拟地址空间</p>
<p>Linux中、地址空间的最上边的区域是给操作系统代码和数据的、底部存放用户进程的代码和数据、地址从下-&gt; 上增加</p>
<p>每个进程看到的虚拟地址空间由大量准确定义的区构成、每个区有专门的功能(下述从最低地址向上)</p>
<ul>
<li>程序代码和数据: 对所有进程来说、代码从同一个固定地址开始、接着是和C全局变量对应的数据位置</li>
<li>堆: 代码和数据区后紧随着是运行时 堆、代码和数据区在进程开始运行时就指定了大小、堆是在运行时可动态扩展和收缩的空间</li>
<li>共享库: 大概地址空间的中间是一块用来存放像C标准库和数学库这样的共享库代码和数据的区域</li>
<li>桟: 位于用户虚拟地址顶部的是用户桟、编译器用它来实现函数调用</li>
<li>内存虚拟内存: 不允许应用程序读写这个区域的内容或者直接调用年内和定义的函数</li>
</ul>
</blockquote>
<p>文件:</p>
<blockquote>
<p>文件就是文字序列、每个io设备、包括磁盘、键盘、显示器 甚至网络都可以看成文件</p>
<p>系统中的输出输入都是通过Unix io的系统函数调用读写文件来实现的</p>
</blockquote>
<p>Amdahl定律:</p>
<blockquote>
<p><code>Amdahl定律</code>: 对系统某部分性能的提升取决于该部分的重要性和加速程度、</p>
<p>eg. 某系统初始耗时 60%、加速比例 k&#x3D;3 则加速为 1&#x2F;((1-0.6)+0.6&#x2F;3) &#x3D; 1.67倍</p>
</blockquote>
<p>并发:</p>
<blockquote>
<p>线程级并行:</p>
<p>1.多个CPU</p>
<p>2.超线程 又称:同时多线程、是一项允许一个CPU执行多个控制流的技术, 它涉及CPU某些硬件有多个备份、eg. 程序计数器和寄存器文件、而其它的硬件只有一份、eg. 执行浮点数运算的单元, 常规的处理器大约需要20000个时钟周期做线程切换、而超线程的处理器可以在单个周期的基础上决定执行哪个线程</p>
<p>指令级并行</p>
<p>早期处理器一个指令需要多个时钟周期来执行、现代处理器可以同时执行多条指令的属性称为: 指令级并行</p>
<p>单指令、多数据并行</p>
<p>现代处理器允许一条指令参数多个并行执行的操作、称为: 单指令、多数据并行 即:SIMD并行</p>
<p>提高这些SIMD指令是为了提高处理影像、声音和视频数据应用的执行速度、虽然有些编译器会试图从C程序中自动抽取SIMD并行性、但更可靠的方法是用编译器支持的特殊向量数据类型来写程序、eg. GCC 就支持向量数据类型</p>
</blockquote>
<p>几个抽象:</p>
<blockquote>
<p>文件是对IO设备的抽象</p>
<p>虚拟内存是对程序存储器的抽象</p>
<p>进程是对一个正在运行的程序的抽象</p>
<p>虚拟机是对整个计算机的抽象、包括 操作系统、处理器和程序</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>超线程和SIMD(27讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%B6%85%E7%BA%BF%E7%A8%8B%E5%92%8CSIMD(27%E8%AE%B2)/</url>
    <content><![CDATA[<p><strong>回顾</strong></p>
<blockquote>
<p><code>超标量</code>: 可以让取指令及指令译码并行进行、</p>
<p><code>VLIW</code>: 可以搞定指令先后依赖关系、使得一次取一个指令包</p>
</blockquote>
<p>最后两个提升CPU性能的设计: <code>超线程</code> 和 <code>SIMD(单指令多数据流)</code></p>
<h4 id="超线程"><a href="#超线程" class="headerlink" title="超线程"></a>超线程</h4><figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">奔腾<span class="number">4</span>处理器失败的重要原因: <span class="meta">CPU</span>的流水线级数太深、高达<span class="number">20</span>级、而后期Prescott更是达到了<span class="number">31</span>级、超长流水线、使得各种冒险、并发的方案都用不上</span><br><span class="line"></span><br><span class="line">解决冒险、提升并发的方案, 本质上是一种 <span class="string">`指令级并行(Instruction-level parallelism)`</span></span><br><span class="line">即: <span class="meta">CPU</span> 想要在同一个时间、并行的执行两条指令、而代码原本是有先后顺序的、流水线太深的话、之前的分支预测、乱序执行等优化方式都无法起到很好的效果、</span><br><span class="line"></span><br><span class="line"><span class="number">2002</span>年底、Pentium4的<span class="meta">CPU</span>、第一次引入了超线程(Hyper-Threading技术)</span><br><span class="line"><span class="string">`超线程`</span>: 既然<span class="meta">CPU</span>运行在代码层面有前后依赖关系的指令、会遇到各种冒险问题、如果运行完全独立的程序呢? 指令间是没有依赖关系的、那么跟多个<span class="meta">CPU</span>运行不同任务、或者多进程、多线程技术有什么区别呢 ?</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>.多个<span class="meta">CPU</span>上运行不同的程序、单个<span class="meta">CPU</span>核心里切换运行不同的线程任务、在同一时间点上、其实一个物理的<span class="meta">CPU</span>核心只运行一个线程的指令、所以, 并没有真正做到指令级并行</span><br><span class="line"><span class="number">2</span>. 超线程 是把一个物理<span class="meta">CPU</span>核心、伪装成两个逻辑<span class="meta">CPU</span>、这个<span class="meta">CPU</span>会在硬件层面增加很多电路、使得我们可以在一个<span class="meta">CPU</span>核心内部、维护两个不同线程的指令状态信息</span><br><span class="line">eg. 在一个物理<span class="meta">CPU</span>核心内部、有双份PC寄存器、指令寄存器及条件码寄存器、可以维护两条并行指令的状态、在外面看起来、好像有两个逻辑层面的<span class="meta">CPU</span>同时在运行、也叫<span class="string">`同时多线程`</span>(Simultanneous Multi-Threading, 简称SMT)技术</span><br><span class="line"></span><br><span class="line">但: 在<span class="meta">CPU</span>其它的功能组件上、eg. 指令译码器和ALU 依然只有一份、因为超线程并不真正运行两个指令、它的目的在于 一个线程A的指令、在流水线停顿的时候、让线程B与执行、利用此时<span class="meta">CPU</span>译码器和ALU的空闲来处理、提高<span class="meta">CPU</span>利用率</span><br><span class="line"></span><br><span class="line">通过很小的<span class="meta">CPU</span>代价、实现了同时运行多个线程的效果、通常只要在<span class="meta">CPU</span>核心添加<span class="number">10</span>%左右的逻辑功能、增加可以忽略不计的晶体管数量、就可以实现、但同样只能应用在特殊的额应用场景下(线程等待时间较长)</span><br><span class="line">eg. 需要对很多请求的数据库应用、就很适合、各个指令都需要等待访问内存数据，<span class="meta">CPU</span>计算并未跑满、但当前指令往往要停顿在流水线上、等待内存数据返回、这时、让<span class="meta">CPU</span>里的各个功能单元、处理另一个<span class="built_in">db</span>查询的案例就很好</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-3b63d476f142a99f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="SIMD-如何加速矩阵算法"><a href="#SIMD-如何加速矩阵算法" class="headerlink" title="SIMD: 如何加速矩阵算法"></a>SIMD: 如何加速矩阵算法</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">SIMD:</span> 单指令多数据流(Single <span class="keyword">Instruction </span><span class="keyword">Multiple </span>Data)</span><br><span class="line"><span class="symbol">SISD:</span> 单指令单数据(Single <span class="keyword">Instruction </span>Single Data)</span><br><span class="line">多核CPU可以实现MIMD(<span class="keyword">Multiple </span><span class="keyword">Instruction </span><span class="keyword">Multiple </span>Data)</span><br><span class="line"></span><br><span class="line">为什么SIMD指令可以提高代码执行效率呢? </span><br><span class="line"><span class="number">1</span>.因为SIMD在获取数据和执行指令的时候都是并行的、从内存读数据的时候、SIMD是一次性读多个数据</span><br><span class="line">Intel在引入SSE指令集的时候、在CPU里添加了<span class="number">8</span>个<span class="number">128</span>Bits的寄存器、即 <span class="number">16</span>Bytes、一个寄存器一次性可以加载<span class="number">4</span>个整数、比起循环加载、时间就节省了</span><br><span class="line"><span class="number">2</span>. 指令执行层面、<span class="number">4</span>个整数加法、相互之间完全无依赖、也就没有冒险问题要处理、有足够多的FU即可并行执行、这个加法就是<span class="number">4</span>路同时并行的、也会节省时间</span><br><span class="line"></span><br><span class="line">基于SIMD的向量计算指令、正是在Intel发布Pentium处理器的时候、被引入的指令集、当时的指令集叫 `MMX`, 即: `Matrix Math <span class="keyword">eXtensions`的英文缩写、中文名字叫 </span>矩阵数学扩展</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-f32a5c0c67a98d4f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<blockquote>
<p>超线程技术是线程级并行的解决方案、很多场景下不一定能带来性能的提升</p>
<p>SIMD是指令级并行的解决方案、在处理向量计算的情况下、同一个向量的不同维度之间的计算是相互独立的、</p>
<p>两者都优化了CPU的使用</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>高速缓存(37~38讲)</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98(37~38%E8%AE%B2)/</url>
    <content><![CDATA[<h4 id="为什么需要高速缓存"><a href="#为什么需要高速缓存" class="headerlink" title="为什么需要高速缓存"></a>为什么需要高速缓存</h4><blockquote>
<p>按照摩尔定律、CPU的访问速度每18个月便会翻一番、相当于每年增长60%、内存的访问速度也在增长、但只有7%左右、使内存和CPU的性能差距不断拉大. 现在一次内存的访问需要120个CPU周期、即: 访问速度有120倍的差距<br>为了弥补两者的性能差异、真实的把CPU使用起来、现代CPU引入了高速缓存</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-63ffb060446bf2df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="CPU和内存的性能差距会越来越大.png"></p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">从CPU <span class="keyword">Cache </span>被加入CPU开始、内存中的指令、数据会先加载到L1</span><br><span class="line">-L3 <span class="keyword">Cache中、而不是直接由CPU访问内存去拿、</span></span><br><span class="line"><span class="keyword"></span>在<span class="number">95</span>%的情况下、CPU只需要访问L1-L3 <span class="keyword">Cache、从里边读取指令和数据、无需访问内存</span></span><br><span class="line"><span class="keyword"></span>注意: CPU <span class="keyword">Cache不是单存概念上的Cache(eg. </span>之前说的以内存作为硬盘的缓存)、而是指特定的由<span class="keyword">SRAM组成的物理芯片</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">CPU从内存中读取数据到CPU <span class="keyword">Cache的过程中、是一小块、一小块读取的、不是按照单个数组元素读取的、</span></span><br><span class="line"><span class="keyword"></span>这样一小块一小块的数据、在CPU <span class="keyword">Cache里、称为 </span>`<span class="keyword">Cache </span>Line`(缓存块)</span><br><span class="line">通常Intel的服务器或者PC里、<span class="keyword">Cache </span>Line的大小通常是<span class="number">64</span>字节</span><br></pre></td></tr></table></figure>

<h4 id="Cache的数据结构和读取过程是什么样的"><a href="#Cache的数据结构和读取过程是什么样的" class="headerlink" title="Cache的数据结构和读取过程是什么样的"></a>Cache的数据结构和读取过程是什么样的</h4><figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">现代CPU在数据读取时、无论数据是否已经存储在<span class="keyword">Cache</span>中、都会先访问<span class="keyword">Cache</span>、</span><br><span class="line">只有<span class="keyword">Cache</span>中找不到时、才会访问内存、并且将读到的数据写入<span class="keyword">Cache</span>中、根据时间局部性原理、这样CPU花在等待内存访问上的时间就会大大缩短</span><br><span class="line">通常在基准测试和实际场景中、CPU <span class="keyword">Cache</span>的命中率可以达到<span class="number">95</span>%以上</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-665111aecb317bc2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="与应用相似的架构.png"></p>
<p>思考: 那么CPU是如何知道要访问的内存数据、存储在Cache的哪个位置呢 ?</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">CPU访问内存数据、是一小块一小块数据来读取的、对于读取内存中的数据、首先拿到的是数据所在的`内存块(Block)`的地址</span><br><span class="line">而直接映射<span class="built_in">Cache</span>(Direct Mapped Cache)采用的策略就是确保任何一个内存块的地址、</span><br><span class="line">始终映射到一个固定的CPU Cache地址(Cache Line), 而这个映射关系、通常用<span class="built_in">mod</span>(求余)计算来实现</span><br><span class="line">eg. 将主内存分成<span class="number">0</span>~<span class="number">31</span>共<span class="number">32</span>个块、共有<span class="number">8</span>个缓存块、用户需要访问第<span class="number">21</span>号内存块、</span><br><span class="line">若<span class="number">21</span>号内存块内容在缓存块中的话、一定在<span class="number">5</span>号缓存块(<span class="number">21%</span><span class="number">8</span> = <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-0e3d70cab102d106.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="cache采用mod方式、将内存块映射到对应的CPU Cache.png"></p>
<p>思考:<br>现在13号、5号和21号都应该在5号缓存块中、那如何区分、当前缓存块中是几号内存对应的数据呢 ？</p>
<figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line">对应的缓存块会存储一个组标记、记录当前缓存块内存储的数据对应的内存块、</span><br><span class="line">除组标记外、缓存块中还有两个数据<span class="operator">:</span></span><br><span class="line"><span class="number">1.</span> 从主内存中加载来的实际存放的数据、</span><br><span class="line"><span class="number">2.</span>有效位<span class="operator">:</span> 用来标记对应的缓存块中的数据是否是有效的、确保不是机器刚启动时的空数据<span class="operator">.</span> 有效位为<span class="number">0</span>时、<span class="variable">CPU</span>会直接访问内存、重新加载数据</span><br><span class="line"><span class="variable">CPU</span>在读取数据的时候、不是要读取医政股<span class="built_in">Block</span>、只读取一个需要的整数、称为<span class="variable">CPU</span>的一个字<span class="built_in">Word</span></span><br><span class="line">具体是哪个字、就用这个字在整个<span class="built_in">Block</span>中的位置来决定、这个位置称为偏移量<span class="built_in">Offset</span></span><br><span class="line">而内存地址对应到<span class="variable">Cache</span> <span class="built_in">Line</span>里的数据结构则多了一个有效位和对应的数据</span><br><span class="line">由 索引 <span class="operator">+</span> 有效位 <span class="operator">+</span> 组标记 <span class="operator">+</span> 数据组成</span><br><span class="line"></span><br><span class="line">若<span class="operator">:</span> 一个内存中的数据已经在<span class="variable">Cache</span>中、访问步骤为<span class="operator">:</span></span><br><span class="line"><span class="number">1.</span> 根据内存地址的地位、计算在<span class="variable">Cache</span>中的索引</span><br><span class="line"><span class="number">2.</span> 判断有效位、确认<span class="variable">Cache</span>中的数据是有效的</span><br><span class="line"><span class="number">3.</span> 对比内存访问地址的高位、和<span class="variable">Cache</span>中的组标记、确认<span class="variable">Cache</span>中的数据就是要访问的内存数据、从<span class="variable">Cache</span> <span class="built_in">Line</span>读取对应数据块</span><br><span class="line"><span class="number">4.</span> 根据内存地址的<span class="built_in">Offset</span>位、从<span class="variable">Data</span> <span class="built_in">Block</span>中读取所需内容</span><br><span class="line">若在<span class="number">2</span>、<span class="number">3</span>步骤中<span class="variable">CPU</span>发现数据不是要访问的数据、<span class="variable">CPU</span>会访问内存、将<span class="built_in">Block</span> <span class="variable">Data</span>更新到<span class="variable">Cache</span> <span class="built_in">Line</span>中、同时更新对应的有效位和组标记的数据</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/14027542-bdbd1ecdec2570de.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="内存地址到Cache Line的关系.png"></p>
<p>思考:volitile 关键字的作用 ?</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">一种错误理解是 当成锁、认为类似sychronized 关键字、不同的线程对于特定变量的访问会加锁</span><br><span class="line">另一种误解是 当成原子化的操作机制、认为加了volitile、对于变量的自增操作就变成原子性的了</span><br><span class="line"></span><br><span class="line">其实: volitile 最核心的知识点要关系到<span class="keyword">Java内存模型(Java </span>Memory Model)上</span><br><span class="line">虽然<span class="keyword">JMM只是Java虚拟机这个进程级虚拟机里的一个内存模型、但这个内存模型和CPU、高速缓存和主内存组合在一起的硬件体系很相似</span></span><br><span class="line"><span class="keyword"></span>虽然<span class="keyword">Java内存模型是一个隔离了硬件实现的虚拟机内的抽象模型、但给了一个很好的缓存同步问题的示例.</span></span><br><span class="line"><span class="keyword"></span>即: 若我们的数据在不同的线程或者CPU核心里去更新、因为不同的线程或者CPU核有各自的缓存、有可能在A线程的更新<span class="keyword">B线程看不到</span></span><br></pre></td></tr></table></figure>

<h4 id="CPU高速缓存的写入"><a href="#CPU高速缓存的写入" class="headerlink" title="CPU高速缓存的写入"></a>CPU高速缓存的写入</h4><figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">现在使用的Intel CPU、通常都是多核的、每一个CPU核里、都有独立属于自己的L1、L2的<span class="keyword">Cache</span> 和 多个CPU共用的L3的<span class="keyword">Cache</span>、主内存</span><br><span class="line">因为CPU <span class="keyword">Cache</span>的访问速度要比主内存快很多、L1/L2 <span class="keyword">Cache</span>的速度也比L3 快、所以、CPU都是尽可能的从CPU <span class="keyword">Cache</span>中获取数据、而不是每次从主内存获取</span><br><span class="line"></span><br><span class="line">Java内存模型里、每个线程都有自己的线程桟、每次数据读取其实是从本地线程桟的<span class="keyword">Cache</span>副本里读取、而不是主内存</span><br><span class="line">若对数据只读还好、但事实是读写同时存在的、这时思考两个问题:</span><br></pre></td></tr></table></figure>
<blockquote>
<ol>
<li>写Cache的性能也比写主内存快、那写入时应该写主内存还是Cache ?<br>2.若直接写主内存、Cache里的数据是否会失效呢 ?</li>
</ol>
</blockquote>
<h4 id="写直达-Write-Through"><a href="#写直达-Write-Through" class="headerlink" title="写直达 Write-Through"></a>写直达 Write-Through</h4><p><img src="https://upload-images.jianshu.io/upload_images/14027542-daf2deb032fab327.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="image.png"></p>
<figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">如上图、最简单的一种写入策略, 写直达. 在这个策略里、每一次数据都要写到主内存里、</span><br><span class="line">写入前, 先判断数据是否在<span class="keyword">Cache</span>中、若在、先更新<span class="keyword">Cache</span>、再写入主内存; 若不在、只更新主内存</span><br><span class="line">缺点是: 无论数据是否在<span class="keyword">Cache</span>里、都需要把数据写到主内存、效率较低</span><br><span class="line">类似volatile关键字、始终把数据同步到主内存里</span><br></pre></td></tr></table></figure>

<h4 id="写回-Write-back"><a href="#写回-Write-back" class="headerlink" title="写回 Write-back"></a>写回 Write-back</h4><p><img src="https://upload-images.jianshu.io/upload_images/14027542-ead03578a6a2f4d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/240" alt="image.png"></p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">不把写入同步到主内存、只写CPU <span class="keyword">Cache呢？是否可行 </span>？</span><br><span class="line">如上图所示就是只写<span class="keyword">Cache的策略 </span>-&gt; 每次只把数据写回<span class="keyword">Cache、只有在CPU </span><span class="keyword">Cache里的数据要被替换的时候、才将数据写回主内存</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">过程: 若发现要写回的数据就在<span class="keyword">Cache中、只更新Cache里的数据即可、同时标记Cache里这个Block的数据是Dirty(与主存不一致)</span></span><br><span class="line"><span class="keyword"></span>若发现要写入的数据对应的<span class="keyword">Cache </span><span class="keyword">Block里、放的是别的内存地址的数据</span></span><br><span class="line"><span class="keyword"></span>check下数据是否是<span class="keyword">Dirty、</span></span><br><span class="line"><span class="keyword"></span>若是、先写回主内存然后把当前要写入的数据写入到<span class="keyword">Cache、同时把Cache </span><span class="keyword">Block标记成Dirty</span></span><br><span class="line"><span class="keyword"></span>若不是、直接将数据写入<span class="keyword">Cache、然后把Cache </span><span class="keyword">Block标记为Dirty</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">在使用`写回`这个策略的时候、加载内存数据到<span class="keyword">Cache里的时候、也要多一步同步脏Cache的动作</span></span><br><span class="line"><span class="keyword"></span>若加载内存里的数据到<span class="keyword">Cache的时候、发现Cache </span><span class="keyword">Block里有Dirty标记、需要先把Cache </span><span class="keyword">Block的数据写回主内存、才能加载数据覆盖掉Cache</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line">在写回这个策略里、若大量的操作、都能命中缓存、大部分时间都不需要读写主内存、性能会比写直达好</span><br></pre></td></tr></table></figure>

<p>然而、无论写直达还是写回、都未解决多线程或者多CPU缓存一致性问题….</p>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理图谱</title>
    <url>/2020/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E5%9B%BE%E8%B0%B1/</url>
    <content><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/14027542-52ce3b562ec64e0e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">存储程序计算机</span><span class="punctuation">:</span> <span class="string">可存储程序、可编程</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">1. 不可编程</span><span class="punctuation">:</span> <span class="string"> eg. 早期的计算器、只能进行简单算术运算、功能不可被修改</span></span><br><span class="line"><span class="attribute">2. 不可存储</span><span class="punctuation">:</span> <span class="string">eg. 早期的插线板式计算机、每次写好的程序不能存储下来供下次使用、需要相同程序的时候、也必须重新插板子、重新编程</span></span><br></pre></td></tr></table></figure>

<p>计算机组成<br><img src="https://upload-images.jianshu.io/upload_images/14027542-6f11ef9e0c7d519e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>所有的计算机程序、都可以抽象为从<code>输入设备</code>读取输入程序，通过<code>运算器</code>和<code>控制器</code>来执行存储在<code>存储器</code>里的程序、最终把结果输出到<code>输出设备</code>中<br><img src="https://upload-images.jianshu.io/upload_images/14027542-e4bfce4bf7b31e33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片来源: 极课时间.png"></p>
]]></content>
      <categories>
        <category>计算机原理</category>
      </categories>
      <tags>
        <tag>计算机原理</tag>
      </tags>
  </entry>
</search>
